{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=4000, help=\"rounds of training\")\n",
    "    \n",
    "    #嵌入向量的训练轮次\n",
    "    parser.add_argument('--emb_train_epochs', type=int, default=3, help=\"rounds of training\")\n",
    "    parser.add_argument('--emb', default=True)\n",
    "    \n",
    "    #验证RL和Fedavg哪个更好的验证轮次\n",
    "    parser.add_argument('--validation_epochs', type=int, default=50, help=\"rounds of training\")\n",
    "    \n",
    "    #有多少个local client\n",
    "    parser.add_argument('--num_users', type=int, default=100, help=\"number of users: K\")\n",
    "    \n",
    "    #每次选多少个local client参与训练\n",
    "    parser.add_argument('--frac', type=float, default=0.1, help=\"the fraction of clients: C\")\n",
    "    \n",
    "    #local client自己本地训练的轮次\n",
    "    parser.add_argument('--local_emb_ep', type=int, default=1, help=\"the number of local epochs: E\")\n",
    "    parser.add_argument('--local_ep', type=int, default=10, help=\"the number of local epochs: E\")\n",
    "    parser.add_argument('--local_chosen_ep', type=int, default=1, help=\"the number of local epochs: E\")\n",
    "    \n",
    "    #local client本地训练的batchsize\n",
    "    parser.add_argument('--local_bs', type=int, default=10, help=\"local batch size: B\")\n",
    "    parser.add_argument('--bs', type=int, default=128, help=\"test batch size\")\n",
    "    \n",
    "    #RL的学习率和衰减率\n",
    "    parser.add_argument('--lr', type=float, default=0.01, help=\"learning rate (default: 0.01)\")\n",
    "    parser.add_argument('--lr_decay', type=float, default=1, help=\"lr decay\")\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
    "    parser.add_argument('--split', type=str, default='user', help=\"train-test split type, user or sample\")\n",
    "\n",
    "    # model arguments\n",
    "    \n",
    "    #使用的client 模型\n",
    "    parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "    parser.add_argument('--kernel_num', type=int, default=9, help='number of each kind of kernel')\n",
    "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                        help='comma-separated kernel size to use for convolution')\n",
    "    parser.add_argument('--norm', type=str, default='batch_norm', help=\"batch_norm, layer_norm, or None\")\n",
    "    parser.add_argument('--num_filters', type=int, default=32, help=\"number of filters for conv nets\")\n",
    "    parser.add_argument('--max_pool', type=str, default='True',\n",
    "                        help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    \n",
    "    #使用的数据集\n",
    "    parser.add_argument('--dataset', type=str, default='mnist', help=\"name of dataset\")\n",
    "    \n",
    "    #数据集的划分是否满足独立同分布\n",
    "    parser.add_argument('--iid', action='store_true', help='whether i.i.d or not')\n",
    "    \n",
    "    #输出的分类个数\n",
    "    parser.add_argument('--num_classes', type=int, default=10, help=\"number of classes\")\n",
    "    \n",
    "    #输入的图片的通道数\n",
    "    parser.add_argument('--num_channels', type=int, default=1, help=\"number of channels of imges\")\n",
    "    parser.add_argument('--gpu', type=int, default=-1, help=\"GPU ID, -1 for CPU\")\n",
    "    parser.add_argument('--stopping_rounds', type=int, default=10, help='rounds of early stopping')\n",
    "    parser.add_argument('--verbose', action='store_true', help='verbose print')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
    "    parser.add_argument('--all_clients', action='store_true', help='aggregation over all clients')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CNNMnistEmbReverse' from 'models.Nets' (/home/chenweilong/federated-learning/models/Nets.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9c96c256447a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist_iid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_noniid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcifar_iid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOriginalUpdate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocalUpdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNNMnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNNCifar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNNMnistEmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNNMnistEmbReverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFedAvg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CNNMnistEmbReverse' from 'models.Nets' (/home/chenweilong/federated-learning/models/Nets.py)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from itertools import count\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from collections import deque\n",
    "  \n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from models.OriginalUpdate import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar, CNNMnistEmb, CNNMnistEmbReverse\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n",
    "\n",
    "# parse args\n",
    "args = args_parser()\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and split users\n",
    "if args.dataset == 'mnist':\n",
    "    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.repeat(1,1,1))])\n",
    "    dataset_train = datasets.MNIST('./data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "    dataset_test = datasets.MNIST('./data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "    # sample users\n",
    "    args.iid = False\n",
    "    if args.iid:\n",
    "        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "elif args.dataset == 'cifar':\n",
    "    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset_train = datasets.CIFAR10('./data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "    dataset_test = datasets.CIFAR10('./data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "    args.iid = True\n",
    "    if args.iid:\n",
    "        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        exit('Error: only consider IID setting in CIFAR10')\n",
    "else:\n",
    "    exit('Error: unrecognized dataset')\n",
    "img_size = dataset_train[0][0].shape\n",
    "\n",
    "# build model\n",
    "if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "    net_glob = CNNCifar(args=args).to(args.device)\n",
    "elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "    net_glob = CNNMnist(args=args).to(args.device)\n",
    "elif args.model == 'mlp':\n",
    "    len_in = 1\n",
    "    for x in img_size:\n",
    "        len_in *= x\n",
    "    net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "print(net_glob)\n",
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBuffer: # MemoryBuffer类实现的功能：buffer内采样，往buffer里塞（sars）\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.buffer = deque(maxlen=size) #buffer设置为双端队列\n",
    "        self.maxSize = size\n",
    "        self.len = 0\n",
    "        \n",
    "    def state_reco(self, s):\n",
    "        s_1 = [i[0] for i in s]\n",
    "        s_2 = [i[1] for i in s]\n",
    "        s_3 = [i[2] for i in s]\n",
    "        return [torch.cat(s_1),torch.cat(s_2),torch.cat(s_3)]\n",
    "\n",
    "    def sample(self, count):\n",
    "        \"\"\"\n",
    "        samples a random batch from the replay memory buffer\n",
    "        :param count: batch size\n",
    "        :return: batch (numpy array)\n",
    "        \"\"\"\n",
    "        batch = []\n",
    "        count = min(count, self.len)\n",
    "        batch = random.sample(self.buffer, count) # 随机取样\n",
    "\n",
    "        s_arr = [arr[0] for arr in batch]\n",
    "        a_arr = torch.cat([arr[1] for arr in batch])\n",
    "        r_arr = torch.tensor([arr[2] for arr in batch]).reshape(-1,1)\n",
    "        s1_arr = [arr[3] for arr in batch]\n",
    "\n",
    "        return self.state_reco(s_arr), a_arr, r_arr, self.state_reco(s1_arr)\n",
    "\n",
    "    def len(self):\n",
    "        return self.len\n",
    "\n",
    "    def add(self, s, a, r, s1):\n",
    "        \"\"\"\n",
    "        adds a particular transaction in the memory buffer\n",
    "        :param s: current state\n",
    "        :param a: action taken\n",
    "        :param r: reward received\n",
    "        :param s1: next state\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        transition = (s,a,r,s1)\n",
    "        self.len += 1\n",
    "        if self.len > self.maxSize:\n",
    "            self.len = self.maxSize\n",
    "        self.buffer.append(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "parameter_dim = 100\n",
    "action_dim = 10\n",
    "loss_dim = 10\n",
    "print(parameter_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim, args, min_log_std=-20, max_log_std=2):\n",
    "        super(Actor, self).__init__()\n",
    "        self.args = args\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(parameter_dim, action_dim)\n",
    "        self.fc2 = nn.Linear(action_dim*(int(args.num_users*args.frac+2)), 256)\n",
    "\n",
    "        self.mu_head = nn.Linear(256, 1)\n",
    "        self.log_std_head = nn.Linear(256, 1)\n",
    "\n",
    "        self.min_log_std = min_log_std\n",
    "        self.max_log_std = max_log_std\n",
    "        \n",
    "    def forward(self, parameters, last_loss, last_weight):\n",
    "        parameter_lst = []\n",
    "        for i in range(self.action_dim):\n",
    "            parameter_lst.append(self.fc1(parameters[:,i,:]))\n",
    "        parameter_layer = torch.cat(parameter_lst,dim=1)\n",
    "        x = torch.cat([parameter_layer,last_loss, last_weight],dim=1)\n",
    "        x = F.relu(self.fc2(x)) # 256\n",
    "        mu = self.mu_head(x)\n",
    "        log_std_head = F.relu(self.log_std_head(x))\n",
    "        log_std_head = torch.clamp(log_std_head, self.min_log_std, self.max_log_std)\n",
    "        return mu, log_std_head\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim, args):\n",
    "        super(Critic, self).__init__()\n",
    "        self.args = args\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(parameter_dim, action_dim)\n",
    "        self.fc2 = nn.Linear(action_dim*(int(args.num_users*args.frac+2)), 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, parameters, last_loss, last_weight):\n",
    "        parameter_lst = []\n",
    "        for i in range(self.action_dim):\n",
    "            parameter_lst.append(self.fc1(parameters[:,i,:]))\n",
    "        parameter_layer = torch.cat(parameter_lst,dim=1)\n",
    "        x = torch.cat([parameter_layer,last_loss, last_weight],dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Q(nn.Module):\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim, args):\n",
    "        super(Q, self).__init__()\n",
    "        self.args = args\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(parameter_dim,action_dim)\n",
    "\n",
    "        self.fc2 = nn.Linear(action_dim*(int(args.num_users*args.frac+3)), 1)\n",
    "\n",
    "    def forward(self, parameters, last_loss, last_weight, action):\n",
    "        parameter_lst = []\n",
    "        for i in range(self.action_dim):\n",
    "            parameter_lst.append(self.fc1(parameters[:,i,:]))\n",
    "        parameter_layer = torch.cat(parameter_lst,dim=1)\n",
    "        x = torch.cat([parameter_layer, last_loss, last_weight, action], dim=1)\n",
    "        q = self.fc2(x)\n",
    "\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA=0.95\n",
    "TRAINING_EPOCH = 10\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim, replay_buffer, args):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.iter = 0\n",
    "        self.loss_critic_save = []\n",
    "        self.loss_actor_save = []\n",
    "        self.loss_Q_save = []\n",
    "        \n",
    "        # 4个网络，其中三个要更新，critic_target用critic进行软更新\n",
    "        self.policy_net = Actor(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim, args).to(args.device)\n",
    "        self.value_net = Critic(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim, args).to(args.device)\n",
    "        self.Q_net = Q(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim, args).to(args.device)\n",
    "        self.Target_value_net = Critic(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim, args).to(args.device)\n",
    "\n",
    "        self.policy_optimizer = optim.Adam(self.policy_net.parameters(), lr=0.001)\n",
    "        self.value_optimizer = optim.Adam(self.value_net.parameters(), lr=0.001)\n",
    "        self.Q_optimizer = optim.Adam(self.Q_net.parameters(), lr=0.001)\n",
    "        self.num_training = 1\n",
    "        \n",
    "        self.value_criterion = nn.MSELoss()\n",
    "        self.Q_criterion = nn.MSELoss()\n",
    "\n",
    "        self.hard_update(self.Target_value_net, self.value_net)\n",
    "\n",
    "    def soft_update(self, target, source, tau):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - tau) + param.data * tau\n",
    "            )\n",
    "    def hard_update(self, target, source):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "                target_param.data.copy_(param.data)\n",
    "                \n",
    "    def select_action(self, parameters, last_loss, last_weight):\n",
    "        mu, log_sigma = self.policy_net(parameters, last_loss, last_weight)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        dist = Normal(mu, sigma)\n",
    "        \n",
    "        l = []\n",
    "        for i in range(10):\n",
    "            z = dist.sample()\n",
    "            l.append(torch.tanh(z).detach().cpu().numpy())\n",
    "        l = torch.tensor(l).squeeze(1).squeeze(1)\n",
    "        v = F.softmax(l, dim=0)\n",
    "        return v # return a tensor\n",
    "\n",
    "    def get_action_log_prob(self, parameters, last_loss, last_weight):\n",
    "        min_Val = torch.tensor(1e-7).float()\n",
    "        \n",
    "        batch_mu, batch_log_sigma = self.policy_net(parameters, last_loss, last_weight)\n",
    "        batch_sigma = torch.exp(batch_log_sigma)\n",
    "        dist = Normal(batch_mu, batch_sigma) # batch_size, batch_size\n",
    "        \n",
    "        l = []\n",
    "\n",
    "        for i in range(self.action_dim):\n",
    "            z = dist.sample()\n",
    "            action = torch.tanh(z)\n",
    "            l.append(action.detach().cpu().tolist())\n",
    "            if i == 0:\n",
    "                z_ = z\n",
    "            else:\n",
    "                z_ = torch.cat([z_, z], dim = 1)\n",
    "\n",
    "        #batch_size * action_dim\n",
    "        for i in range(BATCH_SIZE):\n",
    "            tmp = []\n",
    "            for j in range(self.action_dim):\n",
    "                tmp.append(l[j][i])\n",
    "            v = F.softmax(torch.tensor(tmp).squeeze(1),dim=0)\n",
    "            if i == 0:\n",
    "                action = v.unsqueeze(0)\n",
    "            else:\n",
    "                action = torch.cat([action, v.unsqueeze(0)], dim=0)\n",
    "\n",
    "        tmp = dist.log_prob(z_) - torch.log(1 - action.pow(2) + torch.tensor(0.5))\n",
    "        log_prob = torch.mean(tmp, dim=1)\n",
    "        \n",
    "#         z = dist.sample()\n",
    "#         action = torch.tanh(z)\n",
    "#         log_prob = dist.log_prob(z) - torch.log(1 - action.pow(2) + min_Val)\n",
    "        \n",
    "        return action, log_prob, z_, batch_mu, batch_log_sigma\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Samples a random batch from replay memory and performs optimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for i in range(TRAINING_EPOCH):\n",
    "            s1,a1,r1,s2 = self.replay_buffer.sample(BATCH_SIZE)\n",
    "            \n",
    "            r1 = Variable(r1.float(), requires_grad=True)\n",
    "            \n",
    "            # targte_V\n",
    "            target_value = torch.squeeze(self.Target_value_net.forward(s2[0],s2[1],s2[2]))\n",
    "            # Q = r + gamma*V 无偏估计（大概是）\n",
    "            next_q_value = torch.squeeze(r1) + GAMMA * target_value\n",
    "            \n",
    "            # 通过网络再出一个Q和V\n",
    "            expected_value = torch.squeeze(self.value_net.forward(s1[0], s1[1], s1[2]))\n",
    "            expected_Q = torch.squeeze(self.Q_net.forward(s1[0], s1[1], s1[2], a1))\n",
    "            \n",
    "            # !!!Note that the actions are sampled according to the current policy,\n",
    "            # instead of replay buffer. (From original paper)\n",
    "            # 再出一个soft Q\n",
    "            sample_action, log_prob, z, batch_mu, batch_log_sigma = self.get_action_log_prob(s1[0], s1[1], s1[2])\n",
    "            expected_new_Q = torch.squeeze(self.Q_net.forward(s1[0], s1[1], s1[2], sample_action))\n",
    "            next_value = expected_new_Q - log_prob\n",
    "\n",
    "            #critic更新\n",
    "            V_loss = self.value_criterion(expected_value, next_value.detach())  # J_V\n",
    "            V_loss = V_loss.mean()\n",
    "\n",
    "            \n",
    "            # Single Q_net this is different from original paper!!!\n",
    "            # 单独的Q网络更新\n",
    "            Q_loss = self.Q_criterion(expected_Q, next_q_value.detach()) # J_Q\n",
    "            Q_loss = Q_loss.mean()\n",
    "\n",
    "            log_policy_target = expected_new_Q - expected_value\n",
    "            \n",
    "            \n",
    "            #actor更新\n",
    "            pi_loss = log_prob * (log_prob- log_policy_target).detach()\n",
    "            pi_loss = pi_loss.mean()\n",
    "\n",
    "            \n",
    "            self.loss_actor_save.append(pi_loss)\n",
    "            self.loss_Q_save.append(Q_loss)\n",
    "            self.loss_critic_save.append(V_loss)\n",
    "            \n",
    "        \n",
    "            # mini batch gradient descent\n",
    "            self.value_optimizer.zero_grad()\n",
    "            V_loss.backward(retain_graph=True)\n",
    "            nn.utils.clip_grad_norm_(self.value_net.parameters(), 0.5)\n",
    "            self.value_optimizer.step()\n",
    "\n",
    "\n",
    "            self.Q_optimizer.zero_grad()\n",
    "            Q_loss.backward(retain_graph = True)\n",
    "            nn.utils.clip_grad_norm_(self.Q_net.parameters(), 0.5)\n",
    "            self.Q_optimizer.step()\n",
    "\n",
    "            self.policy_optimizer.zero_grad()\n",
    "            pi_loss.backward(retain_graph = True)\n",
    "            nn.utils.clip_grad_norm_(self.policy_net.parameters(), 0.5)\n",
    "            self.policy_optimizer.step()\n",
    "\n",
    "            # soft update\n",
    "            self.soft_update(self.Target_value_net, self.value_net, 0.001)\n",
    "\n",
    "            self.num_training += 1\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.policy_net.state_dict(), './SAC_model/policy_net.pth')\n",
    "        torch.save(self.value_net.state_dict(), './SAC_model/value_net.pth')\n",
    "        torch.save(self.Q_net.state_dict(), './SAC_model/Q_net.pth')\n",
    "        print(\"====================================\")\n",
    "        print(\"Model has been saved...\")\n",
    "        print(\"====================================\")\n",
    "\n",
    "    def load(self):\n",
    "        torch.load(self.policy_net.state_dict(), './SAC_model/policy_net.pth')\n",
    "        torch.load(self.value_net.state_dict(), './SAC_model/value_net.pth')\n",
    "        torch.load(self.Q_net.state_dict(), './SAC_model/Q_net.pth')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = MemoryBuffer(500)\n",
    "trainer = Trainer(parameter_dim, loss_dim, action_dim, replay_buffer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedPareto(w,action):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(0, len(w)):\n",
    "            if i==0:\n",
    "                w_avg[k] = action[i] * w[i][k]\n",
    "            else:\n",
    "                w_avg[k] += action[i] * w[i][k]\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss_avg:0.12777595221996307\n",
      "epoch:0, loss_avg:0.9532831311225891\n",
      "epoch:0, loss_avg:0.38733646273612976\n",
      "epoch:0, loss_avg:0.12426401674747467\n",
      "epoch:0, loss_avg:0.18679066002368927\n",
      "epoch:0, loss_avg:0.10355566442012787\n",
      "epoch:0, loss_avg:0.08942805230617523\n",
      "epoch:0, loss_avg:0.06175100803375244\n",
      "epoch:0, loss_avg:0.0612008273601532\n",
      "epoch:0, loss_avg:0.6701407432556152\n",
      "epoch:0, loss_avg:0.09483181685209274\n",
      "epoch:0, loss_avg:0.046690575778484344\n",
      "epoch:0, loss_avg:0.0795353576540947\n",
      "epoch:0, loss_avg:0.06891675293445587\n",
      "epoch:0, loss_avg:0.052060775458812714\n",
      "epoch:0, loss_avg:0.0447671115398407\n",
      "epoch:0, loss_avg:0.03965960443019867\n",
      "epoch:0, loss_avg:0.03667260706424713\n",
      "epoch:0, loss_avg:0.058620281517505646\n",
      "epoch:0, loss_avg:0.025368954986333847\n",
      "epoch:0, loss_avg:0.06917595863342285\n",
      "epoch:0, loss_avg:0.057083845138549805\n",
      "epoch:0, loss_avg:0.04337466135621071\n",
      "epoch:0, loss_avg:0.1011178269982338\n",
      "epoch:0, loss_avg:0.05300408601760864\n",
      "epoch:0, loss_avg:0.07704634964466095\n",
      "epoch:0, loss_avg:0.030731577426195145\n",
      "epoch:0, loss_avg:0.04122195392847061\n",
      "epoch:0, loss_avg:0.06020989641547203\n",
      "epoch:0, loss_avg:0.020703041926026344\n",
      "epoch:0, loss_avg:0.046897683292627335\n",
      "epoch:0, loss_avg:0.030802320688962936\n",
      "epoch:0, loss_avg:0.05134541541337967\n",
      "epoch:0, loss_avg:0.04786330461502075\n",
      "epoch:0, loss_avg:0.03728565573692322\n",
      "epoch:0, loss_avg:0.04885432496666908\n",
      "epoch:0, loss_avg:0.04295480251312256\n",
      "epoch:0, loss_avg:0.03931526094675064\n",
      "epoch:0, loss_avg:0.04063591733574867\n",
      "epoch:0, loss_avg:0.030209090560674667\n",
      "epoch:0, loss_avg:0.040089692920446396\n",
      "epoch:0, loss_avg:0.049355845898389816\n",
      "epoch:0, loss_avg:0.035398319363594055\n",
      "epoch:0, loss_avg:0.03706878796219826\n",
      "epoch:0, loss_avg:0.04566363990306854\n",
      "epoch:0, loss_avg:0.055432695895433426\n",
      "epoch:0, loss_avg:0.03832714259624481\n",
      "epoch:0, loss_avg:0.04005460813641548\n",
      "epoch:0, loss_avg:0.030167043209075928\n",
      "epoch:0, loss_avg:0.04237707331776619\n",
      "epoch:0, loss_avg:0.02754463627934456\n",
      "epoch:0, loss_avg:0.049403805285692215\n",
      "epoch:0, loss_avg:0.0461210273206234\n",
      "epoch:0, loss_avg:0.0480838380753994\n",
      "epoch:0, loss_avg:0.03753836452960968\n",
      "epoch:0, loss_avg:0.06073998287320137\n",
      "epoch:0, loss_avg:0.04818373918533325\n",
      "epoch:0, loss_avg:0.057913314551115036\n",
      "epoch:0, loss_avg:0.025217939168214798\n",
      "epoch:0, loss_avg:0.06514281779527664\n",
      "epoch:0, loss_avg:0.040460098534822464\n",
      "epoch:0, loss_avg:0.06572802364826202\n",
      "epoch:0, loss_avg:0.05480622500181198\n",
      "epoch:0, loss_avg:0.054090939462184906\n",
      "epoch:0, loss_avg:0.04626525193452835\n",
      "epoch:0, loss_avg:0.05403590947389603\n",
      "epoch:0, loss_avg:0.04922998696565628\n",
      "epoch:0, loss_avg:0.036242902278900146\n",
      "epoch:0, loss_avg:0.03839815780520439\n",
      "epoch:0, loss_avg:0.04803614318370819\n",
      "epoch:0, loss_avg:0.0462912879884243\n",
      "epoch:0, loss_avg:0.043146077543497086\n",
      "epoch:0, loss_avg:0.04839246720075607\n",
      "epoch:0, loss_avg:0.029351549223065376\n",
      "epoch:0, loss_avg:0.05601667985320091\n",
      "epoch:0, loss_avg:0.041639238595962524\n",
      "epoch:0, loss_avg:0.04086130112409592\n",
      "epoch:0, loss_avg:0.06699717789888382\n",
      "epoch:0, loss_avg:0.04710773751139641\n",
      "epoch:0, loss_avg:0.05940980091691017\n",
      "epoch:0, loss_avg:0.03725069761276245\n",
      "epoch:0, loss_avg:0.047033559530973434\n",
      "epoch:0, loss_avg:0.03795407712459564\n",
      "epoch:0, loss_avg:0.05826420336961746\n",
      "epoch:0, loss_avg:0.07379240542650223\n",
      "epoch:0, loss_avg:0.044012024998664856\n",
      "epoch:0, loss_avg:0.042868901044130325\n",
      "epoch:0, loss_avg:0.05378609150648117\n",
      "epoch:0, loss_avg:0.05408122390508652\n",
      "epoch:0, loss_avg:0.040975362062454224\n",
      "epoch:0, loss_avg:0.03786982595920563\n",
      "epoch:0, loss_avg:0.04932228475809097\n",
      "epoch:0, loss_avg:0.05390549078583717\n",
      "epoch:0, loss_avg:0.043173953890800476\n",
      "epoch:0, loss_avg:0.04148225486278534\n",
      "epoch:0, loss_avg:0.03625497594475746\n",
      "epoch:0, loss_avg:0.03997848555445671\n",
      "epoch:0, loss_avg:0.036859702318906784\n",
      "epoch:0, loss_avg:0.04035026580095291\n",
      "epoch:0, loss_avg:0.06288919597864151\n",
      "epoch:1, loss_avg:0.05268462747335434\n",
      "epoch:1, loss_avg:0.04278570041060448\n",
      "epoch:1, loss_avg:0.04609386622905731\n",
      "epoch:1, loss_avg:0.05112282186746597\n",
      "epoch:1, loss_avg:0.038748305290937424\n",
      "epoch:1, loss_avg:0.032880913466215134\n",
      "epoch:1, loss_avg:0.04229886457324028\n",
      "epoch:1, loss_avg:0.04090788587927818\n",
      "epoch:1, loss_avg:0.04699523374438286\n",
      "epoch:1, loss_avg:0.04542038217186928\n",
      "epoch:1, loss_avg:0.03283614292740822\n",
      "epoch:1, loss_avg:0.045790236443281174\n",
      "epoch:1, loss_avg:0.05187452584505081\n",
      "epoch:1, loss_avg:0.039234332740306854\n",
      "epoch:1, loss_avg:0.05199673771858215\n",
      "epoch:1, loss_avg:0.029007362201809883\n",
      "epoch:1, loss_avg:0.062344737350940704\n",
      "epoch:1, loss_avg:0.04562491178512573\n",
      "epoch:1, loss_avg:0.04204685986042023\n",
      "epoch:1, loss_avg:0.05799258500337601\n",
      "epoch:1, loss_avg:0.06139088049530983\n",
      "epoch:1, loss_avg:0.04049285501241684\n",
      "epoch:1, loss_avg:0.02968391217291355\n",
      "epoch:1, loss_avg:0.05127734690904617\n",
      "epoch:1, loss_avg:0.04954995959997177\n",
      "epoch:1, loss_avg:0.03602370247244835\n",
      "epoch:1, loss_avg:0.038547202944755554\n",
      "epoch:1, loss_avg:0.05297273397445679\n",
      "epoch:1, loss_avg:0.04108666628599167\n",
      "epoch:1, loss_avg:0.03468719497323036\n",
      "epoch:1, loss_avg:0.032030001282691956\n",
      "epoch:1, loss_avg:0.029709141701459885\n",
      "epoch:1, loss_avg:0.034724924713373184\n",
      "epoch:1, loss_avg:0.030430037528276443\n",
      "epoch:1, loss_avg:0.06136215850710869\n",
      "epoch:1, loss_avg:0.050442203879356384\n",
      "epoch:1, loss_avg:0.04891336336731911\n",
      "epoch:1, loss_avg:0.043765388429164886\n",
      "epoch:1, loss_avg:0.03997664898633957\n",
      "epoch:1, loss_avg:0.037880901247262955\n",
      "epoch:1, loss_avg:0.048632074147462845\n",
      "epoch:1, loss_avg:0.043805062770843506\n",
      "epoch:1, loss_avg:0.04961682856082916\n",
      "epoch:1, loss_avg:0.03531012684106827\n",
      "epoch:1, loss_avg:0.03358243778347969\n",
      "epoch:1, loss_avg:0.0484287291765213\n",
      "epoch:1, loss_avg:0.056300804018974304\n",
      "epoch:1, loss_avg:0.04871822148561478\n",
      "epoch:1, loss_avg:0.040828533470630646\n",
      "epoch:1, loss_avg:0.07199588418006897\n",
      "epoch:1, loss_avg:0.042958855628967285\n",
      "epoch:1, loss_avg:0.06548642367124557\n",
      "epoch:1, loss_avg:0.052801769226789474\n",
      "epoch:1, loss_avg:0.05738893151283264\n",
      "epoch:1, loss_avg:0.03590826690196991\n",
      "epoch:1, loss_avg:0.03868824988603592\n",
      "epoch:1, loss_avg:0.04010136052966118\n",
      "epoch:1, loss_avg:0.033998724073171616\n",
      "epoch:1, loss_avg:0.04466062784194946\n",
      "epoch:1, loss_avg:0.03844321891665459\n",
      "epoch:1, loss_avg:0.03795565664768219\n",
      "epoch:1, loss_avg:0.05206018313765526\n",
      "epoch:1, loss_avg:0.05257111042737961\n",
      "epoch:1, loss_avg:0.0529811754822731\n",
      "epoch:1, loss_avg:0.043824464082717896\n",
      "epoch:1, loss_avg:0.04402637481689453\n",
      "epoch:1, loss_avg:0.04772030562162399\n",
      "epoch:1, loss_avg:0.04450031369924545\n",
      "epoch:1, loss_avg:0.04613811895251274\n",
      "epoch:1, loss_avg:0.034187570214271545\n",
      "epoch:1, loss_avg:0.06301631033420563\n",
      "epoch:1, loss_avg:0.031196340918540955\n",
      "epoch:1, loss_avg:0.04869145154953003\n",
      "epoch:1, loss_avg:0.038886211812496185\n",
      "epoch:1, loss_avg:0.044762350618839264\n",
      "epoch:1, loss_avg:0.03909068927168846\n",
      "epoch:1, loss_avg:0.06027241051197052\n",
      "epoch:1, loss_avg:0.04557288438081741\n",
      "epoch:1, loss_avg:0.04466696083545685\n",
      "epoch:1, loss_avg:0.03222353756427765\n",
      "epoch:1, loss_avg:0.03886137157678604\n",
      "epoch:1, loss_avg:0.06884005665779114\n",
      "epoch:1, loss_avg:0.034509457647800446\n",
      "epoch:1, loss_avg:0.0508146733045578\n",
      "epoch:1, loss_avg:0.03496437519788742\n",
      "epoch:1, loss_avg:0.04897741228342056\n",
      "epoch:1, loss_avg:0.037387799471616745\n",
      "epoch:1, loss_avg:0.053570475429296494\n",
      "epoch:1, loss_avg:0.03548923507332802\n",
      "epoch:1, loss_avg:0.04494163393974304\n",
      "epoch:1, loss_avg:0.04270035773515701\n",
      "epoch:1, loss_avg:0.030629005283117294\n",
      "epoch:1, loss_avg:0.039355941116809845\n",
      "epoch:1, loss_avg:0.04162007197737694\n",
      "epoch:1, loss_avg:0.03335709124803543\n",
      "epoch:1, loss_avg:0.05029013007879257\n",
      "epoch:1, loss_avg:0.05387707054615021\n",
      "epoch:1, loss_avg:0.036897823214530945\n",
      "epoch:1, loss_avg:0.038448017090559006\n",
      "epoch:1, loss_avg:0.025359390303492546\n",
      "epoch:2, loss_avg:0.04527891427278519\n",
      "epoch:2, loss_avg:0.05353975668549538\n",
      "epoch:2, loss_avg:0.05468907207250595\n",
      "epoch:2, loss_avg:0.039413079619407654\n",
      "epoch:2, loss_avg:0.0305595975369215\n",
      "epoch:2, loss_avg:0.03894210234284401\n",
      "epoch:2, loss_avg:0.053004950284957886\n",
      "epoch:2, loss_avg:0.037503473460674286\n",
      "epoch:2, loss_avg:0.051828742027282715\n",
      "epoch:2, loss_avg:0.03300796449184418\n",
      "epoch:2, loss_avg:0.039933256804943085\n",
      "epoch:2, loss_avg:0.043864600360393524\n",
      "epoch:2, loss_avg:0.0372653491795063\n",
      "epoch:2, loss_avg:0.03510715812444687\n",
      "epoch:2, loss_avg:0.03683038055896759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2, loss_avg:0.030088230967521667\n",
      "epoch:2, loss_avg:0.038878753781318665\n",
      "epoch:2, loss_avg:0.05068834498524666\n",
      "epoch:2, loss_avg:0.04353484883904457\n",
      "epoch:2, loss_avg:0.03730561584234238\n",
      "epoch:2, loss_avg:0.027650218456983566\n",
      "epoch:2, loss_avg:0.0352642647922039\n",
      "epoch:2, loss_avg:0.06679044663906097\n",
      "epoch:2, loss_avg:0.023705624043941498\n",
      "epoch:2, loss_avg:0.05122097209095955\n",
      "epoch:2, loss_avg:0.04149039834737778\n",
      "epoch:2, loss_avg:0.0391165129840374\n",
      "epoch:2, loss_avg:0.05732688307762146\n",
      "epoch:2, loss_avg:0.034395813941955566\n",
      "epoch:2, loss_avg:0.03492524474859238\n",
      "epoch:2, loss_avg:0.038219153881073\n",
      "epoch:2, loss_avg:0.04522334039211273\n",
      "epoch:2, loss_avg:0.03225579485297203\n",
      "epoch:2, loss_avg:0.03065316379070282\n",
      "epoch:2, loss_avg:0.035244524478912354\n",
      "epoch:2, loss_avg:0.04133361950516701\n",
      "epoch:2, loss_avg:0.06185044348239899\n",
      "epoch:2, loss_avg:0.04943244904279709\n",
      "epoch:2, loss_avg:0.04237539693713188\n",
      "epoch:2, loss_avg:0.04936533421278\n",
      "epoch:2, loss_avg:0.0512583889067173\n",
      "epoch:2, loss_avg:0.053642772138118744\n",
      "epoch:2, loss_avg:0.039502810686826706\n",
      "epoch:2, loss_avg:0.06831111013889313\n",
      "epoch:2, loss_avg:0.04303571581840515\n",
      "epoch:2, loss_avg:0.03664342314004898\n",
      "epoch:2, loss_avg:0.06885497272014618\n",
      "epoch:2, loss_avg:0.02971719205379486\n",
      "epoch:2, loss_avg:0.04332559183239937\n",
      "epoch:2, loss_avg:0.04508109390735626\n",
      "epoch:2, loss_avg:0.042645569890737534\n",
      "epoch:2, loss_avg:0.04711234197020531\n",
      "epoch:2, loss_avg:0.03868100792169571\n",
      "epoch:2, loss_avg:0.037171442061662674\n",
      "epoch:2, loss_avg:0.03194430470466614\n",
      "epoch:2, loss_avg:0.035580363124608994\n",
      "epoch:2, loss_avg:0.040741365402936935\n",
      "epoch:2, loss_avg:0.03171470761299133\n",
      "epoch:2, loss_avg:0.04094374179840088\n",
      "epoch:2, loss_avg:0.05046463757753372\n",
      "epoch:2, loss_avg:0.04773814603686333\n",
      "epoch:2, loss_avg:0.056252576410770416\n",
      "epoch:2, loss_avg:0.053410403430461884\n",
      "epoch:2, loss_avg:0.041008368134498596\n",
      "epoch:2, loss_avg:0.04071999341249466\n",
      "epoch:2, loss_avg:0.05178488790988922\n",
      "epoch:2, loss_avg:0.04612397775053978\n",
      "epoch:2, loss_avg:0.054261159151792526\n",
      "epoch:2, loss_avg:0.041404839605093\n",
      "epoch:2, loss_avg:0.033558715134859085\n",
      "epoch:2, loss_avg:0.049964047968387604\n",
      "epoch:2, loss_avg:0.053603462874889374\n",
      "epoch:2, loss_avg:0.049077268689870834\n",
      "epoch:2, loss_avg:0.03385552763938904\n",
      "epoch:2, loss_avg:0.03770357370376587\n",
      "epoch:2, loss_avg:0.06947259604930878\n",
      "epoch:2, loss_avg:0.0533628910779953\n",
      "epoch:2, loss_avg:0.05935002863407135\n",
      "epoch:2, loss_avg:0.0348019041121006\n",
      "epoch:2, loss_avg:0.049929551780223846\n",
      "epoch:2, loss_avg:0.04105537012219429\n",
      "epoch:2, loss_avg:0.03933268040418625\n",
      "epoch:2, loss_avg:0.04469500854611397\n",
      "epoch:2, loss_avg:0.063267283141613\n",
      "epoch:2, loss_avg:0.04784213379025459\n",
      "epoch:2, loss_avg:0.0352400504052639\n",
      "epoch:2, loss_avg:0.03854404389858246\n",
      "epoch:2, loss_avg:0.05236832797527313\n",
      "epoch:2, loss_avg:0.057584404945373535\n",
      "epoch:2, loss_avg:0.04706667363643646\n",
      "epoch:2, loss_avg:0.057387545704841614\n",
      "epoch:2, loss_avg:0.04324638471007347\n",
      "epoch:2, loss_avg:0.047009021043777466\n",
      "epoch:2, loss_avg:0.036269549280405045\n",
      "epoch:2, loss_avg:0.05443306639790535\n",
      "epoch:2, loss_avg:0.04164914786815643\n",
      "epoch:2, loss_avg:0.060424767434597015\n",
      "epoch:2, loss_avg:0.04028579592704773\n",
      "epoch:2, loss_avg:0.03373013436794281\n",
      "epoch:2, loss_avg:0.047626856714487076\n"
     ]
    }
   ],
   "source": [
    "layer_dict = {}\n",
    "layer_name = []\n",
    "count = 0\n",
    "for name in w_glob.keys():\n",
    "    if count % 2 == 0:\n",
    "        layer_name.append(name.split('.',1)[0])\n",
    "    count += 1\n",
    "    \n",
    "for i in layer_name:\n",
    "#     layer_dict[i] = CNNCifarEmb(torch.cat([w_glob[i+'.weight'].reshape(1,-1), w_glob[i+'.bias'].reshape(1,-1)], 1).numel())\n",
    "    layer_dict[i] = CNNMnistEmb(torch.cat([w_glob[i+'.weight'].reshape(1,-1), w_glob[i+'.bias'].reshape(1,-1)], 1).numel())\n",
    "    \n",
    "# emb_reverse = CNNCifarEmbReverse(args)\n",
    "emb_reverse = CNNMnistEmbReverse(args)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':layer_dict[layer_name[0]].parameters()},\n",
    "    {'params':layer_dict[layer_name[1]].parameters()},\n",
    "    {'params':layer_dict[layer_name[2]].parameters()},\n",
    "    {'params':layer_dict[layer_name[3]].parameters()},\n",
    "#     {'params':layer_dict[layer_name[4]].parameters()},\n",
    "    {'params':emb_reverse.parameters()}\n",
    "] ,0.01)\n",
    "\n",
    "for iter in range(args.emb_train_epochs):\n",
    "    idxs_users = np.random.choice(range(args.num_users), 100, replace=False)\n",
    "    \n",
    "    for idx in idxs_users:\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "            \n",
    "        for i in layer_name:\n",
    "            if i == 'conv1':\n",
    "                emb_feature = layer_dict[i].forward(torch.cat([w[i+'.weight'].reshape(1,-1), w[i+'.bias'].reshape(1,-1)], 1).to(args.device))\n",
    "            else:\n",
    "                emb_feature += layer_dict[i].forward(torch.cat([w[i+'.weight'].reshape(1,-1), w[i+'.bias'].reshape(1,-1)], 1).to(args.device))\n",
    "        avg_emb_feature = emb_feature/4\n",
    "        transform_w = emb_reverse.forward(avg_emb_feature)\n",
    "        loss_w = [sum((w[i].reshape(1,-1) - transform_w[i].reshape(1,-1)) ** 2) for i in w_glob.keys()]\n",
    "        loss_avg = 0\n",
    "        loss_check_dict = {}\n",
    "        for i in range(len(loss_w)):\n",
    "            loss_avg += sum(loss_w[i])/len(loss_w[i])\n",
    "            loss_check_dict[len(loss_w[i])] = loss_w[i]\n",
    "        optimizer.zero_grad()\n",
    "        loss_avg.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print('epoch:{}, loss_avg:{}'.format(iter, loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0398, 0.2937, 0.0398, 0.2928, 0.0398, 0.0399, 0.0670, 0.0398, 0.1066,\n",
      "        0.0409])\n",
      "tensor(8.9200)\n",
      "tensor(8.9200)\n",
      "Round   0, reward -0.683\n",
      "tensor([0.0408, 0.0953, 0.0361, 0.0413, 0.1297, 0.0442, 0.2148, 0.0734, 0.0937,\n",
      "        0.2306])\n",
      "tensor(11.3500)\n",
      "tensor(10.2800)\n",
      "Round   1, reward -0.682\n",
      "tensor([0.1352, 0.0581, 0.0439, 0.0561, 0.0475, 0.0526, 0.0451, 0.2898, 0.1223,\n",
      "        0.1494])\n",
      "tensor(17.8200)\n",
      "tensor(25.8700)\n",
      "Round   2, reward -0.976\n",
      "tensor([0.0427, 0.1535, 0.0411, 0.2036, 0.0673, 0.0451, 0.0829, 0.1248, 0.1868,\n",
      "        0.0523])\n",
      "tensor(21.3600)\n",
      "tensor(17.4200)\n",
      "Round   3, reward -0.672\n",
      "tensor([0.0706, 0.1298, 0.0856, 0.0884, 0.0471, 0.0943, 0.0853, 0.0631, 0.1994,\n",
      "        0.1363])\n",
      "tensor(25.1600)\n",
      "tensor(31.2500)\n",
      "Round   4, reward -0.968\n",
      "tensor([0.1212, 0.1655, 0.0748, 0.1362, 0.1380, 0.0448, 0.1181, 0.1399, 0.0328,\n",
      "        0.0288])\n",
      "tensor(32.9100)\n",
      "tensor(35.4400)\n",
      "Round   5, reward -0.955\n",
      "tensor([0.1496, 0.0355, 0.1934, 0.0694, 0.1846, 0.0413, 0.1673, 0.0426, 0.0782,\n",
      "        0.0380])\n",
      "tensor(42.2200)\n",
      "tensor(37.9700)\n",
      "Round   6, reward -0.634\n",
      "tensor([0.0321, 0.1012, 0.0784, 0.1826, 0.1707, 0.0527, 0.0482, 0.1689, 0.1190,\n",
      "        0.0463])\n",
      "tensor(45.2700)\n",
      "tensor(49.0800)\n",
      "Round   7, reward -0.925\n",
      "tensor([0.1853, 0.0541, 0.0658, 0.0771, 0.1108, 0.1885, 0.1069, 0.0851, 0.0942,\n",
      "        0.0322])\n",
      "tensor(36.6400)\n",
      "tensor(50.6800)\n",
      "Round   8, reward -0.948\n",
      "tensor([0.0343, 0.0487, 0.0672, 0.0351, 0.2431, 0.0746, 0.1771, 0.0657, 0.0929,\n",
      "        0.1614])\n",
      "tensor(33.4100)\n",
      "tensor(53.0600)\n",
      "Round   9, reward -0.954\n",
      "tensor([0.0554, 0.1835, 0.1282, 0.0321, 0.0312, 0.1174, 0.0666, 0.0316, 0.1813,\n",
      "        0.1727])\n",
      "tensor(54.4400)\n",
      "tensor(57.0900)\n",
      "Round  10, reward -0.890\n",
      "tensor([0.1717, 0.0470, 0.0466, 0.0284, 0.1630, 0.1622, 0.1770, 0.0884, 0.0891,\n",
      "        0.0266])\n",
      "tensor(45.1600)\n",
      "tensor(47.0200)\n",
      "Round  11, reward -0.925\n",
      "tensor([0.0466, 0.1942, 0.0618, 0.0318, 0.0638, 0.1642, 0.1682, 0.0391, 0.0618,\n",
      "        0.1686])\n",
      "tensor(54.6600)\n",
      "tensor(59.8300)\n",
      "Round  12, reward -0.889\n",
      "tensor([0.0370, 0.0440, 0.0699, 0.0886, 0.2039, 0.1759, 0.1561, 0.1034, 0.0555,\n",
      "        0.0658])\n",
      "tensor(44.4100)\n",
      "tensor(54.8600)\n",
      "Round  13, reward -0.928\n",
      "tensor([0.1317, 0.0266, 0.1895, 0.1456, 0.1143, 0.1600, 0.0901, 0.0333, 0.0740,\n",
      "        0.0349])\n",
      "tensor(62.7000)\n",
      "tensor(61.0200)\n",
      "Round  14, reward -0.545\n",
      "tensor([0.0736, 0.1121, 0.1909, 0.1249, 0.0779, 0.0561, 0.0843, 0.0562, 0.1668,\n",
      "        0.0572])\n",
      "tensor(61.7700)\n",
      "tensor(57.3200)\n",
      "Round  15, reward -0.551\n",
      "tensor([0.0473, 0.1244, 0.0456, 0.0578, 0.0856, 0.0565, 0.0712, 0.1597, 0.0454,\n",
      "        0.3066])\n",
      "tensor(63.7000)\n",
      "tensor(68.2100)\n",
      "Round  16, reward -0.839\n",
      "tensor([0.0416, 0.0401, 0.1218, 0.0961, 0.1312, 0.1329, 0.1653, 0.0640, 0.0706,\n",
      "        0.1363])\n",
      "tensor(70.2900)\n",
      "tensor(71.0200)\n",
      "Round  17, reward -0.773\n",
      "tensor([0.0280, 0.1181, 0.1362, 0.1408, 0.0342, 0.1532, 0.1222, 0.0956, 0.0266,\n",
      "        0.1451])\n",
      "tensor(67.5800)\n",
      "tensor(66.3500)\n",
      "Round  18, reward -0.511\n",
      "tensor([0.1254, 0.0810, 0.0476, 0.0544, 0.0778, 0.1762, 0.0626, 0.1156, 0.1246,\n",
      "        0.1348])\n",
      "tensor(76.0800)\n",
      "tensor(73.5800)\n",
      "Round  19, reward -0.430\n",
      "tensor([0.0495, 0.0417, 0.1466, 0.1434, 0.0501, 0.0802, 0.2155, 0.0481, 0.1446,\n",
      "        0.0803])\n",
      "tensor(73.8700)\n",
      "tensor(73.5500)\n",
      "Round  20, reward -0.454\n",
      "tensor([0.1347, 0.0400, 0.0388, 0.1466, 0.0427, 0.1342, 0.1148, 0.1065, 0.0941,\n",
      "        0.1476])\n",
      "tensor(65.6500)\n",
      "tensor(75.1000)\n",
      "Round  21, reward -0.825\n",
      "tensor([0.0721, 0.0425, 0.1109, 0.0411, 0.1233, 0.1329, 0.0661, 0.2427, 0.0691,\n",
      "        0.0993])\n",
      "tensor(73.2500)\n",
      "tensor(75.1700)\n",
      "Round  22, reward -0.760\n",
      "tensor([0.0596, 0.0357, 0.2020, 0.0852, 0.1031, 0.1370, 0.0636, 0.0315, 0.1201,\n",
      "        0.1622])\n",
      "tensor(78.2300)\n",
      "tensor(73.3400)\n",
      "Round  23, reward -0.405\n",
      "tensor([0.1339, 0.1732, 0.0872, 0.0865, 0.0506, 0.1177, 0.0333, 0.0524, 0.2137,\n",
      "        0.0515])\n",
      "tensor(70.5900)\n",
      "tensor(70.9600)\n",
      "Round  24, reward -0.721\n",
      "tensor([0.0700, 0.0581, 0.2186, 0.1410, 0.0738, 0.1047, 0.0749, 0.0482, 0.0823,\n",
      "        0.1282])\n",
      "tensor(76.4600)\n",
      "tensor(78.8300)\n",
      "Round  25, reward -0.726\n",
      "tensor([0.0603, 0.0555, 0.0488, 0.0558, 0.0750, 0.1209, 0.1498, 0.1870, 0.0653,\n",
      "        0.1816])\n",
      "tensor(77.8400)\n",
      "tensor(81.1600)\n",
      "Round  26, reward -0.710\n",
      "tensor([0.0452, 0.0394, 0.0608, 0.0877, 0.1862, 0.0415, 0.0330, 0.2198, 0.0710,\n",
      "        0.2156])\n",
      "tensor(75.4400)\n",
      "tensor(78.2500)\n",
      "Round  27, reward -0.737\n",
      "tensor([0.0552, 0.0328, 0.0664, 0.0360, 0.2114, 0.0380, 0.1035, 0.2079, 0.1076,\n",
      "        0.1412])\n",
      "tensor(81.6100)\n",
      "tensor(84.8800)\n",
      "Round  28, reward -0.660\n",
      "tensor([0.1088, 0.0970, 0.0337, 0.2239, 0.1567, 0.0728, 0.1818, 0.0382, 0.0402,\n",
      "        0.0469])\n",
      "tensor(71.1800)\n",
      "tensor(74.5200)\n",
      "Round  29, reward -0.780\n",
      "tensor([0.1427, 0.0773, 0.0450, 0.2024, 0.0981, 0.0335, 0.1019, 0.1635, 0.0504,\n",
      "        0.0852])\n",
      "tensor(78.4400)\n",
      "tensor(77.9500)\n",
      "Round  30, reward -0.402\n",
      "tensor([0.1009, 0.0865, 0.1011, 0.0348, 0.0345, 0.1902, 0.1784, 0.0748, 0.0272,\n",
      "        0.1716])\n",
      "tensor(76.3300)\n",
      "tensor(82.4300)\n",
      "Round  31, reward -0.727\n",
      "tensor([0.0630, 0.0824, 0.0919, 0.0850, 0.0544, 0.0929, 0.1142, 0.0759, 0.0585,\n",
      "        0.2819])\n",
      "tensor(66.7900)\n",
      "tensor(81.4500)\n",
      "Round  32, reward -0.817\n",
      "tensor([0.1956, 0.0387, 0.0418, 0.2185, 0.0910, 0.1743, 0.0766, 0.0870, 0.0382,\n",
      "        0.0384])\n",
      "tensor(81.1600)\n",
      "tensor(78.4900)\n",
      "Round  33, reward -0.367\n",
      "tensor([0.0298, 0.0651, 0.0346, 0.2022, 0.1214, 0.0750, 0.1656, 0.0588, 0.0989,\n",
      "        0.1486])\n",
      "tensor(69.0800)\n",
      "tensor(69.1500)\n",
      "Round  34, reward -0.574\n",
      "tensor([0.1794, 0.0340, 0.0457, 0.0500, 0.2375, 0.0407, 0.0352, 0.0932, 0.1853,\n",
      "        0.0990])\n",
      "tensor(75.8300)\n",
      "tensor(79.7200)\n",
      "Round  35, reward -0.733\n",
      "tensor([0.0650, 0.0281, 0.1576, 0.1495, 0.1798, 0.1555, 0.0824, 0.0659, 0.0310,\n",
      "        0.0851])\n",
      "tensor(80.3400)\n",
      "tensor(83.8700)\n",
      "Round  36, reward -0.678\n",
      "tensor([0.1244, 0.0990, 0.0567, 0.0519, 0.1858, 0.1252, 0.0413, 0.0356, 0.1939,\n",
      "        0.0862])\n",
      "tensor(76.8600)\n",
      "tensor(77.4300)\n",
      "Round  37, reward -0.693\n",
      "tensor([0.1378, 0.0561, 0.1343, 0.1851, 0.1017, 0.0694, 0.0559, 0.0595, 0.0557,\n",
      "        0.1445])\n",
      "tensor(79.5600)\n",
      "tensor(79.4600)\n",
      "Round  38, reward -0.388\n",
      "tensor([0.1833, 0.0948, 0.0939, 0.0647, 0.0458, 0.1646, 0.1115, 0.0558, 0.0945,\n",
      "        0.0912])\n",
      "tensor(73.7000)\n",
      "tensor(77.2700)\n",
      "Round  39, reward -0.756\n",
      "tensor([0.0618, 0.0941, 0.1279, 0.0641, 0.1082, 0.0328, 0.0569, 0.1785, 0.1237,\n",
      "        0.1520])\n",
      "tensor(76.1900)\n",
      "tensor(75.5300)\n",
      "Round  40, reward -0.429\n",
      "tensor([0.0778, 0.1163, 0.0728, 0.0428, 0.0573, 0.0478, 0.1858, 0.2259, 0.0410,\n",
      "        0.1325])\n",
      "tensor(77.8400)\n",
      "tensor(82.4900)\n",
      "Round  41, reward -0.710\n",
      "tensor([0.0360, 0.0412, 0.0364, 0.1366, 0.0534, 0.0634, 0.1402, 0.0595, 0.2277,\n",
      "        0.2056])\n",
      "tensor(79.5200)\n",
      "tensor(80.9600)\n",
      "Round  42, reward -0.688\n",
      "tensor([0.0638, 0.0290, 0.1675, 0.0450, 0.1593, 0.1430, 0.0985, 0.0826, 0.0845,\n",
      "        0.1269])\n",
      "tensor(71.)\n",
      "tensor(72.6200)\n",
      "Round  43, reward -0.781\n",
      "tensor([0.1719, 0.0966, 0.0448, 0.0706, 0.1138, 0.1458, 0.1133, 0.0756, 0.1066,\n",
      "        0.0609])\n",
      "tensor(75.2100)\n",
      "tensor(79.0700)\n",
      "Round  44, reward -0.740\n",
      "tensor([0.1969, 0.0653, 0.1248, 0.0550, 0.0358, 0.1924, 0.0597, 0.0428, 0.0538,\n",
      "        0.1736])\n",
      "tensor(67.5900)\n",
      "tensor(76.9600)\n",
      "Round  45, reward -0.810\n",
      "tensor([0.0546, 0.0770, 0.0370, 0.0326, 0.1740, 0.0735, 0.1606, 0.1852, 0.1620,\n",
      "        0.0433])\n",
      "tensor(85.1400)\n",
      "tensor(84.1400)\n",
      "Round  46, reward -0.307\n",
      "tensor([0.0524, 0.1117, 0.1163, 0.1805, 0.0514, 0.1558, 0.0510, 0.0696, 0.1800,\n",
      "        0.0313])\n",
      "tensor(75.2300)\n",
      "tensor(78.6000)\n",
      "Round  47, reward -0.740\n",
      "tensor([0.0902, 0.0465, 0.0703, 0.0747, 0.1844, 0.2287, 0.0460, 0.0549, 0.0851,\n",
      "        0.1192])\n",
      "tensor(78.9100)\n",
      "tensor(81.9400)\n",
      "Round  48, reward -0.696\n",
      "tensor([0.2036, 0.0305, 0.0911, 0.1789, 0.0868, 0.0873, 0.1569, 0.0343, 0.0777,\n",
      "        0.0529])\n",
      "tensor(77.8500)\n",
      "tensor(81.4900)\n",
      "Round  49, reward -0.710\n",
      "tensor([0.0500, 0.1576, 0.0493, 0.0361, 0.2292, 0.0850, 0.1101, 0.0453, 0.0709,\n",
      "        0.1666])\n",
      "tensor(82.0400)\n",
      "tensor(82.7000)\n",
      "Round  50, reward -0.635\n",
      "tensor([0.1988, 0.0410, 0.0507, 0.0288, 0.0753, 0.0486, 0.0953, 0.1856, 0.1908,\n",
      "        0.0851])\n",
      "tensor(83.0500)\n",
      "tensor(82.2100)\n",
      "Round  51, reward -0.339\n",
      "tensor([0.1783, 0.1250, 0.1057, 0.1689, 0.1221, 0.0524, 0.0849, 0.0399, 0.0456,\n",
      "        0.0771])\n",
      "tensor(86.9400)\n",
      "tensor(87.1100)\n",
      "Round  52, reward -0.428\n",
      "tensor([0.1529, 0.1393, 0.0255, 0.1559, 0.0442, 0.1579, 0.0579, 0.0375, 0.1445,\n",
      "        0.0843])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(84.9300)\n",
      "tensor(88.1100)\n",
      "Round  53, reward -0.610\n",
      "tensor([0.1905, 0.0347, 0.1127, 0.0738, 0.1905, 0.0482, 0.0937, 0.0909, 0.1118,\n",
      "        0.0530])\n",
      "tensor(84.4700)\n",
      "tensor(85.7200)\n",
      "Round  54, reward -0.616\n",
      "tensor([0.2250, 0.1302, 0.0341, 0.0373, 0.0344, 0.1487, 0.1452, 0.0794, 0.0382,\n",
      "        0.1275])\n",
      "tensor(87.7900)\n",
      "tensor(85.0400)\n",
      "Round  55, reward -0.261\n",
      "tensor([0.0372, 0.0481, 0.1572, 0.0618, 0.0605, 0.1442, 0.1057, 0.0809, 0.0551,\n",
      "        0.2493])\n",
      "tensor(80.5900)\n",
      "tensor(82.2500)\n",
      "Round  56, reward -0.674\n",
      "tensor([0.1023, 0.0320, 0.0276, 0.1473, 0.0299, 0.0341, 0.1732, 0.1182, 0.1794,\n",
      "        0.1560])\n",
      "tensor(82.4400)\n",
      "tensor(81.0100)\n",
      "Round  57, reward -0.348\n",
      "tensor([0.1263, 0.0571, 0.0560, 0.0644, 0.1441, 0.0335, 0.1939, 0.0648, 0.0474,\n",
      "        0.2125])\n",
      "tensor(81.6600)\n",
      "tensor(83.3600)\n",
      "Round  58, reward -0.659\n",
      "tensor([0.0396, 0.0445, 0.1725, 0.0557, 0.0406, 0.1756, 0.1479, 0.0973, 0.1404,\n",
      "        0.0858])\n",
      "tensor(82.6200)\n",
      "tensor(83.0700)\n",
      "Round  59, reward -0.600\n",
      "tensor([0.1466, 0.0479, 0.1603, 0.1491, 0.0764, 0.1229, 0.1327, 0.0387, 0.0264,\n",
      "        0.0991])\n",
      "tensor(80.5900)\n",
      "tensor(81.3000)\n",
      "Round  60, reward -0.659\n",
      "tensor([0.0658, 0.0590, 0.1584, 0.1977, 0.1209, 0.0399, 0.0466, 0.1052, 0.0595,\n",
      "        0.1469])\n",
      "tensor(81.2400)\n",
      "tensor(83.3300)\n",
      "Round  61, reward -0.666\n",
      "tensor([0.0851, 0.1361, 0.0553, 0.0321, 0.1334, 0.1809, 0.0981, 0.0483, 0.1767,\n",
      "        0.0540])\n",
      "tensor(84.9100)\n",
      "tensor(84.7000)\n",
      "Round  62, reward -0.310\n",
      "tensor([0.1707, 0.0527, 0.0532, 0.1536, 0.0462, 0.0472, 0.0871, 0.2795, 0.0462,\n",
      "        0.0637])\n",
      "tensor(89.7300)\n",
      "tensor(90.3100)\n",
      "Round  63, reward -0.497\n",
      "tensor([0.0256, 0.0609, 0.1589, 0.1315, 0.1278, 0.1489, 0.0333, 0.0985, 0.1342,\n",
      "        0.0804])\n",
      "tensor(88.1700)\n",
      "tensor(87.0400)\n",
      "Round  64, reward -0.254\n",
      "tensor([0.1026, 0.0613, 0.0734, 0.0771, 0.0961, 0.1344, 0.1260, 0.0635, 0.1419,\n",
      "        0.1236])\n",
      "tensor(87.5800)\n",
      "tensor(88.9900)\n",
      "Round  65, reward -0.564\n",
      "tensor([0.0582, 0.0708, 0.0566, 0.1916, 0.1281, 0.0323, 0.2190, 0.1239, 0.0641,\n",
      "        0.0554])\n",
      "tensor(85.)\n",
      "tensor(90.9100)\n",
      "Round  66, reward -0.609\n",
      "tensor([0.1649, 0.1606, 0.1295, 0.0368, 0.1167, 0.0332, 0.0257, 0.1248, 0.1431,\n",
      "        0.0648])\n",
      "tensor(90.2000)\n",
      "tensor(89.8000)\n",
      "Round  67, reward -0.215\n",
      "tensor([0.0410, 0.1236, 0.1975, 0.0445, 0.1885, 0.0537, 0.0707, 0.1299, 0.0842,\n",
      "        0.0663])\n",
      "tensor(91.7200)\n",
      "tensor(92.0100)\n",
      "Round  68, reward -0.393\n",
      "tensor([0.0283, 0.0754, 0.0817, 0.1844, 0.1789, 0.1267, 0.0384, 0.1301, 0.0979,\n",
      "        0.0582])\n",
      "tensor(88.8200)\n",
      "tensor(87.0800)\n",
      "Round  69, reward -0.242\n",
      "tensor([0.0745, 0.0430, 0.1014, 0.0690, 0.2205, 0.1066, 0.0522, 0.1672, 0.1258,\n",
      "        0.0398])\n",
      "tensor(86.0700)\n",
      "tensor(88.3300)\n",
      "Round  70, reward -0.591\n",
      "tensor([0.1146, 0.1380, 0.1703, 0.0593, 0.0905, 0.1413, 0.0296, 0.0244, 0.1265,\n",
      "        0.1055])\n",
      "tensor(81.0600)\n",
      "tensor(84.4700)\n",
      "Round  71, reward -0.668\n",
      "tensor([0.0393, 0.0377, 0.1113, 0.0460, 0.0377, 0.2140, 0.0819, 0.2571, 0.0560,\n",
      "        0.1189])\n",
      "tensor(79.1000)\n",
      "tensor(83.9500)\n",
      "Round  72, reward -0.694\n",
      "tensor([0.0470, 0.1535, 0.0370, 0.1967, 0.1246, 0.0938, 0.0626, 0.1634, 0.0388,\n",
      "        0.0827])\n",
      "tensor(90.5200)\n",
      "tensor(90.3300)\n",
      "Round  73, reward -0.208\n",
      "tensor([0.0937, 0.1707, 0.0940, 0.0839, 0.0952, 0.2047, 0.0544, 0.0570, 0.0663,\n",
      "        0.0800])\n",
      "tensor(84.5800)\n",
      "tensor(84.6700)\n",
      "Round  74, reward -0.409\n",
      "tensor([0.0355, 0.0281, 0.0931, 0.0787, 0.1452, 0.0353, 0.1747, 0.1568, 0.0874,\n",
      "        0.1650])\n",
      "tensor(80.2300)\n",
      "tensor(80.5200)\n",
      "Round  75, reward -0.590\n",
      "tensor([0.1341, 0.1033, 0.0655, 0.1528, 0.1733, 0.0368, 0.0392, 0.0352, 0.1884,\n",
      "        0.0714])\n",
      "tensor(89.6200)\n",
      "tensor(88.5600)\n",
      "Round  76, reward -0.226\n",
      "tensor([0.0370, 0.0480, 0.1316, 0.0774, 0.0412, 0.1979, 0.1325, 0.0695, 0.0360,\n",
      "        0.2290])\n",
      "tensor(89.5500)\n",
      "tensor(90.4900)\n",
      "Round  77, reward -0.521\n",
      "tensor([0.2320, 0.0498, 0.1663, 0.0586, 0.2133, 0.0522, 0.1121, 0.0443, 0.0357,\n",
      "        0.0358])\n",
      "tensor(82.5400)\n",
      "tensor(90.4500)\n",
      "Round  78, reward -0.647\n",
      "tensor([0.0459, 0.2189, 0.1472, 0.1898, 0.1435, 0.0372, 0.0368, 0.0734, 0.0464,\n",
      "        0.0609])\n",
      "tensor(80.2300)\n",
      "tensor(85.1900)\n",
      "Round  79, reward -0.679\n",
      "tensor([0.0593, 0.0377, 0.2102, 0.0465, 0.0367, 0.1342, 0.1366, 0.2425, 0.0382,\n",
      "        0.0580])\n",
      "tensor(90.5200)\n",
      "tensor(88.2700)\n",
      "Round  80, reward -0.208\n",
      "tensor([0.0197, 0.1452, 0.1452, 0.0198, 0.0769, 0.0956, 0.1042, 0.1069, 0.1427,\n",
      "        0.1439])\n",
      "tensor(87.2000)\n",
      "tensor(87.8800)\n",
      "Round  81, reward -0.554\n",
      "tensor([0.0213, 0.0809, 0.0213, 0.1022, 0.1221, 0.1454, 0.1496, 0.1286, 0.1012,\n",
      "        0.1276])\n",
      "tensor(82.1600)\n",
      "tensor(81.1000)\n",
      "Round  82, reward -0.353\n",
      "tensor([0.0206, 0.0226, 0.1275, 0.1522, 0.0215, 0.1518, 0.1491, 0.1378, 0.0708,\n",
      "        0.1462])\n",
      "tensor(88.8000)\n",
      "tensor(89.2600)\n",
      "Round  83, reward -0.498\n",
      "tensor([0.0568, 0.1211, 0.0232, 0.1467, 0.0442, 0.1468, 0.1462, 0.0298, 0.1432,\n",
      "        0.1421])\n",
      "tensor(91.8600)\n",
      "tensor(91.7400)\n",
      "Round  84, reward -0.180\n",
      "tensor([0.0337, 0.1136, 0.0286, 0.2098, 0.1662, 0.0351, 0.2096, 0.1247, 0.0375,\n",
      "        0.0412])\n",
      "tensor(88.0500)\n",
      "tensor(91.3800)\n",
      "Round  85, reward -0.556\n",
      "tensor([0.1507, 0.0804, 0.1270, 0.1361, 0.1505, 0.0206, 0.1022, 0.0614, 0.1502,\n",
      "        0.0210])\n",
      "tensor(89.1800)\n",
      "tensor(88.7300)\n",
      "Round  86, reward -0.235\n",
      "tensor([0.0251, 0.1706, 0.0621, 0.1463, 0.1437, 0.0818, 0.0512, 0.1374, 0.0499,\n",
      "        0.1318])\n",
      "tensor(90.7300)\n",
      "tensor(90.1900)\n",
      "Round  87, reward -0.204\n",
      "tensor([0.0524, 0.1052, 0.1696, 0.1696, 0.0300, 0.0443, 0.0758, 0.1679, 0.1623,\n",
      "        0.0230])\n",
      "tensor(87.5200)\n",
      "tensor(86.8300)\n",
      "Round  88, reward -0.266\n",
      "tensor([0.1745, 0.0242, 0.0423, 0.0278, 0.0962, 0.1757, 0.1765, 0.0806, 0.0560,\n",
      "        0.1462])\n",
      "tensor(78.4000)\n",
      "tensor(81.7100)\n",
      "Round  89, reward -0.703\n",
      "tensor([0.0573, 0.0246, 0.1230, 0.1049, 0.1506, 0.0235, 0.0255, 0.1716, 0.1505,\n",
      "        0.1684])\n",
      "tensor(86.6600)\n",
      "tensor(87.3800)\n",
      "Round  90, reward -0.566\n",
      "tensor([0.1434, 0.1554, 0.1092, 0.1446, 0.1244, 0.0519, 0.0493, 0.0212, 0.0450,\n",
      "        0.1555])\n",
      "tensor(87.3800)\n",
      "tensor(88.1600)\n",
      "Round  91, reward -0.557\n",
      "tensor([0.0297, 0.2154, 0.1510, 0.0360, 0.0295, 0.0385, 0.0429, 0.0373, 0.2027,\n",
      "        0.2170])\n",
      "tensor(90.1900)\n",
      "tensor(86.4000)\n",
      "Round  92, reward -0.215\n",
      "tensor([0.0951, 0.0928, 0.1455, 0.0358, 0.1493, 0.1477, 0.0793, 0.0223, 0.1128,\n",
      "        0.1194])\n",
      "tensor(89.7200)\n",
      "tensor(92.8000)\n",
      "Round  93, reward -0.524\n",
      "tensor([0.1268, 0.1491, 0.1508, 0.1474, 0.0204, 0.1496, 0.0209, 0.1461, 0.0205,\n",
      "        0.0684])\n",
      "tensor(83.8500)\n",
      "tensor(82.7200)\n",
      "Round  94, reward -0.327\n",
      "tensor([0.1482, 0.1424, 0.1777, 0.1666, 0.0352, 0.0744, 0.0244, 0.0682, 0.1321,\n",
      "        0.0307])\n",
      "tensor(84.6400)\n",
      "tensor(84.4800)\n",
      "Round  95, reward -0.315\n",
      "tensor([0.1436, 0.1193, 0.0257, 0.0269, 0.1642, 0.0471, 0.1686, 0.0396, 0.1709,\n",
      "        0.0941])\n",
      "tensor(82.6000)\n",
      "tensor(89.7200)\n",
      "Round  96, reward -0.646\n",
      "tensor([0.1058, 0.0192, 0.1420, 0.0192, 0.1420, 0.1346, 0.1420, 0.1415, 0.1338,\n",
      "        0.0199])\n",
      "tensor(82.3000)\n",
      "tensor(84.3100)\n",
      "Round  97, reward -0.650\n",
      "tensor([0.1630, 0.0240, 0.0528, 0.0244, 0.1654, 0.0272, 0.0741, 0.1260, 0.1772,\n",
      "        0.1658])\n",
      "tensor(84.3900)\n",
      "tensor(84.8400)\n",
      "Round  98, reward -0.573\n",
      "tensor([0.0915, 0.1074, 0.1634, 0.1009, 0.1466, 0.0543, 0.0235, 0.1633, 0.0236,\n",
      "        0.1256])\n",
      "tensor(87.0500)\n",
      "tensor(88.5500)\n",
      "Round  99, reward -0.574\n",
      "tensor([0.0368, 0.0365, 0.0978, 0.2545, 0.0354, 0.0358, 0.1135, 0.2586, 0.0751,\n",
      "        0.0560])\n",
      "tensor(83.5700)\n",
      "tensor(91.3100)\n",
      "Round 100, reward -0.632\n",
      "tensor([0.0227, 0.0255, 0.0227, 0.1018, 0.1119, 0.1668, 0.1636, 0.0561, 0.1624,\n",
      "        0.1665])\n",
      "tensor(83.4500)\n",
      "tensor(83.2600)\n",
      "Round 101, reward -0.333\n",
      "tensor([0.0321, 0.0315, 0.0736, 0.2297, 0.0376, 0.0687, 0.0316, 0.0390, 0.2238,\n",
      "        0.2325])\n",
      "tensor(83.7800)\n",
      "tensor(84.5800)\n",
      "Round 102, reward -0.618\n",
      "tensor([0.1580, 0.0228, 0.0877, 0.0219, 0.1558, 0.1123, 0.0215, 0.1367, 0.1250,\n",
      "        0.1583])\n",
      "tensor(85.3700)\n",
      "tensor(85.1700)\n",
      "Round 103, reward -0.303\n",
      "tensor([0.1923, 0.1501, 0.0490, 0.0568, 0.0270, 0.1954, 0.0299, 0.1955, 0.0267,\n",
      "        0.0773])\n",
      "tensor(89.4600)\n",
      "tensor(92.2500)\n",
      "Round 104, reward -0.529\n",
      "tensor([0.0314, 0.1492, 0.0241, 0.0257, 0.1761, 0.1686, 0.0292, 0.0448, 0.1760,\n",
      "        0.1749])\n",
      "tensor(88.9000)\n",
      "tensor(88.8400)\n",
      "Round 105, reward -0.240\n",
      "tensor([0.0615, 0.1017, 0.1322, 0.1158, 0.1327, 0.0185, 0.1266, 0.1332, 0.0445,\n",
      "        0.1333])\n",
      "tensor(88.9200)\n",
      "tensor(90.9300)\n",
      "Round 106, reward -0.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0645, 0.0310, 0.0275, 0.0290, 0.0285, 0.2014, 0.1746, 0.0622, 0.1785,\n",
      "        0.2029])\n",
      "tensor(90.0300)\n",
      "tensor(84.5500)\n",
      "Round 107, reward -0.218\n",
      "tensor([0.1055, 0.0320, 0.0349, 0.0840, 0.1466, 0.2187, 0.0322, 0.2192, 0.0392,\n",
      "        0.0877])\n",
      "tensor(90.3600)\n",
      "tensor(90.0800)\n",
      "Round 108, reward -0.211\n",
      "tensor([0.1555, 0.0610, 0.0327, 0.1548, 0.0223, 0.1565, 0.0522, 0.0687, 0.1324,\n",
      "        0.1639])\n",
      "tensor(92.4700)\n",
      "tensor(90.2100)\n",
      "Round 109, reward -0.166\n",
      "tensor([0.1388, 0.1343, 0.0275, 0.1395, 0.0203, 0.0822, 0.1313, 0.1497, 0.1483,\n",
      "        0.0282])\n",
      "tensor(90.8200)\n",
      "tensor(90.8100)\n",
      "Round 110, reward -0.202\n",
      "tensor([0.1552, 0.0229, 0.1359, 0.0561, 0.1552, 0.0340, 0.0222, 0.1141, 0.1551,\n",
      "        0.1493])\n",
      "tensor(84.9100)\n",
      "tensor(89.7100)\n",
      "Round 111, reward -0.610\n",
      "tensor([0.0349, 0.0640, 0.0490, 0.0312, 0.1990, 0.1823, 0.0317, 0.1455, 0.0320,\n",
      "        0.2304])\n",
      "tensor(91.8700)\n",
      "tensor(92.2100)\n",
      "Round 112, reward -0.407\n",
      "tensor([0.1871, 0.0653, 0.1873, 0.1467, 0.1268, 0.0673, 0.0256, 0.0310, 0.1324,\n",
      "        0.0305])\n",
      "tensor(89.7500)\n",
      "tensor(91.2800)\n",
      "Round 113, reward -0.523\n",
      "tensor([0.1475, 0.1471, 0.0201, 0.0309, 0.1469, 0.1480, 0.1304, 0.1472, 0.0202,\n",
      "        0.0618])\n",
      "tensor(90.3600)\n",
      "tensor(91.0800)\n",
      "Round 114, reward -0.496\n",
      "tensor([0.1401, 0.0347, 0.0874, 0.0542, 0.0588, 0.1973, 0.0267, 0.1735, 0.1830,\n",
      "        0.0442])\n",
      "tensor(83.6800)\n",
      "tensor(82.2400)\n",
      "Round 115, reward -0.330\n",
      "tensor([0.1368, 0.0358, 0.0314, 0.0211, 0.1329, 0.1144, 0.1450, 0.1065, 0.1448,\n",
      "        0.1314])\n",
      "tensor(91.9000)\n",
      "tensor(93.2300)\n",
      "Round 116, reward -0.478\n",
      "tensor([0.1877, 0.0404, 0.0286, 0.0339, 0.0313, 0.0477, 0.1957, 0.1197, 0.1208,\n",
      "        0.1943])\n",
      "tensor(91.3900)\n",
      "tensor(91.4500)\n",
      "Round 117, reward -0.256\n",
      "tensor([0.0197, 0.1435, 0.0195, 0.0499, 0.1371, 0.1167, 0.1046, 0.1436, 0.1251,\n",
      "        0.1401])\n",
      "tensor(85.9200)\n",
      "tensor(85.0900)\n",
      "Round 118, reward -0.294\n",
      "tensor([0.0408, 0.0520, 0.0368, 0.2586, 0.0437, 0.0427, 0.2535, 0.1779, 0.0386,\n",
      "        0.0554])\n",
      "tensor(85.7100)\n",
      "tensor(92.0600)\n",
      "Round 119, reward -0.597\n",
      "tensor([0.1403, 0.1562, 0.2035, 0.0289, 0.0412, 0.0430, 0.1821, 0.0315, 0.0280,\n",
      "        0.1454])\n",
      "tensor(85.9000)\n",
      "tensor(86.7100)\n",
      "Round 120, reward -0.584\n",
      "tensor([0.0221, 0.1244, 0.1635, 0.0222, 0.1635, 0.1331, 0.1635, 0.0221, 0.1635,\n",
      "        0.0221])\n",
      "tensor(91.5300)\n",
      "tensor(92.3100)\n",
      "Round 121, reward -0.475\n",
      "tensor([0.1836, 0.0845, 0.0459, 0.1526, 0.0249, 0.1822, 0.0249, 0.0931, 0.0249,\n",
      "        0.1836])\n",
      "tensor(83.5200)\n",
      "tensor(87.0600)\n",
      "Round 122, reward -0.632\n",
      "tensor([0.0297, 0.2189, 0.0297, 0.0297, 0.2191, 0.2191, 0.0297, 0.1510, 0.0297,\n",
      "        0.0437])\n",
      "tensor(84.5600)\n",
      "tensor(82.5100)\n",
      "Round 123, reward -0.316\n",
      "tensor([0.0245, 0.1285, 0.1309, 0.1309, 0.1309, 0.1309, 0.0438, 0.0177, 0.1309,\n",
      "        0.1308])\n",
      "tensor(85.3700)\n",
      "tensor(90.1600)\n",
      "Round 124, reward -0.603\n",
      "tensor([0.2111, 0.0286, 0.2111, 0.0476, 0.2112, 0.1212, 0.0286, 0.0580, 0.0540,\n",
      "        0.0287])\n",
      "tensor(84.9800)\n",
      "tensor(83.3900)\n",
      "Round 125, reward -0.309\n",
      "tensor([0.0338, 0.2485, 0.2491, 0.0337, 0.1788, 0.0337, 0.0337, 0.1085, 0.0347,\n",
      "        0.0453])\n",
      "tensor(85.0300)\n",
      "tensor(90.8500)\n",
      "Round 126, reward -0.608\n",
      "tensor([0.1383, 0.1383, 0.0187, 0.1113, 0.1371, 0.0228, 0.1383, 0.1383, 0.1383,\n",
      "        0.0187])\n",
      "tensor(87.8700)\n",
      "tensor(86.4700)\n",
      "Round 127, reward -0.259\n",
      "tensor([0.0230, 0.1698, 0.1698, 0.1698, 0.0230, 0.0230, 0.1698, 0.0567, 0.0264,\n",
      "        0.1690])\n",
      "tensor(84.4200)\n",
      "tensor(86.7900)\n",
      "Round 128, reward -0.618\n",
      "tensor([0.0282, 0.0281, 0.2077, 0.0281, 0.0281, 0.2078, 0.0283, 0.2078, 0.2078,\n",
      "        0.0282])\n",
      "tensor(80.8300)\n",
      "tensor(86.1100)\n",
      "Round 129, reward -0.671\n",
      "tensor([0.0432, 0.0433, 0.0561, 0.0432, 0.0433, 0.0432, 0.3192, 0.0432, 0.0462,\n",
      "        0.3192])\n",
      "tensor(87.4300)\n",
      "tensor(91.8700)\n",
      "Round 130, reward -0.567\n",
      "tensor([0.1294, 0.1294, 0.1276, 0.1294, 0.0609, 0.0175, 0.0175, 0.1294, 0.1294,\n",
      "        0.1294])\n",
      "tensor(90.7700)\n",
      "tensor(85.6100)\n",
      "Round 131, reward -0.203\n",
      "tensor([0.0164, 0.1209, 0.1209, 0.0164, 0.1209, 0.1207, 0.1209, 0.1209, 0.1209,\n",
      "        0.1209])\n",
      "tensor(92.7200)\n",
      "tensor(93.7500)\n",
      "Round 132, reward -0.457\n",
      "tensor([0.1958, 0.1035, 0.1743, 0.1958, 0.0265, 0.0290, 0.0265, 0.0265, 0.1957,\n",
      "        0.0265])\n",
      "tensor(82.7000)\n",
      "tensor(83.0600)\n",
      "Round 133, reward -0.577\n",
      "tensor([0.0359, 0.1183, 0.2612, 0.0354, 0.0354, 0.0353, 0.1776, 0.0353, 0.0354,\n",
      "        0.2301])\n",
      "tensor(82.4800)\n",
      "tensor(85.2300)\n",
      "Round 134, reward -0.648\n",
      "tensor([0.1974, 0.1974, 0.0267, 0.0267, 0.1974, 0.0725, 0.0268, 0.0267, 0.0310,\n",
      "        0.1972])\n",
      "tensor(89.6400)\n",
      "tensor(89.7200)\n",
      "Round 135, reward -0.311\n",
      "tensor([0.1452, 0.0203, 0.1453, 0.1453, 0.0656, 0.1451, 0.1453, 0.0197, 0.1432,\n",
      "        0.0251])\n",
      "tensor(93.1800)\n",
      "tensor(93.3400)\n",
      "Round 136, reward -0.296\n",
      "tensor([0.0216, 0.1591, 0.1237, 0.1593, 0.1579, 0.1392, 0.0411, 0.1551, 0.0216,\n",
      "        0.0216])\n",
      "tensor(86.6300)\n",
      "tensor(86.3600)\n",
      "Round 137, reward -0.282\n",
      "tensor([0.0305, 0.0290, 0.1818, 0.2143, 0.0290, 0.0290, 0.2141, 0.0290, 0.2142,\n",
      "        0.0291])\n",
      "tensor(87.0500)\n",
      "tensor(92.1800)\n",
      "Round 138, reward -0.574\n",
      "tensor([0.0341, 0.0341, 0.0341, 0.2517, 0.0341, 0.0344, 0.2517, 0.0341, 0.2517,\n",
      "        0.0402])\n",
      "tensor(81.4400)\n",
      "tensor(91.3300)\n",
      "Round 139, reward -0.663\n",
      "tensor([0.0282, 0.0282, 0.2082, 0.0493, 0.2079, 0.0282, 0.0282, 0.1705, 0.0433,\n",
      "        0.2082])\n",
      "tensor(93.8200)\n",
      "tensor(89.2000)\n",
      "Round 140, reward -0.136\n",
      "tensor([0.0341, 0.2371, 0.0358, 0.0341, 0.0341, 0.0532, 0.2517, 0.2517, 0.0342,\n",
      "        0.0341])\n",
      "tensor(91.0700)\n",
      "tensor(91.8300)\n",
      "Round 141, reward -0.484\n",
      "tensor([0.1065, 0.0907, 0.1062, 0.1065, 0.0988, 0.1065, 0.1065, 0.1065, 0.1065,\n",
      "        0.0653])\n",
      "tensor(89.)\n",
      "tensor(88.9200)\n",
      "Round 142, reward -0.238\n",
      "tensor([0.0268, 0.1751, 0.1752, 0.0242, 0.0259, 0.0237, 0.1752, 0.1752, 0.0237,\n",
      "        0.1751])\n",
      "tensor(86.3000)\n",
      "tensor(88.7600)\n",
      "Round 143, reward -0.587\n",
      "tensor([0.2265, 0.0307, 0.0336, 0.0306, 0.2265, 0.0306, 0.0306, 0.0310, 0.1343,\n",
      "        0.2256])\n",
      "tensor(90.0100)\n",
      "tensor(93.0800)\n",
      "Round 144, reward -0.518\n",
      "tensor([0.1880, 0.0254, 0.1880, 0.1868, 0.0254, 0.1879, 0.0278, 0.0256, 0.0254,\n",
      "        0.1196])\n",
      "tensor(82.6400)\n",
      "tensor(85.2000)\n",
      "Round 145, reward -0.646\n",
      "tensor([0.0280, 0.0280, 0.2070, 0.0289, 0.0280, 0.0280, 0.2068, 0.2069, 0.0313,\n",
      "        0.2070])\n",
      "tensor(84.6300)\n",
      "tensor(86.3500)\n",
      "Round 146, reward -0.615\n",
      "tensor([0.0265, 0.0293, 0.0267, 0.1860, 0.1961, 0.0917, 0.0269, 0.1961, 0.1939,\n",
      "        0.0268])\n",
      "tensor(90.4000)\n",
      "tensor(85.7500)\n",
      "Round 147, reward -0.210\n",
      "tensor([0.0338, 0.0305, 0.2254, 0.1367, 0.0306, 0.0305, 0.0305, 0.2254, 0.0311,\n",
      "        0.2254])\n",
      "tensor(84.9800)\n",
      "tensor(90.2100)\n",
      "Round 148, reward -0.609\n",
      "tensor([0.0258, 0.0258, 0.0257, 0.1852, 0.1860, 0.1117, 0.1895, 0.0352, 0.0257,\n",
      "        0.1895])\n",
      "tensor(85.3300)\n",
      "tensor(87.7500)\n",
      "Round 149, reward -0.604\n",
      "tensor([0.0340, 0.2511, 0.0342, 0.0340, 0.2511, 0.0340, 0.0340, 0.0350, 0.0669,\n",
      "        0.2258])\n",
      "tensor(85.6900)\n",
      "tensor(84.7400)\n",
      "Round 150, reward -0.298\n",
      "tensor([0.0252, 0.0247, 0.0247, 0.1822, 0.0247, 0.1798, 0.1822, 0.0296, 0.1585,\n",
      "        0.1685])\n",
      "tensor(93.6500)\n",
      "tensor(88.2300)\n",
      "Round 151, reward -0.140\n",
      "tensor([0.1760, 0.0238, 0.1760, 0.1760, 0.1760, 0.0238, 0.0245, 0.0239, 0.1760,\n",
      "        0.0238])\n",
      "tensor(92.7900)\n",
      "tensor(93.6100)\n",
      "Round 152, reward -0.449\n",
      "tensor([0.1807, 0.1829, 0.0248, 0.0248, 0.1829, 0.0528, 0.0248, 0.0313, 0.1121,\n",
      "        0.1829])\n",
      "tensor(87.1200)\n",
      "tensor(92.7600)\n",
      "Round 153, reward -0.573\n",
      "tensor([0.0188, 0.1375, 0.1375, 0.1369, 0.1375, 0.1197, 0.0186, 0.0186, 0.1375,\n",
      "        0.1375])\n",
      "tensor(88.2400)\n",
      "tensor(88.0100)\n",
      "Round 154, reward -0.253\n",
      "tensor([0.0357, 0.0356, 0.2138, 0.1912, 0.0356, 0.1725, 0.0357, 0.0356, 0.0357,\n",
      "        0.2085])\n",
      "tensor(89.3400)\n",
      "tensor(89.8600)\n",
      "Round 155, reward -0.497\n",
      "tensor([0.0217, 0.1362, 0.1602, 0.1602, 0.0217, 0.0217, 0.1602, 0.1301, 0.1602,\n",
      "        0.0279])\n",
      "tensor(86.6300)\n",
      "tensor(87.9300)\n",
      "Round 156, reward -0.580\n",
      "tensor([0.0322, 0.0812, 0.2381, 0.2371, 0.0322, 0.0322, 0.0444, 0.0324, 0.0322,\n",
      "        0.2380])\n",
      "tensor(91.7500)\n",
      "tensor(92.4400)\n",
      "Round 157, reward -0.465\n",
      "tensor([0.1557, 0.0220, 0.1623, 0.0220, 0.1556, 0.0220, 0.1623, 0.1623, 0.1139,\n",
      "        0.0220])\n",
      "tensor(85.0800)\n",
      "tensor(87.0800)\n",
      "Round 158, reward -0.608\n",
      "tensor([0.0267, 0.1975, 0.0270, 0.0281, 0.0270, 0.0270, 0.1975, 0.0750, 0.1967,\n",
      "        0.1975])\n",
      "tensor(90.3200)\n",
      "tensor(92.6900)\n",
      "Round 159, reward -0.512\n",
      "tensor([0.0962, 0.0232, 0.1712, 0.0232, 0.1585, 0.1390, 0.0232, 0.0232, 0.1712,\n",
      "        0.1712])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.5000)\n",
      "tensor(93.6400)\n",
      "Round 160, reward -0.276\n",
      "tensor([0.0252, 0.0262, 0.1861, 0.0547, 0.0252, 0.1852, 0.1861, 0.0547, 0.0705,\n",
      "        0.1861])\n",
      "tensor(88.3300)\n",
      "tensor(92.7200)\n",
      "Round 161, reward -0.551\n",
      "tensor([0.1669, 0.0247, 0.0226, 0.1480, 0.1665, 0.1657, 0.0338, 0.0824, 0.0226,\n",
      "        0.1669])\n",
      "tensor(85.2200)\n",
      "tensor(86.1300)\n",
      "Round 162, reward -0.599\n",
      "tensor([0.0167, 0.1218, 0.1218, 0.1218, 0.0165, 0.1218, 0.1218, 0.1218, 0.1142,\n",
      "        0.1218])\n",
      "tensor(91.8800)\n",
      "tensor(91.3000)\n",
      "Round 163, reward -0.179\n",
      "tensor([0.1570, 0.0212, 0.1447, 0.0212, 0.1431, 0.1569, 0.1564, 0.1570, 0.0212,\n",
      "        0.0212])\n",
      "tensor(93.5800)\n",
      "tensor(93.1300)\n",
      "Round 164, reward -0.141\n",
      "tensor([0.0171, 0.0860, 0.0170, 0.1257, 0.1258, 0.1255, 0.1258, 0.1257, 0.1257,\n",
      "        0.1257])\n",
      "tensor(91.4700)\n",
      "tensor(92.7200)\n",
      "Round 165, reward -0.487\n",
      "tensor([0.1350, 0.0183, 0.1351, 0.0183, 0.1351, 0.0183, 0.1351, 0.1351, 0.1351,\n",
      "        0.1347])\n",
      "tensor(91.0300)\n",
      "tensor(94.3200)\n",
      "Round 166, reward -0.497\n",
      "tensor([0.2747, 0.0694, 0.0372, 0.0372, 0.0372, 0.1949, 0.2379, 0.0372, 0.0372,\n",
      "        0.0372])\n",
      "tensor(83.4500)\n",
      "tensor(92.9800)\n",
      "Round 167, reward -0.633\n",
      "tensor([0.2035, 0.2035, 0.2033, 0.0275, 0.0281, 0.0276, 0.0275, 0.2035, 0.0276,\n",
      "        0.0480])\n",
      "tensor(90.3700)\n",
      "tensor(91.9400)\n",
      "Round 168, reward -0.511\n",
      "tensor([0.1241, 0.0168, 0.1241, 0.1242, 0.1241, 0.0975, 0.0168, 0.1240, 0.1242,\n",
      "        0.1242])\n",
      "tensor(93.3800)\n",
      "tensor(94.1800)\n",
      "Round 169, reward -0.435\n",
      "tensor([0.0206, 0.1521, 0.1212, 0.0206, 0.0814, 0.1243, 0.0277, 0.1520, 0.1482,\n",
      "        0.1521])\n",
      "tensor(94.3600)\n",
      "tensor(92.7400)\n",
      "Round 170, reward -0.123\n",
      "tensor([0.0210, 0.1550, 0.0210, 0.1542, 0.1547, 0.1486, 0.1550, 0.0239, 0.0210,\n",
      "        0.1456])\n",
      "tensor(86.3800)\n",
      "tensor(90.3400)\n",
      "Round 171, reward -0.586\n",
      "tensor([0.1375, 0.0186, 0.0419, 0.1375, 0.1375, 0.1373, 0.1347, 0.1375, 0.0789,\n",
      "        0.0385])\n",
      "tensor(94.0600)\n",
      "tensor(95.0400)\n",
      "Round 172, reward -0.425\n",
      "tensor([0.0187, 0.1379, 0.1379, 0.1375, 0.0633, 0.1379, 0.0187, 0.1375, 0.0729,\n",
      "        0.1379])\n",
      "tensor(94.3000)\n",
      "tensor(94.6900)\n",
      "Round 173, reward -0.365\n",
      "tensor([0.1712, 0.1712, 0.1712, 0.0232, 0.0377, 0.0235, 0.0232, 0.0384, 0.1712,\n",
      "        0.1692])\n",
      "tensor(92.6200)\n",
      "tensor(94.1700)\n",
      "Round 174, reward -0.463\n",
      "tensor([0.1690, 0.0229, 0.1656, 0.0229, 0.0229, 0.1692, 0.1682, 0.0229, 0.1692,\n",
      "        0.0673])\n",
      "tensor(91.7300)\n",
      "tensor(93.1900)\n",
      "Round 175, reward -0.482\n",
      "tensor([0.0214, 0.0216, 0.1584, 0.1554, 0.0215, 0.1206, 0.0560, 0.1584, 0.1582,\n",
      "        0.1285])\n",
      "tensor(93.5300)\n",
      "tensor(94.8300)\n",
      "Round 176, reward -0.441\n",
      "tensor([0.0702, 0.4189, 0.1140, 0.0567, 0.0567, 0.0567, 0.0567, 0.0568, 0.0567,\n",
      "        0.0567])\n",
      "tensor(90.9500)\n",
      "tensor(93.0700)\n",
      "Round 177, reward -0.499\n",
      "tensor([0.1473, 0.0200, 0.1408, 0.1427, 0.0775, 0.0200, 0.1477, 0.1477, 0.0653,\n",
      "        0.0910])\n",
      "tensor(91.0900)\n",
      "tensor(94.1300)\n",
      "Round 178, reward -0.496\n",
      "tensor([0.0193, 0.1427, 0.0193, 0.1061, 0.1427, 0.1427, 0.0193, 0.1226, 0.1427,\n",
      "        0.1427])\n",
      "tensor(90.9600)\n",
      "tensor(93.4600)\n",
      "Round 179, reward -0.499\n",
      "tensor([0.0316, 0.0268, 0.1977, 0.1978, 0.1978, 0.1964, 0.0268, 0.0268, 0.0268,\n",
      "        0.0717])\n",
      "tensor(85.8000)\n",
      "tensor(88.3900)\n",
      "Round 180, reward -0.596\n",
      "tensor([0.0260, 0.0259, 0.1910, 0.1029, 0.0294, 0.1910, 0.1910, 0.0259, 0.0259,\n",
      "        0.1910])\n",
      "tensor(89.2900)\n",
      "tensor(91.9200)\n",
      "Round 181, reward -0.533\n",
      "tensor([0.1208, 0.0164, 0.1208, 0.0164, 0.1210, 0.1209, 0.1210, 0.1209, 0.1210,\n",
      "        0.1209])\n",
      "tensor(90.6600)\n",
      "tensor(88.7400)\n",
      "Round 182, reward -0.205\n",
      "tensor([0.1530, 0.0207, 0.1530, 0.1530, 0.0207, 0.1530, 0.0220, 0.1514, 0.1525,\n",
      "        0.0207])\n",
      "tensor(89.2700)\n",
      "tensor(87.0600)\n",
      "Round 183, reward -0.233\n",
      "tensor([0.0245, 0.0237, 0.1748, 0.1748, 0.1746, 0.1748, 0.1748, 0.0237, 0.0307,\n",
      "        0.0237])\n",
      "tensor(94.5700)\n",
      "tensor(94.3300)\n",
      "Round 184, reward -0.118\n",
      "tensor([0.0351, 0.0332, 0.0332, 0.2453, 0.0332, 0.0616, 0.2452, 0.0333, 0.0344,\n",
      "        0.2453])\n",
      "tensor(94.2000)\n",
      "tensor(93.4400)\n",
      "Round 185, reward -0.127\n",
      "tensor([0.0278, 0.0329, 0.2056, 0.0292, 0.2055, 0.0278, 0.2053, 0.0279, 0.2056,\n",
      "        0.0323])\n",
      "tensor(89.2800)\n",
      "tensor(92.9900)\n",
      "Round 186, reward -0.533\n",
      "tensor([0.1229, 0.1136, 0.1304, 0.1304, 0.0176, 0.1304, 0.1304, 0.1304, 0.0176,\n",
      "        0.0763])\n",
      "tensor(89.7500)\n",
      "tensor(90.2000)\n",
      "Round 187, reward -0.477\n",
      "tensor([0.0261, 0.1590, 0.0242, 0.1789, 0.0242, 0.1789, 0.0267, 0.1789, 0.1789,\n",
      "        0.0243])\n",
      "tensor(94.3300)\n",
      "tensor(92.9600)\n",
      "Round 188, reward -0.124\n",
      "tensor([0.0273, 0.0248, 0.0250, 0.1831, 0.0250, 0.1476, 0.0255, 0.1834, 0.1834,\n",
      "        0.1749])\n",
      "tensor(93.9200)\n",
      "tensor(92.9400)\n",
      "Round 189, reward -0.133\n",
      "tensor([0.0236, 0.0237, 0.1740, 0.0355, 0.0236, 0.1740, 0.1740, 0.1740, 0.1740,\n",
      "        0.0236])\n",
      "tensor(94.1400)\n",
      "tensor(91.8200)\n",
      "Round 190, reward -0.128\n",
      "tensor([0.1729, 0.1728, 0.0437, 0.0234, 0.1705, 0.1729, 0.1729, 0.0234, 0.0241,\n",
      "        0.0234])\n",
      "tensor(92.5700)\n",
      "tensor(94.8600)\n",
      "Round 191, reward -0.464\n",
      "tensor([0.0284, 0.0283, 0.2087, 0.0282, 0.2087, 0.0282, 0.2079, 0.0282, 0.2048,\n",
      "        0.0283])\n",
      "tensor(85.2200)\n",
      "tensor(84.8400)\n",
      "Round 192, reward -0.305\n",
      "tensor([0.1760, 0.1761, 0.1761, 0.0238, 0.1761, 0.0241, 0.0238, 0.0238, 0.1761,\n",
      "        0.0238])\n",
      "tensor(87.1800)\n",
      "tensor(91.6800)\n",
      "Round 193, reward -0.572\n",
      "tensor([0.0446, 0.0410, 0.1796, 0.0246, 0.0244, 0.0243, 0.1436, 0.1796, 0.1796,\n",
      "        0.1588])\n",
      "tensor(94.0500)\n",
      "tensor(94.4400)\n",
      "Round 194, reward -0.371\n",
      "tensor([0.0365, 0.0337, 0.0461, 0.0347, 0.0345, 0.0337, 0.2491, 0.2490, 0.2488,\n",
      "        0.0338])\n",
      "tensor(89.8000)\n",
      "tensor(93.2500)\n",
      "Round 195, reward -0.523\n",
      "tensor([0.0164, 0.1209, 0.1209, 0.1209, 0.0164, 0.1209, 0.1209, 0.1209, 0.1209,\n",
      "        0.1209])\n",
      "tensor(89.1100)\n",
      "tensor(92.8300)\n",
      "Round 196, reward -0.536\n",
      "tensor([0.0197, 0.1388, 0.1102, 0.1387, 0.1388, 0.1388, 0.0188, 0.0188, 0.1387,\n",
      "        0.1388])\n",
      "tensor(93.7700)\n",
      "tensor(94.3600)\n",
      "Round 197, reward -0.411\n",
      "tensor([0.1247, 0.0238, 0.1756, 0.1756, 0.1700, 0.0416, 0.0656, 0.0238, 0.1756,\n",
      "        0.0238])\n",
      "tensor(93.3600)\n",
      "tensor(94.8600)\n",
      "Round 198, reward -0.446\n",
      "tensor([0.0910, 0.0219, 0.1616, 0.0219, 0.1616, 0.1616, 0.0219, 0.0354, 0.1616,\n",
      "        0.1616])\n",
      "tensor(91.1900)\n",
      "tensor(93.0900)\n",
      "Round 199, reward -0.494\n",
      "tensor([0.0240, 0.1774, 0.1773, 0.0241, 0.0240, 0.1724, 0.1763, 0.0240, 0.1764,\n",
      "        0.0242])\n",
      "tensor(91.5700)\n",
      "tensor(93.2900)\n",
      "Round 200, reward -0.486\n",
      "tensor([0.0424, 0.0538, 0.2783, 0.0421, 0.1054, 0.0422, 0.0421, 0.0421, 0.0430,\n",
      "        0.3087])\n",
      "tensor(84.5100)\n",
      "tensor(85.6700)\n",
      "Round 201, reward -0.614\n",
      "tensor([0.0386, 0.0297, 0.0297, 0.2192, 0.2192, 0.0297, 0.2188, 0.1558, 0.0297,\n",
      "        0.0297])\n",
      "tensor(89.7900)\n",
      "tensor(95.)\n",
      "Round 202, reward -0.523\n",
      "tensor([0.0310, 0.0331, 0.0310, 0.1982, 0.2292, 0.0310, 0.1431, 0.0310, 0.0432,\n",
      "        0.2290])\n",
      "tensor(93.0100)\n",
      "tensor(90.9600)\n",
      "Round 203, reward -0.154\n",
      "tensor([0.1210, 0.0307, 0.1212, 0.1160, 0.1193, 0.1137, 0.1195, 0.0164, 0.1212,\n",
      "        0.1211])\n",
      "tensor(93.3900)\n",
      "tensor(93.9600)\n",
      "Round 204, reward -0.418\n",
      "tensor([0.0319, 0.0351, 0.2355, 0.0319, 0.0889, 0.0319, 0.2355, 0.0421, 0.0319,\n",
      "        0.2355])\n",
      "tensor(91.6900)\n",
      "tensor(93.7700)\n",
      "Round 205, reward -0.483\n",
      "tensor([0.1384, 0.1105, 0.1384, 0.0187, 0.0187, 0.1384, 0.0217, 0.1384, 0.1384,\n",
      "        0.1384])\n",
      "tensor(90.4500)\n",
      "tensor(91.6700)\n",
      "Round 206, reward -0.508\n",
      "tensor([0.0184, 0.0184, 0.1359, 0.0186, 0.1359, 0.1294, 0.1359, 0.1357, 0.1359,\n",
      "        0.1359])\n",
      "tensor(92.8700)\n",
      "tensor(95.1100)\n",
      "Round 207, reward -0.457\n",
      "tensor([0.0371, 0.0369, 0.0367, 0.0367, 0.1989, 0.2710, 0.0367, 0.0383, 0.2710,\n",
      "        0.0369])\n",
      "tensor(83.9700)\n",
      "tensor(91.6700)\n",
      "Round 208, reward -0.625\n",
      "tensor([0.0285, 0.0284, 0.2100, 0.1956, 0.0320, 0.0288, 0.2100, 0.2100, 0.0284,\n",
      "        0.0284])\n",
      "tensor(82.2900)\n",
      "tensor(93.5700)\n",
      "Round 209, reward -0.651\n",
      "tensor([0.0382, 0.2709, 0.0382, 0.0384, 0.0382, 0.0382, 0.2819, 0.0382, 0.1797,\n",
      "        0.0382])\n",
      "tensor(93.4500)\n",
      "tensor(92.7200)\n",
      "Round 210, reward -0.144\n",
      "tensor([0.0286, 0.1940, 0.2113, 0.0288, 0.0286, 0.0286, 0.2114, 0.0286, 0.2114,\n",
      "        0.0286])\n",
      "tensor(86.5900)\n",
      "tensor(94.2800)\n",
      "Round 211, reward -0.582\n",
      "tensor([0.0348, 0.0348, 0.2568, 0.2568, 0.0348, 0.0348, 0.0348, 0.2028, 0.0355,\n",
      "        0.0744])\n",
      "tensor(89.0900)\n",
      "tensor(90.3000)\n",
      "Round 212, reward -0.534\n",
      "tensor([0.2410, 0.0599, 0.0557, 0.2410, 0.0326, 0.2390, 0.0329, 0.0326, 0.0326,\n",
      "        0.0326])\n",
      "tensor(92.8300)\n",
      "tensor(94.7700)\n",
      "Round 213, reward -0.458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2071, 0.0280, 0.2071, 0.2071, 0.0280, 0.0280, 0.2071, 0.0280, 0.0280,\n",
      "        0.0314])\n",
      "tensor(91.6500)\n",
      "tensor(94.2600)\n",
      "Round 214, reward -0.484\n",
      "tensor([0.0342, 0.2517, 0.0420, 0.0342, 0.2489, 0.0342, 0.0342, 0.2524, 0.0342,\n",
      "        0.0342])\n",
      "tensor(93.1300)\n",
      "tensor(94.5800)\n",
      "Round 215, reward -0.451\n",
      "tensor([0.1321, 0.1328, 0.0666, 0.0190, 0.1328, 0.1328, 0.1264, 0.1328, 0.0191,\n",
      "        0.1059])\n",
      "tensor(88.7700)\n",
      "tensor(90.4900)\n",
      "Round 216, reward -0.542\n",
      "tensor([0.0207, 0.1532, 0.0208, 0.1357, 0.0207, 0.1532, 0.0718, 0.1532, 0.1177,\n",
      "        0.1530])\n",
      "tensor(89.6600)\n",
      "tensor(92.4300)\n",
      "Round 217, reward -0.525\n",
      "tensor([0.2099, 0.2012, 0.0284, 0.0284, 0.0284, 0.2086, 0.2099, 0.0284, 0.0284,\n",
      "        0.0284])\n",
      "tensor(87.0100)\n",
      "tensor(88.6100)\n",
      "Round 218, reward -0.574\n",
      "tensor([0.2088, 0.0284, 0.1902, 0.0963, 0.0283, 0.0283, 0.0835, 0.0283, 0.1010,\n",
      "        0.2071])\n",
      "tensor(83.8400)\n",
      "tensor(85.9500)\n",
      "Round 219, reward -0.627\n",
      "tensor([0.2778, 0.0463, 0.0463, 0.0463, 0.0463, 0.3417, 0.0463, 0.0566, 0.0463,\n",
      "        0.0463])\n",
      "tensor(89.0800)\n",
      "tensor(94.0600)\n",
      "Round 220, reward -0.537\n",
      "tensor([0.1563, 0.1561, 0.0212, 0.0212, 0.0212, 0.1368, 0.1537, 0.0212, 0.1563,\n",
      "        0.1563])\n",
      "tensor(93.2300)\n",
      "tensor(93.3600)\n",
      "Round 221, reward -0.275\n",
      "tensor([0.1520, 0.1377, 0.0221, 0.0217, 0.1603, 0.0225, 0.1603, 0.1414, 0.0217,\n",
      "        0.1603])\n",
      "tensor(87.1500)\n",
      "tensor(90.1100)\n",
      "Round 222, reward -0.572\n",
      "tensor([0.0203, 0.0502, 0.1502, 0.0205, 0.1375, 0.1502, 0.1502, 0.1502, 0.0203,\n",
      "        0.1502])\n",
      "tensor(94.5500)\n",
      "tensor(94.0300)\n",
      "Round 223, reward -0.118\n",
      "tensor([0.0244, 0.1805, 0.0244, 0.1805, 0.0244, 0.0293, 0.0244, 0.1805, 0.1805,\n",
      "        0.1510])\n",
      "tensor(94.1200)\n",
      "tensor(93.4400)\n",
      "Round 224, reward -0.129\n",
      "tensor([0.0203, 0.0203, 0.1498, 0.0447, 0.0209, 0.1498, 0.1447, 0.1498, 0.1498,\n",
      "        0.1498])\n",
      "tensor(90.9100)\n",
      "tensor(94.0800)\n",
      "Round 225, reward -0.500\n",
      "tensor([0.1574, 0.0213, 0.0213, 0.0286, 0.1574, 0.1205, 0.0213, 0.1574, 0.1574,\n",
      "        0.1574])\n",
      "tensor(86.2200)\n",
      "tensor(90.7800)\n",
      "Round 226, reward -0.589\n",
      "tensor([0.0479, 0.0447, 0.3221, 0.2853, 0.0587, 0.0447, 0.0447, 0.0449, 0.0447,\n",
      "        0.0624])\n",
      "tensor(87.2900)\n",
      "tensor(91.4900)\n",
      "Round 227, reward -0.570\n",
      "tensor([0.0272, 0.0272, 0.0272, 0.2011, 0.2009, 0.2011, 0.0609, 0.0273, 0.1999,\n",
      "        0.0272])\n",
      "tensor(95.2200)\n",
      "tensor(94.9500)\n",
      "Round 228, reward -0.102\n",
      "tensor([0.2039, 0.0283, 0.2088, 0.0283, 0.0283, 0.2088, 0.2088, 0.0283, 0.0285,\n",
      "        0.0283])\n",
      "tensor(87.6400)\n",
      "tensor(92.9500)\n",
      "Round 229, reward -0.564\n",
      "tensor([0.0343, 0.2064, 0.0280, 0.2064, 0.0279, 0.0279, 0.0282, 0.2064, 0.2064,\n",
      "        0.0280])\n",
      "tensor(83.6400)\n",
      "tensor(93.9400)\n",
      "Round 230, reward -0.630\n",
      "tensor([0.1145, 0.0890, 0.1145, 0.1145, 0.0367, 0.1144, 0.1145, 0.0966, 0.0910,\n",
      "        0.1145])\n",
      "tensor(93.5600)\n",
      "tensor(93.8800)\n",
      "Round 231, reward -0.362\n",
      "tensor([0.1446, 0.0290, 0.1445, 0.1446, 0.0644, 0.0196, 0.1446, 0.1446, 0.0197,\n",
      "        0.1446])\n",
      "tensor(93.6000)\n",
      "tensor(93.9800)\n",
      "Round 232, reward -0.379\n",
      "tensor([0.0245, 0.0245, 0.0245, 0.1806, 0.1806, 0.1806, 0.1552, 0.0244, 0.1806,\n",
      "        0.0244])\n",
      "tensor(88.3300)\n",
      "tensor(94.2600)\n",
      "Round 233, reward -0.551\n",
      "tensor([0.1918, 0.0260, 0.0942, 0.1920, 0.0260, 0.0260, 0.0260, 0.1921, 0.1921,\n",
      "        0.0338])\n",
      "tensor(88.8500)\n",
      "tensor(93.0400)\n",
      "Round 234, reward -0.541\n",
      "tensor([0.0925, 0.0191, 0.0402, 0.1403, 0.1407, 0.1407, 0.0190, 0.1407, 0.1262,\n",
      "        0.1407])\n",
      "tensor(93.0500)\n",
      "tensor(94.2800)\n",
      "Round 235, reward -0.452\n",
      "tensor([0.0300, 0.2214, 0.0300, 0.0496, 0.2213, 0.0300, 0.0300, 0.1411, 0.2167,\n",
      "        0.0300])\n",
      "tensor(92.6600)\n",
      "tensor(94.3900)\n",
      "Round 236, reward -0.462\n",
      "tensor([0.1187, 0.0164, 0.1212, 0.0164, 0.1212, 0.1211, 0.1212, 0.1212, 0.1212,\n",
      "        0.1212])\n",
      "tensor(95.2300)\n",
      "tensor(92.9800)\n",
      "Round 237, reward -0.102\n",
      "tensor([0.1418, 0.1418, 0.0192, 0.0999, 0.1418, 0.1418, 0.0192, 0.1417, 0.1335,\n",
      "        0.0192])\n",
      "tensor(89.0600)\n",
      "tensor(89.9900)\n",
      "Round 238, reward -0.531\n",
      "tensor([0.0241, 0.0253, 0.1784, 0.1784, 0.1784, 0.0242, 0.0241, 0.1717, 0.1712,\n",
      "        0.0241])\n",
      "tensor(93.2700)\n",
      "tensor(94.9900)\n",
      "Round 239, reward -0.448\n",
      "tensor([0.0627, 0.0243, 0.1681, 0.0247, 0.1567, 0.0354, 0.1456, 0.1792, 0.1790,\n",
      "        0.0244])\n",
      "tensor(95.4000)\n",
      "tensor(93.7000)\n",
      "Round 240, reward -0.097\n",
      "tensor([0.0238, 0.1761, 0.0240, 0.0238, 0.1741, 0.0239, 0.1761, 0.1761, 0.0260,\n",
      "        0.1761])\n",
      "tensor(91.9100)\n",
      "tensor(94.8800)\n",
      "Round 241, reward -0.479\n",
      "tensor([0.4485, 0.0608, 0.0615, 0.0612, 0.0608, 0.0608, 0.0609, 0.0612, 0.0608,\n",
      "        0.0635])\n",
      "tensor(88.2400)\n",
      "tensor(92.8600)\n",
      "Round 242, reward -0.553\n",
      "tensor([0.1755, 0.0319, 0.1756, 0.0238, 0.1756, 0.1599, 0.0238, 0.0238, 0.0346,\n",
      "        0.1756])\n",
      "tensor(92.7000)\n",
      "tensor(93.8000)\n",
      "Round 243, reward -0.458\n",
      "tensor([0.0472, 0.2437, 0.0348, 0.2350, 0.0633, 0.0330, 0.0330, 0.0330, 0.0330,\n",
      "        0.2439])\n",
      "tensor(93.0700)\n",
      "tensor(94.7300)\n",
      "Round 244, reward -0.453\n",
      "tensor([0.1398, 0.0277, 0.1401, 0.1401, 0.0658, 0.0190, 0.1401, 0.1401, 0.1401,\n",
      "        0.0471])\n",
      "tensor(94.6800)\n",
      "tensor(95.3500)\n",
      "Round 245, reward -0.397\n",
      "tensor([0.0826, 0.0243, 0.1098, 0.0243, 0.1792, 0.0243, 0.1784, 0.0243, 0.1737,\n",
      "        0.1792])\n",
      "tensor(94.6800)\n",
      "tensor(95.3800)\n",
      "Round 246, reward -0.399\n",
      "tensor([0.0236, 0.1729, 0.1743, 0.1744, 0.0352, 0.0236, 0.0236, 0.0236, 0.1744,\n",
      "        0.1744])\n",
      "tensor(91.7500)\n",
      "tensor(90.9700)\n",
      "Round 247, reward -0.182\n",
      "tensor([0.1642, 0.1771, 0.0240, 0.1770, 0.0316, 0.0241, 0.0240, 0.0240, 0.1771,\n",
      "        0.1771])\n",
      "tensor(92.4800)\n",
      "tensor(94.9300)\n",
      "Round 248, reward -0.466\n",
      "tensor([0.1030, 0.1113, 0.1113, 0.1113, 0.1107, 0.0156, 0.1048, 0.1113, 0.1113,\n",
      "        0.1096])\n",
      "tensor(87.7600)\n",
      "tensor(88.1400)\n",
      "Round 249, reward -0.500\n",
      "tensor([0.1439, 0.1843, 0.0250, 0.0251, 0.0250, 0.1774, 0.0280, 0.1811, 0.0252,\n",
      "        0.1851])\n",
      "tensor(89.0200)\n",
      "tensor(92.0400)\n",
      "Round 250, reward -0.538\n",
      "tensor([0.0403, 0.2980, 0.0758, 0.0403, 0.0420, 0.0403, 0.2979, 0.0846, 0.0403,\n",
      "        0.0403])\n",
      "tensor(90.3500)\n",
      "tensor(94.9100)\n",
      "Round 251, reward -0.512\n",
      "tensor([0.0404, 0.2047, 0.0279, 0.2047, 0.0281, 0.2047, 0.0277, 0.0277, 0.2046,\n",
      "        0.0296])\n",
      "tensor(93.6300)\n",
      "tensor(93.6500)\n",
      "Round 252, reward -0.164\n",
      "tensor([0.2056, 0.0289, 0.0292, 0.1930, 0.0292, 0.2137, 0.2136, 0.0289, 0.0289,\n",
      "        0.0289])\n",
      "tensor(93.0100)\n",
      "tensor(94.7000)\n",
      "Round 253, reward -0.454\n",
      "tensor([0.0547, 0.0528, 0.0519, 0.0532, 0.1957, 0.0519, 0.0519, 0.0520, 0.0519,\n",
      "        0.3838])\n",
      "tensor(93.0300)\n",
      "tensor(93.9100)\n",
      "Round 254, reward -0.446\n",
      "tensor([0.2007, 0.0272, 0.1961, 0.0406, 0.0272, 0.0849, 0.1089, 0.0391, 0.1911,\n",
      "        0.0841])\n",
      "tensor(95.2900)\n",
      "tensor(95.2000)\n",
      "Round 255, reward -0.100\n",
      "tensor([0.1526, 0.0207, 0.0212, 0.1527, 0.0207, 0.1529, 0.1528, 0.1528, 0.1529,\n",
      "        0.0207])\n",
      "tensor(93.6700)\n",
      "tensor(95.0900)\n",
      "Round 256, reward -0.438\n",
      "tensor([0.0333, 0.0333, 0.0333, 0.0627, 0.2459, 0.2459, 0.0333, 0.2459, 0.0333,\n",
      "        0.0333])\n",
      "tensor(91.2200)\n",
      "tensor(93.4700)\n",
      "Round 257, reward -0.493\n",
      "tensor([0.0251, 0.1851, 0.1851, 0.0251, 0.0251, 0.0278, 0.1851, 0.1353, 0.0251,\n",
      "        0.1813])\n",
      "tensor(94.5700)\n",
      "tensor(95.6400)\n",
      "Round 258, reward -0.414\n",
      "tensor([0.2584, 0.0350, 0.0362, 0.0350, 0.0350, 0.2390, 0.0362, 0.0356, 0.2546,\n",
      "        0.0350])\n",
      "tensor(92.7100)\n",
      "tensor(95.0200)\n",
      "Round 259, reward -0.461\n",
      "tensor([0.2120, 0.2120, 0.0288, 0.0288, 0.0288, 0.0288, 0.0288, 0.1902, 0.2129,\n",
      "        0.0288])\n",
      "tensor(94.7600)\n",
      "tensor(93.8900)\n",
      "Round 260, reward -0.113\n",
      "tensor([0.1815, 0.0287, 0.0246, 0.1815, 0.0271, 0.0964, 0.0778, 0.1739, 0.0375,\n",
      "        0.1710])\n",
      "tensor(94.1600)\n",
      "tensor(96.0700)\n",
      "Round 261, reward -0.428\n",
      "tensor([0.0248, 0.1833, 0.1833, 0.1609, 0.1658, 0.1825, 0.0248, 0.0248, 0.0248,\n",
      "        0.0248])\n",
      "tensor(92.7400)\n",
      "tensor(94.5100)\n",
      "Round 262, reward -0.460\n",
      "tensor([0.0520, 0.0386, 0.0342, 0.2510, 0.0656, 0.0941, 0.0359, 0.1420, 0.2524,\n",
      "        0.0342])\n",
      "tensor(90.7300)\n",
      "tensor(91.3500)\n",
      "Round 263, reward -0.481\n",
      "tensor([0.1173, 0.0228, 0.0481, 0.1364, 0.1376, 0.1685, 0.0228, 0.1686, 0.0229,\n",
      "        0.1549])\n",
      "tensor(90.0400)\n",
      "tensor(91.7000)\n",
      "Round 264, reward -0.517\n",
      "tensor([0.1542, 0.0209, 0.1542, 0.1541, 0.0209, 0.1542, 0.1461, 0.0209, 0.1537,\n",
      "        0.0209])\n",
      "tensor(89.8200)\n",
      "tensor(94.1200)\n",
      "Round 265, reward -0.522\n",
      "tensor([0.0206, 0.1526, 0.1524, 0.0231, 0.1526, 0.1524, 0.0206, 0.1526, 0.1526,\n",
      "        0.0206])\n",
      "tensor(94.3300)\n",
      "tensor(94.3900)\n",
      "Round 266, reward -0.190\n",
      "tensor([0.0595, 0.0272, 0.2011, 0.2011, 0.0272, 0.2010, 0.0272, 0.0272, 0.2011,\n",
      "        0.0272])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.9600)\n",
      "tensor(94.4600)\n",
      "Round 267, reward -0.108\n",
      "tensor([0.0283, 0.0284, 0.2093, 0.0283, 0.2025, 0.0283, 0.0283, 0.0283, 0.2089,\n",
      "        0.2093])\n",
      "tensor(94.3300)\n",
      "tensor(94.9900)\n",
      "Round 268, reward -0.404\n",
      "tensor([0.2077, 0.0281, 0.2077, 0.2076, 0.0288, 0.0281, 0.2075, 0.0281, 0.0282,\n",
      "        0.0281])\n",
      "tensor(92.6100)\n",
      "tensor(94.8800)\n",
      "Round 269, reward -0.463\n",
      "tensor([0.2054, 0.0278, 0.2054, 0.0278, 0.0278, 0.2054, 0.2054, 0.0394, 0.0278,\n",
      "        0.0278])\n",
      "tensor(93.2300)\n",
      "tensor(95.5300)\n",
      "Round 270, reward -0.449\n",
      "tensor([0.0186, 0.1189, 0.1376, 0.1376, 0.1376, 0.1376, 0.0186, 0.1374, 0.0186,\n",
      "        0.1376])\n",
      "tensor(95.4500)\n",
      "tensor(95.7100)\n",
      "Round 271, reward -0.294\n",
      "tensor([0.0184, 0.1358, 0.0184, 0.1343, 0.1315, 0.1358, 0.1358, 0.1358, 0.0184,\n",
      "        0.1358])\n",
      "tensor(95.5600)\n",
      "tensor(95.0600)\n",
      "Round 272, reward -0.093\n",
      "tensor([0.0371, 0.1982, 0.0371, 0.0371, 0.2745, 0.2672, 0.0372, 0.0371, 0.0371,\n",
      "        0.0372])\n",
      "tensor(95.1300)\n",
      "tensor(95.5500)\n",
      "Round 273, reward -0.352\n",
      "tensor([0.2066, 0.0324, 0.0280, 0.2070, 0.2070, 0.0280, 0.0280, 0.2068, 0.0281,\n",
      "        0.0282])\n",
      "tensor(93.9900)\n",
      "tensor(94.8600)\n",
      "Round 274, reward -0.424\n",
      "tensor([0.0514, 0.0614, 0.0514, 0.0514, 0.0514, 0.0514, 0.0514, 0.1993, 0.0514,\n",
      "        0.3796])\n",
      "tensor(85.6500)\n",
      "tensor(92.1100)\n",
      "Round 275, reward -0.598\n",
      "tensor([0.0383, 0.2822, 0.0383, 0.1469, 0.0580, 0.0383, 0.2831, 0.0383, 0.0383,\n",
      "        0.0383])\n",
      "tensor(94.6100)\n",
      "tensor(92.6100)\n",
      "Round 276, reward -0.117\n",
      "tensor([0.1738, 0.0311, 0.0238, 0.1754, 0.1740, 0.1754, 0.0237, 0.0237, 0.1754,\n",
      "        0.0237])\n",
      "tensor(93.8800)\n",
      "tensor(93.1800)\n",
      "Round 277, reward -0.134\n",
      "tensor([0.0625, 0.1351, 0.0191, 0.0530, 0.0357, 0.1378, 0.1408, 0.1392, 0.1358,\n",
      "        0.1408])\n",
      "tensor(93.7900)\n",
      "tensor(93.2300)\n",
      "Round 278, reward -0.136\n",
      "tensor([0.3070, 0.0416, 0.0946, 0.0416, 0.3070, 0.0415, 0.0415, 0.0415, 0.0415,\n",
      "        0.0422])\n",
      "tensor(92.7400)\n",
      "tensor(95.4700)\n",
      "Round 279, reward -0.460\n",
      "tensor([0.0237, 0.1532, 0.0522, 0.0237, 0.0237, 0.1749, 0.1751, 0.0237, 0.1749,\n",
      "        0.1749])\n",
      "tensor(92.4500)\n",
      "tensor(94.5300)\n",
      "Round 280, reward -0.467\n",
      "tensor([0.1524, 0.1524, 0.0206, 0.0285, 0.1523, 0.0206, 0.0206, 0.1524, 0.1478,\n",
      "        0.1524])\n",
      "tensor(92.6600)\n",
      "tensor(91.6500)\n",
      "Round 281, reward -0.162\n",
      "tensor([0.0428, 0.0430, 0.0429, 0.0428, 0.0444, 0.3164, 0.0428, 0.0657, 0.0428,\n",
      "        0.3164])\n",
      "tensor(92.4200)\n",
      "tensor(95.5600)\n",
      "Round 282, reward -0.468\n",
      "tensor([0.0271, 0.0658, 0.1999, 0.0271, 0.0271, 0.1994, 0.0272, 0.1890, 0.0382,\n",
      "        0.1994])\n",
      "tensor(89.3100)\n",
      "tensor(89.3000)\n",
      "Round 283, reward -0.232\n",
      "tensor([0.2019, 0.0274, 0.0500, 0.2019, 0.0273, 0.0273, 0.2019, 0.0332, 0.2019,\n",
      "        0.0273])\n",
      "tensor(91.3800)\n",
      "tensor(91.1700)\n",
      "Round 284, reward -0.190\n",
      "tensor([0.1762, 0.1762, 0.1762, 0.0238, 0.1762, 0.1760, 0.0238, 0.0238, 0.0238,\n",
      "        0.0238])\n",
      "tensor(94.6900)\n",
      "tensor(92.3800)\n",
      "Round 285, reward -0.115\n",
      "tensor([0.1529, 0.0207, 0.0207, 0.1529, 0.1528, 0.0207, 0.1529, 0.0208, 0.1529,\n",
      "        0.1529])\n",
      "tensor(95.8700)\n",
      "tensor(95.6200)\n",
      "Round 286, reward -0.085\n",
      "tensor([0.0194, 0.1434, 0.0194, 0.1433, 0.1316, 0.0937, 0.1431, 0.1434, 0.0194,\n",
      "        0.1434])\n",
      "tensor(93.7800)\n",
      "tensor(94.9100)\n",
      "Round 287, reward -0.434\n",
      "tensor([0.2532, 0.0343, 0.0343, 0.2532, 0.0343, 0.0343, 0.0343, 0.2528, 0.0351,\n",
      "        0.0343])\n",
      "tensor(84.6800)\n",
      "tensor(91.5000)\n",
      "Round 288, reward -0.614\n",
      "tensor([0.0255, 0.1031, 0.1775, 0.1884, 0.0255, 0.1763, 0.0644, 0.0255, 0.0255,\n",
      "        0.1883])\n",
      "tensor(90.1400)\n",
      "tensor(94.0900)\n",
      "Round 289, reward -0.516\n",
      "tensor([0.1590, 0.1590, 0.0215, 0.0215, 0.1590, 0.0218, 0.0215, 0.1434, 0.1574,\n",
      "        0.1357])\n",
      "tensor(94.6700)\n",
      "tensor(94.4800)\n",
      "Round 290, reward -0.115\n",
      "tensor([0.0274, 0.0274, 0.0585, 0.0444, 0.0274, 0.1860, 0.2024, 0.1971, 0.2021,\n",
      "        0.0274])\n",
      "tensor(93.5600)\n",
      "tensor(95.5900)\n",
      "Round 291, reward -0.442\n",
      "tensor([0.0349, 0.1796, 0.2575, 0.0349, 0.2576, 0.0349, 0.0349, 0.0349, 0.0349,\n",
      "        0.0962])\n",
      "tensor(94.8700)\n",
      "tensor(94.1400)\n",
      "Round 292, reward -0.110\n",
      "tensor([0.1960, 0.0314, 0.0736, 0.0266, 0.1969, 0.0266, 0.1969, 0.0275, 0.0276,\n",
      "        0.1969])\n",
      "tensor(91.6100)\n",
      "tensor(93.7000)\n",
      "Round 293, reward -0.485\n",
      "tensor([0.0342, 0.0342, 0.0342, 0.0342, 0.2527, 0.0344, 0.0368, 0.2527, 0.2523,\n",
      "        0.0342])\n",
      "tensor(94.5300)\n",
      "tensor(95.6700)\n",
      "Round 294, reward -0.416\n",
      "tensor([0.2216, 0.2216, 0.1552, 0.0300, 0.0300, 0.0300, 0.0300, 0.2215, 0.0302,\n",
      "        0.0300])\n",
      "tensor(84.4000)\n",
      "tensor(94.2200)\n",
      "Round 295, reward -0.619\n",
      "tensor([0.1530, 0.1530, 0.1530, 0.0207, 0.0211, 0.1518, 0.1529, 0.0207, 0.0207,\n",
      "        0.1530])\n",
      "tensor(95.3000)\n",
      "tensor(94.7600)\n",
      "Round 296, reward -0.100\n",
      "tensor([0.0396, 0.2921, 0.0396, 0.0472, 0.0396, 0.1095, 0.0558, 0.2925, 0.0445,\n",
      "        0.0396])\n",
      "tensor(90.0900)\n",
      "tensor(93.0400)\n",
      "Round 297, reward -0.517\n",
      "tensor([0.0747, 0.4443, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601,\n",
      "        0.0602])\n",
      "tensor(90.5200)\n",
      "tensor(92.7000)\n",
      "Round 298, reward -0.508\n",
      "tensor([0.1371, 0.1319, 0.1361, 0.0186, 0.0186, 0.1371, 0.0186, 0.1371, 0.1371,\n",
      "        0.1281])\n",
      "tensor(95.7700)\n",
      "tensor(95.0900)\n",
      "Round 299, reward -0.088\n",
      "tensor([0.1594, 0.1594, 0.1594, 0.0656, 0.0216, 0.0807, 0.0216, 0.1594, 0.0216,\n",
      "        0.1512])\n",
      "tensor(94.6600)\n",
      "tensor(95.2400)\n",
      "Round 300, reward -0.389\n",
      "tensor([0.0834, 0.0536, 0.0539, 0.0692, 0.0536, 0.3844, 0.1396, 0.0550, 0.0536,\n",
      "        0.0536])\n",
      "tensor(93.9400)\n",
      "tensor(95.1800)\n",
      "Round 301, reward -0.431\n",
      "tensor([0.0255, 0.1887, 0.0255, 0.0255, 0.0264, 0.0255, 0.1887, 0.1829, 0.1275,\n",
      "        0.1836])\n",
      "tensor(95.5100)\n",
      "tensor(95.5500)\n",
      "Round 302, reward -0.141\n",
      "tensor([0.0244, 0.1757, 0.0280, 0.0239, 0.1760, 0.1757, 0.0239, 0.0240, 0.1748,\n",
      "        0.1738])\n",
      "tensor(92.8500)\n",
      "tensor(93.7400)\n",
      "Round 303, reward -0.451\n",
      "tensor([0.0281, 0.0281, 0.2078, 0.2076, 0.2078, 0.0281, 0.0283, 0.2078, 0.0281,\n",
      "        0.0281])\n",
      "tensor(94.1600)\n",
      "tensor(95.6300)\n",
      "Round 304, reward -0.427\n",
      "tensor([0.1607, 0.0470, 0.3471, 0.0470, 0.0470, 0.1586, 0.0517, 0.0470, 0.0470,\n",
      "        0.0470])\n",
      "tensor(95.3700)\n",
      "tensor(96.2300)\n",
      "Round 305, reward -0.390\n",
      "tensor([0.0335, 0.2472, 0.0335, 0.2472, 0.0335, 0.0572, 0.0338, 0.2472, 0.0335,\n",
      "        0.0335])\n",
      "tensor(91.1100)\n",
      "tensor(92.8600)\n",
      "Round 306, reward -0.496\n",
      "tensor([0.0437, 0.0437, 0.0437, 0.0495, 0.3215, 0.0437, 0.0437, 0.0437, 0.0437,\n",
      "        0.3230])\n",
      "tensor(94.0400)\n",
      "tensor(96.0700)\n",
      "Round 307, reward -0.430\n",
      "tensor([0.1776, 0.0240, 0.1776, 0.1776, 0.0240, 0.1644, 0.0240, 0.0290, 0.1775,\n",
      "        0.0240])\n",
      "tensor(95.1000)\n",
      "tensor(96.1400)\n",
      "Round 308, reward -0.401\n",
      "tensor([0.0432, 0.0422, 0.0422, 0.0422, 0.0806, 0.0422, 0.0422, 0.0422, 0.3116,\n",
      "        0.3116])\n",
      "tensor(93.2700)\n",
      "tensor(94.3100)\n",
      "Round 309, reward -0.444\n",
      "tensor([0.1814, 0.1491, 0.1814, 0.0246, 0.0246, 0.0247, 0.1814, 0.1810, 0.0246,\n",
      "        0.0274])\n",
      "tensor(95.0400)\n",
      "tensor(95.1100)\n",
      "Round 310, reward -0.182\n",
      "tensor([0.1515, 0.1319, 0.1663, 0.0287, 0.1685, 0.0230, 0.0233, 0.0230, 0.1651,\n",
      "        0.1186])\n",
      "tensor(93.0700)\n",
      "tensor(90.5200)\n",
      "Round 311, reward -0.153\n",
      "tensor([0.0378, 0.2790, 0.0379, 0.0378, 0.0378, 0.1773, 0.2790, 0.0378, 0.0378,\n",
      "        0.0380])\n",
      "tensor(94.1400)\n",
      "tensor(95.6500)\n",
      "Round 312, reward -0.428\n",
      "tensor([0.0345, 0.0343, 0.0343, 0.0345, 0.0343, 0.2532, 0.0344, 0.2532, 0.2532,\n",
      "        0.0344])\n",
      "tensor(93.6400)\n",
      "tensor(95.9400)\n",
      "Round 313, reward -0.440\n",
      "tensor([0.0411, 0.0413, 0.0414, 0.0411, 0.2925, 0.0412, 0.3041, 0.1151, 0.0411,\n",
      "        0.0411])\n",
      "tensor(94.5500)\n",
      "tensor(95.2500)\n",
      "Round 314, reward -0.402\n",
      "tensor([0.0281, 0.2076, 0.2060, 0.0281, 0.2076, 0.0281, 0.0281, 0.0307, 0.0281,\n",
      "        0.2076])\n",
      "tensor(89.9300)\n",
      "tensor(95.4600)\n",
      "Round 315, reward -0.520\n",
      "tensor([0.0782, 0.0441, 0.0441, 0.0441, 0.0441, 0.2875, 0.0443, 0.0448, 0.3249,\n",
      "        0.0441])\n",
      "tensor(93.1300)\n",
      "tensor(95.9100)\n",
      "Round 316, reward -0.452\n",
      "tensor([0.0499, 0.0499, 0.0499, 0.0499, 0.3686, 0.0499, 0.2262, 0.0499, 0.0499,\n",
      "        0.0558])\n",
      "tensor(84.0800)\n",
      "tensor(87.1700)\n",
      "Round 317, reward -0.624\n",
      "tensor([0.0351, 0.0728, 0.0351, 0.0351, 0.2592, 0.0351, 0.0351, 0.0351, 0.2592,\n",
      "        0.1983])\n",
      "tensor(80.2000)\n",
      "tensor(94.2400)\n",
      "Round 318, reward -0.680\n",
      "tensor([0.0610, 0.0610, 0.0610, 0.0612, 0.0610, 0.0610, 0.0610, 0.0610, 0.0610,\n",
      "        0.4507])\n",
      "tensor(93.6600)\n",
      "tensor(92.9600)\n",
      "Round 319, reward -0.139\n",
      "tensor([0.0609, 0.0611, 0.0609, 0.0609, 0.0612, 0.0609, 0.4503, 0.0618, 0.0609,\n",
      "        0.0609])\n",
      "tensor(91.1400)\n",
      "tensor(94.5000)\n",
      "Round 320, reward -0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2312, 0.0427, 0.0427, 0.3157, 0.0463, 0.1429, 0.0432, 0.0427, 0.0498,\n",
      "        0.0428])\n",
      "tensor(95.2500)\n",
      "tensor(96.0300)\n",
      "Round 321, reward -0.389\n",
      "tensor([0.0236, 0.1730, 0.0234, 0.0234, 0.1730, 0.0411, 0.1730, 0.1730, 0.0234,\n",
      "        0.1730])\n",
      "tensor(94.7800)\n",
      "tensor(95.9400)\n",
      "Round 322, reward -0.410\n",
      "tensor([0.1287, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0708, 0.2847, 0.0385,\n",
      "        0.2847])\n",
      "tensor(90.6000)\n",
      "tensor(96.4300)\n",
      "Round 323, reward -0.506\n",
      "tensor([0.1359, 0.2364, 0.0352, 0.0352, 0.1550, 0.0354, 0.0352, 0.0352, 0.2597,\n",
      "        0.0370])\n",
      "tensor(93.9300)\n",
      "tensor(95.1600)\n",
      "Round 324, reward -0.431\n",
      "tensor([0.2232, 0.0304, 0.2246, 0.0322, 0.0304, 0.0304, 0.0357, 0.0304, 0.1924,\n",
      "        0.1702])\n",
      "tensor(89.6700)\n",
      "tensor(93.6300)\n",
      "Round 325, reward -0.525\n",
      "tensor([0.0439, 0.0439, 0.0439, 0.0439, 0.0439, 0.0670, 0.0439, 0.0439, 0.3015,\n",
      "        0.3243])\n",
      "tensor(91.9100)\n",
      "tensor(93.0700)\n",
      "Round 326, reward -0.476\n",
      "tensor([0.3231, 0.0437, 0.3231, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
      "        0.0477])\n",
      "tensor(94.5600)\n",
      "tensor(94.4400)\n",
      "Round 327, reward -0.118\n",
      "tensor([0.1826, 0.1826, 0.0247, 0.0247, 0.0247, 0.1461, 0.0247, 0.1826, 0.0247,\n",
      "        0.1826])\n",
      "tensor(94.8400)\n",
      "tensor(95.7600)\n",
      "Round 328, reward -0.405\n",
      "tensor([0.0515, 0.2132, 0.0517, 0.0632, 0.0515, 0.0518, 0.0515, 0.3624, 0.0515,\n",
      "        0.0515])\n",
      "tensor(85.9800)\n",
      "tensor(95.0800)\n",
      "Round 329, reward -0.593\n",
      "tensor([0.0380, 0.0464, 0.2248, 0.0349, 0.0349, 0.2581, 0.0349, 0.2581, 0.0350,\n",
      "        0.0349])\n",
      "tensor(95.0700)\n",
      "tensor(94.3900)\n",
      "Round 330, reward -0.106\n",
      "tensor([0.0371, 0.0368, 0.0534, 0.2721, 0.0368, 0.0368, 0.0794, 0.0368, 0.2720,\n",
      "        0.1387])\n",
      "tensor(94.6700)\n",
      "tensor(96.1000)\n",
      "Round 331, reward -0.415\n",
      "tensor([0.1927, 0.0264, 0.1904, 0.0277, 0.1531, 0.1929, 0.1385, 0.0261, 0.0261,\n",
      "        0.0261])\n",
      "tensor(94.6800)\n",
      "tensor(95.4900)\n",
      "Round 332, reward -0.405\n",
      "tensor([0.0558, 0.0990, 0.0602, 0.0561, 0.0558, 0.0559, 0.0562, 0.4049, 0.0559,\n",
      "        0.1004])\n",
      "tensor(87.3100)\n",
      "tensor(94.9500)\n",
      "Round 333, reward -0.570\n",
      "tensor([0.0499, 0.0500, 0.0800, 0.0499, 0.0499, 0.0499, 0.0499, 0.2056, 0.0499,\n",
      "        0.3648])\n",
      "tensor(91.6600)\n",
      "tensor(92.5000)\n",
      "Round 334, reward -0.475\n",
      "tensor([0.1526, 0.1528, 0.0207, 0.0210, 0.1528, 0.1528, 0.0207, 0.1527, 0.1528,\n",
      "        0.0213])\n",
      "tensor(94.5900)\n",
      "tensor(94.7700)\n",
      "Round 335, reward -0.275\n",
      "tensor([0.2234, 0.0307, 0.2266, 0.0307, 0.0503, 0.0307, 0.0307, 0.1196, 0.0307,\n",
      "        0.2266])\n",
      "tensor(93.8700)\n",
      "tensor(96.1600)\n",
      "Round 336, reward -0.434\n",
      "tensor([0.0299, 0.0299, 0.0300, 0.1571, 0.0299, 0.2211, 0.0299, 0.2211, 0.2211,\n",
      "        0.0301])\n",
      "tensor(89.3700)\n",
      "tensor(92.2200)\n",
      "Round 337, reward -0.531\n",
      "tensor([0.0438, 0.0439, 0.3233, 0.0438, 0.3010, 0.0438, 0.0499, 0.0438, 0.0438,\n",
      "        0.0631])\n",
      "tensor(85.8400)\n",
      "tensor(96.4000)\n",
      "Round 338, reward -0.595\n",
      "tensor([0.2658, 0.0360, 0.1790, 0.0363, 0.0360, 0.0390, 0.0702, 0.0360, 0.2658,\n",
      "        0.0360])\n",
      "tensor(92.4900)\n",
      "tensor(95.2800)\n",
      "Round 339, reward -0.466\n",
      "tensor([0.4502, 0.0615, 0.0615, 0.0609, 0.0609, 0.0609, 0.0609, 0.0609, 0.0610,\n",
      "        0.0612])\n",
      "tensor(95.0300)\n",
      "tensor(95.8800)\n",
      "Round 340, reward -0.398\n",
      "tensor([0.0303, 0.0303, 0.0303, 0.0303, 0.0303, 0.2178, 0.2236, 0.1532, 0.2236,\n",
      "        0.0303])\n",
      "tensor(95.4700)\n",
      "tensor(96.0100)\n",
      "Round 341, reward -0.364\n",
      "tensor([0.0618, 0.0336, 0.2343, 0.2483, 0.0384, 0.0343, 0.0337, 0.0336, 0.2483,\n",
      "        0.0336])\n",
      "tensor(95.2900)\n",
      "tensor(95.8100)\n",
      "Round 342, reward -0.366\n",
      "tensor([0.0328, 0.0331, 0.1695, 0.2427, 0.0328, 0.0328, 0.0329, 0.0328, 0.2423,\n",
      "        0.1481])\n",
      "tensor(92.3200)\n",
      "tensor(94.5000)\n",
      "Round 343, reward -0.470\n",
      "tensor([0.0761, 0.0420, 0.0319, 0.2355, 0.2322, 0.0506, 0.0322, 0.2357, 0.0319,\n",
      "        0.0319])\n",
      "tensor(92.1000)\n",
      "tensor(94.7000)\n",
      "Round 344, reward -0.475\n",
      "tensor([0.1633, 0.0837, 0.0371, 0.0376, 0.2438, 0.0486, 0.0372, 0.0371, 0.0377,\n",
      "        0.2740])\n",
      "tensor(94.4800)\n",
      "tensor(95.2700)\n",
      "Round 345, reward -0.409\n",
      "tensor([0.0390, 0.1042, 0.0390, 0.2832, 0.0390, 0.0390, 0.0597, 0.2883, 0.0695,\n",
      "        0.0390])\n",
      "tensor(95.3100)\n",
      "tensor(94.8500)\n",
      "Round 346, reward -0.100\n",
      "tensor([0.0438, 0.0444, 0.0438, 0.0438, 0.3233, 0.0438, 0.0438, 0.3234, 0.0438,\n",
      "        0.0462])\n",
      "tensor(95.5700)\n",
      "tensor(95.5900)\n",
      "Round 347, reward -0.117\n",
      "tensor([0.1969, 0.0285, 0.0285, 0.0286, 0.0285, 0.2103, 0.0285, 0.2103, 0.0317,\n",
      "        0.2083])\n",
      "tensor(95.8500)\n",
      "tensor(95.7700)\n",
      "Round 348, reward -0.086\n",
      "tensor([0.0293, 0.2128, 0.0293, 0.1763, 0.0337, 0.2101, 0.0293, 0.0334, 0.0293,\n",
      "        0.2165])\n",
      "tensor(95.3000)\n",
      "tensor(95.8100)\n",
      "Round 349, reward -0.364\n",
      "tensor([0.1903, 0.0257, 0.0257, 0.0258, 0.1901, 0.0262, 0.0257, 0.1141, 0.1899,\n",
      "        0.1864])\n",
      "tensor(95.3400)\n",
      "tensor(95.9000)\n",
      "Round 350, reward -0.370\n",
      "tensor([0.2624, 0.0356, 0.0356, 0.0355, 0.0355, 0.1861, 0.0388, 0.0387, 0.0693,\n",
      "        0.2624])\n",
      "tensor(92.6100)\n",
      "tensor(95.8400)\n",
      "Round 351, reward -0.463\n",
      "tensor([0.0398, 0.1337, 0.2930, 0.0396, 0.0404, 0.0397, 0.0412, 0.0397, 0.2930,\n",
      "        0.0400])\n",
      "tensor(91.8300)\n",
      "tensor(93.3100)\n",
      "Round 352, reward -0.480\n",
      "tensor([0.1765, 0.0239, 0.1765, 0.0239, 0.1750, 0.0239, 0.1765, 0.0239, 0.0270,\n",
      "        0.1729])\n",
      "tensor(95.1700)\n",
      "tensor(95.5700)\n",
      "Round 353, reward -0.346\n",
      "tensor([0.0276, 0.0701, 0.0991, 0.1317, 0.1476, 0.2038, 0.0276, 0.2042, 0.0606,\n",
      "        0.0276])\n",
      "tensor(94.3200)\n",
      "tensor(96.1900)\n",
      "Round 354, reward -0.424\n",
      "tensor([0.1385, 0.1385, 0.1385, 0.1121, 0.0187, 0.0199, 0.1385, 0.0187, 0.1384,\n",
      "        0.1383])\n",
      "tensor(94.5400)\n",
      "tensor(95.2600)\n",
      "Round 355, reward -0.403\n",
      "tensor([0.0278, 0.0278, 0.2051, 0.0892, 0.1501, 0.0278, 0.0343, 0.0278, 0.2051,\n",
      "        0.2051])\n",
      "tensor(91.8200)\n",
      "tensor(93.2500)\n",
      "Round 356, reward -0.480\n",
      "tensor([0.0201, 0.1488, 0.1488, 0.0201, 0.0252, 0.1487, 0.0455, 0.1450, 0.1488,\n",
      "        0.1488])\n",
      "tensor(95.0800)\n",
      "tensor(95.8000)\n",
      "Round 357, reward -0.390\n",
      "tensor([0.0449, 0.3319, 0.0449, 0.0453, 0.0450, 0.0449, 0.3083, 0.0449, 0.0449,\n",
      "        0.0449])\n",
      "tensor(95.7100)\n",
      "tensor(96.6900)\n",
      "Round 358, reward -0.384\n",
      "tensor([0.1326, 0.1329, 0.1329, 0.1329, 0.0180, 0.0489, 0.1305, 0.1329, 0.1203,\n",
      "        0.0180])\n",
      "tensor(93.6900)\n",
      "tensor(94.9700)\n",
      "Round 359, reward -0.437\n",
      "tensor([0.2402, 0.0332, 0.1722, 0.0332, 0.2450, 0.1415, 0.0333, 0.0332, 0.0333,\n",
      "        0.0351])\n",
      "tensor(96.0700)\n",
      "tensor(95.0300)\n",
      "Round 360, reward -0.080\n",
      "tensor([0.1819, 0.0246, 0.1819, 0.0246, 0.1539, 0.0247, 0.1808, 0.0263, 0.1766,\n",
      "        0.0246])\n",
      "tensor(92.7600)\n",
      "tensor(95.2500)\n",
      "Round 361, reward -0.460\n",
      "tensor([0.0326, 0.0326, 0.1787, 0.2407, 0.0326, 0.1443, 0.0326, 0.0326, 0.2407,\n",
      "        0.0328])\n",
      "tensor(91.7400)\n",
      "tensor(93.8800)\n",
      "Round 362, reward -0.482\n",
      "tensor([0.0367, 0.0349, 0.0633, 0.0349, 0.2324, 0.0349, 0.2554, 0.0349, 0.0349,\n",
      "        0.2376])\n",
      "tensor(94.9200)\n",
      "tensor(93.1900)\n",
      "Round 363, reward -0.109\n",
      "tensor([0.0354, 0.2545, 0.0436, 0.2393, 0.2545, 0.0344, 0.0346, 0.0347, 0.0344,\n",
      "        0.0344])\n",
      "tensor(90.3900)\n",
      "tensor(95.9100)\n",
      "Round 364, reward -0.511\n",
      "tensor([0.1874, 0.2175, 0.1876, 0.0295, 0.0307, 0.0294, 0.0297, 0.0294, 0.2176,\n",
      "        0.0412])\n",
      "tensor(92.1700)\n",
      "tensor(95.8900)\n",
      "Round 365, reward -0.473\n",
      "tensor([0.0433, 0.3129, 0.0433, 0.0433, 0.3199, 0.0433, 0.0641, 0.0433, 0.0433,\n",
      "        0.0433])\n",
      "tensor(89.1600)\n",
      "tensor(95.1100)\n",
      "Round 366, reward -0.535\n",
      "tensor([0.1847, 0.0250, 0.0250, 0.1388, 0.1847, 0.0284, 0.1787, 0.1847, 0.0250,\n",
      "        0.0250])\n",
      "tensor(94.9400)\n",
      "tensor(96.0300)\n",
      "Round 367, reward -0.406\n",
      "tensor([0.1749, 0.1749, 0.0276, 0.0277, 0.1749, 0.1736, 0.0237, 0.0240, 0.0240,\n",
      "        0.1749])\n",
      "tensor(94.6400)\n",
      "tensor(95.4200)\n",
      "Round 368, reward -0.404\n",
      "tensor([0.0434, 0.0434, 0.0480, 0.3204, 0.0434, 0.0434, 0.0509, 0.3204, 0.0434,\n",
      "        0.0434])\n",
      "tensor(94.1800)\n",
      "tensor(96.3000)\n",
      "Round 369, reward -0.427\n",
      "tensor([0.0438, 0.0438, 0.0469, 0.0438, 0.0438, 0.0438, 0.3234, 0.3234, 0.0438,\n",
      "        0.0438])\n",
      "tensor(90.3900)\n",
      "tensor(94.7600)\n",
      "Round 370, reward -0.511\n",
      "tensor([0.0501, 0.0501, 0.0501, 0.0501, 0.0501, 0.0561, 0.2226, 0.0501, 0.0501,\n",
      "        0.3704])\n",
      "tensor(88.6900)\n",
      "tensor(87.9400)\n",
      "Round 371, reward -0.244\n",
      "tensor([0.0881, 0.0589, 0.0589, 0.0589, 0.0589, 0.0589, 0.0589, 0.4352, 0.0605,\n",
      "        0.0627])\n",
      "tensor(90.1000)\n",
      "tensor(96.5000)\n",
      "Round 372, reward -0.517\n",
      "tensor([0.2289, 0.1176, 0.2289, 0.0314, 0.0310, 0.2289, 0.0330, 0.0384, 0.0310,\n",
      "        0.0310])\n",
      "tensor(94.5300)\n",
      "tensor(95.8900)\n",
      "Round 373, reward -0.418\n",
      "tensor([0.0284, 0.0284, 0.0284, 0.2009, 0.0284, 0.2097, 0.0284, 0.2074, 0.0303,\n",
      "        0.2097])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95.7800)\n",
      "tensor(96.5800)\n",
      "Round 374, reward -0.377\n",
      "tensor([0.2454, 0.0346, 0.0346, 0.2543, 0.2525, 0.0346, 0.0346, 0.0366, 0.0376,\n",
      "        0.0354])\n",
      "tensor(95.3200)\n",
      "tensor(96.5800)\n",
      "Round 375, reward -0.398\n",
      "tensor([0.2523, 0.0348, 0.0341, 0.2523, 0.0341, 0.0353, 0.0346, 0.2519, 0.0364,\n",
      "        0.0341])\n",
      "tensor(93.6400)\n",
      "tensor(95.6500)\n",
      "Round 376, reward -0.440\n",
      "tensor([0.0522, 0.0522, 0.1367, 0.0522, 0.0541, 0.0525, 0.3854, 0.0522, 0.0522,\n",
      "        0.1103])\n",
      "tensor(95.8400)\n",
      "tensor(96.6600)\n",
      "Round 377, reward -0.376\n",
      "tensor([0.0382, 0.0380, 0.0381, 0.0381, 0.0380, 0.1710, 0.2811, 0.0382, 0.0380,\n",
      "        0.2811])\n",
      "tensor(89.4300)\n",
      "tensor(96.3100)\n",
      "Round 378, reward -0.530\n",
      "tensor([0.0462, 0.0461, 0.0461, 0.0462, 0.2898, 0.0461, 0.0461, 0.0461, 0.3410,\n",
      "        0.0461])\n",
      "tensor(94.9900)\n",
      "tensor(95.8600)\n",
      "Round 379, reward -0.399\n",
      "tensor([0.0393, 0.1775, 0.0292, 0.2157, 0.0292, 0.0292, 0.2157, 0.0292, 0.2058,\n",
      "        0.0292])\n",
      "tensor(95.0400)\n",
      "tensor(94.3800)\n",
      "Round 380, reward -0.106\n",
      "tensor([0.0512, 0.0246, 0.0246, 0.1815, 0.1815, 0.1247, 0.0246, 0.0246, 0.1815,\n",
      "        0.1814])\n",
      "tensor(95.1500)\n",
      "tensor(94.8900)\n",
      "Round 381, reward -0.104\n",
      "tensor([0.0362, 0.2137, 0.0405, 0.0365, 0.0362, 0.0368, 0.0362, 0.0362, 0.2605,\n",
      "        0.2672])\n",
      "tensor(95.1600)\n",
      "tensor(96.3200)\n",
      "Round 382, reward -0.401\n",
      "tensor([0.1524, 0.1524, 0.1524, 0.0206, 0.0221, 0.1524, 0.0221, 0.1524, 0.0206,\n",
      "        0.1524])\n",
      "tensor(94.3400)\n",
      "tensor(95.9900)\n",
      "Round 383, reward -0.423\n",
      "tensor([0.1791, 0.0242, 0.0259, 0.0242, 0.1791, 0.1791, 0.0342, 0.0242, 0.1656,\n",
      "        0.1643])\n",
      "tensor(88.3100)\n",
      "tensor(91.6300)\n",
      "Round 384, reward -0.551\n",
      "tensor([0.0679, 0.0606, 0.0606, 0.0606, 0.0606, 0.0606, 0.0610, 0.4471, 0.0606,\n",
      "        0.0606])\n",
      "tensor(94.7000)\n",
      "tensor(96.2700)\n",
      "Round 385, reward -0.414\n",
      "tensor([0.0447, 0.1980, 0.3300, 0.1443, 0.0447, 0.0447, 0.0569, 0.0447, 0.0475,\n",
      "        0.0447])\n",
      "tensor(93.7400)\n",
      "tensor(95.9300)\n",
      "Round 386, reward -0.438\n",
      "tensor([0.0394, 0.0394, 0.0394, 0.0396, 0.0395, 0.2896, 0.0877, 0.2907, 0.0953,\n",
      "        0.0396])\n",
      "tensor(95.6200)\n",
      "tensor(94.9900)\n",
      "Round 387, reward -0.092\n",
      "tensor([0.0441, 0.0441, 0.0441, 0.3262, 0.0441, 0.0442, 0.0442, 0.3206, 0.0441,\n",
      "        0.0441])\n",
      "tensor(92.4600)\n",
      "tensor(94.8500)\n",
      "Round 388, reward -0.467\n",
      "tensor([0.0351, 0.2389, 0.0351, 0.0350, 0.0351, 0.2568, 0.0350, 0.0350, 0.2589,\n",
      "        0.0350])\n",
      "tensor(93.5900)\n",
      "tensor(95.7600)\n",
      "Round 389, reward -0.441\n",
      "tensor([0.1337, 0.0898, 0.0901, 0.1472, 0.0898, 0.0898, 0.0899, 0.0898, 0.0899,\n",
      "        0.0898])\n",
      "tensor(91.0200)\n",
      "tensor(92.9900)\n",
      "Round 390, reward -0.498\n",
      "tensor([0.0335, 0.0342, 0.1408, 0.2395, 0.0335, 0.0335, 0.2476, 0.1670, 0.0368,\n",
      "        0.0335])\n",
      "tensor(94.6300)\n",
      "tensor(94.4900)\n",
      "Round 391, reward -0.116\n",
      "tensor([0.0319, 0.2357, 0.2358, 0.0327, 0.2342, 0.0319, 0.0319, 0.0319, 0.1019,\n",
      "        0.0320])\n",
      "tensor(94.8500)\n",
      "tensor(94.7800)\n",
      "Round 392, reward -0.111\n",
      "tensor([0.0441, 0.0451, 0.0453, 0.0436, 0.3225, 0.0437, 0.0436, 0.3225, 0.0439,\n",
      "        0.0458])\n",
      "tensor(89.8300)\n",
      "tensor(93.4500)\n",
      "Round 393, reward -0.522\n",
      "tensor([0.0238, 0.1755, 0.1755, 0.0238, 0.1755, 0.0238, 0.1599, 0.0238, 0.0431,\n",
      "        0.1755])\n",
      "tensor(95.6800)\n",
      "tensor(94.3500)\n",
      "Round 394, reward -0.090\n",
      "tensor([0.0347, 0.2525, 0.2513, 0.0342, 0.0342, 0.2524, 0.0383, 0.0342, 0.0342,\n",
      "        0.0342])\n",
      "tensor(92.3300)\n",
      "tensor(96.4700)\n",
      "Round 395, reward -0.470\n",
      "tensor([0.0610, 0.0610, 0.0616, 0.0610, 0.0610, 0.0610, 0.4504, 0.0613, 0.0610,\n",
      "        0.0610])\n",
      "tensor(89.1900)\n",
      "tensor(94.7100)\n",
      "Round 396, reward -0.535\n",
      "tensor([0.0609, 0.0300, 0.1838, 0.0300, 0.0300, 0.2128, 0.2213, 0.0300, 0.1714,\n",
      "        0.0300])\n",
      "tensor(95.7200)\n",
      "tensor(94.5900)\n",
      "Round 397, reward -0.089\n",
      "tensor([0.3086, 0.0418, 0.0418, 0.0418, 0.0418, 0.0895, 0.0427, 0.0418, 0.3086,\n",
      "        0.0418])\n",
      "tensor(94.9200)\n",
      "tensor(95.8200)\n",
      "Round 398, reward -0.402\n",
      "tensor([0.0326, 0.0326, 0.2395, 0.2392, 0.2398, 0.0809, 0.0326, 0.0326, 0.0375,\n",
      "        0.0326])\n",
      "tensor(96.1500)\n",
      "tensor(96.4900)\n",
      "Round 399, reward -0.305\n",
      "tensor([0.0231, 0.0279, 0.1703, 0.0231, 0.1705, 0.1704, 0.1706, 0.0503, 0.0231,\n",
      "        0.1706])\n",
      "tensor(95.7800)\n",
      "tensor(96.1800)\n",
      "Round 400, reward -0.331\n",
      "tensor([0.1381, 0.0413, 0.3053, 0.2095, 0.0413, 0.0413, 0.0991, 0.0413, 0.0413,\n",
      "        0.0413])\n",
      "tensor(95.8200)\n",
      "tensor(94.5500)\n",
      "Round 401, reward -0.087\n",
      "tensor([0.2913, 0.0399, 0.0496, 0.0403, 0.1041, 0.0401, 0.0399, 0.2947, 0.0399,\n",
      "        0.0601])\n",
      "tensor(94.7600)\n",
      "tensor(95.5300)\n",
      "Round 402, reward -0.401\n",
      "tensor([0.3198, 0.0441, 0.0433, 0.0433, 0.0434, 0.0433, 0.0433, 0.0433, 0.3198,\n",
      "        0.0564])\n",
      "tensor(94.8100)\n",
      "tensor(96.3500)\n",
      "Round 403, reward -0.411\n",
      "tensor([0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.2535, 0.0343, 0.2535, 0.0343,\n",
      "        0.2529])\n",
      "tensor(93.4000)\n",
      "tensor(95.6900)\n",
      "Round 404, reward -0.445\n",
      "tensor([0.0358, 0.0374, 0.0633, 0.0358, 0.0358, 0.1795, 0.0358, 0.2624, 0.2642,\n",
      "        0.0501])\n",
      "tensor(90.0700)\n",
      "tensor(92.7900)\n",
      "Round 405, reward -0.517\n",
      "tensor([0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.0610, 0.4505, 0.0613,\n",
      "        0.0614])\n",
      "tensor(96.1900)\n",
      "tensor(94.4600)\n",
      "Round 406, reward -0.077\n",
      "tensor([0.1887, 0.2103, 0.0378, 0.0285, 0.0285, 0.2104, 0.2104, 0.0285, 0.0285,\n",
      "        0.0285])\n",
      "tensor(94.7100)\n",
      "tensor(95.4300)\n",
      "Round 407, reward -0.399\n",
      "tensor([0.1771, 0.0291, 0.2150, 0.1946, 0.0291, 0.0291, 0.0291, 0.0525, 0.0298,\n",
      "        0.2145])\n",
      "tensor(94.3400)\n",
      "tensor(96.4700)\n",
      "Round 408, reward -0.423\n",
      "tensor([0.0440, 0.2008, 0.0504, 0.0440, 0.1225, 0.3252, 0.0440, 0.0440, 0.0810,\n",
      "        0.0440])\n",
      "tensor(93.5900)\n",
      "tensor(94.9700)\n",
      "Round 409, reward -0.440\n",
      "tensor([0.2495, 0.0338, 0.2437, 0.2368, 0.0339, 0.0343, 0.0338, 0.0339, 0.0666,\n",
      "        0.0338])\n",
      "tensor(94.0800)\n",
      "tensor(95.6400)\n",
      "Round 410, reward -0.429\n",
      "tensor([0.0385, 0.2833, 0.0390, 0.0383, 0.2831, 0.0385, 0.0551, 0.0383, 0.0383,\n",
      "        0.1475])\n",
      "tensor(95.9100)\n",
      "tensor(96.3000)\n",
      "Round 411, reward -0.325\n",
      "tensor([0.0600, 0.0600, 0.0600, 0.4430, 0.0600, 0.0624, 0.0610, 0.0600, 0.0600,\n",
      "        0.0739])\n",
      "tensor(93.2800)\n",
      "tensor(93.0400)\n",
      "Round 412, reward -0.148\n",
      "tensor([0.1600, 0.1629, 0.1629, 0.0311, 0.0220, 0.0221, 0.1453, 0.1093, 0.0220,\n",
      "        0.1624])\n",
      "tensor(96.0300)\n",
      "tensor(95.5100)\n",
      "Round 413, reward -0.081\n",
      "tensor([0.0697, 0.2066, 0.0415, 0.1568, 0.2066, 0.0280, 0.0280, 0.2067, 0.0280,\n",
      "        0.0280])\n",
      "tensor(94.4700)\n",
      "tensor(96.0900)\n",
      "Round 414, reward -0.420\n",
      "tensor([0.0600, 0.0600, 0.0604, 0.0600, 0.4432, 0.0600, 0.0600, 0.0672, 0.0691,\n",
      "        0.0600])\n",
      "tensor(95.2000)\n",
      "tensor(96.1700)\n",
      "Round 415, reward -0.397\n",
      "tensor([0.0212, 0.1566, 0.1566, 0.0212, 0.0212, 0.1566, 0.1320, 0.0212, 0.1566,\n",
      "        0.1566])\n",
      "tensor(90.0700)\n",
      "tensor(92.7400)\n",
      "Round 416, reward -0.517\n",
      "tensor([0.0345, 0.0345, 0.2549, 0.2550, 0.0345, 0.1960, 0.0345, 0.0345, 0.0870,\n",
      "        0.0345])\n",
      "tensor(91.7900)\n",
      "tensor(92.6400)\n",
      "Round 417, reward -0.473\n",
      "tensor([0.0325, 0.1984, 0.2003, 0.1752, 0.0318, 0.2344, 0.0319, 0.0319, 0.0318,\n",
      "        0.0317])\n",
      "tensor(95.7000)\n",
      "tensor(95.9400)\n",
      "Round 418, reward -0.279\n",
      "tensor([0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.0611, 0.4500,\n",
      "        0.0611])\n",
      "tensor(90.3600)\n",
      "tensor(96.6500)\n",
      "Round 419, reward -0.511\n",
      "tensor([0.1639, 0.0222, 0.1639, 0.0222, 0.0934, 0.0222, 0.1634, 0.1624, 0.0225,\n",
      "        0.1639])\n",
      "tensor(92.5100)\n",
      "tensor(94.9800)\n",
      "Round 420, reward -0.466\n",
      "tensor([0.2505, 0.2312, 0.0339, 0.0358, 0.2503, 0.0339, 0.0343, 0.0339, 0.0354,\n",
      "        0.0609])\n",
      "tensor(85.8800)\n",
      "tensor(92.6400)\n",
      "Round 421, reward -0.594\n",
      "tensor([0.0945, 0.0615, 0.0586, 0.0587, 0.4333, 0.0586, 0.0586, 0.0586, 0.0588,\n",
      "        0.0586])\n",
      "tensor(85.9000)\n",
      "tensor(88.4400)\n",
      "Round 422, reward -0.594\n",
      "tensor([0.0442, 0.0443, 0.0442, 0.0442, 0.0445, 0.3196, 0.0442, 0.0442, 0.3264,\n",
      "        0.0442])\n",
      "tensor(94.8600)\n",
      "tensor(96.3000)\n",
      "Round 423, reward -0.410\n",
      "tensor([0.0501, 0.0501, 0.0519, 0.0512, 0.0501, 0.0503, 0.0501, 0.2265, 0.0501,\n",
      "        0.3698])\n",
      "tensor(94.4500)\n",
      "tensor(96.0400)\n",
      "Round 424, reward -0.420\n",
      "tensor([0.0317, 0.0317, 0.2344, 0.0317, 0.0732, 0.0320, 0.1311, 0.0317, 0.1989,\n",
      "        0.2036])\n",
      "tensor(96.6600)\n",
      "tensor(96.6800)\n",
      "Round 425, reward -0.089\n",
      "tensor([0.0262, 0.0262, 0.1932, 0.0262, 0.0953, 0.1931, 0.0262, 0.1932, 0.0273,\n",
      "        0.1932])\n",
      "tensor(94.4900)\n",
      "tensor(92.9300)\n",
      "Round 426, reward -0.120\n",
      "tensor([0.2764, 0.0397, 0.0374, 0.0374, 0.0374, 0.0374, 0.1906, 0.2686, 0.0376,\n",
      "        0.0374])\n",
      "tensor(92.7500)\n",
      "tensor(92.6000)\n",
      "Round 427, reward -0.160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1888, 0.0255, 0.1885, 0.1827, 0.0256, 0.0256, 0.1888, 0.1234, 0.0255,\n",
      "        0.0255])\n",
      "tensor(94.3300)\n",
      "tensor(95.8500)\n",
      "Round 428, reward -0.423\n",
      "tensor([0.2369, 0.0321, 0.0321, 0.0321, 0.2370, 0.0520, 0.0321, 0.0767, 0.2370,\n",
      "        0.0321])\n",
      "tensor(94.8000)\n",
      "tensor(96.3500)\n",
      "Round 429, reward -0.412\n",
      "tensor([0.0270, 0.1992, 0.1992, 0.0270, 0.0270, 0.0270, 0.1968, 0.1992, 0.0270,\n",
      "        0.0707])\n",
      "tensor(95.5800)\n",
      "tensor(95.6800)\n",
      "Round 430, reward -0.195\n",
      "tensor([0.0277, 0.0277, 0.0277, 0.0343, 0.0366, 0.2049, 0.1990, 0.0363, 0.2007,\n",
      "        0.2049])\n",
      "tensor(96.1500)\n",
      "tensor(96.1000)\n",
      "Round 431, reward -0.078\n",
      "tensor([0.1523, 0.0206, 0.1523, 0.0230, 0.1522, 0.1503, 0.1520, 0.0245, 0.0206,\n",
      "        0.1523])\n",
      "tensor(95.2100)\n",
      "tensor(95.2800)\n",
      "Round 432, reward -0.178\n",
      "tensor([0.1833, 0.0485, 0.1842, 0.0251, 0.0249, 0.1198, 0.1801, 0.1842, 0.0249,\n",
      "        0.0249])\n",
      "tensor(94.8500)\n",
      "tensor(95.3900)\n",
      "Round 433, reward -0.379\n",
      "tensor([0.0543, 0.0474, 0.0474, 0.0474, 0.0474, 0.2579, 0.3502, 0.0518, 0.0488,\n",
      "        0.0474])\n",
      "tensor(92.4000)\n",
      "tensor(95.7400)\n",
      "Round 434, reward -0.468\n",
      "tensor([0.1200, 0.1200, 0.0162, 0.1200, 0.1190, 0.1200, 0.1200, 0.1200, 0.0248,\n",
      "        0.1200])\n",
      "tensor(95.0600)\n",
      "tensor(95.9500)\n",
      "Round 435, reward -0.398\n",
      "tensor([0.0360, 0.2663, 0.2166, 0.0360, 0.0360, 0.2635, 0.0360, 0.0360, 0.0360,\n",
      "        0.0374])\n",
      "tensor(95.2600)\n",
      "tensor(95.2900)\n",
      "Round 436, reward -0.136\n",
      "tensor([0.0429, 0.0273, 0.2017, 0.1984, 0.2017, 0.0273, 0.0273, 0.0274, 0.0443,\n",
      "        0.2017])\n",
      "tensor(95.4700)\n",
      "tensor(96.3000)\n",
      "Round 437, reward -0.386\n",
      "tensor([0.0281, 0.0281, 0.2077, 0.0281, 0.2077, 0.0282, 0.0284, 0.2077, 0.2077,\n",
      "        0.0281])\n",
      "tensor(95.5300)\n",
      "tensor(96.7800)\n",
      "Round 438, reward -0.392\n",
      "tensor([0.1263, 0.2127, 0.0823, 0.2127, 0.0288, 0.0288, 0.0384, 0.0288, 0.2127,\n",
      "        0.0288])\n",
      "tensor(95.7300)\n",
      "tensor(96.5100)\n",
      "Round 439, reward -0.377\n",
      "tensor([0.0603, 0.0725, 0.0603, 0.0603, 0.4453, 0.0603, 0.0603, 0.0603, 0.0603,\n",
      "        0.0603])\n",
      "tensor(93.9200)\n",
      "tensor(96.2500)\n",
      "Round 440, reward -0.433\n",
      "tensor([0.1164, 0.1675, 0.0382, 0.1675, 0.0227, 0.0227, 0.1321, 0.0227, 0.1430,\n",
      "        0.1673])\n",
      "tensor(92.3000)\n",
      "tensor(95.2300)\n",
      "Round 441, reward -0.470\n",
      "tensor([0.0294, 0.0314, 0.0294, 0.2173, 0.0294, 0.2173, 0.2164, 0.0294, 0.0295,\n",
      "        0.1705])\n",
      "tensor(90.8700)\n",
      "tensor(88.6500)\n",
      "Round 442, reward -0.201\n",
      "tensor([0.0381, 0.0297, 0.2193, 0.0523, 0.0297, 0.2193, 0.1163, 0.2193, 0.0462,\n",
      "        0.0297])\n",
      "tensor(94.1800)\n",
      "tensor(95.6300)\n",
      "Round 443, reward -0.426\n",
      "tensor([0.1527, 0.1525, 0.0278, 0.1514, 0.1527, 0.0207, 0.1448, 0.0317, 0.0207,\n",
      "        0.1450])\n",
      "tensor(88.1800)\n",
      "tensor(89.1000)\n",
      "Round 444, reward -0.547\n",
      "tensor([0.0282, 0.2084, 0.2052, 0.0282, 0.0285, 0.0282, 0.2084, 0.0282, 0.0282,\n",
      "        0.2084])\n",
      "tensor(93.1700)\n",
      "tensor(94.3200)\n",
      "Round 445, reward -0.448\n",
      "tensor([0.0371, 0.0371, 0.0397, 0.0373, 0.0371, 0.0371, 0.2744, 0.2709, 0.0371,\n",
      "        0.1921])\n",
      "tensor(96.0800)\n",
      "tensor(96.2300)\n",
      "Round 446, reward -0.219\n",
      "tensor([0.0454, 0.0454, 0.3011, 0.0454, 0.0454, 0.0454, 0.0454, 0.0454, 0.3356,\n",
      "        0.0454])\n",
      "tensor(96.2800)\n",
      "tensor(96.4100)\n",
      "Round 447, reward -0.200\n",
      "tensor([0.0385, 0.0385, 0.0385, 0.0385, 0.2842, 0.0385, 0.1608, 0.0399, 0.2842,\n",
      "        0.0385])\n",
      "tensor(94.6000)\n",
      "tensor(95.7200)\n",
      "Round 448, reward -0.414\n",
      "tensor([0.0333, 0.0329, 0.0328, 0.0328, 0.2410, 0.2427, 0.1574, 0.0426, 0.1516,\n",
      "        0.0329])\n",
      "tensor(94.8400)\n",
      "tensor(96.1400)\n",
      "Round 449, reward -0.410\n",
      "tensor([0.0490, 0.0490, 0.0490, 0.0498, 0.2208, 0.0490, 0.0490, 0.0490, 0.0742,\n",
      "        0.3614])\n",
      "tensor(94.4700)\n",
      "tensor(95.7600)\n",
      "Round 450, reward -0.419\n",
      "tensor([0.0239, 0.0239, 0.1748, 0.0239, 0.1765, 0.1765, 0.0239, 0.0239, 0.1765,\n",
      "        0.1765])\n",
      "tensor(94.9200)\n",
      "tensor(96.1500)\n",
      "Round 451, reward -0.407\n",
      "tensor([0.1952, 0.0270, 0.1992, 0.1992, 0.0270, 0.0725, 0.0270, 0.0270, 0.1991,\n",
      "        0.0270])\n",
      "tensor(95.5500)\n",
      "tensor(95.7300)\n",
      "Round 452, reward -0.252\n",
      "tensor([0.0436, 0.3207, 0.0436, 0.0436, 0.0436, 0.3224, 0.0513, 0.0436, 0.0437,\n",
      "        0.0436])\n",
      "tensor(96.0500)\n",
      "tensor(96.0400)\n",
      "Round 453, reward -0.081\n",
      "tensor([0.2077, 0.2077, 0.0281, 0.0285, 0.2077, 0.0281, 0.0281, 0.2077, 0.0281,\n",
      "        0.0281])\n",
      "tensor(94.9000)\n",
      "tensor(96.5900)\n",
      "Round 454, reward -0.409\n",
      "tensor([0.1798, 0.3268, 0.0442, 0.0442, 0.0442, 0.0442, 0.0443, 0.0442, 0.1838,\n",
      "        0.0442])\n",
      "tensor(94.7500)\n",
      "tensor(96.2900)\n",
      "Round 455, reward -0.413\n",
      "tensor([0.0300, 0.0300, 0.2215, 0.2213, 0.0526, 0.0300, 0.0300, 0.2122, 0.1425,\n",
      "        0.0300])\n",
      "tensor(93.9300)\n",
      "tensor(96.)\n",
      "Round 456, reward -0.433\n",
      "tensor([0.0642, 0.0544, 0.0544, 0.0544, 0.0544, 0.4013, 0.0544, 0.0544, 0.1536,\n",
      "        0.0544])\n",
      "tensor(94.1100)\n",
      "tensor(95.6600)\n",
      "Round 457, reward -0.428\n",
      "tensor([0.2008, 0.0273, 0.0273, 0.2014, 0.0273, 0.2014, 0.2014, 0.0429, 0.0430,\n",
      "        0.0273])\n",
      "tensor(94.4300)\n",
      "tensor(95.5100)\n",
      "Round 458, reward -0.418\n",
      "tensor([0.2459, 0.2490, 0.0344, 0.0344, 0.0348, 0.0344, 0.0552, 0.2396, 0.0344,\n",
      "        0.0379])\n",
      "tensor(95.5500)\n",
      "tensor(96.8600)\n",
      "Round 459, reward -0.392\n",
      "tensor([0.0281, 0.0281, 0.0282, 0.2080, 0.2080, 0.0285, 0.2067, 0.0281, 0.2080,\n",
      "        0.0281])\n",
      "tensor(96.4500)\n",
      "tensor(96.5900)\n",
      "Round 460, reward -0.203\n",
      "tensor([0.1487, 0.1488, 0.1488, 0.0214, 0.1486, 0.1488, 0.1473, 0.0474, 0.0201,\n",
      "        0.0201])\n",
      "tensor(95.3400)\n",
      "tensor(96.2800)\n",
      "Round 461, reward -0.393\n",
      "tensor([0.0292, 0.0313, 0.0293, 0.0292, 0.2133, 0.0292, 0.2159, 0.0292, 0.1774,\n",
      "        0.2159])\n",
      "tensor(95.7300)\n",
      "tensor(95.2400)\n",
      "Round 462, reward -0.089\n",
      "tensor([0.0348, 0.2550, 0.0349, 0.0348, 0.0350, 0.0348, 0.2572, 0.2438, 0.0348,\n",
      "        0.0348])\n",
      "tensor(94.3300)\n",
      "tensor(95.0800)\n",
      "Round 463, reward -0.410\n",
      "tensor([0.0187, 0.0311, 0.1053, 0.1378, 0.1378, 0.1378, 0.1377, 0.1377, 0.0186,\n",
      "        0.1376])\n",
      "tensor(96.3900)\n",
      "tensor(96.4300)\n",
      "Round 464, reward -0.118\n",
      "tensor([0.0605, 0.0605, 0.0605, 0.0605, 0.0607, 0.4470, 0.0687, 0.0605, 0.0605,\n",
      "        0.0605])\n",
      "tensor(93.5100)\n",
      "tensor(92.4100)\n",
      "Round 465, reward -0.143\n",
      "tensor([0.1527, 0.0215, 0.1527, 0.1527, 0.1527, 0.0207, 0.0213, 0.1527, 0.0207,\n",
      "        0.1525])\n",
      "tensor(95.7900)\n",
      "tensor(96.1100)\n",
      "Round 466, reward -0.308\n",
      "tensor([0.0381, 0.0385, 0.0381, 0.0720, 0.0413, 0.0381, 0.0503, 0.1200, 0.2818,\n",
      "        0.2818])\n",
      "tensor(94.9700)\n",
      "tensor(96.5400)\n",
      "Round 467, reward -0.408\n",
      "tensor([0.2423, 0.0328, 0.0328, 0.0764, 0.2423, 0.0328, 0.0328, 0.0328, 0.0328,\n",
      "        0.2423])\n",
      "tensor(94.6500)\n",
      "tensor(96.8300)\n",
      "Round 468, reward -0.416\n",
      "tensor([0.1976, 0.0267, 0.1976, 0.0267, 0.0759, 0.0270, 0.0267, 0.1976, 0.1975,\n",
      "        0.0267])\n",
      "tensor(93.8300)\n",
      "tensor(93.5600)\n",
      "Round 469, reward -0.135\n",
      "tensor([0.0350, 0.2402, 0.0350, 0.0350, 0.0350, 0.2562, 0.0350, 0.0350, 0.2586,\n",
      "        0.0350])\n",
      "tensor(96.4100)\n",
      "tensor(96.5700)\n",
      "Round 470, reward -0.217\n",
      "tensor([0.2611, 0.2167, 0.2664, 0.0394, 0.0361, 0.0361, 0.0361, 0.0361, 0.0361,\n",
      "        0.0361])\n",
      "tensor(94.3700)\n",
      "tensor(93.5800)\n",
      "Round 471, reward -0.123\n",
      "tensor([0.1909, 0.0263, 0.0329, 0.1135, 0.0264, 0.0258, 0.1764, 0.0258, 0.1910,\n",
      "        0.1910])\n",
      "tensor(94.3400)\n",
      "tensor(95.7000)\n",
      "Round 472, reward -0.422\n",
      "tensor([0.0344, 0.0347, 0.2514, 0.0344, 0.2538, 0.0344, 0.0344, 0.0344, 0.2538,\n",
      "        0.0344])\n",
      "tensor(95.2400)\n",
      "tensor(96.7500)\n",
      "Round 473, reward -0.401\n",
      "tensor([0.0239, 0.1749, 0.1763, 0.1765, 0.0239, 0.1765, 0.0239, 0.0239, 0.0239,\n",
      "        0.1764])\n",
      "tensor(94.9300)\n",
      "tensor(94.9800)\n",
      "Round 474, reward -0.165\n",
      "tensor([0.1987, 0.0269, 0.1986, 0.1987, 0.0707, 0.0269, 0.0269, 0.0269, 0.1959,\n",
      "        0.0299])\n",
      "tensor(95.8600)\n",
      "tensor(96.0700)\n",
      "Round 475, reward -0.260\n",
      "tensor([0.0275, 0.0275, 0.0275, 0.0275, 0.0518, 0.2027, 0.2028, 0.2025, 0.0275,\n",
      "        0.2030])\n",
      "tensor(96.0700)\n",
      "tensor(96.3100)\n",
      "Round 476, reward -0.270\n",
      "tensor([0.0346, 0.2544, 0.0648, 0.0373, 0.0346, 0.0350, 0.2554, 0.0346, 0.2150,\n",
      "        0.0346])\n",
      "tensor(95.3100)\n",
      "tensor(96.7300)\n",
      "Round 477, reward -0.399\n",
      "tensor([0.3896, 0.0689, 0.0670, 0.0691, 0.0670, 0.0670, 0.0670, 0.0670, 0.0702,\n",
      "        0.0670])\n",
      "tensor(89.0900)\n",
      "tensor(93.7700)\n",
      "Round 478, reward -0.536\n",
      "tensor([0.0438, 0.0438, 0.0450, 0.3233, 0.0438, 0.0438, 0.0438, 0.0459, 0.3233,\n",
      "        0.0438])\n",
      "tensor(93.7900)\n",
      "tensor(96.3000)\n",
      "Round 479, reward -0.436\n",
      "tensor([0.1157, 0.1111, 0.1738, 0.1590, 0.0235, 0.1738, 0.1725, 0.0235, 0.0235,\n",
      "        0.0235])\n",
      "tensor(95.1300)\n",
      "tensor(95.8700)\n",
      "Round 480, reward -0.390\n",
      "tensor([0.2996, 0.0405, 0.0415, 0.0405, 0.0405, 0.0407, 0.2996, 0.0405, 0.1159,\n",
      "        0.0405])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.8900)\n",
      "tensor(96.4200)\n",
      "Round 481, reward -0.409\n",
      "tensor([0.0282, 0.2061, 0.2075, 0.2085, 0.0282, 0.0282, 0.2085, 0.0282, 0.0282,\n",
      "        0.0282])\n",
      "tensor(95.5600)\n",
      "tensor(96.5500)\n",
      "Round 482, reward -0.388\n",
      "tensor([0.0239, 0.0239, 0.0239, 0.1767, 0.0239, 0.1767, 0.1767, 0.0239, 0.1736,\n",
      "        0.1766])\n",
      "tensor(89.9100)\n",
      "tensor(89.7600)\n",
      "Round 483, reward -0.220\n",
      "tensor([0.0342, 0.0341, 0.2497, 0.0341, 0.0341, 0.0341, 0.2520, 0.0341, 0.0424,\n",
      "        0.2512])\n",
      "tensor(91.4000)\n",
      "tensor(89.8600)\n",
      "Round 484, reward -0.190\n",
      "tensor([0.0728, 0.0304, 0.0818, 0.1405, 0.2245, 0.0305, 0.0304, 0.2043, 0.0306,\n",
      "        0.1541])\n",
      "tensor(96.6600)\n",
      "tensor(96.8600)\n",
      "Round 485, reward -0.234\n",
      "tensor([0.0608, 0.0608, 0.0609, 0.0620, 0.0624, 0.0615, 0.0608, 0.0608, 0.0608,\n",
      "        0.4492])\n",
      "tensor(85.9600)\n",
      "tensor(95.9500)\n",
      "Round 486, reward -0.593\n",
      "tensor([0.0373, 0.0470, 0.0373, 0.0638, 0.2757, 0.0373, 0.2757, 0.1508, 0.0376,\n",
      "        0.0373])\n",
      "tensor(96.5900)\n",
      "tensor(95.9000)\n",
      "Round 487, reward -0.067\n",
      "tensor([0.0290, 0.0286, 0.1971, 0.0286, 0.2112, 0.2089, 0.0286, 0.2109, 0.0286,\n",
      "        0.0286])\n",
      "tensor(96.6100)\n",
      "tensor(96.8500)\n",
      "Round 488, reward -0.256\n",
      "tensor([0.0337, 0.0337, 0.0337, 0.0661, 0.0337, 0.2143, 0.1025, 0.0337, 0.2044,\n",
      "        0.2444])\n",
      "tensor(96.0500)\n",
      "tensor(96.5000)\n",
      "Round 489, reward -0.335\n",
      "tensor([0.0342, 0.0684, 0.0342, 0.2529, 0.0356, 0.2187, 0.0342, 0.0342, 0.2529,\n",
      "        0.0347])\n",
      "tensor(96.9800)\n",
      "tensor(94.7500)\n",
      "Round 490, reward -0.056\n",
      "tensor([0.0296, 0.1719, 0.0296, 0.0298, 0.2126, 0.0296, 0.0296, 0.0296, 0.2188,\n",
      "        0.2188])\n",
      "tensor(88.1400)\n",
      "tensor(96.5000)\n",
      "Round 491, reward -0.554\n",
      "tensor([0.0318, 0.0451, 0.0318, 0.0318, 0.2348, 0.0318, 0.2329, 0.2348, 0.0318,\n",
      "        0.0935])\n",
      "tensor(93.7400)\n",
      "tensor(94.8400)\n",
      "Round 492, reward -0.434\n",
      "tensor([0.1968, 0.0266, 0.0266, 0.1352, 0.0279, 0.0266, 0.1968, 0.0268, 0.1483,\n",
      "        0.1884])\n",
      "tensor(93.9600)\n",
      "tensor(94.4900)\n",
      "Round 493, reward -0.399\n",
      "tensor([0.0267, 0.1765, 0.1765, 0.0240, 0.1765, 0.1765, 0.0239, 0.0239, 0.0239,\n",
      "        0.1716])\n",
      "tensor(92.5800)\n",
      "tensor(95.5400)\n",
      "Round 494, reward -0.464\n",
      "tensor([0.0352, 0.2603, 0.0354, 0.2326, 0.0352, 0.0352, 0.0352, 0.0352, 0.2604,\n",
      "        0.0352])\n",
      "tensor(96.1500)\n",
      "tensor(96.8500)\n",
      "Round 495, reward -0.362\n",
      "tensor([0.0369, 0.2423, 0.0715, 0.0328, 0.0328, 0.2423, 0.0328, 0.2423, 0.0328,\n",
      "        0.0334])\n",
      "tensor(95.8200)\n",
      "tensor(96.6400)\n",
      "Round 496, reward -0.377\n",
      "tensor([0.2435, 0.0330, 0.0825, 0.2327, 0.0330, 0.0330, 0.0330, 0.0330, 0.2435,\n",
      "        0.0330])\n",
      "tensor(94.7500)\n",
      "tensor(96.5500)\n",
      "Round 497, reward -0.413\n",
      "tensor([0.0333, 0.0333, 0.2461, 0.2300, 0.0333, 0.2461, 0.0333, 0.0775, 0.0333,\n",
      "        0.0337])\n",
      "tensor(89.4200)\n",
      "tensor(91.2100)\n",
      "Round 498, reward -0.530\n",
      "tensor([0.1619, 0.1619, 0.1030, 0.1615, 0.1619, 0.1619, 0.0219, 0.0219, 0.0220,\n",
      "        0.0219])\n",
      "tensor(96.8200)\n",
      "tensor(96.6400)\n",
      "Round 499, reward -0.061\n",
      "tensor([0.0324, 0.0324, 0.0375, 0.0892, 0.2329, 0.0324, 0.2391, 0.2392, 0.0324,\n",
      "        0.0327])\n",
      "tensor(91.3500)\n",
      "tensor(95.8300)\n",
      "Round 500, reward -0.491\n",
      "tensor([0.0282, 0.0282, 0.2081, 0.2065, 0.2081, 0.0282, 0.0282, 0.2081, 0.0282,\n",
      "        0.0282])\n",
      "tensor(95.7100)\n",
      "tensor(96.3100)\n",
      "Round 501, reward -0.365\n",
      "tensor([0.2885, 0.0457, 0.0515, 0.0487, 0.0457, 0.0457, 0.3374, 0.0457, 0.0457,\n",
      "        0.0457])\n",
      "tensor(95.6500)\n",
      "tensor(96.5500)\n",
      "Round 502, reward -0.384\n",
      "tensor([0.0327, 0.0335, 0.0327, 0.0385, 0.0330, 0.0327, 0.2417, 0.2340, 0.0796,\n",
      "        0.2416])\n",
      "tensor(95.9300)\n",
      "tensor(95.7800)\n",
      "Round 503, reward -0.084\n",
      "tensor([0.0318, 0.0306, 0.2263, 0.0575, 0.0307, 0.0306, 0.1326, 0.2028, 0.0306,\n",
      "        0.2263])\n",
      "tensor(95.6100)\n",
      "tensor(96.1300)\n",
      "Round 504, reward -0.358\n",
      "tensor([0.1608, 0.1609, 0.0218, 0.0218, 0.1530, 0.1606, 0.1221, 0.0218, 0.1554,\n",
      "        0.0218])\n",
      "tensor(95.7800)\n",
      "tensor(97.0700)\n",
      "Round 505, reward -0.386\n",
      "tensor([0.0918, 0.0561, 0.0312, 0.0353, 0.2307, 0.2297, 0.0320, 0.0312, 0.0312,\n",
      "        0.2307])\n",
      "tensor(95.9200)\n",
      "tensor(96.4800)\n",
      "Round 506, reward -0.355\n",
      "tensor([0.2493, 0.0341, 0.2493, 0.0337, 0.0733, 0.0337, 0.0337, 0.0358, 0.2232,\n",
      "        0.0337])\n",
      "tensor(90.8200)\n",
      "tensor(91.9200)\n",
      "Round 507, reward -0.499\n",
      "tensor([0.0623, 0.4378, 0.0623, 0.0629, 0.0625, 0.0630, 0.0623, 0.0623, 0.0623,\n",
      "        0.0623])\n",
      "tensor(94.8500)\n",
      "tensor(96.9600)\n",
      "Round 508, reward -0.411\n",
      "tensor([0.0294, 0.0289, 0.2136, 0.1838, 0.2136, 0.0289, 0.0289, 0.0303, 0.2136,\n",
      "        0.0289])\n",
      "tensor(96.1700)\n",
      "tensor(96.4400)\n",
      "Round 509, reward -0.280\n",
      "tensor([0.0282, 0.2078, 0.2078, 0.0281, 0.0281, 0.0281, 0.2078, 0.0281, 0.0281,\n",
      "        0.2078])\n",
      "tensor(94.0300)\n",
      "tensor(96.1500)\n",
      "Round 510, reward -0.431\n",
      "tensor([0.0280, 0.0280, 0.0280, 0.1285, 0.0284, 0.2072, 0.1444, 0.1722, 0.2072,\n",
      "        0.0280])\n",
      "tensor(86.1600)\n",
      "tensor(94.7800)\n",
      "Round 511, reward -0.590\n",
      "tensor([0.1708, 0.0231, 0.0233, 0.1708, 0.0231, 0.1613, 0.1708, 0.1684, 0.0231,\n",
      "        0.0651])\n",
      "tensor(88.7500)\n",
      "tensor(91.5300)\n",
      "Round 512, reward -0.543\n",
      "tensor([0.0343, 0.0343, 0.2534, 0.0343, 0.0343, 0.2529, 0.0344, 0.2535, 0.0343,\n",
      "        0.0343])\n",
      "tensor(95.1000)\n",
      "tensor(96.5900)\n",
      "Round 513, reward -0.404\n",
      "tensor([0.3634, 0.0513, 0.2231, 0.0513, 0.0541, 0.0513, 0.0514, 0.0513, 0.0513,\n",
      "        0.0513])\n",
      "tensor(95.6600)\n",
      "tensor(97.)\n",
      "Round 514, reward -0.390\n",
      "tensor([0.0314, 0.0313, 0.1158, 0.0313, 0.2316, 0.2308, 0.0313, 0.2316, 0.0334,\n",
      "        0.0313])\n",
      "tensor(95.8800)\n",
      "tensor(96.1600)\n",
      "Round 515, reward -0.292\n",
      "tensor([0.1826, 0.0247, 0.1825, 0.1461, 0.0247, 0.0247, 0.0247, 0.1826, 0.0247,\n",
      "        0.1826])\n",
      "tensor(91.6400)\n",
      "tensor(94.5500)\n",
      "Round 516, reward -0.485\n",
      "tensor([0.1602, 0.0226, 0.0440, 0.0222, 0.1634, 0.0221, 0.0752, 0.1634, 0.1634,\n",
      "        0.1634])\n",
      "tensor(94.2500)\n",
      "tensor(91.9500)\n",
      "Round 517, reward -0.125\n",
      "tensor([0.0283, 0.2028, 0.2090, 0.0332, 0.0283, 0.0283, 0.0283, 0.2046, 0.2090,\n",
      "        0.0283])\n",
      "tensor(95.7500)\n",
      "tensor(96.4100)\n",
      "Round 518, reward -0.369\n",
      "tensor([0.0414, 0.3057, 0.0414, 0.0450, 0.0414, 0.0415, 0.0862, 0.3048, 0.0514,\n",
      "        0.0414])\n",
      "tensor(95.6900)\n",
      "tensor(96.0700)\n",
      "Round 519, reward -0.328\n",
      "tensor([0.1526, 0.1527, 0.1527, 0.0207, 0.0221, 0.0207, 0.1527, 0.1527, 0.1527,\n",
      "        0.0207])\n",
      "tensor(96.9600)\n",
      "tensor(97.2300)\n",
      "Round 520, reward -0.259\n",
      "tensor([0.1611, 0.0223, 0.0223, 0.0891, 0.1648, 0.1646, 0.0237, 0.0224, 0.1648,\n",
      "        0.1648])\n",
      "tensor(96.4500)\n",
      "tensor(96.8500)\n",
      "Round 521, reward -0.314\n",
      "tensor([0.0336, 0.0336, 0.0336, 0.2480, 0.0336, 0.2477, 0.0549, 0.0336, 0.0336,\n",
      "        0.2480])\n",
      "tensor(96.3000)\n",
      "tensor(96.4800)\n",
      "Round 522, reward -0.232\n",
      "tensor([0.1799, 0.0244, 0.0244, 0.0244, 0.1584, 0.0244, 0.1800, 0.1800, 0.0244,\n",
      "        0.1800])\n",
      "tensor(96.5200)\n",
      "tensor(96.3700)\n",
      "Round 523, reward -0.069\n",
      "tensor([0.4200, 0.0647, 0.0644, 0.0644, 0.0644, 0.0644, 0.0644, 0.0644, 0.0646,\n",
      "        0.0644])\n",
      "tensor(94.5400)\n",
      "tensor(95.9500)\n",
      "Round 524, reward -0.418\n",
      "tensor([0.0307, 0.2230, 0.1258, 0.0548, 0.0303, 0.0302, 0.2220, 0.0302, 0.0302,\n",
      "        0.2229])\n",
      "tensor(96.3000)\n",
      "tensor(97.2400)\n",
      "Round 525, reward -0.368\n",
      "tensor([0.0475, 0.0476, 0.0721, 0.0475, 0.1631, 0.1407, 0.0475, 0.0475, 0.0475,\n",
      "        0.3390])\n",
      "tensor(95.9600)\n",
      "tensor(96.1200)\n",
      "Round 526, reward -0.229\n",
      "tensor([0.0291, 0.0291, 0.0291, 0.2150, 0.0404, 0.0291, 0.2149, 0.2149, 0.1692,\n",
      "        0.0291])\n",
      "tensor(96.2800)\n",
      "tensor(97.1900)\n",
      "Round 527, reward -0.368\n",
      "tensor([0.1429, 0.0389, 0.0389, 0.0389, 0.2877, 0.0390, 0.2875, 0.0483, 0.0389,\n",
      "        0.0389])\n",
      "tensor(93.0600)\n",
      "tensor(96.4300)\n",
      "Round 528, reward -0.453\n",
      "tensor([0.2060, 0.2060, 0.0279, 0.2058, 0.0279, 0.0279, 0.2060, 0.0279, 0.0366,\n",
      "        0.0280])\n",
      "tensor(94.2700)\n",
      "tensor(96.9300)\n",
      "Round 529, reward -0.425\n",
      "tensor([0.2079, 0.2019, 0.0281, 0.0281, 0.0281, 0.0281, 0.0338, 0.0281, 0.2079,\n",
      "        0.2079])\n",
      "tensor(96.5300)\n",
      "tensor(96.4500)\n",
      "Round 530, reward -0.068\n",
      "tensor([0.4284, 0.0580, 0.0648, 0.1010, 0.0580, 0.0580, 0.0580, 0.0580, 0.0580,\n",
      "        0.0580])\n",
      "tensor(96.3700)\n",
      "tensor(96.7000)\n",
      "Round 531, reward -0.296\n",
      "tensor([0.1496, 0.0207, 0.1531, 0.1531, 0.1523, 0.0207, 0.1514, 0.0207, 0.0265,\n",
      "        0.1519])\n",
      "tensor(96.4200)\n",
      "tensor(96.8800)\n",
      "Round 532, reward -0.327\n",
      "tensor([0.0443, 0.0443, 0.0445, 0.0443, 0.0443, 0.3185, 0.0443, 0.0443, 0.3271,\n",
      "        0.0443])\n",
      "tensor(95.4300)\n",
      "tensor(95.0700)\n",
      "Round 533, reward -0.097\n",
      "tensor([0.0608, 0.0608, 0.0622, 0.0608, 0.0609, 0.0619, 0.0608, 0.0613, 0.4495,\n",
      "        0.0608])\n",
      "tensor(89.5100)\n",
      "tensor(94.5700)\n",
      "Round 534, reward -0.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0242, 0.1769, 0.0240, 0.1770, 0.0240, 0.1770, 0.0240, 0.1770, 0.0249,\n",
      "        0.1711])\n",
      "tensor(90.6200)\n",
      "tensor(94.8200)\n",
      "Round 535, reward -0.506\n",
      "tensor([0.2077, 0.0282, 0.0282, 0.2080, 0.0282, 0.2073, 0.2080, 0.0282, 0.0282,\n",
      "        0.0282])\n",
      "tensor(94.7300)\n",
      "tensor(95.7300)\n",
      "Round 536, reward -0.409\n",
      "tensor([0.0256, 0.0238, 0.1754, 0.1754, 0.0244, 0.0238, 0.0251, 0.1755, 0.1755,\n",
      "        0.1755])\n",
      "tensor(95.2600)\n",
      "tensor(96.3600)\n",
      "Round 537, reward -0.398\n",
      "tensor([0.0441, 0.0441, 0.1507, 0.0441, 0.0441, 0.2148, 0.3256, 0.0441, 0.0443,\n",
      "        0.0442])\n",
      "tensor(96.3000)\n",
      "tensor(96.9600)\n",
      "Round 538, reward -0.355\n",
      "tensor([0.1529, 0.1529, 0.1529, 0.1529, 0.1529, 0.1529, 0.0207, 0.0207, 0.0207,\n",
      "        0.0207])\n",
      "tensor(96.6000)\n",
      "tensor(96.7400)\n",
      "Round 539, reward -0.199\n",
      "tensor([0.1769, 0.1782, 0.1819, 0.0246, 0.0246, 0.1819, 0.0246, 0.0246, 0.0250,\n",
      "        0.1577])\n",
      "tensor(95.8400)\n",
      "tensor(96.7500)\n",
      "Round 540, reward -0.379\n",
      "tensor([0.2114, 0.0286, 0.2114, 0.2002, 0.0286, 0.0286, 0.0286, 0.0287, 0.2052,\n",
      "        0.0286])\n",
      "tensor(93.8100)\n",
      "tensor(95.6900)\n",
      "Round 541, reward -0.436\n",
      "tensor([0.0217, 0.1548, 0.1444, 0.0217, 0.1586, 0.1602, 0.1602, 0.0217, 0.0217,\n",
      "        0.1350])\n",
      "tensor(96.8300)\n",
      "tensor(96.5100)\n",
      "Round 542, reward -0.060\n",
      "tensor([0.1652, 0.1652, 0.0672, 0.0224, 0.0224, 0.0224, 0.0402, 0.1652, 0.1648,\n",
      "        0.1651])\n",
      "tensor(95.1000)\n",
      "tensor(96.5300)\n",
      "Round 543, reward -0.404\n",
      "tensor([0.0623, 0.0405, 0.0394, 0.0394, 0.0517, 0.0394, 0.2584, 0.0394, 0.2902,\n",
      "        0.1393])\n",
      "tensor(96.6800)\n",
      "tensor(96.6100)\n",
      "Round 544, reward -0.064\n",
      "tensor([0.0301, 0.0301, 0.0328, 0.2221, 0.0301, 0.2213, 0.2221, 0.1514, 0.0301,\n",
      "        0.0301])\n",
      "tensor(96.7500)\n",
      "tensor(97.0500)\n",
      "Round 545, reward -0.276\n",
      "tensor([0.0274, 0.0259, 0.0272, 0.1912, 0.1810, 0.0259, 0.1909, 0.1859, 0.0259,\n",
      "        0.1186])\n",
      "tensor(95.8800)\n",
      "tensor(95.7500)\n",
      "Round 546, reward -0.085\n",
      "tensor([0.0320, 0.1141, 0.0295, 0.0326, 0.2177, 0.2171, 0.2181, 0.0797, 0.0295,\n",
      "        0.0295])\n",
      "tensor(95.7100)\n",
      "tensor(95.8500)\n",
      "Round 547, reward -0.222\n",
      "tensor([0.0226, 0.1656, 0.1640, 0.1656, 0.0224, 0.1151, 0.1656, 0.1341, 0.0226,\n",
      "        0.0224])\n",
      "tensor(96.6400)\n",
      "tensor(96.8700)\n",
      "Round 548, reward -0.250\n",
      "tensor([0.1646, 0.0224, 0.0223, 0.1648, 0.1646, 0.0226, 0.1647, 0.1648, 0.0870,\n",
      "        0.0223])\n",
      "tensor(95.8300)\n",
      "tensor(96.3200)\n",
      "Round 549, reward -0.347\n",
      "tensor([0.0535, 0.2205, 0.0303, 0.2166, 0.0299, 0.0299, 0.0299, 0.0299, 0.2211,\n",
      "        0.1383])\n",
      "tensor(92.7200)\n",
      "tensor(96.1000)\n",
      "Round 550, reward -0.461\n",
      "tensor([0.0434, 0.0430, 0.0430, 0.0430, 0.3177, 0.0430, 0.0430, 0.3176, 0.0507,\n",
      "        0.0555])\n",
      "tensor(91.5000)\n",
      "tensor(95.9000)\n",
      "Round 551, reward -0.488\n",
      "tensor([0.0346, 0.0346, 0.0346, 0.0346, 0.2461, 0.0346, 0.0346, 0.2558, 0.2557,\n",
      "        0.0346])\n",
      "tensor(96.1000)\n",
      "tensor(96.3300)\n",
      "Round 552, reward -0.264\n",
      "tensor([0.0338, 0.0338, 0.2364, 0.0338, 0.2499, 0.0338, 0.0615, 0.0338, 0.0339,\n",
      "        0.2493])\n",
      "tensor(88.5400)\n",
      "tensor(96.8300)\n",
      "Round 553, reward -0.547\n",
      "tensor([0.2535, 0.0343, 0.0343, 0.0343, 0.0343, 0.2534, 0.0343, 0.0343, 0.2528,\n",
      "        0.0343])\n",
      "tensor(92.7100)\n",
      "tensor(95.9200)\n",
      "Round 554, reward -0.461\n",
      "tensor([0.0442, 0.0423, 0.0948, 0.0421, 0.0421, 0.0422, 0.3114, 0.0421, 0.2952,\n",
      "        0.0435])\n",
      "tensor(92.9600)\n",
      "tensor(96.4900)\n",
      "Round 555, reward -0.455\n",
      "tensor([0.1365, 0.1485, 0.1487, 0.0202, 0.0202, 0.1490, 0.1490, 0.0589, 0.1490,\n",
      "        0.0202])\n",
      "tensor(95.5100)\n",
      "tensor(96.7200)\n",
      "Round 556, reward -0.393\n",
      "tensor([0.0433, 0.0405, 0.0374, 0.0622, 0.0374, 0.0374, 0.2763, 0.1518, 0.2763,\n",
      "        0.0374])\n",
      "tensor(95.4900)\n",
      "tensor(96.5200)\n",
      "Round 557, reward -0.391\n",
      "tensor([0.1282, 0.0238, 0.0238, 0.0718, 0.0266, 0.0238, 0.1760, 0.1751, 0.1749,\n",
      "        0.1760])\n",
      "tensor(96.8300)\n",
      "tensor(95.9000)\n",
      "Round 558, reward -0.060\n",
      "tensor([0.0458, 0.0463, 0.0458, 0.0457, 0.2436, 0.0459, 0.0468, 0.3377, 0.0962,\n",
      "        0.0460])\n",
      "tensor(95.4400)\n",
      "tensor(96.7700)\n",
      "Round 559, reward -0.395\n",
      "tensor([0.0357, 0.0346, 0.0342, 0.2527, 0.0342, 0.0347, 0.0342, 0.0342, 0.2527,\n",
      "        0.2527])\n",
      "tensor(93.3700)\n",
      "tensor(93.9700)\n",
      "Round 560, reward -0.421\n",
      "tensor([0.2018, 0.0283, 0.0283, 0.0283, 0.0283, 0.2094, 0.0283, 0.2094, 0.0283,\n",
      "        0.2094])\n",
      "tensor(95.7600)\n",
      "tensor(96.6500)\n",
      "Round 561, reward -0.381\n",
      "tensor([0.0319, 0.0319, 0.0328, 0.0319, 0.2176, 0.2354, 0.0516, 0.0997, 0.0319,\n",
      "        0.2354])\n",
      "tensor(96.7700)\n",
      "tensor(96.6200)\n",
      "Round 562, reward -0.062\n",
      "tensor([0.0257, 0.0257, 0.1887, 0.0257, 0.0257, 0.1124, 0.1901, 0.1901, 0.1901,\n",
      "        0.0257])\n",
      "tensor(95.7600)\n",
      "tensor(96.7300)\n",
      "Round 563, reward -0.383\n",
      "tensor([0.1823, 0.0247, 0.1749, 0.1823, 0.0247, 0.0247, 0.0247, 0.1549, 0.1823,\n",
      "        0.0247])\n",
      "tensor(91.0500)\n",
      "tensor(94.8900)\n",
      "Round 564, reward -0.497\n",
      "tensor([0.0283, 0.0278, 0.0278, 0.0386, 0.0278, 0.2053, 0.2055, 0.2055, 0.2055,\n",
      "        0.0278])\n",
      "tensor(94.6600)\n",
      "tensor(96.3600)\n",
      "Round 565, reward -0.415\n",
      "tensor([0.2050, 0.0282, 0.0282, 0.2084, 0.2084, 0.0282, 0.0282, 0.0288, 0.2084,\n",
      "        0.0282])\n",
      "tensor(93.3500)\n",
      "tensor(94.7600)\n",
      "Round 566, reward -0.446\n",
      "tensor([0.0358, 0.0358, 0.0358, 0.2645, 0.2636, 0.0358, 0.0358, 0.0358, 0.2214,\n",
      "        0.0358])\n",
      "tensor(96.3900)\n",
      "tensor(96.1900)\n",
      "Round 567, reward -0.072\n",
      "tensor([0.1713, 0.0232, 0.1682, 0.0655, 0.0232, 0.1713, 0.0238, 0.1590, 0.0232,\n",
      "        0.1713])\n",
      "tensor(96.6100)\n",
      "tensor(97.2600)\n",
      "Round 568, reward -0.346\n",
      "tensor([0.0374, 0.2629, 0.0356, 0.0363, 0.0356, 0.0356, 0.0356, 0.0356, 0.2631,\n",
      "        0.2222])\n",
      "tensor(94.7200)\n",
      "tensor(95.5500)\n",
      "Round 569, reward -0.405\n",
      "tensor([0.0308, 0.0316, 0.0308, 0.1483, 0.0339, 0.2275, 0.2030, 0.0308, 0.2275,\n",
      "        0.0357])\n",
      "tensor(95.7500)\n",
      "tensor(96.9400)\n",
      "Round 570, reward -0.386\n",
      "tensor([0.0207, 0.1530, 0.1530, 0.1506, 0.1530, 0.0207, 0.1522, 0.0230, 0.1530,\n",
      "        0.0207])\n",
      "tensor(96.8900)\n",
      "tensor(97.1800)\n",
      "Round 571, reward -0.269\n",
      "tensor([0.1980, 0.0284, 0.0301, 0.0284, 0.2098, 0.0284, 0.0289, 0.2098, 0.0284,\n",
      "        0.2098])\n",
      "tensor(96.5900)\n",
      "tensor(96.6300)\n",
      "Round 572, reward -0.113\n",
      "tensor([0.0229, 0.0229, 0.0230, 0.1695, 0.1695, 0.1695, 0.0594, 0.1695, 0.1695,\n",
      "        0.0241])\n",
      "tensor(96.5500)\n",
      "tensor(95.6100)\n",
      "Round 573, reward -0.068\n",
      "tensor([0.0257, 0.0303, 0.1900, 0.1655, 0.0257, 0.1361, 0.1851, 0.1900, 0.0257,\n",
      "        0.0257])\n",
      "tensor(96.0400)\n",
      "tensor(96.4400)\n",
      "Round 574, reward -0.324\n",
      "tensor([0.2791, 0.3456, 0.0468, 0.0471, 0.0468, 0.0468, 0.0468, 0.0468, 0.0472,\n",
      "        0.0468])\n",
      "tensor(96.2300)\n",
      "tensor(96.2000)\n",
      "Round 575, reward -0.076\n",
      "tensor([0.0501, 0.0545, 0.0501, 0.0501, 0.0501, 0.0562, 0.0501, 0.1559, 0.1124,\n",
      "        0.3704])\n",
      "tensor(96.9900)\n",
      "tensor(97.1900)\n",
      "Round 576, reward -0.226\n",
      "tensor([0.0251, 0.1850, 0.0250, 0.0250, 0.0250, 0.1348, 0.1850, 0.0251, 0.1850,\n",
      "        0.1850])\n",
      "tensor(96.1300)\n",
      "tensor(95.6500)\n",
      "Round 577, reward -0.079\n",
      "tensor([0.1745, 0.0242, 0.0265, 0.0242, 0.0371, 0.0236, 0.1668, 0.1745, 0.1743,\n",
      "        0.1743])\n",
      "tensor(95.4000)\n",
      "tensor(95.8000)\n",
      "Round 578, reward -0.340\n",
      "tensor([0.1039, 0.0409, 0.0409, 0.0409, 0.0409, 0.0547, 0.0409, 0.2932, 0.0410,\n",
      "        0.3025])\n",
      "tensor(92.5300)\n",
      "tensor(96.2400)\n",
      "Round 579, reward -0.465\n",
      "tensor([0.0265, 0.1955, 0.1951, 0.0265, 0.0419, 0.0267, 0.1954, 0.0715, 0.1945,\n",
      "        0.0265])\n",
      "tensor(95.9400)\n",
      "tensor(96.0200)\n",
      "Round 580, reward -0.169\n",
      "tensor([0.2223, 0.0301, 0.0301, 0.0301, 0.2223, 0.0301, 0.0305, 0.0301, 0.1522,\n",
      "        0.2223])\n",
      "tensor(96.9100)\n",
      "tensor(96.1100)\n",
      "Round 581, reward -0.058\n",
      "tensor([0.0284, 0.1812, 0.1812, 0.1479, 0.0245, 0.1812, 0.0245, 0.0252, 0.1812,\n",
      "        0.0245])\n",
      "tensor(95.3500)\n",
      "tensor(96.2700)\n",
      "Round 582, reward -0.392\n",
      "tensor([0.2008, 0.2008, 0.0498, 0.2005, 0.0272, 0.0272, 0.2008, 0.0387, 0.0272,\n",
      "        0.0272])\n",
      "tensor(94.9600)\n",
      "tensor(96.2600)\n",
      "Round 583, reward -0.407\n",
      "tensor([0.0338, 0.0311, 0.2253, 0.1236, 0.0308, 0.0392, 0.2274, 0.0308, 0.2273,\n",
      "        0.0308])\n",
      "tensor(96.1400)\n",
      "tensor(96.7400)\n",
      "Round 584, reward -0.354\n",
      "tensor([0.0267, 0.0299, 0.0266, 0.1962, 0.1962, 0.0266, 0.0956, 0.1803, 0.0266,\n",
      "        0.1955])\n",
      "tensor(96.1400)\n",
      "tensor(96.3600)\n",
      "Round 585, reward -0.258\n",
      "tensor([0.1350, 0.2090, 0.1342, 0.0283, 0.1714, 0.0283, 0.2090, 0.0283, 0.0283,\n",
      "        0.0283])\n",
      "tensor(96.7900)\n",
      "tensor(96.8600)\n",
      "Round 586, reward -0.137\n",
      "tensor([0.0287, 0.2081, 0.0282, 0.2081, 0.0282, 0.0412, 0.0282, 0.1932, 0.0282,\n",
      "        0.2081])\n",
      "tensor(94.9800)\n",
      "tensor(93.5600)\n",
      "Round 587, reward -0.108\n",
      "tensor([0.0309, 0.2274, 0.0311, 0.0493, 0.0314, 0.0309, 0.0309, 0.2285, 0.2206,\n",
      "        0.1190])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(96.3400)\n",
      "tensor(97.0200)\n",
      "Round 588, reward -0.356\n",
      "tensor([0.0255, 0.1879, 0.0255, 0.0255, 0.0255, 0.1190, 0.0257, 0.1884, 0.1887,\n",
      "        0.1881])\n",
      "tensor(95.7500)\n",
      "tensor(96.5400)\n",
      "Round 589, reward -0.377\n",
      "tensor([0.0238, 0.0285, 0.1754, 0.0237, 0.1754, 0.1749, 0.0237, 0.1754, 0.0237,\n",
      "        0.1754])\n",
      "tensor(93.1900)\n",
      "tensor(95.4000)\n",
      "Round 590, reward -0.450\n",
      "tensor([0.1442, 0.0195, 0.1351, 0.1442, 0.1371, 0.0934, 0.0195, 0.1442, 0.0195,\n",
      "        0.1434])\n",
      "tensor(96.0300)\n",
      "tensor(95.8200)\n",
      "Round 591, reward -0.081\n",
      "tensor([0.1943, 0.0263, 0.0900, 0.0263, 0.0263, 0.1812, 0.0406, 0.1943, 0.0263,\n",
      "        0.1942])\n",
      "tensor(94.7500)\n",
      "tensor(96.0600)\n",
      "Round 592, reward -0.412\n",
      "tensor([0.1647, 0.1848, 0.1848, 0.1559, 0.1848, 0.0250, 0.0250, 0.0250, 0.0250,\n",
      "        0.0250])\n",
      "tensor(91.2100)\n",
      "tensor(93.0500)\n",
      "Round 593, reward -0.494\n",
      "tensor([0.0439, 0.0439, 0.0439, 0.3247, 0.0443, 0.0439, 0.0468, 0.0439, 0.0439,\n",
      "        0.3206])\n",
      "tensor(95.6600)\n",
      "tensor(97.0400)\n",
      "Round 594, reward -0.390\n",
      "tensor([0.0349, 0.0349, 0.2575, 0.0349, 0.0350, 0.0349, 0.0349, 0.2404, 0.0353,\n",
      "        0.2575])\n",
      "tensor(96.6700)\n",
      "tensor(97.4300)\n",
      "Round 595, reward -0.352\n",
      "tensor([0.1491, 0.1467, 0.1121, 0.1491, 0.0202, 0.0202, 0.0202, 0.1491, 0.1304,\n",
      "        0.1029])\n",
      "tensor(96.4100)\n",
      "tensor(97.2500)\n",
      "Round 596, reward -0.362\n",
      "tensor([0.0238, 0.0243, 0.0274, 0.1755, 0.0238, 0.0238, 0.1754, 0.1751, 0.1756,\n",
      "        0.1754])\n",
      "tensor(96.3700)\n",
      "tensor(96.7400)\n",
      "Round 597, reward -0.308\n",
      "tensor([0.1755, 0.0237, 0.1755, 0.0277, 0.1755, 0.0237, 0.0237, 0.0237, 0.1755,\n",
      "        0.1755])\n",
      "tensor(93.7900)\n",
      "tensor(96.7600)\n",
      "Round 598, reward -0.436\n",
      "tensor([0.0422, 0.0431, 0.0425, 0.3119, 0.0428, 0.0789, 0.0423, 0.0423, 0.0422,\n",
      "        0.3119])\n",
      "tensor(88.0700)\n",
      "tensor(89.9100)\n",
      "Round 599, reward -0.556\n",
      "tensor([0.2331, 0.2049, 0.0395, 0.2332, 0.0316, 0.1303, 0.0327, 0.0316, 0.0316,\n",
      "        0.0316])\n",
      "tensor(88.6600)\n",
      "tensor(91.1600)\n",
      "Round 600, reward -0.545\n",
      "tensor([0.2078, 0.0282, 0.2078, 0.0281, 0.0281, 0.0281, 0.2078, 0.0281, 0.0281,\n",
      "        0.2078])\n",
      "tensor(90.7200)\n",
      "tensor(89.8400)\n",
      "Round 601, reward -0.204\n",
      "tensor([0.1570, 0.0228, 0.0258, 0.0779, 0.1687, 0.1475, 0.0318, 0.1613, 0.0430,\n",
      "        0.1643])\n",
      "tensor(95.8100)\n",
      "tensor(94.2300)\n",
      "Round 602, reward -0.087\n",
      "tensor([0.0308, 0.0311, 0.0814, 0.0308, 0.1760, 0.0308, 0.1343, 0.2266, 0.2272,\n",
      "        0.0308])\n",
      "tensor(92.8400)\n",
      "tensor(95.6300)\n",
      "Round 603, reward -0.458\n",
      "tensor([0.0451, 0.0451, 0.3329, 0.2920, 0.0451, 0.0451, 0.0451, 0.0451, 0.0451,\n",
      "        0.0595])\n",
      "tensor(93.4100)\n",
      "tensor(96.2500)\n",
      "Round 604, reward -0.445\n",
      "tensor([0.0998, 0.0998, 0.1019, 0.0998, 0.0998, 0.0998, 0.0998, 0.0998, 0.0998,\n",
      "        0.0998])\n",
      "tensor(96.6300)\n",
      "tensor(96.6500)\n",
      "Round 605, reward -0.090\n",
      "tensor([0.0561, 0.4142, 0.0952, 0.0561, 0.0981, 0.0561, 0.0561, 0.0561, 0.0561,\n",
      "        0.0561])\n",
      "tensor(96.1000)\n",
      "tensor(96.0200)\n",
      "Round 606, reward -0.080\n",
      "tensor([0.0453, 0.0452, 0.0624, 0.2666, 0.0452, 0.0466, 0.0639, 0.0452, 0.3343,\n",
      "        0.0452])\n",
      "tensor(96.8400)\n",
      "tensor(96.2800)\n",
      "Round 607, reward -0.060\n",
      "tensor([0.1612, 0.1594, 0.0994, 0.1829, 0.0248, 0.1125, 0.0267, 0.1829, 0.0248,\n",
      "        0.0256])\n",
      "tensor(97.1000)\n",
      "tensor(97.3000)\n",
      "Round 608, reward -0.223\n",
      "tensor([0.0221, 0.0310, 0.1629, 0.0221, 0.1631, 0.1600, 0.0939, 0.0221, 0.1626,\n",
      "        0.1602])\n",
      "tensor(96.6800)\n",
      "tensor(97.2300)\n",
      "Round 609, reward -0.334\n",
      "tensor([0.1261, 0.0858, 0.1261, 0.1261, 0.1261, 0.1261, 0.0171, 0.1261, 0.1236,\n",
      "        0.0171])\n",
      "tensor(96.3100)\n",
      "tensor(97.0600)\n",
      "Round 610, reward -0.361\n",
      "tensor([0.0613, 0.0615, 0.0613, 0.0613, 0.0613, 0.0613, 0.0613, 0.4482, 0.0613,\n",
      "        0.0615])\n",
      "tensor(94.7400)\n",
      "tensor(95.9100)\n",
      "Round 611, reward -0.411\n",
      "tensor([0.1800, 0.0244, 0.1222, 0.1485, 0.0254, 0.1800, 0.0244, 0.1800, 0.0908,\n",
      "        0.0244])\n",
      "tensor(96.9000)\n",
      "tensor(96.9800)\n",
      "Round 612, reward -0.143\n",
      "tensor([0.0294, 0.0294, 0.2175, 0.0295, 0.0547, 0.1490, 0.2143, 0.0294, 0.0294,\n",
      "        0.2174])\n",
      "tensor(96.7700)\n",
      "tensor(96.8500)\n",
      "Round 613, reward -0.147\n",
      "tensor([0.1928, 0.0261, 0.0261, 0.0261, 0.1695, 0.1087, 0.1928, 0.1926, 0.0393,\n",
      "        0.0262])\n",
      "tensor(95.7900)\n",
      "tensor(96.1900)\n",
      "Round 614, reward -0.331\n",
      "tensor([0.0655, 0.0654, 0.0654, 0.0654, 0.0654, 0.0655, 0.0654, 0.0654, 0.0654,\n",
      "        0.4110])\n",
      "tensor(95.6400)\n",
      "tensor(96.9200)\n",
      "Round 615, reward -0.390\n",
      "tensor([0.1780, 0.0241, 0.1780, 0.1780, 0.0241, 0.1672, 0.0241, 0.1780, 0.0246,\n",
      "        0.0241])\n",
      "tensor(95.9800)\n",
      "tensor(96.3000)\n",
      "Round 616, reward -0.303\n",
      "tensor([0.0342, 0.0427, 0.2527, 0.2463, 0.0342, 0.0342, 0.2440, 0.0342, 0.0342,\n",
      "        0.0432])\n",
      "tensor(95.6100)\n",
      "tensor(96.5600)\n",
      "Round 617, reward -0.386\n",
      "tensor([0.1560, 0.0211, 0.0211, 0.0213, 0.1363, 0.1558, 0.1559, 0.0211, 0.1560,\n",
      "        0.1554])\n",
      "tensor(95.8100)\n",
      "tensor(94.0800)\n",
      "Round 618, reward -0.087\n",
      "tensor([0.1615, 0.2177, 0.0295, 0.0446, 0.0295, 0.0295, 0.0295, 0.2107, 0.0301,\n",
      "        0.2177])\n",
      "tensor(96.7900)\n",
      "tensor(97.3700)\n",
      "Round 619, reward -0.335\n",
      "tensor([0.0261, 0.0261, 0.0263, 0.1927, 0.1026, 0.0261, 0.1906, 0.1908, 0.1927,\n",
      "        0.0261])\n",
      "tensor(93.5300)\n",
      "tensor(96.7500)\n",
      "Round 620, reward -0.442\n",
      "tensor([0.0647, 0.1591, 0.0218, 0.0966, 0.1314, 0.1610, 0.0218, 0.0218, 0.1610,\n",
      "        0.1610])\n",
      "tensor(96.6100)\n",
      "tensor(96.9000)\n",
      "Round 621, reward -0.276\n",
      "tensor([0.2509, 0.0340, 0.2509, 0.0431, 0.0340, 0.2504, 0.0342, 0.0340, 0.0340,\n",
      "        0.0347])\n",
      "tensor(96.5400)\n",
      "tensor(97.2700)\n",
      "Round 622, reward -0.354\n",
      "tensor([0.2477, 0.1579, 0.1437, 0.0335, 0.0341, 0.0336, 0.2478, 0.0335, 0.0345,\n",
      "        0.0335])\n",
      "tensor(95.7800)\n",
      "tensor(95.6600)\n",
      "Round 623, reward -0.088\n",
      "tensor([0.2259, 0.0343, 0.0306, 0.1351, 0.0306, 0.0306, 0.0306, 0.2259, 0.2259,\n",
      "        0.0306])\n",
      "tensor(96.7000)\n",
      "tensor(96.8800)\n",
      "Round 624, reward -0.222\n",
      "tensor([0.2507, 0.2500, 0.0339, 0.0339, 0.2507, 0.0340, 0.0340, 0.0357, 0.0431,\n",
      "        0.0339])\n",
      "tensor(94.3900)\n",
      "tensor(96.2100)\n",
      "Round 625, reward -0.422\n",
      "tensor([0.0293, 0.2165, 0.0293, 0.2165, 0.0362, 0.0293, 0.0801, 0.2165, 0.0293,\n",
      "        0.1170])\n",
      "tensor(97.1800)\n",
      "tensor(96.7100)\n",
      "Round 626, reward -0.051\n",
      "tensor([0.0333, 0.0628, 0.0333, 0.0333, 0.0333, 0.0333, 0.2459, 0.2459, 0.0333,\n",
      "        0.2456])\n",
      "tensor(96.7900)\n",
      "tensor(97.3700)\n",
      "Round 627, reward -0.335\n",
      "tensor([0.1762, 0.0238, 0.1762, 0.1755, 0.0238, 0.0239, 0.1762, 0.0242, 0.0238,\n",
      "        0.1762])\n",
      "tensor(97.0800)\n",
      "tensor(97.1400)\n",
      "Round 628, reward -0.120\n",
      "tensor([0.0253, 0.0251, 0.0251, 0.1462, 0.1737, 0.1851, 0.0255, 0.1840, 0.1851,\n",
      "        0.0251])\n",
      "tensor(96.8100)\n",
      "tensor(97.4400)\n",
      "Round 629, reward -0.339\n",
      "tensor([0.0269, 0.0269, 0.0269, 0.1889, 0.1989, 0.0269, 0.1986, 0.0271, 0.1990,\n",
      "        0.0798])\n",
      "tensor(96.2000)\n",
      "tensor(97.5000)\n",
      "Round 630, reward -0.376\n",
      "tensor([0.2570, 0.0358, 0.0355, 0.2605, 0.0398, 0.0355, 0.2295, 0.0355, 0.0355,\n",
      "        0.0355])\n",
      "tensor(96.6200)\n",
      "tensor(97.1100)\n",
      "Round 631, reward -0.327\n",
      "tensor([0.0204, 0.1421, 0.1486, 0.0201, 0.1486, 0.0201, 0.1003, 0.1064, 0.1461,\n",
      "        0.1472])\n",
      "tensor(95.7400)\n",
      "tensor(96.)\n",
      "Round 632, reward -0.287\n",
      "tensor([0.3243, 0.0443, 0.0439, 0.0439, 0.0439, 0.0439, 0.0439, 0.0439, 0.3243,\n",
      "        0.0439])\n",
      "tensor(97.2300)\n",
      "tensor(97.3600)\n",
      "Round 633, reward -0.175\n",
      "tensor([0.0605, 0.0605, 0.0605, 0.4463, 0.0605, 0.0605, 0.0655, 0.0648, 0.0605,\n",
      "        0.0605])\n",
      "tensor(92.4900)\n",
      "tensor(97.1500)\n",
      "Round 634, reward -0.466\n",
      "tensor([0.0287, 0.0287, 0.0305, 0.2119, 0.0287, 0.2019, 0.0287, 0.1981, 0.0310,\n",
      "        0.2119])\n",
      "tensor(96.8700)\n",
      "tensor(96.4900)\n",
      "Round 635, reward -0.059\n",
      "tensor([0.1777, 0.1779, 0.0241, 0.1779, 0.0787, 0.1195, 0.0241, 0.1641, 0.0241,\n",
      "        0.0319])\n",
      "tensor(96.9400)\n",
      "tensor(97.0500)\n",
      "Round 636, reward -0.168\n",
      "tensor([0.2716, 0.0379, 0.0528, 0.0368, 0.2716, 0.0368, 0.0368, 0.1824, 0.0368,\n",
      "        0.0368])\n",
      "tensor(95.0700)\n",
      "tensor(96.8400)\n",
      "Round 637, reward -0.405\n",
      "tensor([0.2877, 0.0390, 0.0535, 0.0390, 0.2878, 0.0677, 0.0957, 0.0518, 0.0390,\n",
      "        0.0390])\n",
      "tensor(96.2700)\n",
      "tensor(96.8300)\n",
      "Round 638, reward -0.346\n",
      "tensor([0.0345, 0.0345, 0.0345, 0.2507, 0.0345, 0.2551, 0.2525, 0.0345, 0.0345,\n",
      "        0.0345])\n",
      "tensor(95.4800)\n",
      "tensor(96.2700)\n",
      "Round 639, reward -0.384\n",
      "tensor([0.1663, 0.0242, 0.1629, 0.1586, 0.0248, 0.1620, 0.0905, 0.0225, 0.0233,\n",
      "        0.1648])\n",
      "tensor(93.5900)\n",
      "tensor(94.7100)\n",
      "Round 640, reward -0.438\n",
      "tensor([0.0384, 0.0335, 0.2477, 0.2477, 0.0335, 0.2477, 0.0508, 0.0336, 0.0335,\n",
      "        0.0336])\n",
      "tensor(93.8300)\n",
      "tensor(97.2500)\n",
      "Round 641, reward -0.435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0333, 0.2455, 0.1983, 0.0333, 0.1002, 0.0333, 0.0449, 0.0333, 0.0333,\n",
      "        0.2446])\n",
      "tensor(89.6200)\n",
      "tensor(96.1600)\n",
      "Round 642, reward -0.526\n",
      "tensor([0.0235, 0.1719, 0.1732, 0.1732, 0.0487, 0.1658, 0.0235, 0.0235, 0.0235,\n",
      "        0.1733])\n",
      "tensor(96.7400)\n",
      "tensor(95.3600)\n",
      "Round 643, reward -0.063\n",
      "tensor([0.0327, 0.0327, 0.2416, 0.0329, 0.0330, 0.0327, 0.0806, 0.2399, 0.0327,\n",
      "        0.2412])\n",
      "tensor(96.1300)\n",
      "tensor(95.9400)\n",
      "Round 644, reward -0.079\n",
      "tensor([0.2551, 0.0823, 0.0823, 0.0823, 0.0868, 0.0823, 0.0823, 0.0823, 0.0823,\n",
      "        0.0823])\n",
      "tensor(97.2100)\n",
      "tensor(97.3000)\n",
      "Round 645, reward -0.144\n",
      "tensor([0.0458, 0.3061, 0.0447, 0.0446, 0.0447, 0.0450, 0.0448, 0.0446, 0.3213,\n",
      "        0.0584])\n",
      "tensor(94.1300)\n",
      "tensor(96.8100)\n",
      "Round 646, reward -0.428\n",
      "tensor([0.1570, 0.0213, 0.0212, 0.0213, 0.1068, 0.1296, 0.1570, 0.0760, 0.1527,\n",
      "        0.1570])\n",
      "tensor(94.7500)\n",
      "tensor(95.7700)\n",
      "Round 647, reward -0.409\n",
      "tensor([0.0747, 0.0747, 0.0748, 0.0752, 0.0747, 0.0750, 0.3211, 0.0800, 0.0747,\n",
      "        0.0748])\n",
      "tensor(95.4500)\n",
      "tensor(95.5400)\n",
      "Round 648, reward -0.190\n",
      "tensor([0.0284, 0.1753, 0.0335, 0.2099, 0.0443, 0.0284, 0.0327, 0.0284, 0.2093,\n",
      "        0.2099])\n",
      "tensor(97.3500)\n",
      "tensor(97.3100)\n",
      "Round 649, reward -0.046\n",
      "tensor([0.1162, 0.1214, 0.1215, 0.1215, 0.1215, 0.0168, 0.1215, 0.1215, 0.1215,\n",
      "        0.0164])\n",
      "tensor(97.4300)\n",
      "tensor(97.5200)\n",
      "Round 650, reward -0.138\n",
      "tensor([0.1550, 0.0224, 0.1537, 0.1423, 0.0211, 0.1274, 0.0491, 0.0211, 0.1551,\n",
      "        0.1527])\n",
      "tensor(96.7300)\n",
      "tensor(97.3100)\n",
      "Round 651, reward -0.336\n",
      "tensor([0.0743, 0.0280, 0.0280, 0.2069, 0.2069, 0.0280, 0.0421, 0.0282, 0.1507,\n",
      "        0.2069])\n",
      "tensor(97.0800)\n",
      "tensor(97.2600)\n",
      "Round 652, reward -0.212\n",
      "tensor([0.0450, 0.0448, 0.0436, 0.3222, 0.3222, 0.0436, 0.0477, 0.0436, 0.0436,\n",
      "        0.0436])\n",
      "tensor(96.1400)\n",
      "tensor(96.6200)\n",
      "Round 653, reward -0.338\n",
      "tensor([0.1595, 0.3835, 0.0519, 0.0570, 0.0886, 0.0519, 0.0519, 0.0519, 0.0519,\n",
      "        0.0519])\n",
      "tensor(94.1200)\n",
      "tensor(96.1900)\n",
      "Round 654, reward -0.429\n",
      "tensor([0.0367, 0.0367, 0.0367, 0.0370, 0.2195, 0.0367, 0.0368, 0.2521, 0.0367,\n",
      "        0.2712])\n",
      "tensor(93.1800)\n",
      "tensor(96.5700)\n",
      "Round 655, reward -0.450\n",
      "tensor([0.2482, 0.0361, 0.2499, 0.0341, 0.0365, 0.0341, 0.0341, 0.0410, 0.2519,\n",
      "        0.0341])\n",
      "tensor(95.7000)\n",
      "tensor(96.8300)\n",
      "Round 656, reward -0.387\n",
      "tensor([0.0595, 0.0625, 0.0595, 0.0596, 0.0595, 0.1035, 0.4169, 0.0600, 0.0595,\n",
      "        0.0595])\n",
      "tensor(96.2700)\n",
      "tensor(96.9300)\n",
      "Round 657, reward -0.356\n",
      "tensor([0.0424, 0.0747, 0.0424, 0.0424, 0.3134, 0.0440, 0.0424, 0.0424, 0.0424,\n",
      "        0.3134])\n",
      "tensor(95.4300)\n",
      "tensor(96.9500)\n",
      "Round 658, reward -0.396\n",
      "tensor([0.2055, 0.2059, 0.0283, 0.0279, 0.0279, 0.1991, 0.2058, 0.0440, 0.0279,\n",
      "        0.0279])\n",
      "tensor(97.0100)\n",
      "tensor(97.2500)\n",
      "Round 659, reward -0.245\n",
      "tensor([0.1257, 0.1257, 0.1250, 0.1257, 0.1257, 0.1255, 0.0464, 0.0574, 0.1257,\n",
      "        0.0170])\n",
      "tensor(96.5900)\n",
      "tensor(96.5700)\n",
      "Round 660, reward -0.067\n",
      "tensor([0.1750, 0.1751, 0.0283, 0.0237, 0.1750, 0.0237, 0.0265, 0.0238, 0.1751,\n",
      "        0.1738])\n",
      "tensor(97.0400)\n",
      "tensor(97.1800)\n",
      "Round 661, reward -0.187\n",
      "tensor([0.2545, 0.0344, 0.0344, 0.2533, 0.0344, 0.0344, 0.0344, 0.2510, 0.0344,\n",
      "        0.0344])\n",
      "tensor(96.5500)\n",
      "tensor(97.2700)\n",
      "Round 662, reward -0.353\n",
      "tensor([0.2658, 0.0540, 0.2658, 0.0360, 0.0362, 0.0360, 0.0360, 0.0360, 0.1984,\n",
      "        0.0360])\n",
      "tensor(92.1000)\n",
      "tensor(97.3500)\n",
      "Round 663, reward -0.475\n",
      "tensor([0.1912, 0.1941, 0.1940, 0.0263, 0.0263, 0.0263, 0.1674, 0.1219, 0.0263,\n",
      "        0.0263])\n",
      "tensor(93.8600)\n",
      "tensor(96.1400)\n",
      "Round 664, reward -0.435\n",
      "tensor([0.0424, 0.0424, 0.1201, 0.3126, 0.0424, 0.0424, 0.0424, 0.0558, 0.0424,\n",
      "        0.2570])\n",
      "tensor(94.3400)\n",
      "tensor(95.0700)\n",
      "Round 665, reward -0.409\n",
      "tensor([0.1527, 0.0505, 0.0505, 0.0505, 0.0505, 0.0573, 0.0505, 0.1134, 0.3734,\n",
      "        0.0505])\n",
      "tensor(95.2400)\n",
      "tensor(97.0800)\n",
      "Round 666, reward -0.401\n",
      "tensor([0.2133, 0.2127, 0.0290, 0.0289, 0.0289, 0.1859, 0.2131, 0.0289, 0.0289,\n",
      "        0.0304])\n",
      "tensor(95.9500)\n",
      "tensor(96.5700)\n",
      "Round 667, reward -0.361\n",
      "tensor([0.0427, 0.0769, 0.0433, 0.3156, 0.0431, 0.0477, 0.2792, 0.0427, 0.0661,\n",
      "        0.0427])\n",
      "tensor(92.5400)\n",
      "tensor(96.5100)\n",
      "Round 668, reward -0.465\n",
      "tensor([0.1726, 0.0319, 0.0290, 0.2144, 0.0290, 0.2095, 0.0290, 0.0290, 0.0429,\n",
      "        0.2126])\n",
      "tensor(94.4400)\n",
      "tensor(97.1300)\n",
      "Round 669, reward -0.421\n",
      "tensor([0.0410, 0.0469, 0.0410, 0.0410, 0.0423, 0.2848, 0.1264, 0.0416, 0.2938,\n",
      "        0.0411])\n",
      "tensor(96.4100)\n",
      "tensor(96.7300)\n",
      "Round 670, reward -0.292\n",
      "tensor([0.0353, 0.2415, 0.0353, 0.0368, 0.0417, 0.2426, 0.2609, 0.0353, 0.0353,\n",
      "        0.0353])\n",
      "tensor(96.9400)\n",
      "tensor(97.2200)\n",
      "Round 671, reward -0.264\n",
      "tensor([0.0497, 0.0497, 0.0497, 0.0907, 0.2509, 0.0497, 0.0497, 0.0498, 0.3106,\n",
      "        0.0497])\n",
      "tensor(94.7500)\n",
      "tensor(96.3800)\n",
      "Round 672, reward -0.413\n",
      "tensor([0.3257, 0.0467, 0.0441, 0.0441, 0.3178, 0.0441, 0.0452, 0.0441, 0.0441,\n",
      "        0.0441])\n",
      "tensor(96.)\n",
      "tensor(95.8900)\n",
      "Round 673, reward -0.082\n",
      "tensor([0.0280, 0.0431, 0.1471, 0.1464, 0.0199, 0.0275, 0.1462, 0.1473, 0.1472,\n",
      "        0.1472])\n",
      "tensor(96.4400)\n",
      "tensor(97.1000)\n",
      "Round 674, reward -0.351\n",
      "tensor([0.0283, 0.0281, 0.2077, 0.0281, 0.0284, 0.2074, 0.0281, 0.2078, 0.0281,\n",
      "        0.2078])\n",
      "tensor(96.6600)\n",
      "tensor(97.5500)\n",
      "Round 675, reward -0.358\n",
      "tensor([0.0238, 0.0238, 0.0242, 0.1759, 0.0245, 0.1757, 0.1761, 0.1759, 0.0238,\n",
      "        0.1761])\n",
      "tensor(96.9200)\n",
      "tensor(97.5000)\n",
      "Round 676, reward -0.331\n",
      "tensor([0.1984, 0.0277, 0.0559, 0.1115, 0.0330, 0.0276, 0.0276, 0.2037, 0.2038,\n",
      "        0.1108])\n",
      "tensor(97.3000)\n",
      "tensor(97.6100)\n",
      "Round 677, reward -0.265\n",
      "tensor([0.1589, 0.1589, 0.0215, 0.1470, 0.1549, 0.1176, 0.0215, 0.0893, 0.1088,\n",
      "        0.0215])\n",
      "tensor(97.1200)\n",
      "tensor(97.3400)\n",
      "Round 678, reward -0.232\n",
      "tensor([0.1514, 0.1514, 0.1452, 0.0461, 0.0205, 0.0205, 0.1510, 0.0205, 0.1513,\n",
      "        0.1422])\n",
      "tensor(96.8100)\n",
      "tensor(96.8100)\n",
      "Round 679, reward -0.061\n",
      "tensor([0.1243, 0.0898, 0.1455, 0.1453, 0.1455, 0.0198, 0.1450, 0.0197, 0.1455,\n",
      "        0.0197])\n",
      "tensor(96.6100)\n",
      "tensor(97.2100)\n",
      "Round 680, reward -0.341\n",
      "tensor([0.0471, 0.0473, 0.0449, 0.0563, 0.0449, 0.0449, 0.0473, 0.3308, 0.0449,\n",
      "        0.2917])\n",
      "tensor(95.6600)\n",
      "tensor(97.1100)\n",
      "Round 681, reward -0.390\n",
      "tensor([0.2055, 0.0279, 0.0279, 0.2061, 0.2061, 0.2061, 0.0279, 0.0367, 0.0280,\n",
      "        0.0279])\n",
      "tensor(94.5100)\n",
      "tensor(95.8900)\n",
      "Round 682, reward -0.418\n",
      "tensor([0.3150, 0.0426, 0.0426, 0.3150, 0.0444, 0.0684, 0.0430, 0.0426, 0.0430,\n",
      "        0.0435])\n",
      "tensor(95.5900)\n",
      "tensor(97.5100)\n",
      "Round 683, reward -0.392\n",
      "tensor([0.0686, 0.0686, 0.0686, 0.3313, 0.0686, 0.1088, 0.0687, 0.0686, 0.0796,\n",
      "        0.0686])\n",
      "tensor(96.5400)\n",
      "tensor(96.8600)\n",
      "Round 684, reward -0.289\n",
      "tensor([0.0357, 0.0354, 0.2615, 0.1259, 0.0354, 0.0354, 0.0354, 0.0354, 0.2220,\n",
      "        0.1779])\n",
      "tensor(96.5900)\n",
      "tensor(96.9700)\n",
      "Round 685, reward -0.305\n",
      "tensor([0.0516, 0.0509, 0.0509, 0.2124, 0.0510, 0.0509, 0.0509, 0.0539, 0.3764,\n",
      "        0.0509])\n",
      "tensor(95.6400)\n",
      "tensor(97.0300)\n",
      "Round 686, reward -0.390\n",
      "tensor([0.0361, 0.2636, 0.2598, 0.2171, 0.0357, 0.0449, 0.0357, 0.0357, 0.0357,\n",
      "        0.0357])\n",
      "tensor(97.2900)\n",
      "tensor(97.3300)\n",
      "Round 687, reward -0.094\n",
      "tensor([0.1669, 0.0241, 0.1780, 0.1780, 0.0469, 0.0241, 0.1506, 0.1780, 0.0292,\n",
      "        0.0242])\n",
      "tensor(97.3100)\n",
      "tensor(97.7200)\n",
      "Round 688, reward -0.293\n",
      "tensor([0.0516, 0.0517, 0.0783, 0.3816, 0.1551, 0.0516, 0.0517, 0.0516, 0.0516,\n",
      "        0.0750])\n",
      "tensor(97.0100)\n",
      "tensor(97.0700)\n",
      "Round 689, reward -0.122\n",
      "tensor([0.3197, 0.0443, 0.3264, 0.0444, 0.0442, 0.0442, 0.0442, 0.0442, 0.0442,\n",
      "        0.0442])\n",
      "tensor(93.0200)\n",
      "tensor(94.7400)\n",
      "Round 690, reward -0.454\n",
      "tensor([0.0242, 0.0241, 0.1782, 0.0242, 0.1759, 0.1695, 0.0250, 0.1765, 0.1783,\n",
      "        0.0241])\n",
      "tensor(92.4200)\n",
      "tensor(97.1000)\n",
      "Round 691, reward -0.468\n",
      "tensor([0.0233, 0.1671, 0.0227, 0.1671, 0.0226, 0.0251, 0.1671, 0.1671, 0.0709,\n",
      "        0.1671])\n",
      "tensor(95.3300)\n",
      "tensor(97.0100)\n",
      "Round 692, reward -0.399\n",
      "tensor([0.0517, 0.0295, 0.0295, 0.2155, 0.1494, 0.2180, 0.0295, 0.0295, 0.2179,\n",
      "        0.0295])\n",
      "tensor(96.6800)\n",
      "tensor(97.2700)\n",
      "Round 693, reward -0.339\n",
      "tensor([0.1573, 0.1573, 0.0213, 0.1307, 0.1573, 0.1546, 0.1573, 0.0213, 0.0216,\n",
      "        0.0215])\n",
      "tensor(96.9500)\n",
      "tensor(96.9600)\n",
      "Round 694, reward -0.069\n",
      "tensor([0.1810, 0.1810, 0.1810, 0.0245, 0.0247, 0.1810, 0.0995, 0.0701, 0.0329,\n",
      "        0.0245])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.3600)\n",
      "tensor(97.2400)\n",
      "Round 695, reward -0.046\n",
      "tensor([0.0440, 0.3248, 0.3235, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440,\n",
      "        0.0440])\n",
      "tensor(92.9900)\n",
      "tensor(96.7400)\n",
      "Round 696, reward -0.455\n",
      "tensor([0.0278, 0.0278, 0.2051, 0.0278, 0.0278, 0.2037, 0.0421, 0.0278, 0.2051,\n",
      "        0.2051])\n",
      "tensor(97.0800)\n",
      "tensor(97.1800)\n",
      "Round 697, reward -0.156\n",
      "tensor([0.0224, 0.1528, 0.1528, 0.0207, 0.0249, 0.1528, 0.1475, 0.1527, 0.1528,\n",
      "        0.0207])\n",
      "tensor(97.3900)\n",
      "tensor(97.5400)\n",
      "Round 698, reward -0.185\n",
      "tensor([0.0234, 0.1701, 0.1703, 0.0551, 0.1700, 0.1703, 0.0230, 0.1702, 0.0245,\n",
      "        0.0231])\n",
      "tensor(97.3900)\n",
      "tensor(97.0600)\n",
      "Round 699, reward -0.045\n",
      "tensor([0.1831, 0.1839, 0.0249, 0.0485, 0.0252, 0.0267, 0.1839, 0.1839, 0.0249,\n",
      "        0.1150])\n",
      "tensor(96.4600)\n",
      "tensor(96.2900)\n",
      "Round 700, reward -0.070\n",
      "tensor([0.0270, 0.1908, 0.1999, 0.0276, 0.0270, 0.0270, 0.0297, 0.1988, 0.0723,\n",
      "        0.1998])\n",
      "tensor(96.3200)\n",
      "tensor(96.6900)\n",
      "Round 701, reward -0.309\n",
      "tensor([0.0517, 0.2072, 0.1865, 0.2072, 0.0281, 0.0280, 0.0280, 0.2072, 0.0280,\n",
      "        0.0281])\n",
      "tensor(96.4200)\n",
      "tensor(96.7700)\n",
      "Round 702, reward -0.301\n",
      "tensor([0.0270, 0.1997, 0.0271, 0.0581, 0.1997, 0.1957, 0.1997, 0.0385, 0.0270,\n",
      "        0.0275])\n",
      "tensor(96.0900)\n",
      "tensor(96.7500)\n",
      "Round 703, reward -0.361\n",
      "tensor([0.1903, 0.3154, 0.0591, 0.0592, 0.0591, 0.0591, 0.0591, 0.0604, 0.0591,\n",
      "        0.0791])\n",
      "tensor(96.9600)\n",
      "tensor(97.4800)\n",
      "Round 704, reward -0.322\n",
      "tensor([0.0389, 0.0389, 0.0389, 0.0522, 0.0389, 0.2872, 0.0389, 0.2872, 0.0389,\n",
      "        0.1402])\n",
      "tensor(96.5100)\n",
      "tensor(97.1800)\n",
      "Round 705, reward -0.350\n",
      "tensor([0.0283, 0.2090, 0.0283, 0.2077, 0.0283, 0.0283, 0.2090, 0.2045, 0.0283,\n",
      "        0.0283])\n",
      "tensor(95.9700)\n",
      "tensor(96.8400)\n",
      "Round 706, reward -0.375\n",
      "tensor([0.1739, 0.0250, 0.1836, 0.0250, 0.1787, 0.0287, 0.1507, 0.0250, 0.1846,\n",
      "        0.0250])\n",
      "tensor(96.6300)\n",
      "tensor(97.1700)\n",
      "Round 707, reward -0.334\n",
      "tensor([0.1486, 0.0235, 0.1511, 0.0235, 0.0235, 0.0242, 0.1711, 0.1662, 0.0946,\n",
      "        0.1737])\n",
      "tensor(96.0600)\n",
      "tensor(96.9500)\n",
      "Round 708, reward -0.373\n",
      "tensor([0.1503, 0.1503, 0.1503, 0.1503, 0.0206, 0.0203, 0.1503, 0.0210, 0.1503,\n",
      "        0.0364])\n",
      "tensor(93.1900)\n",
      "tensor(96.0100)\n",
      "Round 709, reward -0.450\n",
      "tensor([0.2086, 0.0392, 0.0363, 0.0363, 0.0363, 0.0363, 0.0363, 0.0515, 0.2679,\n",
      "        0.2516])\n",
      "tensor(97.1800)\n",
      "tensor(96.2300)\n",
      "Round 710, reward -0.051\n",
      "tensor([0.0209, 0.1548, 0.1277, 0.1546, 0.0224, 0.1548, 0.0324, 0.1548, 0.0229,\n",
      "        0.1548])\n",
      "tensor(96.5400)\n",
      "tensor(97.1300)\n",
      "Round 711, reward -0.342\n",
      "tensor([0.2627, 0.0365, 0.0355, 0.1923, 0.0677, 0.0357, 0.0358, 0.0355, 0.0355,\n",
      "        0.2627])\n",
      "tensor(94.3400)\n",
      "tensor(95.4200)\n",
      "Round 712, reward -0.420\n",
      "tensor([0.0607, 0.0607, 0.0608, 0.0607, 0.0607, 0.0607, 0.0654, 0.4487, 0.0607,\n",
      "        0.0608])\n",
      "tensor(95.5700)\n",
      "tensor(96.1400)\n",
      "Round 713, reward -0.365\n",
      "tensor([0.0266, 0.0367, 0.0269, 0.1966, 0.0266, 0.1773, 0.1966, 0.1966, 0.0895,\n",
      "        0.0266])\n",
      "tensor(94.3200)\n",
      "tensor(95.3800)\n",
      "Round 714, reward -0.420\n",
      "tensor([0.0345, 0.0341, 0.0341, 0.0341, 0.2273, 0.0341, 0.2518, 0.0341, 0.0644,\n",
      "        0.2516])\n",
      "tensor(94.6600)\n",
      "tensor(96.5000)\n",
      "Round 715, reward -0.415\n",
      "tensor([0.1423, 0.0254, 0.1871, 0.0253, 0.1658, 0.0253, 0.1871, 0.0253, 0.0291,\n",
      "        0.1871])\n",
      "tensor(97.3300)\n",
      "tensor(97.6400)\n",
      "Round 716, reward -0.264\n",
      "tensor([0.1515, 0.0238, 0.1758, 0.0474, 0.0266, 0.0238, 0.0238, 0.1758, 0.1758,\n",
      "        0.1758])\n",
      "tensor(96.3300)\n",
      "tensor(97.0100)\n",
      "Round 717, reward -0.356\n",
      "tensor([0.0354, 0.0354, 0.0354, 0.0355, 0.0361, 0.2322, 0.0354, 0.2574, 0.0354,\n",
      "        0.2617])\n",
      "tensor(97.0200)\n",
      "tensor(97.5300)\n",
      "Round 718, reward -0.319\n",
      "tensor([0.0247, 0.1823, 0.0247, 0.0354, 0.1799, 0.1823, 0.1822, 0.1392, 0.0247,\n",
      "        0.0247])\n",
      "tensor(96.5900)\n",
      "tensor(97.3300)\n",
      "Round 719, reward -0.353\n",
      "tensor([0.1530, 0.0224, 0.0224, 0.0224, 0.1634, 0.1655, 0.1655, 0.0224, 0.1651,\n",
      "        0.0978])\n",
      "tensor(97.1600)\n",
      "tensor(97.2400)\n",
      "Round 720, reward -0.136\n",
      "tensor([0.0298, 0.0298, 0.2200, 0.0298, 0.1597, 0.1779, 0.2151, 0.0783, 0.0298,\n",
      "        0.0298])\n",
      "tensor(95.8100)\n",
      "tensor(96.9700)\n",
      "Round 721, reward -0.385\n",
      "tensor([0.0327, 0.2416, 0.0327, 0.0327, 0.2408, 0.0327, 0.0327, 0.0786, 0.0342,\n",
      "        0.2413])\n",
      "tensor(95.8600)\n",
      "tensor(96.9900)\n",
      "Round 722, reward -0.383\n",
      "tensor([0.0423, 0.3119, 0.0423, 0.0423, 0.0525, 0.0718, 0.0425, 0.0442, 0.0423,\n",
      "        0.3079])\n",
      "tensor(93.6500)\n",
      "tensor(96.8500)\n",
      "Round 723, reward -0.440\n",
      "tensor([0.0343, 0.0343, 0.2533, 0.0343, 0.2533, 0.0343, 0.0343, 0.2533, 0.0343,\n",
      "        0.0343])\n",
      "tensor(96.)\n",
      "tensor(97.3000)\n",
      "Round 724, reward -0.381\n",
      "tensor([0.0321, 0.0288, 0.0289, 0.1851, 0.2124, 0.0288, 0.2131, 0.0288, 0.2131,\n",
      "        0.0288])\n",
      "tensor(96.7200)\n",
      "tensor(96.6300)\n",
      "Round 725, reward -0.063\n",
      "tensor([0.2353, 0.1429, 0.0420, 0.0635, 0.0420, 0.0420, 0.3058, 0.0420, 0.0420,\n",
      "        0.0426])\n",
      "tensor(97.1200)\n",
      "tensor(96.1400)\n",
      "Round 726, reward -0.053\n",
      "tensor([0.0344, 0.2122, 0.0287, 0.1836, 0.0287, 0.0290, 0.0287, 0.2116, 0.0309,\n",
      "        0.2122])\n",
      "tensor(97.3500)\n",
      "tensor(97.4500)\n",
      "Round 727, reward -0.148\n",
      "tensor([0.1561, 0.0211, 0.0211, 0.1551, 0.1561, 0.1561, 0.0211, 0.0211, 0.1561,\n",
      "        0.1361])\n",
      "tensor(95.3900)\n",
      "tensor(97.3200)\n",
      "Round 728, reward -0.397\n",
      "tensor([0.2353, 0.0318, 0.0318, 0.2344, 0.0318, 0.2353, 0.0318, 0.1040, 0.0318,\n",
      "        0.0318])\n",
      "tensor(97.4400)\n",
      "tensor(97.7000)\n",
      "Round 729, reward -0.242\n",
      "tensor([0.1973, 0.0270, 0.1994, 0.0270, 0.0270, 0.0270, 0.1994, 0.1993, 0.0273,\n",
      "        0.0693])\n",
      "tensor(95.7700)\n",
      "tensor(96.7300)\n",
      "Round 730, reward -0.382\n",
      "tensor([0.1995, 0.0303, 0.0303, 0.2239, 0.0303, 0.1949, 0.1999, 0.0303, 0.0303,\n",
      "        0.0303])\n",
      "tensor(97.0800)\n",
      "tensor(97.3500)\n",
      "Round 731, reward -0.256\n",
      "tensor([0.0285, 0.2107, 0.0285, 0.0286, 0.1970, 0.2103, 0.0285, 0.2107, 0.0285,\n",
      "        0.0286])\n",
      "tensor(96.6900)\n",
      "tensor(97.4700)\n",
      "Round 732, reward -0.352\n",
      "tensor([0.0230, 0.0700, 0.1617, 0.1695, 0.0229, 0.0229, 0.0230, 0.1695, 0.1695,\n",
      "        0.1678])\n",
      "tensor(97.0400)\n",
      "tensor(97.0900)\n",
      "Round 733, reward -0.111\n",
      "tensor([0.2153, 0.0293, 0.0986, 0.0814, 0.0293, 0.0445, 0.0399, 0.0296, 0.2161,\n",
      "        0.2161])\n",
      "tensor(95.9000)\n",
      "tensor(97.0200)\n",
      "Round 734, reward -0.382\n",
      "tensor([0.0290, 0.2076, 0.0281, 0.2076, 0.2076, 0.0281, 0.2076, 0.0281, 0.0281,\n",
      "        0.0281])\n",
      "tensor(97.4500)\n",
      "tensor(97.5800)\n",
      "Round 735, reward -0.169\n",
      "tensor([0.3243, 0.0439, 0.0439, 0.0439, 0.0439, 0.0439, 0.0441, 0.3243, 0.0439,\n",
      "        0.0439])\n",
      "tensor(96.3300)\n",
      "tensor(96.7300)\n",
      "Round 736, reward -0.317\n",
      "tensor([0.0253, 0.1868, 0.1258, 0.0253, 0.0253, 0.0253, 0.0261, 0.1866, 0.1868,\n",
      "        0.1868])\n",
      "tensor(97.3200)\n",
      "tensor(97.2900)\n",
      "Round 737, reward -0.047\n",
      "tensor([0.0649, 0.0604, 0.0604, 0.0660, 0.0604, 0.0604, 0.0604, 0.0604, 0.4462,\n",
      "        0.0605])\n",
      "tensor(96.4200)\n",
      "tensor(97.1000)\n",
      "Round 738, reward -0.353\n",
      "tensor([0.0375, 0.0375, 0.0375, 0.0375, 0.2770, 0.0400, 0.2770, 0.0375, 0.0383,\n",
      "        0.1803])\n",
      "tensor(95.4600)\n",
      "tensor(97.4500)\n",
      "Round 739, reward -0.396\n",
      "tensor([0.0269, 0.0626, 0.1988, 0.1043, 0.0270, 0.1341, 0.0333, 0.1179, 0.0972,\n",
      "        0.1978])\n",
      "tensor(96.4800)\n",
      "tensor(97.3000)\n",
      "Round 740, reward -0.360\n",
      "tensor([0.1638, 0.0327, 0.0740, 0.0223, 0.1642, 0.1367, 0.0547, 0.0223, 0.1646,\n",
      "        0.1647])\n",
      "tensor(96.5700)\n",
      "tensor(97.2200)\n",
      "Round 741, reward -0.347\n",
      "tensor([0.0338, 0.0338, 0.1042, 0.2420, 0.2494, 0.0338, 0.0435, 0.0343, 0.0338,\n",
      "        0.1915])\n",
      "tensor(96.5900)\n",
      "tensor(96.5200)\n",
      "Round 742, reward -0.067\n",
      "tensor([0.0246, 0.0246, 0.1818, 0.1788, 0.0646, 0.1818, 0.1124, 0.0251, 0.1818,\n",
      "        0.0246])\n",
      "tensor(97.1000)\n",
      "tensor(96.7100)\n",
      "Round 743, reward -0.053\n",
      "tensor([0.1072, 0.1599, 0.0216, 0.0216, 0.1599, 0.0284, 0.1599, 0.0216, 0.1599,\n",
      "        0.1598])\n",
      "tensor(97.3500)\n",
      "tensor(97.5500)\n",
      "Round 744, reward -0.216\n",
      "tensor([0.1742, 0.1742, 0.1740, 0.0739, 0.0253, 0.0238, 0.1742, 0.0236, 0.0236,\n",
      "        0.1331])\n",
      "tensor(94.8700)\n",
      "tensor(97.3600)\n",
      "Round 745, reward -0.410\n",
      "tensor([0.0386, 0.0347, 0.0345, 0.0346, 0.0345, 0.2435, 0.0345, 0.2550, 0.0350,\n",
      "        0.2551])\n",
      "tensor(97.4500)\n",
      "tensor(97.0700)\n",
      "Round 746, reward -0.044\n",
      "tensor([0.0315, 0.2280, 0.0313, 0.2309, 0.0313, 0.0313, 0.0313, 0.0313, 0.1740,\n",
      "        0.1793])\n",
      "tensor(95.9500)\n",
      "tensor(97.4500)\n",
      "Round 747, reward -0.383\n",
      "tensor([0.1617, 0.0298, 0.2201, 0.0298, 0.0298, 0.2196, 0.0298, 0.2198, 0.0298,\n",
      "        0.0298])\n",
      "tensor(96.5700)\n",
      "tensor(97.3600)\n",
      "Round 748, reward -0.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2075, 0.0282, 0.2079, 0.0281, 0.0281, 0.2079, 0.2079, 0.0281, 0.0281,\n",
      "        0.0281])\n",
      "tensor(95.7100)\n",
      "tensor(97.1400)\n",
      "Round 749, reward -0.389\n",
      "tensor([0.2095, 0.0357, 0.0448, 0.0382, 0.2603, 0.2583, 0.0475, 0.0352, 0.0352,\n",
      "        0.0352])\n",
      "tensor(91.9800)\n",
      "tensor(96.5600)\n",
      "Round 750, reward -0.477\n",
      "tensor([0.0562, 0.0499, 0.0508, 0.0499, 0.2910, 0.0499, 0.0499, 0.0673, 0.0701,\n",
      "        0.2648])\n",
      "tensor(95.8700)\n",
      "tensor(97.5300)\n",
      "Round 751, reward -0.385\n",
      "tensor([0.1491, 0.0202, 0.0202, 0.1491, 0.1491, 0.1490, 0.0457, 0.1484, 0.1491,\n",
      "        0.0202])\n",
      "tensor(92.7400)\n",
      "tensor(96.0400)\n",
      "Round 752, reward -0.460\n",
      "tensor([0.0343, 0.0343, 0.2529, 0.0343, 0.0343, 0.2533, 0.0343, 0.2533, 0.0346,\n",
      "        0.0343])\n",
      "tensor(97.6500)\n",
      "tensor(97.0800)\n",
      "Round 753, reward -0.038\n",
      "tensor([0.0410, 0.0410, 0.2385, 0.2140, 0.0410, 0.0410, 0.0413, 0.0410, 0.0410,\n",
      "        0.2605])\n",
      "tensor(96.5900)\n",
      "tensor(96.9200)\n",
      "Round 754, reward -0.291\n",
      "tensor([0.2096, 0.0284, 0.2095, 0.0284, 0.0367, 0.0304, 0.0284, 0.2095, 0.0284,\n",
      "        0.1909])\n",
      "tensor(95.0600)\n",
      "tensor(96.8400)\n",
      "Round 755, reward -0.406\n",
      "tensor([0.1799, 0.1802, 0.0244, 0.1802, 0.1802, 0.0244, 0.0244, 0.0244, 0.0290,\n",
      "        0.1530])\n",
      "tensor(92.1000)\n",
      "tensor(95.6800)\n",
      "Round 756, reward -0.475\n",
      "tensor([0.0410, 0.0433, 0.0410, 0.0416, 0.0410, 0.3024, 0.1056, 0.3025, 0.0409,\n",
      "        0.0409])\n",
      "tensor(86.2600)\n",
      "tensor(91.4600)\n",
      "Round 757, reward -0.588\n",
      "tensor([0.1375, 0.0187, 0.1354, 0.0508, 0.1375, 0.0898, 0.1371, 0.1374, 0.0186,\n",
      "        0.1371])\n",
      "tensor(88.9700)\n",
      "tensor(90.6100)\n",
      "Round 758, reward -0.538\n",
      "tensor([0.0464, 0.0464, 0.1946, 0.2862, 0.0492, 0.1861, 0.0464, 0.0465, 0.0479,\n",
      "        0.0505])\n",
      "tensor(96.6700)\n",
      "tensor(97.4200)\n",
      "Round 759, reward -0.351\n",
      "tensor([0.1516, 0.1511, 0.1516, 0.1515, 0.0205, 0.0305, 0.0205, 0.1516, 0.1505,\n",
      "        0.0206])\n",
      "tensor(97.0500)\n",
      "tensor(97.0800)\n",
      "Round 760, reward -0.090\n",
      "tensor([0.0235, 0.0309, 0.1728, 0.1728, 0.1728, 0.0281, 0.1728, 0.1728, 0.0234,\n",
      "        0.0299])\n",
      "tensor(95.3500)\n",
      "tensor(94.9600)\n",
      "Round 761, reward -0.099\n",
      "tensor([0.1530, 0.1530, 0.0214, 0.0207, 0.1516, 0.0210, 0.1529, 0.0207, 0.1530,\n",
      "        0.1529])\n",
      "tensor(94.4700)\n",
      "tensor(92.1800)\n",
      "Round 762, reward -0.120\n",
      "tensor([0.0233, 0.1722, 0.0233, 0.1722, 0.1560, 0.1722, 0.0554, 0.0298, 0.0236,\n",
      "        0.1722])\n",
      "tensor(97.4600)\n",
      "tensor(97.1200)\n",
      "Round 763, reward -0.043\n",
      "tensor([0.0210, 0.1548, 0.0210, 0.0212, 0.0210, 0.1411, 0.1547, 0.1551, 0.1551,\n",
      "        0.1550])\n",
      "tensor(97.0500)\n",
      "tensor(97.4300)\n",
      "Round 764, reward -0.293\n",
      "tensor([0.1704, 0.0297, 0.0295, 0.0295, 0.2169, 0.0295, 0.2178, 0.0295, 0.2179,\n",
      "        0.0295])\n",
      "tensor(96.5800)\n",
      "tensor(97.7300)\n",
      "Round 765, reward -0.365\n",
      "tensor([0.0280, 0.0281, 0.0280, 0.2066, 0.0282, 0.0280, 0.2067, 0.0330, 0.2067,\n",
      "        0.2067])\n",
      "tensor(96.5000)\n",
      "tensor(96.3400)\n",
      "Round 766, reward -0.069\n",
      "tensor([0.0344, 0.0344, 0.2541, 0.2508, 0.0344, 0.2541, 0.0344, 0.0344, 0.0344,\n",
      "        0.0346])\n",
      "tensor(92.7000)\n",
      "tensor(92.4400)\n",
      "Round 767, reward -0.161\n",
      "tensor([0.1441, 0.1546, 0.0209, 0.1543, 0.1546, 0.0209, 0.1546, 0.0209, 0.0209,\n",
      "        0.1542])\n",
      "tensor(95.5400)\n",
      "tensor(96.7400)\n",
      "Round 768, reward -0.392\n",
      "tensor([0.1364, 0.0366, 0.0821, 0.0366, 0.0765, 0.0366, 0.0366, 0.0374, 0.2703,\n",
      "        0.2511])\n",
      "tensor(91.8000)\n",
      "tensor(94.5400)\n",
      "Round 769, reward -0.481\n",
      "tensor([0.0990, 0.0989, 0.0989, 0.1086, 0.0989, 0.0989, 0.0989, 0.1000, 0.0989,\n",
      "        0.0989])\n",
      "tensor(96.3200)\n",
      "tensor(96.2800)\n",
      "Round 770, reward -0.074\n",
      "tensor([0.0232, 0.1711, 0.1711, 0.1711, 0.0232, 0.1586, 0.0641, 0.0234, 0.0232,\n",
      "        0.1711])\n",
      "tensor(97.1600)\n",
      "tensor(97.5200)\n",
      "Round 771, reward -0.284\n",
      "tensor([0.0254, 0.1878, 0.1878, 0.0254, 0.1878, 0.1860, 0.1224, 0.0254, 0.0265,\n",
      "        0.0254])\n",
      "tensor(96.4100)\n",
      "tensor(96.2400)\n",
      "Round 772, reward -0.071\n",
      "tensor([0.0256, 0.1892, 0.0256, 0.0300, 0.0257, 0.1507, 0.1853, 0.1892, 0.1530,\n",
      "        0.0256])\n",
      "tensor(97.2500)\n",
      "tensor(97.4800)\n",
      "Round 773, reward -0.234\n",
      "tensor([0.0285, 0.0285, 0.0285, 0.2103, 0.2103, 0.1977, 0.2103, 0.0285, 0.0285,\n",
      "        0.0289])\n",
      "tensor(94.0100)\n",
      "tensor(95.5400)\n",
      "Round 774, reward -0.431\n",
      "tensor([0.1583, 0.1583, 0.0217, 0.0851, 0.1583, 0.0214, 0.0838, 0.1470, 0.0214,\n",
      "        0.1448])\n",
      "tensor(91.5700)\n",
      "tensor(91.8800)\n",
      "Round 775, reward -0.403\n",
      "tensor([0.1470, 0.0324, 0.0324, 0.0324, 0.2390, 0.0324, 0.0324, 0.0324, 0.1830,\n",
      "        0.2368])\n",
      "tensor(96.4700)\n",
      "tensor(96.3900)\n",
      "Round 776, reward -0.070\n",
      "tensor([0.1880, 0.0254, 0.1879, 0.0254, 0.1149, 0.0254, 0.0265, 0.0303, 0.1880,\n",
      "        0.1880])\n",
      "tensor(95.4600)\n",
      "tensor(97.3500)\n",
      "Round 777, reward -0.396\n",
      "tensor([0.0470, 0.0470, 0.0556, 0.0472, 0.0470, 0.0697, 0.2454, 0.0470, 0.3471,\n",
      "        0.0470])\n",
      "tensor(94.9900)\n",
      "tensor(97.3400)\n",
      "Round 778, reward -0.408\n",
      "tensor([0.2147, 0.2132, 0.0886, 0.0291, 0.0313, 0.1213, 0.0291, 0.0291, 0.2147,\n",
      "        0.0291])\n",
      "tensor(94.5400)\n",
      "tensor(95.7500)\n",
      "Round 779, reward -0.417\n",
      "tensor([0.1759, 0.0238, 0.0238, 0.0252, 0.1759, 0.0238, 0.1759, 0.1759, 0.1759,\n",
      "        0.0238])\n",
      "tensor(95.3700)\n",
      "tensor(96.1300)\n",
      "Round 780, reward -0.385\n",
      "tensor([0.0607, 0.0607, 0.0607, 0.4486, 0.0607, 0.0617, 0.0607, 0.0647, 0.0607,\n",
      "        0.0607])\n",
      "tensor(96.6000)\n",
      "tensor(96.6300)\n",
      "Round 781, reward -0.102\n",
      "tensor([0.2132, 0.0289, 0.0289, 0.1902, 0.0289, 0.1591, 0.0289, 0.0814, 0.2116,\n",
      "        0.0289])\n",
      "tensor(96.1900)\n",
      "tensor(96.0600)\n",
      "Round 782, reward -0.077\n",
      "tensor([0.2372, 0.0322, 0.0354, 0.0321, 0.2094, 0.2302, 0.0321, 0.1263, 0.0321,\n",
      "        0.0330])\n",
      "tensor(95.8300)\n",
      "tensor(96.9500)\n",
      "Round 783, reward -0.384\n",
      "tensor([0.0497, 0.0497, 0.0497, 0.0584, 0.2321, 0.0497, 0.0507, 0.3591, 0.0511,\n",
      "        0.0497])\n",
      "tensor(96.2700)\n",
      "tensor(97.4600)\n",
      "Round 784, reward -0.373\n",
      "tensor([0.0439, 0.0439, 0.3242, 0.0439, 0.0439, 0.3242, 0.0443, 0.0441, 0.0439,\n",
      "        0.0439])\n",
      "tensor(94.5400)\n",
      "tensor(96.5300)\n",
      "Round 785, reward -0.418\n",
      "tensor([0.1896, 0.1361, 0.1659, 0.0257, 0.0257, 0.0267, 0.1896, 0.0257, 0.1896,\n",
      "        0.0257])\n",
      "tensor(97.3400)\n",
      "tensor(97.1400)\n",
      "Round 786, reward -0.047\n",
      "tensor([0.0309, 0.0257, 0.0257, 0.1813, 0.1898, 0.1898, 0.1158, 0.1898, 0.0257,\n",
      "        0.0257])\n",
      "tensor(97.1800)\n",
      "tensor(97.6400)\n",
      "Round 787, reward -0.307\n",
      "tensor([0.0379, 0.1649, 0.1649, 0.0223, 0.1649, 0.0224, 0.0764, 0.1579, 0.1649,\n",
      "        0.0233])\n",
      "tensor(97.6500)\n",
      "tensor(97.4900)\n",
      "Round 788, reward -0.038\n",
      "tensor([0.3318, 0.0449, 0.3089, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449,\n",
      "        0.0449])\n",
      "tensor(96.7600)\n",
      "tensor(97.5600)\n",
      "Round 789, reward -0.351\n",
      "tensor([0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.3103, 0.0449, 0.0459,\n",
      "        0.3294])\n",
      "tensor(94.0300)\n",
      "tensor(96.7000)\n",
      "Round 790, reward -0.431\n",
      "tensor([0.2181, 0.2234, 0.0302, 0.0302, 0.0302, 0.0302, 0.0335, 0.1431, 0.0391,\n",
      "        0.2218])\n",
      "tensor(94.3800)\n",
      "tensor(95.7900)\n",
      "Round 791, reward -0.422\n",
      "tensor([0.0439, 0.0439, 0.3243, 0.0439, 0.0439, 0.3244, 0.0439, 0.0439, 0.0439,\n",
      "        0.0439])\n",
      "tensor(93.9800)\n",
      "tensor(97.2200)\n",
      "Round 792, reward -0.432\n",
      "tensor([0.2718, 0.2696, 0.0385, 0.0368, 0.0382, 0.1978, 0.0369, 0.0368, 0.0368,\n",
      "        0.0368])\n",
      "tensor(92.9800)\n",
      "tensor(93.6700)\n",
      "Round 793, reward -0.438\n",
      "tensor([0.1918, 0.1918, 0.0862, 0.0260, 0.1918, 0.0260, 0.0270, 0.1918, 0.0418,\n",
      "        0.0260])\n",
      "tensor(92.2200)\n",
      "tensor(96.4300)\n",
      "Round 794, reward -0.472\n",
      "tensor([0.0241, 0.0238, 0.0238, 0.1759, 0.1757, 0.0369, 0.1759, 0.1641, 0.1759,\n",
      "        0.0238])\n",
      "tensor(97.3600)\n",
      "tensor(97.0300)\n",
      "Round 795, reward -0.046\n",
      "tensor([0.0308, 0.0314, 0.0622, 0.0315, 0.2266, 0.0308, 0.1008, 0.2276, 0.0308,\n",
      "        0.2276])\n",
      "tensor(95.7100)\n",
      "tensor(95.8300)\n",
      "Round 796, reward -0.207\n",
      "tensor([0.0367, 0.2129, 0.0308, 0.0312, 0.1765, 0.0308, 0.1945, 0.0308, 0.0308,\n",
      "        0.2251])\n",
      "tensor(92.1800)\n",
      "tensor(94.2500)\n",
      "Round 797, reward -0.473\n",
      "tensor([0.1832, 0.1342, 0.0248, 0.0248, 0.1829, 0.1802, 0.1832, 0.0248, 0.0372,\n",
      "        0.0248])\n",
      "tensor(96.4100)\n",
      "tensor(95.9000)\n",
      "Round 798, reward -0.071\n",
      "tensor([0.0795, 0.0485, 0.0498, 0.0485, 0.2217, 0.3581, 0.0485, 0.0485, 0.0485,\n",
      "        0.0485])\n",
      "tensor(94.1700)\n",
      "tensor(97.2100)\n",
      "Round 799, reward -0.427\n",
      "tensor([0.0239, 0.0238, 0.0247, 0.1747, 0.0238, 0.1760, 0.1760, 0.0275, 0.1760,\n",
      "        0.1734])\n",
      "tensor(95.0600)\n",
      "tensor(96.6700)\n",
      "Round 800, reward -0.405\n",
      "tensor([0.0425, 0.0488, 0.0417, 0.0417, 0.3077, 0.0416, 0.0419, 0.2633, 0.1290,\n",
      "        0.0416])\n",
      "tensor(11.5400)\n",
      "tensor(10.1000)\n",
      "Round 801, reward -0.682\n",
      "tensor([0.0658, 0.0670, 0.3866, 0.0655, 0.0658, 0.0655, 0.0655, 0.0655, 0.0847,\n",
      "        0.0683])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.2700)\n",
      "tensor(10.1000)\n",
      "Round 802, reward -0.679\n",
      "tensor([0.0285, 0.2102, 0.0285, 0.0303, 0.2095, 0.0285, 0.0285, 0.0285, 0.1975,\n",
      "        0.2102])\n",
      "tensor(23.0600)\n",
      "tensor(21.5300)\n",
      "Round 803, reward -0.670\n",
      "tensor([0.3076, 0.0416, 0.0416, 0.0416, 0.0975, 0.0416, 0.0416, 0.0416, 0.0466,\n",
      "        0.2985])\n",
      "tensor(22.5500)\n",
      "tensor(32.7200)\n",
      "Round 804, reward -0.971\n",
      "tensor([0.0435, 0.0568, 0.0454, 0.0435, 0.0982, 0.0415, 0.3026, 0.0413, 0.0412,\n",
      "        0.2860])\n",
      "tensor(26.6600)\n",
      "tensor(11.9000)\n",
      "Round 805, reward -0.665\n",
      "tensor([0.0509, 0.0326, 0.0349, 0.2410, 0.2376, 0.0326, 0.0326, 0.2410, 0.0326,\n",
      "        0.0642])\n",
      "tensor(40.6400)\n",
      "tensor(59.8200)\n",
      "Round 806, reward -0.938\n",
      "tensor([0.0343, 0.0345, 0.2533, 0.0343, 0.0343, 0.0343, 0.0343, 0.2533, 0.0343,\n",
      "        0.2533])\n",
      "tensor(31.3000)\n",
      "tensor(45.5400)\n",
      "Round 807, reward -0.958\n",
      "tensor([0.0410, 0.0410, 0.3027, 0.3027, 0.0410, 0.1070, 0.0413, 0.0413, 0.0410,\n",
      "        0.0411])\n",
      "tensor(31.4900)\n",
      "tensor(43.5600)\n",
      "Round 808, reward -0.958\n",
      "tensor([0.0242, 0.0242, 0.1789, 0.1689, 0.0242, 0.1783, 0.1738, 0.1789, 0.0242,\n",
      "        0.0242])\n",
      "tensor(59.5400)\n",
      "tensor(64.2100)\n",
      "Round 809, reward -0.864\n",
      "tensor([0.0242, 0.0244, 0.0242, 0.1635, 0.1791, 0.1779, 0.1791, 0.1791, 0.0242,\n",
      "        0.0242])\n",
      "tensor(49.2800)\n",
      "tensor(52.1300)\n",
      "Round 810, reward -0.911\n",
      "tensor([0.0571, 0.0571, 0.0571, 0.2114, 0.0572, 0.0588, 0.1780, 0.0571, 0.0571,\n",
      "        0.2089])\n",
      "tensor(61.8500)\n",
      "tensor(60.3100)\n",
      "Round 811, reward -0.551\n",
      "tensor([0.2030, 0.0334, 0.0275, 0.0275, 0.2030, 0.2017, 0.0282, 0.0451, 0.2030,\n",
      "        0.0275])\n",
      "tensor(60.7000)\n",
      "tensor(67.9700)\n",
      "Round 812, reward -0.858\n",
      "tensor([0.1755, 0.0342, 0.0342, 0.0342, 0.0342, 0.2519, 0.2520, 0.0342, 0.0343,\n",
      "        0.1154])\n",
      "tensor(39.8400)\n",
      "tensor(60.0800)\n",
      "Round 813, reward -0.940\n",
      "tensor([0.1391, 0.1390, 0.1168, 0.1391, 0.1372, 0.0188, 0.0188, 0.1391, 0.0188,\n",
      "        0.1333])\n",
      "tensor(49.6200)\n",
      "tensor(48.8400)\n",
      "Round 814, reward -0.610\n",
      "tensor([0.2087, 0.0284, 0.2095, 0.0284, 0.2010, 0.0284, 0.0284, 0.0284, 0.2091,\n",
      "        0.0298])\n",
      "tensor(63.2600)\n",
      "tensor(74.6200)\n",
      "Round 815, reward -0.842\n",
      "tensor([0.0244, 0.0275, 0.1800, 0.0258, 0.0310, 0.1471, 0.1800, 0.1800, 0.0244,\n",
      "        0.1799])\n",
      "tensor(49.5500)\n",
      "tensor(74.7700)\n",
      "Round 816, reward -0.910\n",
      "tensor([0.1688, 0.0252, 0.1862, 0.1485, 0.0252, 0.1864, 0.1833, 0.0252, 0.0258,\n",
      "        0.0252])\n",
      "tensor(81.4500)\n",
      "tensor(74.8100)\n",
      "Round 817, reward -0.363\n",
      "tensor([0.2078, 0.0281, 0.0282, 0.0281, 0.0281, 0.0281, 0.2078, 0.2078, 0.2078,\n",
      "        0.0281])\n",
      "tensor(65.9500)\n",
      "tensor(76.9700)\n",
      "Round 818, reward -0.823\n",
      "tensor([0.1296, 0.0184, 0.1358, 0.0184, 0.1359, 0.1359, 0.1359, 0.1359, 0.1358,\n",
      "        0.0184])\n",
      "tensor(76.3100)\n",
      "tensor(69.9600)\n",
      "Round 819, reward -0.428\n",
      "tensor([0.0349, 0.2316, 0.0313, 0.0313, 0.0350, 0.1127, 0.0313, 0.2316, 0.2288,\n",
      "        0.0313])\n",
      "tensor(62.6600)\n",
      "tensor(80.9300)\n",
      "Round 820, reward -0.846\n",
      "tensor([0.1576, 0.0213, 0.1576, 0.0213, 0.0213, 0.1266, 0.0213, 0.1576, 0.1575,\n",
      "        0.1576])\n",
      "tensor(74.7600)\n",
      "tensor(79.5300)\n",
      "Round 821, reward -0.745\n",
      "tensor([0.0282, 0.2084, 0.0336, 0.2084, 0.0282, 0.0304, 0.2084, 0.0298, 0.1933,\n",
      "        0.0313])\n",
      "tensor(78.7800)\n",
      "tensor(82.3900)\n",
      "Round 822, reward -0.698\n",
      "tensor([0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.2533, 0.0343, 0.2533, 0.2533,\n",
      "        0.0343])\n",
      "tensor(66.6500)\n",
      "tensor(75.7500)\n",
      "Round 823, reward -0.818\n",
      "tensor([0.0327, 0.0714, 0.0327, 0.0426, 0.0327, 0.0378, 0.2416, 0.0327, 0.2418,\n",
      "        0.2340])\n",
      "tensor(71.7500)\n",
      "tensor(81.7600)\n",
      "Round 824, reward -0.775\n",
      "tensor([0.0342, 0.0345, 0.0346, 0.2211, 0.0342, 0.0342, 0.1398, 0.1810, 0.2523,\n",
      "        0.0342])\n",
      "tensor(76.6000)\n",
      "tensor(80.9100)\n",
      "Round 825, reward -0.724\n",
      "tensor([0.0299, 0.1762, 0.0238, 0.1701, 0.1760, 0.0239, 0.0238, 0.1762, 0.1762,\n",
      "        0.0238])\n",
      "tensor(78.4300)\n",
      "tensor(77.4700)\n",
      "Round 826, reward -0.402\n",
      "tensor([0.0239, 0.1764, 0.1764, 0.0239, 0.0239, 0.0239, 0.0239, 0.1766, 0.1743,\n",
      "        0.1766])\n",
      "tensor(76.2600)\n",
      "tensor(81.6700)\n",
      "Round 827, reward -0.728\n",
      "tensor([0.2472, 0.0335, 0.0335, 0.0335, 0.0335, 0.2479, 0.2479, 0.0336, 0.0335,\n",
      "        0.0557])\n",
      "tensor(80.7100)\n",
      "tensor(80.9500)\n",
      "Round 828, reward -0.562\n",
      "tensor([0.0193, 0.1429, 0.0193, 0.1428, 0.1214, 0.1064, 0.1429, 0.0193, 0.1429,\n",
      "        0.1429])\n",
      "tensor(84.4700)\n",
      "tensor(81.0400)\n",
      "Round 829, reward -0.317\n",
      "tensor([0.0819, 0.1547, 0.0239, 0.1460, 0.0239, 0.1730, 0.1732, 0.0239, 0.1754,\n",
      "        0.0239])\n",
      "tensor(76.9100)\n",
      "tensor(86.7900)\n",
      "Round 830, reward -0.721\n",
      "tensor([0.0516, 0.0300, 0.1974, 0.0300, 0.2214, 0.0300, 0.1499, 0.2214, 0.0300,\n",
      "        0.0385])\n",
      "tensor(82.6200)\n",
      "tensor(80.4500)\n",
      "Round 831, reward -0.346\n",
      "tensor([0.0279, 0.0279, 0.2064, 0.0279, 0.2064, 0.0352, 0.2064, 0.2058, 0.0279,\n",
      "        0.0279])\n",
      "tensor(80.2000)\n",
      "tensor(79.9400)\n",
      "Round 832, reward -0.380\n",
      "tensor([0.1772, 0.0240, 0.1772, 0.1761, 0.1719, 0.0240, 0.0240, 0.1772, 0.0244,\n",
      "        0.0240])\n",
      "tensor(75.6000)\n",
      "tensor(80.8800)\n",
      "Round 833, reward -0.735\n",
      "tensor([0.2061, 0.0404, 0.0279, 0.0279, 0.0279, 0.0284, 0.2060, 0.0279, 0.2016,\n",
      "        0.2060])\n",
      "tensor(70.8400)\n",
      "tensor(82.1300)\n",
      "Round 834, reward -0.783\n",
      "tensor([0.1490, 0.1490, 0.0212, 0.0202, 0.1155, 0.1490, 0.0774, 0.1490, 0.1490,\n",
      "        0.0207])\n",
      "tensor(80.9500)\n",
      "tensor(84.6800)\n",
      "Round 835, reward -0.670\n",
      "tensor([0.0437, 0.0437, 0.3225, 0.3224, 0.0437, 0.0467, 0.0464, 0.0437, 0.0437,\n",
      "        0.0437])\n",
      "tensor(75.2400)\n",
      "tensor(84.6400)\n",
      "Round 836, reward -0.739\n",
      "tensor([0.2014, 0.0283, 0.2095, 0.2094, 0.0283, 0.2095, 0.0285, 0.0284, 0.0283,\n",
      "        0.0284])\n",
      "tensor(80.0700)\n",
      "tensor(79.7600)\n",
      "Round 837, reward -0.381\n",
      "tensor([0.1896, 0.0377, 0.0372, 0.0372, 0.2748, 0.0372, 0.2747, 0.0372, 0.0372,\n",
      "        0.0373])\n",
      "tensor(73.8700)\n",
      "tensor(84.7100)\n",
      "Round 838, reward -0.754\n",
      "tensor([0.1625, 0.0220, 0.0226, 0.1625, 0.1625, 0.0220, 0.1595, 0.0824, 0.1521,\n",
      "        0.0519])\n",
      "tensor(82.7600)\n",
      "tensor(86.7100)\n",
      "Round 839, reward -0.644\n",
      "tensor([0.0468, 0.0468, 0.0469, 0.0468, 0.3458, 0.0530, 0.0468, 0.0468, 0.2734,\n",
      "        0.0468])\n",
      "tensor(81.2000)\n",
      "tensor(86.8200)\n",
      "Round 840, reward -0.666\n",
      "tensor([0.2450, 0.0332, 0.2452, 0.0332, 0.0396, 0.2286, 0.0532, 0.0332, 0.0539,\n",
      "        0.0349])\n",
      "tensor(81.8900)\n",
      "tensor(86.6700)\n",
      "Round 841, reward -0.656\n",
      "tensor([0.0242, 0.0250, 0.1760, 0.0238, 0.1761, 0.1755, 0.1761, 0.1755, 0.0238,\n",
      "        0.0238])\n",
      "tensor(75.9300)\n",
      "tensor(79.3600)\n",
      "Round 842, reward -0.732\n",
      "tensor([0.0436, 0.0674, 0.0439, 0.3043, 0.0437, 0.0436, 0.0436, 0.0440, 0.0439,\n",
      "        0.3220])\n",
      "tensor(78.5300)\n",
      "tensor(89.7200)\n",
      "Round 843, reward -0.701\n",
      "tensor([0.3213, 0.3213, 0.0435, 0.0456, 0.0435, 0.0435, 0.0509, 0.0435, 0.0435,\n",
      "        0.0435])\n",
      "tensor(81.9900)\n",
      "tensor(86.8500)\n",
      "Round 844, reward -0.655\n",
      "tensor([0.0293, 0.0293, 0.0293, 0.0308, 0.0293, 0.1737, 0.2164, 0.2164, 0.0293,\n",
      "        0.2164])\n",
      "tensor(80.8200)\n",
      "tensor(84.4600)\n",
      "Round 845, reward -0.671\n",
      "tensor([0.0228, 0.1025, 0.0228, 0.0232, 0.1686, 0.1670, 0.1686, 0.1686, 0.0228,\n",
      "        0.1329])\n",
      "tensor(85.9400)\n",
      "tensor(85.6000)\n",
      "Round 846, reward -0.293\n",
      "tensor([0.0446, 0.0446, 0.0446, 0.0446, 0.0446, 0.0446, 0.0446, 0.3143, 0.0446,\n",
      "        0.3292])\n",
      "tensor(84.9800)\n",
      "tensor(87.0500)\n",
      "Round 847, reward -0.609\n",
      "tensor([0.2180, 0.0297, 0.0297, 0.0297, 0.1717, 0.0297, 0.0401, 0.2194, 0.0297,\n",
      "        0.2024])\n",
      "tensor(84.6300)\n",
      "tensor(88.6500)\n",
      "Round 848, reward -0.615\n",
      "tensor([0.0287, 0.2117, 0.0289, 0.2117, 0.0287, 0.0287, 0.0287, 0.0287, 0.2113,\n",
      "        0.1930])\n",
      "tensor(84.6300)\n",
      "tensor(79.4300)\n",
      "Round 849, reward -0.315\n",
      "tensor([0.0297, 0.1603, 0.0297, 0.2132, 0.2191, 0.2194, 0.0298, 0.0393, 0.0297,\n",
      "        0.0297])\n",
      "tensor(84.9800)\n",
      "tensor(88.0800)\n",
      "Round 850, reward -0.609\n",
      "tensor([0.0307, 0.1016, 0.2271, 0.0645, 0.2271, 0.0311, 0.0307, 0.0307, 0.2256,\n",
      "        0.0307])\n",
      "tensor(86.8200)\n",
      "tensor(86.5300)\n",
      "Round 851, reward -0.278\n",
      "tensor([0.0346, 0.0346, 0.2497, 0.0347, 0.0349, 0.2524, 0.2555, 0.0346, 0.0346,\n",
      "        0.0346])\n",
      "tensor(80.0300)\n",
      "tensor(89.8200)\n",
      "Round 852, reward -0.682\n",
      "tensor([0.0249, 0.1820, 0.0249, 0.1842, 0.0249, 0.1842, 0.1839, 0.0249, 0.0280,\n",
      "        0.1381])\n",
      "tensor(89.1400)\n",
      "tensor(90.3500)\n",
      "Round 853, reward -0.534\n",
      "tensor([0.1768, 0.0239, 0.0239, 0.1768, 0.0239, 0.0239, 0.1733, 0.1768, 0.1768,\n",
      "        0.0239])\n",
      "tensor(88.6000)\n",
      "tensor(87.0300)\n",
      "Round 854, reward -0.246\n",
      "tensor([0.0459, 0.0372, 0.2637, 0.0357, 0.2089, 0.0357, 0.0357, 0.0378, 0.2637,\n",
      "        0.0357])\n",
      "tensor(79.6200)\n",
      "tensor(82.1500)\n",
      "Round 855, reward -0.687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1683, 0.0490, 0.0490, 0.0490, 0.0490, 0.3622, 0.0490, 0.1263, 0.0490,\n",
      "        0.0490])\n",
      "tensor(80.5300)\n",
      "tensor(90.9500)\n",
      "Round 856, reward -0.675\n",
      "tensor([0.1032, 0.2353, 0.0318, 0.0318, 0.0318, 0.0318, 0.0318, 0.2352, 0.2353,\n",
      "        0.0318])\n",
      "tensor(85.0700)\n",
      "tensor(83.8300)\n",
      "Round 857, reward -0.308\n",
      "tensor([0.0368, 0.0368, 0.0368, 0.0907, 0.2723, 0.0685, 0.1386, 0.0369, 0.2458,\n",
      "        0.0368])\n",
      "tensor(86.1100)\n",
      "tensor(85.5800)\n",
      "Round 858, reward -0.290\n",
      "tensor([0.0201, 0.1485, 0.1440, 0.0892, 0.0201, 0.1485, 0.1374, 0.1485, 0.0208,\n",
      "        0.1228])\n",
      "tensor(86.1400)\n",
      "tensor(87.7900)\n",
      "Round 859, reward -0.590\n",
      "tensor([0.2325, 0.0315, 0.2330, 0.0694, 0.0315, 0.0315, 0.0315, 0.0315, 0.0744,\n",
      "        0.2330])\n",
      "tensor(89.5400)\n",
      "tensor(91.1800)\n",
      "Round 860, reward -0.527\n",
      "tensor([0.0448, 0.3046, 0.0495, 0.3312, 0.0448, 0.0448, 0.0451, 0.0448, 0.0453,\n",
      "        0.0448])\n",
      "tensor(82.2200)\n",
      "tensor(81.0800)\n",
      "Round 861, reward -0.352\n",
      "tensor([0.0362, 0.2667, 0.0363, 0.0370, 0.2116, 0.0362, 0.0362, 0.2673, 0.0362,\n",
      "        0.0362])\n",
      "tensor(81.7600)\n",
      "tensor(88.5500)\n",
      "Round 862, reward -0.658\n",
      "tensor([0.2350, 0.0320, 0.0321, 0.2361, 0.0320, 0.1009, 0.0320, 0.0320, 0.2361,\n",
      "        0.0320])\n",
      "tensor(89.5700)\n",
      "tensor(88.6100)\n",
      "Round 863, reward -0.227\n",
      "tensor([0.0337, 0.0337, 0.2430, 0.2461, 0.0337, 0.0337, 0.0337, 0.0337, 0.2482,\n",
      "        0.0607])\n",
      "tensor(88.9400)\n",
      "tensor(88.3900)\n",
      "Round 864, reward -0.239\n",
      "tensor([0.0464, 0.0464, 0.0464, 0.0464, 0.0464, 0.3396, 0.2890, 0.0464, 0.0464,\n",
      "        0.0464])\n",
      "tensor(72.4300)\n",
      "tensor(91.2600)\n",
      "Round 865, reward -0.768\n",
      "tensor([0.0726, 0.0295, 0.0285, 0.2109, 0.2109, 0.0285, 0.2108, 0.0285, 0.0292,\n",
      "        0.1506])\n",
      "tensor(90.3900)\n",
      "tensor(89.7200)\n",
      "Round 866, reward -0.211\n",
      "tensor([0.1383, 0.0370, 0.2732, 0.0370, 0.0462, 0.0370, 0.0370, 0.0837, 0.0376,\n",
      "        0.2732])\n",
      "tensor(79.1600)\n",
      "tensor(88.6900)\n",
      "Round 867, reward -0.693\n",
      "tensor([0.0490, 0.0616, 0.0514, 0.0490, 0.0490, 0.1622, 0.0490, 0.1153, 0.3616,\n",
      "        0.0518])\n",
      "tensor(89.2800)\n",
      "tensor(90.3400)\n",
      "Round 868, reward -0.529\n",
      "tensor([0.1732, 0.0235, 0.1725, 0.1530, 0.0235, 0.0235, 0.1733, 0.0607, 0.1734,\n",
      "        0.0235])\n",
      "tensor(81.2200)\n",
      "tensor(88.5200)\n",
      "Round 869, reward -0.666\n",
      "tensor([0.2147, 0.0291, 0.0291, 0.1166, 0.1996, 0.0292, 0.1070, 0.0292, 0.2145,\n",
      "        0.0310])\n",
      "tensor(87.8400)\n",
      "tensor(90.6800)\n",
      "Round 870, reward -0.560\n",
      "tensor([0.0315, 0.0884, 0.2325, 0.0315, 0.0316, 0.2328, 0.0442, 0.2329, 0.0315,\n",
      "        0.0431])\n",
      "tensor(90.7300)\n",
      "tensor(89.9200)\n",
      "Round 871, reward -0.204\n",
      "tensor([0.0348, 0.0389, 0.0489, 0.0460, 0.0338, 0.2498, 0.0339, 0.2317, 0.2482,\n",
      "        0.0338])\n",
      "tensor(82.7000)\n",
      "tensor(91.5000)\n",
      "Round 872, reward -0.645\n",
      "tensor([0.0526, 0.2431, 0.1250, 0.0526, 0.0548, 0.0526, 0.0531, 0.0526, 0.0526,\n",
      "        0.2609])\n",
      "tensor(81.6900)\n",
      "tensor(86.9300)\n",
      "Round 873, reward -0.659\n",
      "tensor([0.2597, 0.0645, 0.0352, 0.0352, 0.2040, 0.0352, 0.2597, 0.0358, 0.0356,\n",
      "        0.0352])\n",
      "tensor(82.4600)\n",
      "tensor(87.2600)\n",
      "Round 874, reward -0.648\n",
      "tensor([0.1411, 0.0307, 0.2116, 0.0288, 0.0290, 0.0480, 0.2080, 0.0288, 0.0612,\n",
      "        0.2128])\n",
      "tensor(83.0900)\n",
      "tensor(82.3500)\n",
      "Round 875, reward -0.339\n",
      "tensor([0.0609, 0.0609, 0.0609, 0.0613, 0.0612, 0.0609, 0.4503, 0.0609, 0.0610,\n",
      "        0.0616])\n",
      "tensor(78.7200)\n",
      "tensor(91.6800)\n",
      "Round 876, reward -0.699\n",
      "tensor([0.0299, 0.0287, 0.2122, 0.0288, 0.0287, 0.2116, 0.1977, 0.0554, 0.1782,\n",
      "        0.0287])\n",
      "tensor(92.8600)\n",
      "tensor(92.5800)\n",
      "Round 877, reward -0.158\n",
      "tensor([0.0242, 0.0241, 0.0241, 0.1780, 0.1780, 0.0241, 0.1680, 0.1773, 0.1780,\n",
      "        0.0241])\n",
      "tensor(87.4600)\n",
      "tensor(91.0500)\n",
      "Round 878, reward -0.567\n",
      "tensor([0.1345, 0.1351, 0.0282, 0.0183, 0.1257, 0.1348, 0.1351, 0.0183, 0.1351,\n",
      "        0.1349])\n",
      "tensor(91.2200)\n",
      "tensor(87.2800)\n",
      "Round 879, reward -0.194\n",
      "tensor([0.2093, 0.0329, 0.0329, 0.0329, 0.2431, 0.2431, 0.0329, 0.0518, 0.0879,\n",
      "        0.0332])\n",
      "tensor(92.3600)\n",
      "tensor(91.1100)\n",
      "Round 880, reward -0.169\n",
      "tensor([0.1727, 0.2762, 0.0473, 0.0374, 0.2761, 0.0375, 0.0374, 0.0406, 0.0374,\n",
      "        0.0374])\n",
      "tensor(89.7800)\n",
      "tensor(90.6400)\n",
      "Round 881, reward -0.515\n",
      "tensor([0.0283, 0.0281, 0.0281, 0.0281, 0.2073, 0.0307, 0.2073, 0.2073, 0.2069,\n",
      "        0.0281])\n",
      "tensor(88.9700)\n",
      "tensor(92.9200)\n",
      "Round 882, reward -0.539\n",
      "tensor([0.1565, 0.0293, 0.0338, 0.0423, 0.0304, 0.2164, 0.2164, 0.0294, 0.2163,\n",
      "        0.0293])\n",
      "tensor(76.1600)\n",
      "tensor(91.8500)\n",
      "Round 883, reward -0.729\n",
      "tensor([0.0345, 0.0345, 0.0631, 0.0345, 0.0358, 0.0347, 0.2548, 0.0523, 0.2009,\n",
      "        0.2548])\n",
      "tensor(87.0800)\n",
      "tensor(89.5400)\n",
      "Round 884, reward -0.574\n",
      "tensor([0.0437, 0.0436, 0.3205, 0.0436, 0.0436, 0.0436, 0.0437, 0.0514, 0.0436,\n",
      "        0.3225])\n",
      "tensor(88.3900)\n",
      "tensor(92.1200)\n",
      "Round 885, reward -0.550\n",
      "tensor([0.0289, 0.0289, 0.2132, 0.0289, 0.2131, 0.0289, 0.1992, 0.0685, 0.0419,\n",
      "        0.1487])\n",
      "tensor(80.9700)\n",
      "tensor(88.9300)\n",
      "Round 886, reward -0.669\n",
      "tensor([0.3217, 0.0438, 0.0438, 0.0580, 0.3151, 0.0435, 0.0435, 0.0435, 0.0435,\n",
      "        0.0435])\n",
      "tensor(90.5100)\n",
      "tensor(92.8100)\n",
      "Round 887, reward -0.508\n",
      "tensor([0.2056, 0.0278, 0.0327, 0.0333, 0.2056, 0.2056, 0.0278, 0.0280, 0.2056,\n",
      "        0.0279])\n",
      "tensor(86.6000)\n",
      "tensor(92.1100)\n",
      "Round 888, reward -0.582\n",
      "tensor([0.1563, 0.1351, 0.1563, 0.1563, 0.0211, 0.0212, 0.1553, 0.0211, 0.0211,\n",
      "        0.1563])\n",
      "tensor(83.2200)\n",
      "tensor(89.6600)\n",
      "Round 889, reward -0.637\n",
      "tensor([0.4250, 0.0639, 0.0630, 0.0630, 0.0630, 0.0630, 0.0703, 0.0630, 0.0630,\n",
      "        0.0630])\n",
      "tensor(78.6500)\n",
      "tensor(92.1200)\n",
      "Round 890, reward -0.700\n",
      "tensor([0.0576, 0.1110, 0.0577, 0.0576, 0.0576, 0.0579, 0.0576, 0.4259, 0.0594,\n",
      "        0.0576])\n",
      "tensor(85.4500)\n",
      "tensor(91.2900)\n",
      "Round 891, reward -0.602\n",
      "tensor([0.0232, 0.1718, 0.1718, 0.0232, 0.0232, 0.1705, 0.0238, 0.1718, 0.0492,\n",
      "        0.1714])\n",
      "tensor(85.2200)\n",
      "tensor(84.6800)\n",
      "Round 892, reward -0.305\n",
      "tensor([0.0290, 0.1812, 0.0290, 0.0290, 0.2146, 0.0290, 0.0298, 0.2146, 0.0290,\n",
      "        0.2145])\n",
      "tensor(90.9400)\n",
      "tensor(92.3300)\n",
      "Round 893, reward -0.498\n",
      "tensor([0.0349, 0.0349, 0.0353, 0.0349, 0.0454, 0.2557, 0.2322, 0.0349, 0.0349,\n",
      "        0.2570])\n",
      "tensor(90.5500)\n",
      "tensor(93.2500)\n",
      "Round 894, reward -0.507\n",
      "tensor([0.1544, 0.0209, 0.1545, 0.1545, 0.0209, 0.1439, 0.1544, 0.1545, 0.0209,\n",
      "        0.0209])\n",
      "tensor(92.4600)\n",
      "tensor(91.3700)\n",
      "Round 895, reward -0.167\n",
      "tensor([0.2413, 0.1377, 0.0327, 0.0966, 0.1887, 0.1724, 0.0327, 0.0327, 0.0327,\n",
      "        0.0327])\n",
      "tensor(86.5300)\n",
      "tensor(93.8900)\n",
      "Round 896, reward -0.583\n",
      "tensor([0.1366, 0.0195, 0.0186, 0.1372, 0.1372, 0.1372, 0.1214, 0.1365, 0.0186,\n",
      "        0.1372])\n",
      "tensor(88.4200)\n",
      "tensor(90.7900)\n",
      "Round 897, reward -0.549\n",
      "tensor([0.0548, 0.0550, 0.0548, 0.0548, 0.0582, 0.1531, 0.0550, 0.4047, 0.0548,\n",
      "        0.0550])\n",
      "tensor(80.4300)\n",
      "tensor(90.8800)\n",
      "Round 898, reward -0.677\n",
      "tensor([0.2054, 0.0493, 0.0475, 0.3510, 0.0475, 0.1085, 0.0477, 0.0476, 0.0477,\n",
      "        0.0479])\n",
      "tensor(88.4800)\n",
      "tensor(89.2400)\n",
      "Round 899, reward -0.535\n",
      "tensor([0.2170, 0.2171, 0.2171, 0.0294, 0.0294, 0.0294, 0.0294, 0.0593, 0.1222,\n",
      "        0.0498])\n",
      "tensor(89.8600)\n",
      "tensor(92.5300)\n",
      "Round 900, reward -0.521\n",
      "tensor([0.0343, 0.2536, 0.0343, 0.0343, 0.2523, 0.2536, 0.0343, 0.0345, 0.0343,\n",
      "        0.0343])\n",
      "tensor(91.4400)\n",
      "tensor(92.7800)\n",
      "Round 901, reward -0.488\n",
      "tensor([0.0227, 0.1675, 0.1675, 0.0228, 0.1675, 0.0717, 0.1675, 0.0227, 0.0227,\n",
      "        0.1675])\n",
      "tensor(91.0100)\n",
      "tensor(91.4400)\n",
      "Round 902, reward -0.448\n",
      "tensor([0.2086, 0.0282, 0.2086, 0.0289, 0.2027, 0.0296, 0.0282, 0.2086, 0.0282,\n",
      "        0.0282])\n",
      "tensor(92.8100)\n",
      "tensor(92.5500)\n",
      "Round 903, reward -0.159\n",
      "tensor([0.2087, 0.2081, 0.0282, 0.0284, 0.0282, 0.2034, 0.0282, 0.2054, 0.0282,\n",
      "        0.0331])\n",
      "tensor(83.7200)\n",
      "tensor(93.2600)\n",
      "Round 904, reward -0.629\n",
      "tensor([0.0594, 0.4375, 0.0594, 0.0594, 0.0597, 0.0594, 0.0594, 0.0594, 0.0857,\n",
      "        0.0606])\n",
      "tensor(81.9000)\n",
      "tensor(92.9800)\n",
      "Round 905, reward -0.656\n",
      "tensor([0.0347, 0.2335, 0.0347, 0.2562, 0.0347, 0.0464, 0.0347, 0.0347, 0.2558,\n",
      "        0.0347])\n",
      "tensor(92.6400)\n",
      "tensor(93.4600)\n",
      "Round 906, reward -0.453\n",
      "tensor([0.2359, 0.0320, 0.0320, 0.0320, 0.1005, 0.2361, 0.2342, 0.0320, 0.0334,\n",
      "        0.0320])\n",
      "tensor(82.9500)\n",
      "tensor(86.9600)\n",
      "Round 907, reward -0.641\n",
      "tensor([0.0702, 0.1678, 0.1677, 0.1678, 0.0227, 0.0227, 0.1678, 0.1678, 0.0227,\n",
      "        0.0227])\n",
      "tensor(91.7300)\n",
      "tensor(85.9600)\n",
      "Round 908, reward -0.183\n",
      "tensor([0.0242, 0.1484, 0.1790, 0.1790, 0.1415, 0.0247, 0.1728, 0.0242, 0.0243,\n",
      "        0.0818])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88.9700)\n",
      "tensor(91.3100)\n",
      "Round 909, reward -0.539\n",
      "tensor([0.0398, 0.2655, 0.0677, 0.0398, 0.2942, 0.1330, 0.0398, 0.0405, 0.0398,\n",
      "        0.0398])\n",
      "tensor(88.2100)\n",
      "tensor(88.4200)\n",
      "Round 910, reward -0.428\n",
      "tensor([0.0389, 0.2735, 0.0375, 0.0375, 0.1874, 0.0375, 0.2753, 0.0375, 0.0375,\n",
      "        0.0375])\n",
      "tensor(91.3600)\n",
      "tensor(93.6800)\n",
      "Round 911, reward -0.491\n",
      "tensor([0.0164, 0.0164, 0.1212, 0.1212, 0.1212, 0.1212, 0.1212, 0.1212, 0.1190,\n",
      "        0.1212])\n",
      "tensor(89.4100)\n",
      "tensor(91.2300)\n",
      "Round 912, reward -0.530\n",
      "tensor([0.1921, 0.1289, 0.1733, 0.1917, 0.0260, 0.0262, 0.1770, 0.0312, 0.0260,\n",
      "        0.0277])\n",
      "tensor(85.2700)\n",
      "tensor(92.3800)\n",
      "Round 913, reward -0.605\n",
      "tensor([0.0479, 0.0498, 0.0484, 0.3540, 0.2604, 0.0479, 0.0479, 0.0479, 0.0479,\n",
      "        0.0479])\n",
      "tensor(91.3600)\n",
      "tensor(93.6300)\n",
      "Round 914, reward -0.491\n",
      "tensor([0.3163, 0.0430, 0.0430, 0.0430, 0.0430, 0.0439, 0.3178, 0.0430, 0.0640,\n",
      "        0.0430])\n",
      "tensor(90.5700)\n",
      "tensor(92.0400)\n",
      "Round 915, reward -0.506\n",
      "tensor([0.0684, 0.0684, 0.0684, 0.1010, 0.0805, 0.0684, 0.3397, 0.0684, 0.0687,\n",
      "        0.0684])\n",
      "tensor(93.7900)\n",
      "tensor(92.6200)\n",
      "Round 916, reward -0.136\n",
      "tensor([0.0622, 0.0450, 0.0829, 0.0410, 0.0410, 0.3026, 0.0410, 0.0410, 0.0410,\n",
      "        0.3024])\n",
      "tensor(91.0900)\n",
      "tensor(93.6400)\n",
      "Round 917, reward -0.496\n",
      "tensor([0.0249, 0.1420, 0.0253, 0.0249, 0.1838, 0.0249, 0.0249, 0.1838, 0.1837,\n",
      "        0.1818])\n",
      "tensor(91.1300)\n",
      "tensor(93.1000)\n",
      "Round 918, reward -0.495\n",
      "tensor([0.0566, 0.0337, 0.0337, 0.0337, 0.0337, 0.2493, 0.0337, 0.2440, 0.0993,\n",
      "        0.1821])\n",
      "tensor(93.0500)\n",
      "tensor(94.8400)\n",
      "Round 919, reward -0.453\n",
      "tensor([0.0301, 0.1993, 0.0299, 0.0299, 0.0299, 0.2206, 0.2206, 0.1800, 0.0299,\n",
      "        0.0299])\n",
      "tensor(88.9600)\n",
      "tensor(94.5700)\n",
      "Round 920, reward -0.539\n",
      "tensor([0.0996, 0.0996, 0.0996, 0.0996, 0.1037, 0.0996, 0.0996, 0.0996, 0.0996,\n",
      "        0.0996])\n",
      "tensor(94.1900)\n",
      "tensor(94.1500)\n",
      "Round 921, reward -0.127\n",
      "tensor([0.0416, 0.0422, 0.0817, 0.0426, 0.0417, 0.3077, 0.3077, 0.0421, 0.0509,\n",
      "        0.0416])\n",
      "tensor(87.9600)\n",
      "tensor(94.5200)\n",
      "Round 922, reward -0.558\n",
      "tensor([0.0324, 0.0543, 0.0351, 0.0324, 0.2390, 0.0631, 0.0324, 0.2395, 0.0324,\n",
      "        0.2394])\n",
      "tensor(86.4500)\n",
      "tensor(90.2600)\n",
      "Round 923, reward -0.585\n",
      "tensor([0.0389, 0.0368, 0.0368, 0.0368, 0.2721, 0.2573, 0.2104, 0.0370, 0.0368,\n",
      "        0.0370])\n",
      "tensor(88.0500)\n",
      "tensor(92.5400)\n",
      "Round 924, reward -0.556\n",
      "tensor([0.1075, 0.1937, 0.0321, 0.0321, 0.0511, 0.0396, 0.2371, 0.2371, 0.0321,\n",
      "        0.0377])\n",
      "tensor(93.2200)\n",
      "tensor(90.5200)\n",
      "Round 925, reward -0.150\n",
      "tensor([0.0292, 0.0292, 0.2105, 0.0292, 0.1398, 0.0665, 0.2157, 0.0292, 0.2124,\n",
      "        0.0385])\n",
      "tensor(88.6400)\n",
      "tensor(88.8900)\n",
      "Round 926, reward -0.439\n",
      "tensor([0.0272, 0.0601, 0.2010, 0.2010, 0.0272, 0.2009, 0.2009, 0.0272, 0.0273,\n",
      "        0.0272])\n",
      "tensor(91.4000)\n",
      "tensor(93.5900)\n",
      "Round 927, reward -0.490\n",
      "tensor([0.0347, 0.0345, 0.2551, 0.2483, 0.0347, 0.0345, 0.0345, 0.0345, 0.2545,\n",
      "        0.0345])\n",
      "tensor(84.7300)\n",
      "tensor(91.2800)\n",
      "Round 928, reward -0.613\n",
      "tensor([0.0318, 0.0318, 0.0318, 0.0408, 0.2352, 0.0318, 0.0970, 0.0318, 0.2326,\n",
      "        0.2352])\n",
      "tensor(82.4000)\n",
      "tensor(85.0100)\n",
      "Round 929, reward -0.649\n",
      "tensor([0.1447, 0.0393, 0.0393, 0.0393, 0.0393, 0.0393, 0.2902, 0.0393, 0.0393,\n",
      "        0.2902])\n",
      "tensor(82.4900)\n",
      "tensor(85.0900)\n",
      "Round 930, reward -0.648\n",
      "tensor([0.0265, 0.0929, 0.0265, 0.1960, 0.0265, 0.1867, 0.0268, 0.0265, 0.1959,\n",
      "        0.1956])\n",
      "tensor(91.0500)\n",
      "tensor(92.7600)\n",
      "Round 931, reward -0.497\n",
      "tensor([0.0238, 0.1760, 0.0247, 0.0238, 0.1760, 0.1760, 0.1760, 0.1760, 0.0238,\n",
      "        0.0238])\n",
      "tensor(93.8100)\n",
      "tensor(93.4600)\n",
      "Round 932, reward -0.136\n",
      "tensor([0.2516, 0.0342, 0.0383, 0.0341, 0.0341, 0.2459, 0.0341, 0.0341, 0.2504,\n",
      "        0.0433])\n",
      "tensor(86.8100)\n",
      "tensor(93.6000)\n",
      "Round 933, reward -0.578\n",
      "tensor([0.0259, 0.0238, 0.1756, 0.0238, 0.0238, 0.1758, 0.1758, 0.0240, 0.1758,\n",
      "        0.1757])\n",
      "tensor(93.)\n",
      "tensor(91.0400)\n",
      "Round 934, reward -0.155\n",
      "tensor([0.1748, 0.0316, 0.0237, 0.0237, 0.0237, 0.1747, 0.1748, 0.1747, 0.0237,\n",
      "        0.1748])\n",
      "tensor(91.1000)\n",
      "tensor(92.3700)\n",
      "Round 935, reward -0.494\n",
      "tensor([0.0343, 0.0345, 0.2533, 0.0343, 0.2532, 0.2533, 0.0343, 0.0343, 0.0344,\n",
      "        0.0343])\n",
      "tensor(91.2800)\n",
      "tensor(93.0600)\n",
      "Round 936, reward -0.492\n",
      "tensor([0.0239, 0.0575, 0.1731, 0.0239, 0.1767, 0.1474, 0.1767, 0.1694, 0.0239,\n",
      "        0.0273])\n",
      "tensor(93.8000)\n",
      "tensor(93.8400)\n",
      "Round 937, reward -0.182\n",
      "tensor([0.2295, 0.0311, 0.1707, 0.0311, 0.0311, 0.0311, 0.1946, 0.0311, 0.0311,\n",
      "        0.2184])\n",
      "tensor(91.2100)\n",
      "tensor(92.5200)\n",
      "Round 938, reward -0.492\n",
      "tensor([0.1707, 0.1829, 0.1554, 0.0247, 0.1828, 0.0264, 0.0248, 0.0247, 0.0248,\n",
      "        0.1829])\n",
      "tensor(93.5900)\n",
      "tensor(94.4200)\n",
      "Round 939, reward -0.432\n",
      "tensor([0.0516, 0.2519, 0.2414, 0.0341, 0.0341, 0.0341, 0.0341, 0.2505, 0.0341,\n",
      "        0.0341])\n",
      "tensor(87.2100)\n",
      "tensor(90.1600)\n",
      "Round 940, reward -0.571\n",
      "tensor([0.1395, 0.1088, 0.1406, 0.0190, 0.1395, 0.0191, 0.0190, 0.1405, 0.1333,\n",
      "        0.1406])\n",
      "tensor(89.9300)\n",
      "tensor(90.0200)\n",
      "Round 941, reward -0.314\n",
      "tensor([0.0354, 0.0354, 0.2612, 0.0354, 0.0354, 0.0354, 0.0354, 0.2612, 0.0354,\n",
      "        0.2300])\n",
      "tensor(93.7300)\n",
      "tensor(95.2500)\n",
      "Round 942, reward -0.437\n",
      "tensor([0.2662, 0.2557, 0.0360, 0.0367, 0.0360, 0.0370, 0.0360, 0.0360, 0.2058,\n",
      "        0.0546])\n",
      "tensor(93.8600)\n",
      "tensor(92.0400)\n",
      "Round 943, reward -0.135\n",
      "tensor([0.0229, 0.0230, 0.0729, 0.0243, 0.1578, 0.0240, 0.1689, 0.1689, 0.1689,\n",
      "        0.1686])\n",
      "tensor(93.7000)\n",
      "tensor(93.4000)\n",
      "Round 944, reward -0.138\n",
      "tensor([0.1182, 0.1671, 0.0226, 0.1671, 0.0226, 0.1669, 0.0232, 0.0228, 0.1671,\n",
      "        0.1226])\n",
      "tensor(93.8100)\n",
      "tensor(94.7200)\n",
      "Round 945, reward -0.429\n",
      "tensor([0.0776, 0.0600, 0.0599, 0.0599, 0.0601, 0.0599, 0.0599, 0.4428, 0.0599,\n",
      "        0.0599])\n",
      "tensor(85.5300)\n",
      "tensor(91.5200)\n",
      "Round 946, reward -0.600\n",
      "tensor([0.1804, 0.0780, 0.0275, 0.0874, 0.0244, 0.1795, 0.1803, 0.0244, 0.1804,\n",
      "        0.0378])\n",
      "tensor(93.8200)\n",
      "tensor(94.1000)\n",
      "Round 947, reward -0.342\n",
      "tensor([0.3830, 0.0518, 0.0518, 0.0518, 0.0552, 0.0518, 0.1978, 0.0518, 0.0529,\n",
      "        0.0518])\n",
      "tensor(86.3800)\n",
      "tensor(91.6300)\n",
      "Round 948, reward -0.586\n",
      "tensor([0.0435, 0.0339, 0.2503, 0.0339, 0.0339, 0.0367, 0.0346, 0.2503, 0.2492,\n",
      "        0.0339])\n",
      "tensor(91.5200)\n",
      "tensor(93.2400)\n",
      "Round 949, reward -0.487\n",
      "tensor([0.0219, 0.0602, 0.1460, 0.1440, 0.1460, 0.1384, 0.0316, 0.1460, 0.1460,\n",
      "        0.0198])\n",
      "tensor(88.6400)\n",
      "tensor(90.4000)\n",
      "Round 950, reward -0.545\n",
      "tensor([0.0261, 0.0303, 0.1924, 0.0261, 0.0987, 0.1926, 0.1918, 0.1880, 0.0261,\n",
      "        0.0279])\n",
      "tensor(84.2000)\n",
      "tensor(87.4700)\n",
      "Round 951, reward -0.622\n",
      "tensor([0.0323, 0.2208, 0.1591, 0.2112, 0.0301, 0.0307, 0.2222, 0.0329, 0.0305,\n",
      "        0.0301])\n",
      "tensor(84.5500)\n",
      "tensor(91.0800)\n",
      "Round 952, reward -0.616\n",
      "tensor([0.0437, 0.0428, 0.0613, 0.0428, 0.3122, 0.0429, 0.0428, 0.3165, 0.0430,\n",
      "        0.0518])\n",
      "tensor(89.4700)\n",
      "tensor(93.5600)\n",
      "Round 953, reward -0.529\n",
      "tensor([0.2245, 0.0307, 0.0304, 0.0304, 0.2245, 0.0306, 0.1439, 0.0304, 0.0304,\n",
      "        0.2242])\n",
      "tensor(91.0900)\n",
      "tensor(93.8300)\n",
      "Round 954, reward -0.496\n",
      "tensor([0.1977, 0.1753, 0.0346, 0.1980, 0.0805, 0.0268, 0.0269, 0.0301, 0.1981,\n",
      "        0.0320])\n",
      "tensor(92.0200)\n",
      "tensor(91.2000)\n",
      "Round 955, reward -0.176\n",
      "tensor([0.0412, 0.0412, 0.0412, 0.3048, 0.0412, 0.3048, 0.0412, 0.0416, 0.0412,\n",
      "        0.1015])\n",
      "tensor(91.9400)\n",
      "tensor(95.5600)\n",
      "Round 956, reward -0.478\n",
      "tensor([0.1790, 0.0243, 0.0243, 0.1770, 0.0270, 0.1611, 0.0243, 0.0243, 0.1794,\n",
      "        0.1794])\n",
      "tensor(89.8900)\n",
      "tensor(93.6900)\n",
      "Round 957, reward -0.521\n",
      "tensor([0.1944, 0.0370, 0.0373, 0.0370, 0.0371, 0.0372, 0.0378, 0.2710, 0.2736,\n",
      "        0.0376])\n",
      "tensor(89.9200)\n",
      "tensor(90.8700)\n",
      "Round 958, reward -0.514\n",
      "tensor([0.1907, 0.1907, 0.0258, 0.0258, 0.0259, 0.1556, 0.1512, 0.0264, 0.0258,\n",
      "        0.1822])\n",
      "tensor(87.3700)\n",
      "tensor(94.8100)\n",
      "Round 959, reward -0.568\n",
      "tensor([0.0277, 0.0277, 0.2043, 0.0935, 0.2043, 0.0277, 0.1515, 0.2029, 0.0277,\n",
      "        0.0329])\n",
      "tensor(89.9800)\n",
      "tensor(95.5000)\n",
      "Round 960, reward -0.519\n",
      "tensor([0.0278, 0.0278, 0.2050, 0.0278, 0.2051, 0.0287, 0.0279, 0.2051, 0.0406,\n",
      "        0.2044])\n",
      "tensor(86.8900)\n",
      "tensor(94.1300)\n",
      "Round 961, reward -0.577\n",
      "tensor([0.0416, 0.0410, 0.1081, 0.0409, 0.0409, 0.0409, 0.3023, 0.0409, 0.0411,\n",
      "        0.3023])\n",
      "tensor(93.4000)\n",
      "tensor(94.7600)\n",
      "Round 962, reward -0.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1360, 0.0472, 0.0293, 0.0277, 0.1166, 0.2045, 0.1793, 0.0277, 0.0277,\n",
      "        0.2041])\n",
      "tensor(93.9700)\n",
      "tensor(94.8100)\n",
      "Round 963, reward -0.423\n",
      "tensor([0.0254, 0.1875, 0.0254, 0.1875, 0.1296, 0.0268, 0.1818, 0.1852, 0.0254,\n",
      "        0.0254])\n",
      "tensor(94.7600)\n",
      "tensor(95.8600)\n",
      "Round 964, reward -0.410\n",
      "tensor([0.2138, 0.0641, 0.0486, 0.3588, 0.0689, 0.0486, 0.0516, 0.0486, 0.0486,\n",
      "        0.0486])\n",
      "tensor(94.4500)\n",
      "tensor(95.4100)\n",
      "Round 965, reward -0.415\n",
      "tensor([0.0281, 0.2078, 0.2080, 0.2070, 0.2080, 0.0281, 0.0281, 0.0285, 0.0282,\n",
      "        0.0281])\n",
      "tensor(88.8300)\n",
      "tensor(92.1100)\n",
      "Round 966, reward -0.541\n",
      "tensor([0.0271, 0.1999, 0.0273, 0.0271, 0.0819, 0.1994, 0.1866, 0.0284, 0.1952,\n",
      "        0.0271])\n",
      "tensor(89.0600)\n",
      "tensor(94.1700)\n",
      "Round 967, reward -0.537\n",
      "tensor([0.1347, 0.1345, 0.1342, 0.1347, 0.0182, 0.0191, 0.1333, 0.1346, 0.0222,\n",
      "        0.1346])\n",
      "tensor(94.2200)\n",
      "tensor(95.3700)\n",
      "Round 968, reward -0.424\n",
      "tensor([0.1769, 0.0239, 0.1769, 0.1769, 0.0239, 0.0239, 0.1727, 0.0239, 0.1769,\n",
      "        0.0239])\n",
      "tensor(92.4500)\n",
      "tensor(92.1700)\n",
      "Round 969, reward -0.167\n",
      "tensor([0.0196, 0.0196, 0.1383, 0.1449, 0.1451, 0.1451, 0.0196, 0.1451, 0.1442,\n",
      "        0.0784])\n",
      "tensor(93.4600)\n",
      "tensor(94.6100)\n",
      "Round 970, reward -0.442\n",
      "tensor([0.1856, 0.1850, 0.0251, 0.1857, 0.0251, 0.0251, 0.1855, 0.0324, 0.0251,\n",
      "        0.1254])\n",
      "tensor(93.6800)\n",
      "tensor(94.3800)\n",
      "Round 971, reward -0.423\n",
      "tensor([0.1369, 0.1247, 0.1369, 0.1369, 0.0185, 0.1369, 0.1350, 0.0185, 0.0188,\n",
      "        0.1369])\n",
      "tensor(93.9700)\n",
      "tensor(94.4800)\n",
      "Round 972, reward -0.396\n",
      "tensor([0.2397, 0.0324, 0.0324, 0.0324, 0.2397, 0.2389, 0.0326, 0.0869, 0.0325,\n",
      "        0.0324])\n",
      "tensor(94.7100)\n",
      "tensor(95.8600)\n",
      "Round 973, reward -0.412\n",
      "tensor([0.0292, 0.0964, 0.0286, 0.0286, 0.2071, 0.2112, 0.1110, 0.2116, 0.0286,\n",
      "        0.0475])\n",
      "tensor(94.6600)\n",
      "tensor(94.0800)\n",
      "Round 974, reward -0.116\n",
      "tensor([0.0277, 0.2044, 0.2043, 0.0559, 0.2044, 0.1923, 0.0277, 0.0277, 0.0281,\n",
      "        0.0277])\n",
      "tensor(93.3200)\n",
      "tensor(94.6800)\n",
      "Round 975, reward -0.446\n",
      "tensor([0.1481, 0.1475, 0.1483, 0.0208, 0.1459, 0.1483, 0.0201, 0.0519, 0.0210,\n",
      "        0.1483])\n",
      "tensor(89.0100)\n",
      "tensor(91.1700)\n",
      "Round 976, reward -0.538\n",
      "tensor([0.0299, 0.0300, 0.0881, 0.2208, 0.0299, 0.0299, 0.2208, 0.2176, 0.1031,\n",
      "        0.0299])\n",
      "tensor(93.2800)\n",
      "tensor(93.9800)\n",
      "Round 977, reward -0.432\n",
      "tensor([0.1658, 0.0229, 0.1193, 0.1659, 0.1247, 0.1659, 0.0227, 0.0225, 0.0245,\n",
      "        0.1659])\n",
      "tensor(92.0600)\n",
      "tensor(92.8300)\n",
      "Round 978, reward -0.463\n",
      "tensor([0.0283, 0.0282, 0.2078, 0.0282, 0.2087, 0.0294, 0.0282, 0.0282, 0.2041,\n",
      "        0.2087])\n",
      "tensor(92.4500)\n",
      "tensor(94.4100)\n",
      "Round 979, reward -0.467\n",
      "tensor([0.0209, 0.1530, 0.1541, 0.0209, 0.1546, 0.1467, 0.1546, 0.1527, 0.0213,\n",
      "        0.0209])\n",
      "tensor(94.9900)\n",
      "tensor(95.2400)\n",
      "Round 980, reward -0.301\n",
      "tensor([0.0320, 0.0320, 0.1949, 0.2361, 0.1413, 0.0320, 0.0320, 0.0320, 0.2358,\n",
      "        0.0320])\n",
      "tensor(94.3100)\n",
      "tensor(95.6700)\n",
      "Round 981, reward -0.423\n",
      "tensor([0.0374, 0.2266, 0.0374, 0.2767, 0.0444, 0.0374, 0.0376, 0.0375, 0.0375,\n",
      "        0.2274])\n",
      "tensor(95.0100)\n",
      "tensor(93.0200)\n",
      "Round 982, reward -0.107\n",
      "tensor([0.0604, 0.0603, 0.0719, 0.0603, 0.0603, 0.0603, 0.0603, 0.0604, 0.0605,\n",
      "        0.4451])\n",
      "tensor(90.9600)\n",
      "tensor(95.4100)\n",
      "Round 983, reward -0.499\n",
      "tensor([0.1913, 0.0289, 0.0361, 0.0259, 0.1901, 0.1913, 0.1913, 0.0259, 0.0590,\n",
      "        0.0602])\n",
      "tensor(92.7900)\n",
      "tensor(88.8500)\n",
      "Round 984, reward -0.159\n",
      "tensor([0.2441, 0.2810, 0.0456, 0.0380, 0.0380, 0.0380, 0.0384, 0.1955, 0.0433,\n",
      "        0.0380])\n",
      "tensor(91.9000)\n",
      "tensor(93.7800)\n",
      "Round 985, reward -0.479\n",
      "tensor([0.1270, 0.1894, 0.0256, 0.0279, 0.1894, 0.1894, 0.0256, 0.0256, 0.1743,\n",
      "        0.0256])\n",
      "tensor(88.5000)\n",
      "tensor(93.7500)\n",
      "Round 986, reward -0.548\n",
      "tensor([0.0303, 0.0303, 0.2210, 0.0305, 0.1689, 0.2237, 0.2045, 0.0303, 0.0303,\n",
      "        0.0303])\n",
      "tensor(91.3700)\n",
      "tensor(90.0100)\n",
      "Round 987, reward -0.190\n",
      "tensor([0.1776, 0.0502, 0.1449, 0.0240, 0.1768, 0.0240, 0.1768, 0.0240, 0.0240,\n",
      "        0.1776])\n",
      "tensor(93.8800)\n",
      "tensor(95.5300)\n",
      "Round 988, reward -0.434\n",
      "tensor([0.0377, 0.0398, 0.0377, 0.0377, 0.0377, 0.0379, 0.1763, 0.0378, 0.2788,\n",
      "        0.2785])\n",
      "tensor(87.1200)\n",
      "tensor(93.7800)\n",
      "Round 989, reward -0.573\n",
      "tensor([0.3805, 0.0757, 0.0676, 0.0676, 0.0676, 0.0676, 0.0680, 0.0701, 0.0676,\n",
      "        0.0676])\n",
      "tensor(83.7600)\n",
      "tensor(88.5900)\n",
      "Round 990, reward -0.629\n",
      "tensor([0.1320, 0.0846, 0.1007, 0.1497, 0.0425, 0.0210, 0.1497, 0.1497, 0.0203,\n",
      "        0.1497])\n",
      "tensor(93.0900)\n",
      "tensor(93.8800)\n",
      "Round 991, reward -0.441\n",
      "tensor([0.2103, 0.2103, 0.0285, 0.0285, 0.0285, 0.1982, 0.0286, 0.0286, 0.0285,\n",
      "        0.2103])\n",
      "tensor(92.6500)\n",
      "tensor(93.5200)\n",
      "Round 992, reward -0.454\n",
      "tensor([0.3128, 0.0423, 0.0423, 0.0423, 0.0504, 0.0679, 0.3128, 0.0439, 0.0428,\n",
      "        0.0423])\n",
      "tensor(93.5500)\n",
      "tensor(94.7800)\n",
      "Round 993, reward -0.440\n",
      "tensor([0.0347, 0.0347, 0.1929, 0.0347, 0.0347, 0.2549, 0.0876, 0.2563, 0.0347,\n",
      "        0.0348])\n",
      "tensor(91.9400)\n",
      "tensor(88.7300)\n",
      "Round 994, reward -0.178\n",
      "tensor([0.1199, 0.0877, 0.0577, 0.4008, 0.0542, 0.0543, 0.0595, 0.0574, 0.0542,\n",
      "        0.0542])\n",
      "tensor(93.2700)\n",
      "tensor(93.1400)\n",
      "Round 995, reward -0.148\n",
      "tensor([0.0282, 0.2079, 0.0282, 0.0282, 0.2082, 0.0282, 0.0494, 0.1912, 0.2022,\n",
      "        0.0283])\n",
      "tensor(90.7500)\n",
      "tensor(94.7800)\n",
      "Round 996, reward -0.503\n",
      "tensor([0.0606, 0.0606, 0.4477, 0.0606, 0.0676, 0.0606, 0.0606, 0.0606, 0.0606,\n",
      "        0.0606])\n",
      "tensor(91.2400)\n",
      "tensor(93.7000)\n",
      "Round 997, reward -0.493\n",
      "tensor([0.0382, 0.0306, 0.1386, 0.0306, 0.2254, 0.0306, 0.2191, 0.0306, 0.2254,\n",
      "        0.0308])\n",
      "tensor(94.0300)\n",
      "tensor(90.4200)\n",
      "Round 998, reward -0.131\n",
      "tensor([0.1892, 0.0533, 0.0882, 0.0256, 0.1893, 0.0256, 0.0256, 0.1893, 0.1882,\n",
      "        0.0256])\n",
      "tensor(94.1900)\n",
      "tensor(94.1600)\n",
      "Round 999, reward -0.127\n",
      "tensor([0.0361, 0.2660, 0.0360, 0.0360, 0.0360, 0.0360, 0.2170, 0.2649, 0.0360,\n",
      "        0.0360])\n",
      "tensor(91.3900)\n",
      "tensor(92.5400)\n",
      "Round 1000, reward -0.487\n",
      "tensor([0.0351, 0.0357, 0.2351, 0.2590, 0.0350, 0.2590, 0.0358, 0.0350, 0.0351,\n",
      "        0.0352])\n",
      "tensor(88.6300)\n",
      "tensor(90.5400)\n",
      "Round 1001, reward -0.545\n",
      "tensor([0.0295, 0.0493, 0.0277, 0.1963, 0.2047, 0.0277, 0.2047, 0.2046, 0.0277,\n",
      "        0.0277])\n",
      "tensor(85.5600)\n",
      "tensor(92.4800)\n",
      "Round 1002, reward -0.600\n",
      "tensor([0.0215, 0.1590, 0.1326, 0.1590, 0.0219, 0.1342, 0.0322, 0.0215, 0.1590,\n",
      "        0.1590])\n",
      "tensor(94.5000)\n",
      "tensor(95.3100)\n",
      "Round 1003, reward -0.409\n",
      "tensor([0.0691, 0.0427, 0.0490, 0.0427, 0.3152, 0.0427, 0.2826, 0.0427, 0.0707,\n",
      "        0.0427])\n",
      "tensor(93.4600)\n",
      "tensor(95.0300)\n",
      "Round 1004, reward -0.444\n",
      "tensor([0.0342, 0.2489, 0.2528, 0.0372, 0.0368, 0.0342, 0.2528, 0.0342, 0.0342,\n",
      "        0.0345])\n",
      "tensor(89.8400)\n",
      "tensor(93.9700)\n",
      "Round 1005, reward -0.522\n",
      "tensor([0.0433, 0.3197, 0.0433, 0.0553, 0.0452, 0.0433, 0.3197, 0.0439, 0.0433,\n",
      "        0.0433])\n",
      "tensor(85.4800)\n",
      "tensor(93.9100)\n",
      "Round 1006, reward -0.601\n",
      "tensor([0.2515, 0.2515, 0.0344, 0.0341, 0.0340, 0.0343, 0.0340, 0.0394, 0.2515,\n",
      "        0.0353])\n",
      "tensor(84.0800)\n",
      "tensor(89.8000)\n",
      "Round 1007, reward -0.624\n",
      "tensor([0.0381, 0.2419, 0.0327, 0.0726, 0.2419, 0.0328, 0.0327, 0.2419, 0.0327,\n",
      "        0.0327])\n",
      "tensor(88.4500)\n",
      "tensor(93.2600)\n",
      "Round 1008, reward -0.549\n",
      "tensor([0.1663, 0.1431, 0.1659, 0.0225, 0.0225, 0.1020, 0.1663, 0.1663, 0.0225,\n",
      "        0.0225])\n",
      "tensor(88.0700)\n",
      "tensor(90.3400)\n",
      "Round 1009, reward -0.556\n",
      "tensor([0.1928, 0.1180, 0.1733, 0.0261, 0.0261, 0.1928, 0.1928, 0.0261, 0.0261,\n",
      "        0.0261])\n",
      "tensor(93.9800)\n",
      "tensor(93.9300)\n",
      "Round 1010, reward -0.132\n",
      "tensor([0.3133, 0.0549, 0.3133, 0.0424, 0.0424, 0.0614, 0.0438, 0.0424, 0.0424,\n",
      "        0.0438])\n",
      "tensor(94.8400)\n",
      "tensor(90.2300)\n",
      "Round 1011, reward -0.111\n",
      "tensor([0.1823, 0.0247, 0.1573, 0.1823, 0.0247, 0.0247, 0.1816, 0.0247, 0.1731,\n",
      "        0.0247])\n",
      "tensor(94.2000)\n",
      "tensor(94.1000)\n",
      "Round 1012, reward -0.127\n",
      "tensor([0.1419, 0.0719, 0.0237, 0.1446, 0.0201, 0.1446, 0.1446, 0.1446, 0.1446,\n",
      "        0.0196])\n",
      "tensor(95.0200)\n",
      "tensor(95.0800)\n",
      "Round 1013, reward -0.173\n",
      "tensor([0.0208, 0.1540, 0.0210, 0.1540, 0.0208, 0.1540, 0.1471, 0.1540, 0.1535,\n",
      "        0.0208])\n",
      "tensor(94.0900)\n",
      "tensor(95.5200)\n",
      "Round 1014, reward -0.429\n",
      "tensor([0.0288, 0.0288, 0.0293, 0.2126, 0.2127, 0.1163, 0.0288, 0.2121, 0.0818,\n",
      "        0.0488])\n",
      "tensor(92.5500)\n",
      "tensor(94.1000)\n",
      "Round 1015, reward -0.464\n",
      "tensor([0.0465, 0.0694, 0.0449, 0.0986, 0.0447, 0.0446, 0.0446, 0.0446, 0.2322,\n",
      "        0.3299])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88.0200)\n",
      "tensor(95.2900)\n",
      "Round 1016, reward -0.557\n",
      "tensor([0.1465, 0.1466, 0.0226, 0.1466, 0.1438, 0.1466, 0.0608, 0.0199, 0.1466,\n",
      "        0.0198])\n",
      "tensor(94.2200)\n",
      "tensor(94.8600)\n",
      "Round 1017, reward -0.405\n",
      "tensor([0.1700, 0.0608, 0.0612, 0.0612, 0.0608, 0.0609, 0.0608, 0.0609, 0.3425,\n",
      "        0.0608])\n",
      "tensor(93.3000)\n",
      "tensor(95.1200)\n",
      "Round 1018, reward -0.448\n",
      "tensor([0.0419, 0.0819, 0.0474, 0.0419, 0.3097, 0.0419, 0.0419, 0.3094, 0.0419,\n",
      "        0.0420])\n",
      "tensor(93.0800)\n",
      "tensor(95.4200)\n",
      "Round 1019, reward -0.453\n",
      "tensor([0.0300, 0.0358, 0.2220, 0.0300, 0.0300, 0.0300, 0.1853, 0.2219, 0.1849,\n",
      "        0.0300])\n",
      "tensor(91.8600)\n",
      "tensor(95.6500)\n",
      "Round 1020, reward -0.480\n",
      "tensor([0.1185, 0.1401, 0.0191, 0.0190, 0.0190, 0.1405, 0.1224, 0.1405, 0.1405,\n",
      "        0.1405])\n",
      "tensor(96.2500)\n",
      "tensor(95.7900)\n",
      "Round 1021, reward -0.076\n",
      "tensor([0.0524, 0.0524, 0.2663, 0.3143, 0.0524, 0.0524, 0.0524, 0.0524, 0.0524,\n",
      "        0.0525])\n",
      "tensor(89.1700)\n",
      "tensor(95.3900)\n",
      "Round 1022, reward -0.535\n",
      "tensor([0.1667, 0.1664, 0.0230, 0.0226, 0.1667, 0.0756, 0.1536, 0.1667, 0.0357,\n",
      "        0.0229])\n",
      "tensor(86.9800)\n",
      "tensor(92.1700)\n",
      "Round 1023, reward -0.575\n",
      "tensor([0.2089, 0.0291, 0.2018, 0.0285, 0.2089, 0.0290, 0.2089, 0.0283, 0.0283,\n",
      "        0.0283])\n",
      "tensor(86.5600)\n",
      "tensor(87.3800)\n",
      "Round 1024, reward -0.573\n",
      "tensor([0.0537, 0.0445, 0.2329, 0.0337, 0.2373, 0.0321, 0.0321, 0.0645, 0.2372,\n",
      "        0.0321])\n",
      "tensor(93.7200)\n",
      "tensor(96.1800)\n",
      "Round 1025, reward -0.438\n",
      "tensor([0.0216, 0.1450, 0.0216, 0.0216, 0.1598, 0.1575, 0.1598, 0.1598, 0.0216,\n",
      "        0.1316])\n",
      "tensor(94.6600)\n",
      "tensor(94.8800)\n",
      "Round 1026, reward -0.295\n",
      "tensor([0.0427, 0.0427, 0.0525, 0.0427, 0.3152, 0.3151, 0.0427, 0.0612, 0.0427,\n",
      "        0.0427])\n",
      "tensor(94.5800)\n",
      "tensor(94.6900)\n",
      "Round 1027, reward -0.228\n",
      "tensor([0.0338, 0.0338, 0.2482, 0.2480, 0.0507, 0.0338, 0.0338, 0.0340, 0.2499,\n",
      "        0.0338])\n",
      "tensor(82.1500)\n",
      "tensor(93.3200)\n",
      "Round 1028, reward -0.653\n",
      "tensor([0.1755, 0.1755, 0.1754, 0.1755, 0.0238, 0.0237, 0.1755, 0.0257, 0.0258,\n",
      "        0.0237])\n",
      "tensor(92.1300)\n",
      "tensor(95.8900)\n",
      "Round 1029, reward -0.474\n",
      "tensor([0.0372, 0.0280, 0.0282, 0.0280, 0.0283, 0.0300, 0.2072, 0.2068, 0.2072,\n",
      "        0.1989])\n",
      "tensor(93.4700)\n",
      "tensor(94.1400)\n",
      "Round 1030, reward -0.425\n",
      "tensor([0.0397, 0.1459, 0.1458, 0.1459, 0.0198, 0.0284, 0.1459, 0.0366, 0.1459,\n",
      "        0.1459])\n",
      "tensor(94.6800)\n",
      "tensor(94.6400)\n",
      "Round 1031, reward -0.115\n",
      "tensor([0.0307, 0.2151, 0.2265, 0.0343, 0.0307, 0.2271, 0.0307, 0.1433, 0.0307,\n",
      "        0.0307])\n",
      "tensor(95.8300)\n",
      "tensor(96.3800)\n",
      "Round 1032, reward -0.356\n",
      "tensor([0.0241, 0.0242, 0.0241, 0.1784, 0.0241, 0.1776, 0.1666, 0.1783, 0.0241,\n",
      "        0.1784])\n",
      "tensor(95.6000)\n",
      "tensor(95.5900)\n",
      "Round 1033, reward -0.092\n",
      "tensor([0.0239, 0.0254, 0.1557, 0.1572, 0.1668, 0.0697, 0.0239, 0.0239, 0.1768,\n",
      "        0.1768])\n",
      "tensor(92.6700)\n",
      "tensor(95.4000)\n",
      "Round 1034, reward -0.462\n",
      "tensor([0.0278, 0.2049, 0.0413, 0.0278, 0.0278, 0.0278, 0.2050, 0.0278, 0.2049,\n",
      "        0.2051])\n",
      "tensor(89.2900)\n",
      "tensor(90.8300)\n",
      "Round 1035, reward -0.532\n",
      "tensor([0.0239, 0.1750, 0.1766, 0.1763, 0.0240, 0.0239, 0.0239, 0.1758, 0.0241,\n",
      "        0.1766])\n",
      "tensor(89.)\n",
      "tensor(93.1600)\n",
      "Round 1036, reward -0.538\n",
      "tensor([0.1339, 0.0941, 0.0941, 0.1081, 0.0941, 0.0941, 0.0941, 0.0941, 0.0994,\n",
      "        0.0941])\n",
      "tensor(94.3300)\n",
      "tensor(94.5700)\n",
      "Round 1037, reward -0.313\n",
      "tensor([0.0464, 0.0464, 0.0464, 0.3426, 0.0464, 0.0464, 0.0464, 0.0464, 0.2858,\n",
      "        0.0468])\n",
      "tensor(88.7800)\n",
      "tensor(94.2100)\n",
      "Round 1038, reward -0.542\n",
      "tensor([0.2100, 0.0284, 0.0284, 0.0285, 0.0308, 0.2100, 0.1971, 0.0284, 0.0284,\n",
      "        0.2099])\n",
      "tensor(86.9500)\n",
      "tensor(91.8600)\n",
      "Round 1039, reward -0.576\n",
      "tensor([0.0567, 0.0286, 0.1456, 0.0286, 0.0575, 0.2115, 0.2026, 0.2116, 0.0286,\n",
      "        0.0286])\n",
      "tensor(93.6200)\n",
      "tensor(91.0700)\n",
      "Round 1040, reward -0.140\n",
      "tensor([0.0308, 0.2150, 0.0295, 0.1943, 0.0329, 0.2177, 0.0311, 0.1866, 0.0295,\n",
      "        0.0326])\n",
      "tensor(94.1900)\n",
      "tensor(94.6700)\n",
      "Round 1041, reward -0.386\n",
      "tensor([0.0305, 0.0305, 0.1386, 0.2253, 0.0305, 0.0305, 0.2256, 0.2256, 0.0321,\n",
      "        0.0306])\n",
      "tensor(95.2000)\n",
      "tensor(96.2800)\n",
      "Round 1042, reward -0.399\n",
      "tensor([0.2592, 0.1113, 0.1126, 0.0372, 0.0551, 0.0372, 0.0372, 0.2750, 0.0379,\n",
      "        0.0372])\n",
      "tensor(93.1000)\n",
      "tensor(94.7300)\n",
      "Round 1043, reward -0.452\n",
      "tensor([0.0490, 0.0281, 0.1876, 0.0282, 0.0281, 0.2075, 0.0281, 0.2070, 0.2077,\n",
      "        0.0286])\n",
      "tensor(93.3800)\n",
      "tensor(93.4900)\n",
      "Round 1044, reward -0.256\n",
      "tensor([0.0309, 0.2278, 0.2285, 0.0615, 0.0309, 0.2260, 0.0309, 0.1014, 0.0311,\n",
      "        0.0309])\n",
      "tensor(84.4000)\n",
      "tensor(89.4400)\n",
      "Round 1045, reward -0.619\n",
      "tensor([0.1348, 0.0183, 0.0194, 0.1349, 0.1349, 0.1348, 0.1349, 0.1349, 0.1349,\n",
      "        0.0183])\n",
      "tensor(95.1500)\n",
      "tensor(95.4800)\n",
      "Round 1046, reward -0.328\n",
      "tensor([0.1339, 0.1339, 0.0217, 0.1339, 0.1337, 0.0219, 0.1339, 0.0973, 0.1301,\n",
      "        0.0596])\n",
      "tensor(95.5600)\n",
      "tensor(95.4400)\n",
      "Round 1047, reward -0.093\n",
      "tensor([0.0340, 0.0341, 0.0340, 0.0340, 0.2509, 0.0435, 0.0340, 0.2510, 0.2506,\n",
      "        0.0340])\n",
      "tensor(92.7400)\n",
      "tensor(95.7600)\n",
      "Round 1048, reward -0.460\n",
      "tensor([0.2086, 0.2050, 0.2085, 0.0282, 0.0283, 0.2086, 0.0282, 0.0282, 0.0282,\n",
      "        0.0282])\n",
      "tensor(90.3800)\n",
      "tensor(95.1600)\n",
      "Round 1049, reward -0.511\n",
      "tensor([0.0387, 0.0387, 0.2791, 0.0388, 0.0387, 0.0387, 0.0387, 0.1642, 0.2858,\n",
      "        0.0387])\n",
      "tensor(88.8800)\n",
      "tensor(92.2600)\n",
      "Round 1050, reward -0.540\n",
      "tensor([0.0327, 0.0327, 0.0883, 0.2416, 0.0327, 0.0327, 0.0327, 0.2416, 0.2324,\n",
      "        0.0327])\n",
      "tensor(91.5900)\n",
      "tensor(95.7900)\n",
      "Round 1051, reward -0.486\n",
      "tensor([0.0455, 0.0478, 0.0455, 0.0455, 0.2880, 0.0455, 0.0604, 0.0455, 0.3307,\n",
      "        0.0455])\n",
      "tensor(95.6900)\n",
      "tensor(94.8300)\n",
      "Round 1052, reward -0.090\n",
      "tensor([0.0492, 0.2292, 0.0492, 0.0492, 0.0492, 0.0515, 0.0492, 0.0492, 0.0609,\n",
      "        0.3633])\n",
      "tensor(93.8800)\n",
      "tensor(95.8100)\n",
      "Round 1053, reward -0.434\n",
      "tensor([0.0279, 0.0832, 0.1696, 0.0279, 0.2065, 0.0311, 0.0279, 0.0279, 0.2065,\n",
      "        0.1913])\n",
      "tensor(91.0400)\n",
      "tensor(94.9500)\n",
      "Round 1054, reward -0.497\n",
      "tensor([0.0943, 0.0946, 0.0941, 0.0952, 0.0941, 0.0941, 0.0941, 0.0941, 0.0942,\n",
      "        0.1512])\n",
      "tensor(95.3400)\n",
      "tensor(95.5700)\n",
      "Round 1055, reward -0.284\n",
      "tensor([0.3116, 0.0422, 0.0422, 0.0422, 0.0422, 0.0817, 0.0422, 0.3115, 0.0422,\n",
      "        0.0422])\n",
      "tensor(95.2200)\n",
      "tensor(96.4600)\n",
      "Round 1056, reward -0.400\n",
      "tensor([0.0799, 0.0803, 0.0796, 0.0796, 0.1000, 0.1161, 0.2091, 0.0844, 0.0915,\n",
      "        0.0796])\n",
      "tensor(95.1800)\n",
      "tensor(95.1700)\n",
      "Round 1057, reward -0.103\n",
      "tensor([0.1977, 0.0268, 0.0269, 0.0752, 0.1977, 0.0268, 0.0268, 0.0268, 0.1977,\n",
      "        0.1977])\n",
      "tensor(93.8700)\n",
      "tensor(95.1900)\n",
      "Round 1058, reward -0.433\n",
      "tensor([0.0302, 0.0302, 0.0788, 0.0303, 0.0570, 0.2231, 0.0345, 0.2153, 0.0774,\n",
      "        0.2232])\n",
      "tensor(93.8900)\n",
      "tensor(96.5700)\n",
      "Round 1059, reward -0.434\n",
      "tensor([0.0338, 0.0338, 0.0357, 0.0338, 0.2495, 0.2495, 0.2405, 0.0338, 0.0560,\n",
      "        0.0338])\n",
      "tensor(93.4400)\n",
      "tensor(94.9600)\n",
      "Round 1060, reward -0.444\n",
      "tensor([0.4502, 0.0615, 0.0609, 0.0610, 0.0609, 0.0616, 0.0609, 0.0611, 0.0609,\n",
      "        0.0609])\n",
      "tensor(94.0500)\n",
      "tensor(95.8700)\n",
      "Round 1061, reward -0.430\n",
      "tensor([0.0347, 0.2540, 0.0344, 0.0474, 0.0344, 0.2380, 0.2540, 0.0344, 0.0344,\n",
      "        0.0344])\n",
      "tensor(95.5500)\n",
      "tensor(96.0600)\n",
      "Round 1062, reward -0.358\n",
      "tensor([0.2152, 0.2152, 0.0291, 0.0291, 0.2150, 0.0291, 0.1797, 0.0292, 0.0292,\n",
      "        0.0291])\n",
      "tensor(93.5900)\n",
      "tensor(95.1500)\n",
      "Round 1063, reward -0.441\n",
      "tensor([0.0290, 0.0287, 0.2119, 0.2023, 0.0287, 0.0297, 0.0287, 0.1858, 0.0435,\n",
      "        0.2119])\n",
      "tensor(95.2900)\n",
      "tensor(95.3400)\n",
      "Round 1064, reward -0.156\n",
      "tensor([0.0433, 0.0288, 0.0288, 0.0289, 0.0288, 0.2128, 0.1772, 0.0288, 0.2119,\n",
      "        0.2108])\n",
      "tensor(94.3000)\n",
      "tensor(94.5100)\n",
      "Round 1065, reward -0.299\n",
      "tensor([0.2046, 0.2233, 0.0307, 0.0307, 0.0307, 0.0307, 0.0312, 0.1601, 0.2271,\n",
      "        0.0307])\n",
      "tensor(92.9500)\n",
      "tensor(95.5200)\n",
      "Round 1066, reward -0.456\n",
      "tensor([0.0252, 0.1862, 0.1863, 0.0256, 0.1752, 0.0274, 0.0252, 0.0252, 0.1374,\n",
      "        0.1863])\n",
      "tensor(96.1000)\n",
      "tensor(95.8400)\n",
      "Round 1067, reward -0.080\n",
      "tensor([0.1030, 0.1615, 0.0219, 0.1615, 0.0221, 0.0243, 0.1615, 0.0219, 0.1610,\n",
      "        0.1615])\n",
      "tensor(93.0800)\n",
      "tensor(96.2300)\n",
      "Round 1068, reward -0.453\n",
      "tensor([0.0384, 0.2830, 0.0384, 0.1563, 0.2839, 0.0384, 0.0384, 0.0384, 0.0463,\n",
      "        0.0384])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.5000)\n",
      "tensor(95.3100)\n",
      "Round 1069, reward -0.443\n",
      "tensor([0.0269, 0.1986, 0.1986, 0.0269, 0.0837, 0.1825, 0.1981, 0.0310, 0.0269,\n",
      "        0.0269])\n",
      "tensor(93.5000)\n",
      "tensor(94.9800)\n",
      "Round 1070, reward -0.442\n",
      "tensor([0.0423, 0.0361, 0.0360, 0.0360, 0.0360, 0.2663, 0.2626, 0.0360, 0.0360,\n",
      "        0.2125])\n",
      "tensor(86.0700)\n",
      "tensor(94.3400)\n",
      "Round 1071, reward -0.591\n",
      "tensor([0.0308, 0.0305, 0.2242, 0.0305, 0.0583, 0.1767, 0.2253, 0.0305, 0.0305,\n",
      "        0.1628])\n",
      "tensor(88.7800)\n",
      "tensor(88.0100)\n",
      "Round 1072, reward -0.242\n",
      "tensor([0.0336, 0.0290, 0.0798, 0.0290, 0.0290, 0.1409, 0.2145, 0.2003, 0.0290,\n",
      "        0.2146])\n",
      "tensor(89.9300)\n",
      "tensor(91.5800)\n",
      "Round 1073, reward -0.520\n",
      "tensor([0.4118, 0.0558, 0.0626, 0.0557, 0.1304, 0.0557, 0.0605, 0.0557, 0.0559,\n",
      "        0.0557])\n",
      "tensor(93.7700)\n",
      "tensor(96.1200)\n",
      "Round 1074, reward -0.437\n",
      "tensor([0.0437, 0.0457, 0.0461, 0.0437, 0.3229, 0.0439, 0.3229, 0.0437, 0.0437,\n",
      "        0.0437])\n",
      "tensor(90.2600)\n",
      "tensor(95.3600)\n",
      "Round 1075, reward -0.513\n",
      "tensor([0.0314, 0.0314, 0.2322, 0.0314, 0.1458, 0.0314, 0.2011, 0.2322, 0.0315,\n",
      "        0.0314])\n",
      "tensor(92.8300)\n",
      "tensor(92.6600)\n",
      "Round 1076, reward -0.158\n",
      "tensor([0.1934, 0.0263, 0.1417, 0.1934, 0.0262, 0.0262, 0.0263, 0.0262, 0.1934,\n",
      "        0.1469])\n",
      "tensor(95.8000)\n",
      "tensor(96.6100)\n",
      "Round 1077, reward -0.377\n",
      "tensor([0.1973, 0.0267, 0.1030, 0.0267, 0.0267, 0.1973, 0.1753, 0.1937, 0.0267,\n",
      "        0.0267])\n",
      "tensor(96.2100)\n",
      "tensor(95.6900)\n",
      "Round 1078, reward -0.077\n",
      "tensor([0.0390, 0.0384, 0.2836, 0.0384, 0.0384, 0.0387, 0.2833, 0.0387, 0.0384,\n",
      "        0.1631])\n",
      "tensor(94.6900)\n",
      "tensor(96.1300)\n",
      "Round 1079, reward -0.414\n",
      "tensor([0.0311, 0.1522, 0.0318, 0.0311, 0.0311, 0.2299, 0.1616, 0.2300, 0.0311,\n",
      "        0.0699])\n",
      "tensor(93.7600)\n",
      "tensor(93.8500)\n",
      "Round 1080, reward -0.231\n",
      "tensor([0.0829, 0.0783, 0.0783, 0.1212, 0.2453, 0.0807, 0.0783, 0.0783, 0.0784,\n",
      "        0.0783])\n",
      "tensor(95.0100)\n",
      "tensor(96.3500)\n",
      "Round 1081, reward -0.406\n",
      "tensor([0.0331, 0.2445, 0.0331, 0.0628, 0.0331, 0.0380, 0.2445, 0.0331, 0.2445,\n",
      "        0.0334])\n",
      "tensor(95.4100)\n",
      "tensor(95.3200)\n",
      "Round 1082, reward -0.097\n",
      "tensor([0.3069, 0.0426, 0.0426, 0.0426, 0.0426, 0.0426, 0.0427, 0.0520, 0.0710,\n",
      "        0.3145])\n",
      "tensor(89.8600)\n",
      "tensor(96.1100)\n",
      "Round 1083, reward -0.521\n",
      "tensor([0.2130, 0.3707, 0.0523, 0.0502, 0.0613, 0.0502, 0.0502, 0.0502, 0.0518,\n",
      "        0.0502])\n",
      "tensor(94.2900)\n",
      "tensor(94.4500)\n",
      "Round 1084, reward -0.270\n",
      "tensor([0.0339, 0.2387, 0.0342, 0.0339, 0.0568, 0.0339, 0.0343, 0.2501, 0.0339,\n",
      "        0.2504])\n",
      "tensor(94.1400)\n",
      "tensor(96.2800)\n",
      "Round 1085, reward -0.428\n",
      "tensor([0.2534, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.2555, 0.0346, 0.0346,\n",
      "        0.2491])\n",
      "tensor(90.5300)\n",
      "tensor(95.4800)\n",
      "Round 1086, reward -0.508\n",
      "tensor([0.0608, 0.0621, 0.4489, 0.0610, 0.0608, 0.0608, 0.0608, 0.0608, 0.0608,\n",
      "        0.0632])\n",
      "tensor(94.5300)\n",
      "tensor(96.4400)\n",
      "Round 1087, reward -0.419\n",
      "tensor([0.1425, 0.1426, 0.1403, 0.0197, 0.1036, 0.1275, 0.1426, 0.0193, 0.0193,\n",
      "        0.1426])\n",
      "tensor(95.9300)\n",
      "tensor(96.0200)\n",
      "Round 1088, reward -0.178\n",
      "tensor([0.0438, 0.0438, 0.0444, 0.3240, 0.3240, 0.0440, 0.0438, 0.0444, 0.0438,\n",
      "        0.0438])\n",
      "tensor(86.5900)\n",
      "tensor(93.8400)\n",
      "Round 1089, reward -0.582\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0448, 0.3112, 0.3307, 0.0448, 0.0448,\n",
      "        0.0448])\n",
      "tensor(92.4600)\n",
      "tensor(94.7800)\n",
      "Round 1090, reward -0.467\n",
      "tensor([0.0272, 0.0273, 0.1250, 0.0276, 0.2013, 0.1390, 0.2003, 0.0272, 0.1978,\n",
      "        0.0272])\n",
      "tensor(95.6500)\n",
      "tensor(95.6600)\n",
      "Round 1091, reward -0.103\n",
      "tensor([0.1384, 0.0419, 0.0371, 0.0851, 0.2744, 0.2744, 0.0371, 0.0372, 0.0373,\n",
      "        0.0371])\n",
      "tensor(94.3700)\n",
      "tensor(96.)\n",
      "Round 1092, reward -0.422\n",
      "tensor([0.0345, 0.0322, 0.0322, 0.2364, 0.2342, 0.2377, 0.0323, 0.0322, 0.0962,\n",
      "        0.0322])\n",
      "tensor(93.9600)\n",
      "tensor(95.6000)\n",
      "Round 1093, reward -0.432\n",
      "tensor([0.0253, 0.0253, 0.1870, 0.0253, 0.1253, 0.0253, 0.0253, 0.1871, 0.1871,\n",
      "        0.1870])\n",
      "tensor(90.2700)\n",
      "tensor(93.7100)\n",
      "Round 1094, reward -0.513\n",
      "tensor([0.0537, 0.0537, 0.3963, 0.0537, 0.0537, 0.0537, 0.0537, 0.1020, 0.0537,\n",
      "        0.1261])\n",
      "tensor(86.7100)\n",
      "tensor(88.3000)\n",
      "Round 1095, reward -0.580\n",
      "tensor([0.1363, 0.1352, 0.1278, 0.1363, 0.0189, 0.0185, 0.1363, 0.1361, 0.0184,\n",
      "        0.1362])\n",
      "tensor(96.5200)\n",
      "tensor(95.8000)\n",
      "Round 1096, reward -0.069\n",
      "tensor([0.0340, 0.2349, 0.2510, 0.0340, 0.2508, 0.0340, 0.0593, 0.0341, 0.0340,\n",
      "        0.0340])\n",
      "tensor(94.1700)\n",
      "tensor(95.8400)\n",
      "Round 1097, reward -0.427\n",
      "tensor([0.0279, 0.2053, 0.0278, 0.0306, 0.0284, 0.0278, 0.2054, 0.2054, 0.0362,\n",
      "        0.2054])\n",
      "tensor(91.2900)\n",
      "tensor(95.7200)\n",
      "Round 1098, reward -0.492\n",
      "tensor([0.0320, 0.1082, 0.0320, 0.0320, 0.2280, 0.2357, 0.2361, 0.0323, 0.0320,\n",
      "        0.0320])\n",
      "tensor(90.4600)\n",
      "tensor(96.2100)\n",
      "Round 1099, reward -0.509\n",
      "tensor([0.2535, 0.1888, 0.0782, 0.2503, 0.0343, 0.0343, 0.0576, 0.0343, 0.0343,\n",
      "        0.0344])\n",
      "tensor(95.3600)\n",
      "tensor(95.4600)\n",
      "Round 1100, reward -0.200\n",
      "tensor([0.1531, 0.2165, 0.0301, 0.0301, 0.0301, 0.0352, 0.2224, 0.0301, 0.2224,\n",
      "        0.0301])\n",
      "tensor(94.2900)\n",
      "tensor(96.2200)\n",
      "Round 1101, reward -0.424\n",
      "tensor([0.2451, 0.0332, 0.0332, 0.2451, 0.2361, 0.0332, 0.0706, 0.0332, 0.0332,\n",
      "        0.0373])\n",
      "tensor(94.2700)\n",
      "tensor(96.4600)\n",
      "Round 1102, reward -0.425\n",
      "tensor([0.2077, 0.0282, 0.2057, 0.0282, 0.2070, 0.0282, 0.0282, 0.0311, 0.2078,\n",
      "        0.0282])\n",
      "tensor(93.5500)\n",
      "tensor(95.9800)\n",
      "Round 1103, reward -0.442\n",
      "tensor([0.0595, 0.0616, 0.0595, 0.0595, 0.0613, 0.0649, 0.3853, 0.1292, 0.0595,\n",
      "        0.0595])\n",
      "tensor(95.2300)\n",
      "tensor(96.3400)\n",
      "Round 1104, reward -0.399\n",
      "tensor([0.0238, 0.1757, 0.1760, 0.0239, 0.1757, 0.1760, 0.0238, 0.0238, 0.1760,\n",
      "        0.0252])\n",
      "tensor(94.7800)\n",
      "tensor(96.6500)\n",
      "Round 1105, reward -0.413\n",
      "tensor([0.0241, 0.1698, 0.0248, 0.0247, 0.1743, 0.0241, 0.0241, 0.1780, 0.1780,\n",
      "        0.1781])\n",
      "tensor(95.9300)\n",
      "tensor(96.3600)\n",
      "Round 1106, reward -0.334\n",
      "tensor([0.1365, 0.1366, 0.0185, 0.1363, 0.1366, 0.1138, 0.1366, 0.0223, 0.0262,\n",
      "        0.1366])\n",
      "tensor(95.3400)\n",
      "tensor(95.6800)\n",
      "Round 1107, reward -0.326\n",
      "tensor([0.0372, 0.1965, 0.2706, 0.0366, 0.0366, 0.0366, 0.0366, 0.0419, 0.2707,\n",
      "        0.0366])\n",
      "tensor(94.3300)\n",
      "tensor(95.2900)\n",
      "Round 1108, reward -0.418\n",
      "tensor([0.0437, 0.0437, 0.3196, 0.3222, 0.0440, 0.0439, 0.0440, 0.0442, 0.0511,\n",
      "        0.0437])\n",
      "tensor(94.7300)\n",
      "tensor(96.2100)\n",
      "Round 1109, reward -0.413\n",
      "tensor([0.2089, 0.2004, 0.0283, 0.0284, 0.2014, 0.0387, 0.0283, 0.0283, 0.2089,\n",
      "        0.0283])\n",
      "tensor(91.8300)\n",
      "tensor(96.0100)\n",
      "Round 1110, reward -0.480\n",
      "tensor([0.1389, 0.0188, 0.1389, 0.1389, 0.1389, 0.1389, 0.0188, 0.0188, 0.1387,\n",
      "        0.1104])\n",
      "tensor(95.1200)\n",
      "tensor(94.1600)\n",
      "Round 1111, reward -0.104\n",
      "tensor([0.0411, 0.0413, 0.0411, 0.3039, 0.0411, 0.0411, 0.1039, 0.0411, 0.0411,\n",
      "        0.3040])\n",
      "tensor(91.6500)\n",
      "tensor(94.3200)\n",
      "Round 1112, reward -0.484\n",
      "tensor([0.0439, 0.0439, 0.3227, 0.0439, 0.0439, 0.3245, 0.0442, 0.0450, 0.0439,\n",
      "        0.0439])\n",
      "tensor(89.7400)\n",
      "tensor(94.5700)\n",
      "Round 1113, reward -0.524\n",
      "tensor([0.0795, 0.1929, 0.0261, 0.0286, 0.1929, 0.1919, 0.1929, 0.0429, 0.0261,\n",
      "        0.0261])\n",
      "tensor(96.3700)\n",
      "tensor(96.3400)\n",
      "Round 1114, reward -0.073\n",
      "tensor([0.2127, 0.0288, 0.0289, 0.0291, 0.0288, 0.0288, 0.2120, 0.2060, 0.0288,\n",
      "        0.1962])\n",
      "tensor(95.7400)\n",
      "tensor(96.3900)\n",
      "Round 1115, reward -0.369\n",
      "tensor([0.1891, 0.0293, 0.2164, 0.0293, 0.1916, 0.0296, 0.0295, 0.0387, 0.0301,\n",
      "        0.2164])\n",
      "tensor(94.8100)\n",
      "tensor(96.2900)\n",
      "Round 1116, reward -0.411\n",
      "tensor([0.0285, 0.0285, 0.0296, 0.1966, 0.2104, 0.0285, 0.0285, 0.0285, 0.2105,\n",
      "        0.2105])\n",
      "tensor(95.2200)\n",
      "tensor(95.3300)\n",
      "Round 1117, reward -0.212\n",
      "tensor([0.2523, 0.2523, 0.0341, 0.2523, 0.0341, 0.0375, 0.0342, 0.0341, 0.0341,\n",
      "        0.0349])\n",
      "tensor(84.9600)\n",
      "tensor(90.3700)\n",
      "Round 1118, reward -0.610\n",
      "tensor([0.0340, 0.2513, 0.2514, 0.2460, 0.0340, 0.0340, 0.0457, 0.0354, 0.0340,\n",
      "        0.0340])\n",
      "tensor(95.5600)\n",
      "tensor(92.7300)\n",
      "Round 1119, reward -0.093\n",
      "tensor([0.0207, 0.0207, 0.1522, 0.1524, 0.1532, 0.1530, 0.1531, 0.0207, 0.0207,\n",
      "        0.1532])\n",
      "tensor(93.1500)\n",
      "tensor(95.5600)\n",
      "Round 1120, reward -0.451\n",
      "tensor([0.1592, 0.0215, 0.1592, 0.0215, 0.1463, 0.1169, 0.1582, 0.0215, 0.1592,\n",
      "        0.0363])\n",
      "tensor(96.7200)\n",
      "tensor(96.8800)\n",
      "Round 1121, reward -0.209\n",
      "tensor([0.1318, 0.1369, 0.1332, 0.0185, 0.1369, 0.1319, 0.1369, 0.0185, 0.1368,\n",
      "        0.0185])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.1400)\n",
      "tensor(95.5000)\n",
      "Round 1122, reward -0.427\n",
      "tensor([0.2478, 0.0335, 0.2438, 0.0343, 0.0335, 0.0336, 0.0335, 0.0335, 0.0587,\n",
      "        0.2478])\n",
      "tensor(94.3100)\n",
      "tensor(96.9500)\n",
      "Round 1123, reward -0.424\n",
      "tensor([0.0505, 0.0505, 0.3726, 0.0505, 0.0505, 0.0505, 0.0505, 0.0505, 0.2237,\n",
      "        0.0505])\n",
      "tensor(95.9000)\n",
      "tensor(96.6100)\n",
      "Round 1124, reward -0.369\n",
      "tensor([0.0191, 0.0191, 0.1413, 0.1319, 0.1216, 0.1414, 0.1414, 0.0191, 0.1389,\n",
      "        0.1261])\n",
      "tensor(95.5100)\n",
      "tensor(96.1400)\n",
      "Round 1125, reward -0.373\n",
      "tensor([0.1449, 0.1437, 0.1449, 0.1449, 0.1411, 0.1073, 0.0991, 0.0347, 0.0196,\n",
      "        0.0196])\n",
      "tensor(95.7900)\n",
      "tensor(96.0800)\n",
      "Round 1126, reward -0.298\n",
      "tensor([0.2105, 0.1980, 0.0285, 0.0285, 0.0285, 0.0285, 0.0285, 0.2091, 0.0293,\n",
      "        0.2106])\n",
      "tensor(96.8800)\n",
      "tensor(96.9700)\n",
      "Round 1127, reward -0.153\n",
      "tensor([0.0243, 0.0243, 0.1793, 0.1793, 0.1793, 0.0243, 0.0348, 0.0243, 0.1793,\n",
      "        0.1510])\n",
      "tensor(94.6100)\n",
      "tensor(96.4400)\n",
      "Round 1128, reward -0.417\n",
      "tensor([0.0255, 0.1853, 0.0256, 0.0421, 0.1651, 0.0255, 0.1882, 0.1880, 0.1293,\n",
      "        0.0255])\n",
      "tensor(93.4400)\n",
      "tensor(95.7300)\n",
      "Round 1129, reward -0.444\n",
      "tensor([0.0405, 0.0410, 0.1197, 0.0405, 0.0405, 0.0405, 0.0408, 0.2991, 0.2971,\n",
      "        0.0405])\n",
      "tensor(91.3300)\n",
      "tensor(94.6700)\n",
      "Round 1130, reward -0.491\n",
      "tensor([0.1627, 0.2104, 0.2153, 0.0295, 0.0298, 0.0295, 0.0298, 0.2177, 0.0455,\n",
      "        0.0298])\n",
      "tensor(92.5000)\n",
      "tensor(94.9000)\n",
      "Round 1131, reward -0.466\n",
      "tensor([0.0551, 0.0856, 0.0561, 0.0551, 0.0551, 0.4070, 0.0551, 0.0551, 0.1208,\n",
      "        0.0551])\n",
      "tensor(94.)\n",
      "tensor(96.4100)\n",
      "Round 1132, reward -0.431\n",
      "tensor([0.1594, 0.0825, 0.0226, 0.1670, 0.0226, 0.0228, 0.1626, 0.0265, 0.1670,\n",
      "        0.1670])\n",
      "tensor(95.9900)\n",
      "tensor(96.1700)\n",
      "Round 1133, reward -0.240\n",
      "tensor([0.0358, 0.0421, 0.0358, 0.2644, 0.2441, 0.0358, 0.0358, 0.0364, 0.0489,\n",
      "        0.2209])\n",
      "tensor(92.0800)\n",
      "tensor(95.9700)\n",
      "Round 1134, reward -0.475\n",
      "tensor([0.0248, 0.1553, 0.1541, 0.1831, 0.0248, 0.0248, 0.0424, 0.0248, 0.1831,\n",
      "        0.1831])\n",
      "tensor(94.6900)\n",
      "tensor(96.7000)\n",
      "Round 1135, reward -0.415\n",
      "tensor([0.0215, 0.0215, 0.1330, 0.1590, 0.1548, 0.1535, 0.0215, 0.1590, 0.0217,\n",
      "        0.1543])\n",
      "tensor(91.0500)\n",
      "tensor(92.2900)\n",
      "Round 1136, reward -0.495\n",
      "tensor([0.2077, 0.2077, 0.0281, 0.0281, 0.0281, 0.0281, 0.0281, 0.2077, 0.2077,\n",
      "        0.0286])\n",
      "tensor(95.6300)\n",
      "tensor(96.6400)\n",
      "Round 1137, reward -0.387\n",
      "tensor([0.1697, 0.1770, 0.0240, 0.1775, 0.1775, 0.0240, 0.0251, 0.0240, 0.1773,\n",
      "        0.0240])\n",
      "tensor(96.3100)\n",
      "tensor(96.7000)\n",
      "Round 1138, reward -0.315\n",
      "tensor([0.0692, 0.0692, 0.0692, 0.0692, 0.0692, 0.3719, 0.0692, 0.0745, 0.0692,\n",
      "        0.0692])\n",
      "tensor(95.6200)\n",
      "tensor(95.3100)\n",
      "Round 1139, reward -0.092\n",
      "tensor([0.1856, 0.0376, 0.0252, 0.0251, 0.1856, 0.1856, 0.0251, 0.0251, 0.1845,\n",
      "        0.1206])\n",
      "tensor(95.4600)\n",
      "tensor(95.8300)\n",
      "Round 1140, reward -0.331\n",
      "tensor([0.0765, 0.2647, 0.0358, 0.1246, 0.0427, 0.0358, 0.2647, 0.0434, 0.0358,\n",
      "        0.0761])\n",
      "tensor(87.8300)\n",
      "tensor(92.6100)\n",
      "Round 1141, reward -0.560\n",
      "tensor([0.1317, 0.0304, 0.2248, 0.0305, 0.0304, 0.2248, 0.2037, 0.0330, 0.0599,\n",
      "        0.0307])\n",
      "tensor(95.9800)\n",
      "tensor(96.2600)\n",
      "Round 1142, reward -0.289\n",
      "tensor([0.0367, 0.0362, 0.0362, 0.1454, 0.0362, 0.2664, 0.1186, 0.2440, 0.0362,\n",
      "        0.0441])\n",
      "tensor(95.3800)\n",
      "tensor(96.2300)\n",
      "Round 1143, reward -0.389\n",
      "tensor([0.0299, 0.0298, 0.1726, 0.2199, 0.2160, 0.2125, 0.0299, 0.0298, 0.0298,\n",
      "        0.0298])\n",
      "tensor(96.1800)\n",
      "tensor(95.9800)\n",
      "Round 1144, reward -0.077\n",
      "tensor([0.2373, 0.0955, 0.0321, 0.0321, 0.0321, 0.2372, 0.0321, 0.2373, 0.0321,\n",
      "        0.0321])\n",
      "tensor(87.1200)\n",
      "tensor(94.9300)\n",
      "Round 1145, reward -0.573\n",
      "tensor([0.1535, 0.1533, 0.1534, 0.0208, 0.1535, 0.0208, 0.0208, 0.0208, 0.1535,\n",
      "        0.1497])\n",
      "tensor(93.9500)\n",
      "tensor(93.0100)\n",
      "Round 1146, reward -0.133\n",
      "tensor([0.0418, 0.0841, 0.0418, 0.0418, 0.0442, 0.3087, 0.0445, 0.0426, 0.0418,\n",
      "        0.3087])\n",
      "tensor(90.6800)\n",
      "tensor(95.1900)\n",
      "Round 1147, reward -0.505\n",
      "tensor([0.1539, 0.0209, 0.1541, 0.1540, 0.1541, 0.1540, 0.0208, 0.1465, 0.0208,\n",
      "        0.0208])\n",
      "tensor(94.8600)\n",
      "tensor(95.3500)\n",
      "Round 1148, reward -0.372\n",
      "tensor([0.0240, 0.1751, 0.0293, 0.0237, 0.0237, 0.1751, 0.1751, 0.0237, 0.1751,\n",
      "        0.1751])\n",
      "tensor(94.8200)\n",
      "tensor(95.2600)\n",
      "Round 1149, reward -0.364\n",
      "tensor([0.2071, 0.0282, 0.0282, 0.2080, 0.0282, 0.2080, 0.0282, 0.2080, 0.0282,\n",
      "        0.0282])\n",
      "tensor(95.7400)\n",
      "tensor(95.9500)\n",
      "Round 1150, reward -0.263\n",
      "tensor([0.2497, 0.0437, 0.0340, 0.2234, 0.0457, 0.0340, 0.0498, 0.0340, 0.0348,\n",
      "        0.2509])\n",
      "tensor(95.7200)\n",
      "tensor(97.0500)\n",
      "Round 1151, reward -0.388\n",
      "tensor([0.0288, 0.2118, 0.1891, 0.0293, 0.0288, 0.0288, 0.2129, 0.2129, 0.0288,\n",
      "        0.0288])\n",
      "tensor(95.8800)\n",
      "tensor(96.3000)\n",
      "Round 1152, reward -0.333\n",
      "tensor([0.0224, 0.0223, 0.0460, 0.1646, 0.1646, 0.0776, 0.1521, 0.1646, 0.1635,\n",
      "        0.0223])\n",
      "tensor(94.0600)\n",
      "tensor(94.2000)\n",
      "Round 1153, reward -0.262\n",
      "tensor([0.1814, 0.1606, 0.1814, 0.0245, 0.0245, 0.0246, 0.0246, 0.0245, 0.1814,\n",
      "        0.1725])\n",
      "tensor(93.2600)\n",
      "tensor(95.4500)\n",
      "Round 1154, reward -0.449\n",
      "tensor([0.2027, 0.2019, 0.0274, 0.2017, 0.0274, 0.0539, 0.0274, 0.0274, 0.0275,\n",
      "        0.2026])\n",
      "tensor(89.5800)\n",
      "tensor(92.4300)\n",
      "Round 1155, reward -0.527\n",
      "tensor([0.0291, 0.0291, 0.2053, 0.2153, 0.2153, 0.0291, 0.0291, 0.1867, 0.0291,\n",
      "        0.0318])\n",
      "tensor(87.6300)\n",
      "tensor(89.)\n",
      "Round 1156, reward -0.563\n",
      "tensor([0.1462, 0.0601, 0.0601, 0.0601, 0.0601, 0.0601, 0.3732, 0.0601, 0.0601,\n",
      "        0.0601])\n",
      "tensor(93.6700)\n",
      "tensor(94.8900)\n",
      "Round 1157, reward -0.437\n",
      "tensor([0.0268, 0.0791, 0.0266, 0.1969, 0.0266, 0.1969, 0.0266, 0.1969, 0.1969,\n",
      "        0.0266])\n",
      "tensor(91.3000)\n",
      "tensor(94.2500)\n",
      "Round 1158, reward -0.492\n",
      "tensor([0.0503, 0.3717, 0.0542, 0.0503, 0.2184, 0.0506, 0.0536, 0.0503, 0.0503,\n",
      "        0.0503])\n",
      "tensor(89.6100)\n",
      "tensor(89.7300)\n",
      "Round 1159, reward -0.344\n",
      "tensor([0.2074, 0.2074, 0.0298, 0.0281, 0.2074, 0.0281, 0.0281, 0.0281, 0.0281,\n",
      "        0.2074])\n",
      "tensor(96.0100)\n",
      "tensor(95.5200)\n",
      "Round 1160, reward -0.082\n",
      "tensor([0.1220, 0.1864, 0.1758, 0.1864, 0.0394, 0.0253, 0.1864, 0.0252, 0.0277,\n",
      "        0.0253])\n",
      "tensor(95.5800)\n",
      "tensor(96.2700)\n",
      "Round 1161, reward -0.376\n",
      "tensor([0.0289, 0.2138, 0.0320, 0.2138, 0.0290, 0.0289, 0.1818, 0.0289, 0.2138,\n",
      "        0.0289])\n",
      "tensor(95.8900)\n",
      "tensor(94.2000)\n",
      "Round 1162, reward -0.085\n",
      "tensor([0.0528, 0.0528, 0.3900, 0.0539, 0.0528, 0.0528, 0.1102, 0.0690, 0.0528,\n",
      "        0.1129])\n",
      "tensor(94.1500)\n",
      "tensor(96.4100)\n",
      "Round 1163, reward -0.428\n",
      "tensor([0.1727, 0.1728, 0.1728, 0.1664, 0.0234, 0.0242, 0.0490, 0.0234, 0.0234,\n",
      "        0.1720])\n",
      "tensor(93.0900)\n",
      "tensor(93.1600)\n",
      "Round 1164, reward -0.228\n",
      "tensor([0.0420, 0.2952, 0.0416, 0.0436, 0.0554, 0.0416, 0.3071, 0.0416, 0.0417,\n",
      "        0.0904])\n",
      "tensor(94.7300)\n",
      "tensor(97.2700)\n",
      "Round 1165, reward -0.414\n",
      "tensor([0.0458, 0.3386, 0.0458, 0.2777, 0.0458, 0.0459, 0.0619, 0.0458, 0.0458,\n",
      "        0.0467])\n",
      "tensor(93.7900)\n",
      "tensor(95.7800)\n",
      "Round 1166, reward -0.436\n",
      "tensor([0.0195, 0.0198, 0.1436, 0.1425, 0.1438, 0.1438, 0.1260, 0.1438, 0.0195,\n",
      "        0.0978])\n",
      "tensor(94.9600)\n",
      "tensor(95.7500)\n",
      "Round 1167, reward -0.397\n",
      "tensor([0.1651, 0.0252, 0.1861, 0.1508, 0.1856, 0.0252, 0.0252, 0.1862, 0.0254,\n",
      "        0.0252])\n",
      "tensor(94.2300)\n",
      "tensor(94.9600)\n",
      "Round 1168, reward -0.412\n",
      "tensor([0.2705, 0.1022, 0.0370, 0.2705, 0.0366, 0.0369, 0.0366, 0.0366, 0.0366,\n",
      "        0.1365])\n",
      "tensor(96.4300)\n",
      "tensor(96.6200)\n",
      "Round 1169, reward -0.235\n",
      "tensor([0.2532, 0.0343, 0.0356, 0.2525, 0.0343, 0.0343, 0.0343, 0.2532, 0.0343,\n",
      "        0.0343])\n",
      "tensor(92.5800)\n",
      "tensor(95.7800)\n",
      "Round 1170, reward -0.464\n",
      "tensor([0.0378, 0.2650, 0.0378, 0.1727, 0.0506, 0.2783, 0.0378, 0.0378, 0.0378,\n",
      "        0.0443])\n",
      "tensor(91.6800)\n",
      "tensor(95.3700)\n",
      "Round 1171, reward -0.484\n",
      "tensor([0.2064, 0.0281, 0.0281, 0.0281, 0.0281, 0.2078, 0.2078, 0.2078, 0.0288,\n",
      "        0.0289])\n",
      "tensor(94.2200)\n",
      "tensor(97.2100)\n",
      "Round 1172, reward -0.426\n",
      "tensor([0.0291, 0.0291, 0.0291, 0.2141, 0.2149, 0.1789, 0.0307, 0.2149, 0.0291,\n",
      "        0.0302])\n",
      "tensor(90.9400)\n",
      "tensor(90.9300)\n",
      "Round 1173, reward -0.199\n",
      "tensor([0.0393, 0.0393, 0.2899, 0.0407, 0.1436, 0.0393, 0.2901, 0.0393, 0.0393,\n",
      "        0.0393])\n",
      "tensor(95.0100)\n",
      "tensor(95.4300)\n",
      "Round 1174, reward -0.355\n",
      "tensor([0.2231, 0.0353, 0.0353, 0.2583, 0.0353, 0.0353, 0.0353, 0.0462, 0.2607,\n",
      "        0.0353])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95.3300)\n",
      "tensor(93.9400)\n",
      "Round 1175, reward -0.099\n",
      "tensor([0.1325, 0.0224, 0.1498, 0.1494, 0.1383, 0.0628, 0.1494, 0.1499, 0.0252,\n",
      "        0.0203])\n",
      "tensor(95.8700)\n",
      "tensor(96.2100)\n",
      "Round 1176, reward -0.312\n",
      "tensor([0.2450, 0.0332, 0.0332, 0.0332, 0.2442, 0.0332, 0.0332, 0.0332, 0.2450,\n",
      "        0.0667])\n",
      "tensor(95.5800)\n",
      "tensor(96.2200)\n",
      "Round 1177, reward -0.372\n",
      "tensor([0.0430, 0.0430, 0.0462, 0.0430, 0.0430, 0.0430, 0.3180, 0.0430, 0.0595,\n",
      "        0.3180])\n",
      "tensor(86.5200)\n",
      "tensor(93.7800)\n",
      "Round 1178, reward -0.583\n",
      "tensor([0.2846, 0.0387, 0.0386, 0.1541, 0.0386, 0.0386, 0.0386, 0.2850, 0.0448,\n",
      "        0.0386])\n",
      "tensor(87.7700)\n",
      "tensor(88.2600)\n",
      "Round 1179, reward -0.522\n",
      "tensor([0.2107, 0.1698, 0.0285, 0.0285, 0.0285, 0.0285, 0.0285, 0.0556, 0.2107,\n",
      "        0.2107])\n",
      "tensor(90.0600)\n",
      "tensor(94.2800)\n",
      "Round 1180, reward -0.517\n",
      "tensor([0.1293, 0.1362, 0.0185, 0.1370, 0.0185, 0.1370, 0.1317, 0.0185, 0.1369,\n",
      "        0.1363])\n",
      "tensor(94.4600)\n",
      "tensor(95.9700)\n",
      "Round 1181, reward -0.420\n",
      "tensor([0.0341, 0.1770, 0.0337, 0.2485, 0.0336, 0.0336, 0.1190, 0.2485, 0.0350,\n",
      "        0.0370])\n",
      "tensor(95.7700)\n",
      "tensor(96.6900)\n",
      "Round 1182, reward -0.381\n",
      "tensor([0.0293, 0.0293, 0.1706, 0.2164, 0.2136, 0.0293, 0.0366, 0.2162, 0.0293,\n",
      "        0.0293])\n",
      "tensor(96.0600)\n",
      "tensor(96.1100)\n",
      "Round 1183, reward -0.137\n",
      "tensor([0.0540, 0.2470, 0.0334, 0.0456, 0.1345, 0.1960, 0.1237, 0.0334, 0.0394,\n",
      "        0.0928])\n",
      "tensor(92.8400)\n",
      "tensor(95.7000)\n",
      "Round 1184, reward -0.458\n",
      "tensor([0.0437, 0.3220, 0.0490, 0.3230, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
      "        0.0437])\n",
      "tensor(96.1700)\n",
      "tensor(95.4200)\n",
      "Round 1185, reward -0.078\n",
      "tensor([0.0434, 0.0548, 0.0441, 0.0434, 0.0434, 0.0434, 0.0434, 0.0434, 0.3204,\n",
      "        0.3204])\n",
      "tensor(90.7900)\n",
      "tensor(96.7800)\n",
      "Round 1186, reward -0.502\n",
      "tensor([0.0337, 0.0335, 0.0335, 0.0366, 0.2476, 0.2391, 0.0607, 0.0335, 0.2479,\n",
      "        0.0339])\n",
      "tensor(95.6500)\n",
      "tensor(96.8200)\n",
      "Round 1187, reward -0.389\n",
      "tensor([0.0611, 0.0610, 0.0610, 0.0610, 0.0610, 0.0613, 0.0610, 0.0610, 0.0610,\n",
      "        0.4506])\n",
      "tensor(89.8400)\n",
      "tensor(89.1800)\n",
      "Round 1188, reward -0.222\n",
      "tensor([0.0282, 0.2084, 0.2084, 0.0282, 0.0282, 0.1200, 0.1137, 0.0282, 0.2084,\n",
      "        0.0282])\n",
      "tensor(90.3500)\n",
      "tensor(93.7200)\n",
      "Round 1189, reward -0.512\n",
      "tensor([0.0428, 0.0426, 0.3151, 0.0426, 0.0712, 0.0426, 0.3151, 0.0426, 0.0426,\n",
      "        0.0426])\n",
      "tensor(90.4200)\n",
      "tensor(96.8900)\n",
      "Round 1190, reward -0.510\n",
      "tensor([0.2454, 0.0350, 0.0350, 0.0350, 0.2583, 0.0368, 0.2496, 0.0350, 0.0350,\n",
      "        0.0350])\n",
      "tensor(92.3200)\n",
      "tensor(93.0500)\n",
      "Round 1191, reward -0.455\n",
      "tensor([0.0581, 0.1053, 0.0581, 0.0581, 0.4296, 0.0581, 0.0581, 0.0581, 0.0581,\n",
      "        0.0581])\n",
      "tensor(90.4300)\n",
      "tensor(96.5000)\n",
      "Round 1192, reward -0.510\n",
      "tensor([0.0462, 0.0462, 0.0462, 0.0496, 0.3413, 0.2850, 0.0469, 0.0462, 0.0462,\n",
      "        0.0462])\n",
      "tensor(95.3500)\n",
      "tensor(97.0200)\n",
      "Round 1193, reward -0.398\n",
      "tensor([0.2580, 0.0357, 0.0360, 0.0357, 0.0357, 0.0357, 0.2344, 0.0357, 0.2574,\n",
      "        0.0357])\n",
      "tensor(95.9700)\n",
      "tensor(96.2900)\n",
      "Round 1194, reward -0.304\n",
      "tensor([0.0282, 0.2085, 0.0735, 0.2081, 0.2080, 0.0324, 0.0284, 0.1515, 0.0331,\n",
      "        0.0282])\n",
      "tensor(94.4400)\n",
      "tensor(95.6800)\n",
      "Round 1195, reward -0.419\n",
      "tensor([0.0232, 0.1713, 0.0543, 0.1714, 0.1714, 0.1673, 0.0232, 0.1714, 0.0232,\n",
      "        0.0232])\n",
      "tensor(95.1900)\n",
      "tensor(95.3700)\n",
      "Round 1196, reward -0.261\n",
      "tensor([0.0325, 0.1170, 0.0325, 0.2081, 0.2398, 0.2401, 0.0325, 0.0325, 0.0325,\n",
      "        0.0325])\n",
      "tensor(95.2900)\n",
      "tensor(96.5400)\n",
      "Round 1197, reward -0.398\n",
      "tensor([0.0349, 0.0366, 0.2580, 0.0349, 0.0349, 0.0349, 0.2580, 0.0349, 0.0350,\n",
      "        0.2378])\n",
      "tensor(94.7400)\n",
      "tensor(96.8300)\n",
      "Round 1198, reward -0.414\n",
      "tensor([0.1888, 0.1890, 0.0524, 0.0580, 0.0571, 0.1890, 0.0256, 0.1890, 0.0256,\n",
      "        0.0256])\n",
      "tensor(96.0200)\n",
      "tensor(96.5900)\n",
      "Round 1199, reward -0.354\n",
      "tensor([0.3108, 0.0448, 0.0453, 0.0448, 0.0448, 0.0448, 0.0449, 0.0448, 0.0448,\n",
      "        0.3303])\n",
      "tensor(95.5900)\n",
      "tensor(96.6600)\n",
      "Round 1200, reward -0.389\n",
      "tensor([0.1738, 0.1195, 0.0236, 0.0980, 0.1652, 0.1745, 0.0236, 0.0236, 0.1745,\n",
      "        0.0236])\n",
      "tensor(96.0800)\n",
      "tensor(96.6500)\n",
      "Round 1201, reward -0.352\n",
      "tensor([0.1565, 0.1552, 0.1339, 0.1565, 0.1565, 0.1565, 0.0212, 0.0212, 0.0212,\n",
      "        0.0212])\n",
      "tensor(96.0400)\n",
      "tensor(95.3900)\n",
      "Round 1202, reward -0.081\n",
      "tensor([0.0564, 0.1279, 0.0564, 0.0564, 0.0641, 0.0564, 0.0564, 0.0565, 0.0564,\n",
      "        0.4129])\n",
      "tensor(95.7900)\n",
      "tensor(96.3300)\n",
      "Round 1203, reward -0.356\n",
      "tensor([0.0339, 0.2507, 0.0339, 0.0339, 0.0339, 0.1627, 0.0467, 0.1197, 0.0339,\n",
      "        0.2507])\n",
      "tensor(93.3700)\n",
      "tensor(96.6100)\n",
      "Round 1204, reward -0.446\n",
      "tensor([0.2166, 0.0295, 0.0295, 0.1244, 0.0299, 0.0295, 0.2175, 0.0296, 0.2176,\n",
      "        0.0760])\n",
      "tensor(93.0800)\n",
      "tensor(96.4500)\n",
      "Round 1205, reward -0.453\n",
      "tensor([0.0415, 0.0415, 0.0415, 0.0684, 0.0415, 0.0415, 0.3065, 0.0415, 0.3069,\n",
      "        0.0690])\n",
      "tensor(96.3700)\n",
      "tensor(97.0400)\n",
      "Round 1206, reward -0.354\n",
      "tensor([0.0349, 0.0344, 0.0344, 0.2503, 0.0344, 0.2540, 0.0344, 0.0348, 0.0344,\n",
      "        0.2541])\n",
      "tensor(96.6900)\n",
      "tensor(96.6200)\n",
      "Round 1207, reward -0.064\n",
      "tensor([0.0310, 0.0327, 0.1255, 0.0310, 0.0313, 0.2289, 0.0310, 0.2289, 0.0310,\n",
      "        0.2289])\n",
      "tensor(94.8900)\n",
      "tensor(96.2800)\n",
      "Round 1208, reward -0.409\n",
      "tensor([0.0264, 0.1950, 0.0270, 0.1898, 0.0264, 0.1949, 0.0264, 0.0264, 0.0929,\n",
      "        0.1948])\n",
      "tensor(95.9100)\n",
      "tensor(96.3800)\n",
      "Round 1209, reward -0.342\n",
      "tensor([0.1838, 0.0278, 0.0278, 0.0770, 0.2042, 0.0278, 0.0278, 0.0552, 0.1634,\n",
      "        0.2053])\n",
      "tensor(96.1500)\n",
      "tensor(97.0800)\n",
      "Round 1210, reward -0.372\n",
      "tensor([0.0325, 0.1861, 0.0489, 0.0320, 0.1749, 0.2365, 0.0320, 0.0396, 0.1854,\n",
      "        0.0321])\n",
      "tensor(96.0800)\n",
      "tensor(96.1300)\n",
      "Round 1211, reward -0.136\n",
      "tensor([0.2097, 0.1680, 0.0541, 0.2097, 0.0284, 0.2097, 0.0284, 0.0284, 0.0352,\n",
      "        0.0284])\n",
      "tensor(94.7700)\n",
      "tensor(95.7700)\n",
      "Round 1212, reward -0.408\n",
      "tensor([0.0411, 0.0411, 0.3036, 0.0617, 0.0411, 0.0423, 0.0832, 0.0411, 0.3036,\n",
      "        0.0413])\n",
      "tensor(95.7400)\n",
      "tensor(95.9100)\n",
      "Round 1213, reward -0.241\n",
      "tensor([0.2277, 0.0485, 0.0310, 0.0310, 0.2287, 0.0310, 0.2025, 0.0311, 0.0310,\n",
      "        0.1377])\n",
      "tensor(95.2700)\n",
      "tensor(96.6400)\n",
      "Round 1214, reward -0.400\n",
      "tensor([0.0381, 0.2816, 0.0381, 0.0381, 0.0381, 0.0398, 0.0381, 0.1683, 0.2816,\n",
      "        0.0382])\n",
      "tensor(90.8200)\n",
      "tensor(96.7200)\n",
      "Round 1215, reward -0.502\n",
      "tensor([0.0249, 0.0249, 0.0249, 0.0249, 0.1840, 0.0249, 0.1397, 0.1839, 0.1840,\n",
      "        0.1840])\n",
      "tensor(95.8600)\n",
      "tensor(95.2400)\n",
      "Round 1216, reward -0.086\n",
      "tensor([0.0258, 0.0258, 0.1904, 0.1904, 0.0258, 0.1099, 0.0258, 0.1900, 0.1904,\n",
      "        0.0258])\n",
      "tensor(96.2100)\n",
      "tensor(96.7000)\n",
      "Round 1217, reward -0.338\n",
      "tensor([0.0290, 0.0283, 0.0283, 0.0283, 0.2090, 0.2053, 0.0283, 0.0283, 0.2063,\n",
      "        0.2090])\n",
      "tensor(95.4400)\n",
      "tensor(96.6200)\n",
      "Round 1218, reward -0.394\n",
      "tensor([0.0349, 0.2410, 0.0349, 0.0349, 0.0349, 0.0349, 0.2576, 0.2573, 0.0349,\n",
      "        0.0349])\n",
      "tensor(95.8400)\n",
      "tensor(96.8600)\n",
      "Round 1219, reward -0.382\n",
      "tensor([0.0402, 0.2704, 0.0369, 0.0368, 0.0368, 0.2691, 0.0368, 0.1947, 0.0413,\n",
      "        0.0368])\n",
      "tensor(95.1200)\n",
      "tensor(95.9100)\n",
      "Round 1220, reward -0.393\n",
      "tensor([0.2095, 0.0284, 0.2014, 0.2095, 0.0284, 0.0284, 0.0284, 0.0284, 0.2095,\n",
      "        0.0284])\n",
      "tensor(95.1300)\n",
      "tensor(96.6600)\n",
      "Round 1221, reward -0.404\n",
      "tensor([0.1960, 0.0266, 0.1962, 0.0267, 0.0266, 0.0266, 0.1909, 0.0370, 0.1961,\n",
      "        0.0775])\n",
      "tensor(95.7000)\n",
      "tensor(95.5900)\n",
      "Round 1222, reward -0.090\n",
      "tensor([0.2531, 0.0342, 0.2531, 0.0342, 0.0342, 0.2531, 0.0350, 0.0344, 0.0344,\n",
      "        0.0342])\n",
      "tensor(94.7300)\n",
      "tensor(97.1700)\n",
      "Round 1223, reward -0.414\n",
      "tensor([0.2531, 0.0343, 0.0343, 0.0343, 0.0343, 0.2531, 0.2531, 0.0351, 0.0344,\n",
      "        0.0343])\n",
      "tensor(92.7700)\n",
      "tensor(95.0300)\n",
      "Round 1224, reward -0.460\n",
      "tensor([0.1326, 0.1330, 0.1331, 0.1328, 0.1331, 0.1331, 0.1331, 0.0180, 0.0331,\n",
      "        0.0180])\n",
      "tensor(95.2800)\n",
      "tensor(96.1000)\n",
      "Round 1225, reward -0.390\n",
      "tensor([0.3231, 0.0448, 0.0448, 0.0448, 0.0459, 0.0448, 0.0448, 0.0449, 0.0448,\n",
      "        0.3176])\n",
      "tensor(93.4800)\n",
      "tensor(96.6600)\n",
      "Round 1226, reward -0.444\n",
      "tensor([0.0439, 0.0439, 0.0439, 0.3244, 0.0439, 0.0440, 0.0439, 0.0439, 0.0439,\n",
      "        0.3244])\n",
      "tensor(95.6600)\n",
      "tensor(96.5200)\n",
      "Round 1227, reward -0.382\n",
      "tensor([0.0266, 0.1949, 0.1963, 0.0266, 0.0268, 0.1888, 0.0360, 0.0267, 0.0812,\n",
      "        0.1962])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.1700)\n",
      "tensor(97.3100)\n",
      "Round 1228, reward -0.184\n",
      "tensor([0.1540, 0.1545, 0.0209, 0.0209, 0.1443, 0.1545, 0.0209, 0.1544, 0.1545,\n",
      "        0.0209])\n",
      "tensor(92.5600)\n",
      "tensor(94.1600)\n",
      "Round 1229, reward -0.464\n",
      "tensor([0.2037, 0.1074, 0.1998, 0.0304, 0.0279, 0.0300, 0.1498, 0.0279, 0.0279,\n",
      "        0.1953])\n",
      "tensor(91.3200)\n",
      "tensor(91.2100)\n",
      "Round 1230, reward -0.191\n",
      "tensor([0.0556, 0.0505, 0.1551, 0.1551, 0.0772, 0.0210, 0.1551, 0.0210, 0.1545,\n",
      "        0.1550])\n",
      "tensor(96.9200)\n",
      "tensor(97.1000)\n",
      "Round 1231, reward -0.216\n",
      "tensor([0.1440, 0.0280, 0.1822, 0.0247, 0.1824, 0.1824, 0.0247, 0.0247, 0.0247,\n",
      "        0.1824])\n",
      "tensor(96.8700)\n",
      "tensor(97.0100)\n",
      "Round 1232, reward -0.192\n",
      "tensor([0.0221, 0.0221, 0.0221, 0.1623, 0.0221, 0.1629, 0.1629, 0.1586, 0.1629,\n",
      "        0.1020])\n",
      "tensor(96.9500)\n",
      "tensor(96.9300)\n",
      "Round 1233, reward -0.057\n",
      "tensor([0.0342, 0.2530, 0.0342, 0.0342, 0.0344, 0.0354, 0.0342, 0.2530, 0.2530,\n",
      "        0.0342])\n",
      "tensor(95.3300)\n",
      "tensor(97.1500)\n",
      "Round 1234, reward -0.399\n",
      "tensor([0.1388, 0.1388, 0.0937, 0.0385, 0.1387, 0.0188, 0.0188, 0.1388, 0.1378,\n",
      "        0.1372])\n",
      "tensor(96.4700)\n",
      "tensor(97.2800)\n",
      "Round 1235, reward -0.360\n",
      "tensor([0.1651, 0.1649, 0.1654, 0.0733, 0.1656, 0.0224, 0.1606, 0.0234, 0.0311,\n",
      "        0.0283])\n",
      "tensor(96.7000)\n",
      "tensor(97.0900)\n",
      "Round 1236, reward -0.305\n",
      "tensor([0.0356, 0.0356, 0.2629, 0.0398, 0.2627, 0.0461, 0.2104, 0.0356, 0.0356,\n",
      "        0.0357])\n",
      "tensor(92.4500)\n",
      "tensor(96.8700)\n",
      "Round 1237, reward -0.467\n",
      "tensor([0.1369, 0.1370, 0.1300, 0.1318, 0.0185, 0.0185, 0.1348, 0.1370, 0.0185,\n",
      "        0.1370])\n",
      "tensor(91.8000)\n",
      "tensor(95.4900)\n",
      "Round 1238, reward -0.481\n",
      "tensor([0.1424, 0.0892, 0.0193, 0.1424, 0.1424, 0.0193, 0.1424, 0.0193, 0.1424,\n",
      "        0.1410])\n",
      "tensor(96.5500)\n",
      "tensor(96.8300)\n",
      "Round 1239, reward -0.274\n",
      "tensor([0.0245, 0.0244, 0.1806, 0.1806, 0.1023, 0.0321, 0.0281, 0.1806, 0.0784,\n",
      "        0.1683])\n",
      "tensor(96.8700)\n",
      "tensor(97.1900)\n",
      "Round 1240, reward -0.280\n",
      "tensor([0.0327, 0.0326, 0.0326, 0.0326, 0.2412, 0.0807, 0.2411, 0.0326, 0.0326,\n",
      "        0.2412])\n",
      "tensor(92.7000)\n",
      "tensor(96.6700)\n",
      "Round 1241, reward -0.461\n",
      "tensor([0.0498, 0.0322, 0.2382, 0.0322, 0.0322, 0.2325, 0.0322, 0.0322, 0.0800,\n",
      "        0.2382])\n",
      "tensor(96.5400)\n",
      "tensor(96.8100)\n",
      "Round 1242, reward -0.270\n",
      "tensor([0.0279, 0.2060, 0.0279, 0.0280, 0.2052, 0.0433, 0.0279, 0.2000, 0.2059,\n",
      "        0.0279])\n",
      "tensor(92.0600)\n",
      "tensor(95.9900)\n",
      "Round 1243, reward -0.475\n",
      "tensor([0.0462, 0.0462, 0.0462, 0.0462, 0.2889, 0.0462, 0.0462, 0.3365, 0.0463,\n",
      "        0.0510])\n",
      "tensor(93.6200)\n",
      "tensor(96.5100)\n",
      "Round 1244, reward -0.440\n",
      "tensor([0.2331, 0.0316, 0.0315, 0.0315, 0.0315, 0.2331, 0.0315, 0.1113, 0.0317,\n",
      "        0.2331])\n",
      "tensor(97.1200)\n",
      "tensor(97.3700)\n",
      "Round 1245, reward -0.247\n",
      "tensor([0.0288, 0.2120, 0.2117, 0.0287, 0.2038, 0.0287, 0.0287, 0.2003, 0.0287,\n",
      "        0.0287])\n",
      "tensor(96.6800)\n",
      "tensor(97.0100)\n",
      "Round 1246, reward -0.288\n",
      "tensor([0.0598, 0.0672, 0.0598, 0.0737, 0.0598, 0.0598, 0.4390, 0.0598, 0.0613,\n",
      "        0.0598])\n",
      "tensor(96.8000)\n",
      "tensor(95.2800)\n",
      "Round 1247, reward -0.061\n",
      "tensor([0.0395, 0.2088, 0.0395, 0.0489, 0.2921, 0.0395, 0.0395, 0.0395, 0.0395,\n",
      "        0.2130])\n",
      "tensor(96.8900)\n",
      "tensor(97.4300)\n",
      "Round 1248, reward -0.327\n",
      "tensor([0.0593, 0.4347, 0.0593, 0.0593, 0.0593, 0.0604, 0.0593, 0.0676, 0.0593,\n",
      "        0.0815])\n",
      "tensor(85.2800)\n",
      "tensor(96.0600)\n",
      "Round 1249, reward -0.604\n",
      "tensor([0.1510, 0.1513, 0.0205, 0.1513, 0.0205, 0.0316, 0.0205, 0.1510, 0.1513,\n",
      "        0.1513])\n",
      "tensor(93.4800)\n",
      "tensor(95.3100)\n",
      "Round 1250, reward -0.443\n",
      "tensor([0.0234, 0.1729, 0.1729, 0.0234, 0.0234, 0.0234, 0.0441, 0.1728, 0.1707,\n",
      "        0.1729])\n",
      "tensor(96.8100)\n",
      "tensor(96.4400)\n",
      "Round 1251, reward -0.061\n",
      "tensor([0.2757, 0.2757, 0.0379, 0.0373, 0.1867, 0.0373, 0.0373, 0.0373, 0.0373,\n",
      "        0.0374])\n",
      "tensor(96.2600)\n",
      "tensor(97.1400)\n",
      "Round 1252, reward -0.368\n",
      "tensor([0.1766, 0.1762, 0.0239, 0.0257, 0.0262, 0.1763, 0.0239, 0.1767, 0.0326,\n",
      "        0.1619])\n",
      "tensor(96.7500)\n",
      "tensor(96.6700)\n",
      "Round 1253, reward -0.063\n",
      "tensor([0.0665, 0.0328, 0.2420, 0.1764, 0.0328, 0.0374, 0.0328, 0.0328, 0.1044,\n",
      "        0.2422])\n",
      "tensor(94.5800)\n",
      "tensor(96.4500)\n",
      "Round 1254, reward -0.417\n",
      "tensor([0.0343, 0.0339, 0.0339, 0.0510, 0.2501, 0.2451, 0.0339, 0.2501, 0.0339,\n",
      "        0.0339])\n",
      "tensor(95.5600)\n",
      "tensor(96.9400)\n",
      "Round 1255, reward -0.392\n",
      "tensor([0.0326, 0.0326, 0.2406, 0.2406, 0.0760, 0.0326, 0.0326, 0.0346, 0.2406,\n",
      "        0.0374])\n",
      "tensor(90.7100)\n",
      "tensor(94.6000)\n",
      "Round 1256, reward -0.504\n",
      "tensor([0.0286, 0.0286, 0.0286, 0.2111, 0.0290, 0.0286, 0.2017, 0.2111, 0.2043,\n",
      "        0.0286])\n",
      "tensor(95.6300)\n",
      "tensor(96.6800)\n",
      "Round 1257, reward -0.388\n",
      "tensor([0.0431, 0.0344, 0.2428, 0.0344, 0.2530, 0.2544, 0.0345, 0.0344, 0.0344,\n",
      "        0.0344])\n",
      "tensor(94.7400)\n",
      "tensor(95.6900)\n",
      "Round 1258, reward -0.408\n",
      "tensor([0.2044, 0.0287, 0.0287, 0.0287, 0.2118, 0.0288, 0.0287, 0.1996, 0.0289,\n",
      "        0.2118])\n",
      "tensor(96.1000)\n",
      "tensor(96.3200)\n",
      "Round 1259, reward -0.259\n",
      "tensor([0.1293, 0.1788, 0.1837, 0.0292, 0.0258, 0.0274, 0.0316, 0.0250, 0.1846,\n",
      "        0.1846])\n",
      "tensor(91.5300)\n",
      "tensor(96.6600)\n",
      "Round 1260, reward -0.487\n",
      "tensor([0.0631, 0.1008, 0.0631, 0.0631, 0.0631, 0.3412, 0.0631, 0.0631, 0.1152,\n",
      "        0.0644])\n",
      "tensor(95.9800)\n",
      "tensor(95.6000)\n",
      "Round 1261, reward -0.083\n",
      "tensor([0.4151, 0.0562, 0.0562, 0.0562, 0.1336, 0.0571, 0.0562, 0.0562, 0.0562,\n",
      "        0.0572])\n",
      "tensor(95.9100)\n",
      "tensor(96.1700)\n",
      "Round 1262, reward -0.283\n",
      "tensor([0.0357, 0.2516, 0.0341, 0.0344, 0.0357, 0.2516, 0.0341, 0.0341, 0.2516,\n",
      "        0.0371])\n",
      "tensor(95.5700)\n",
      "tensor(97.3400)\n",
      "Round 1263, reward -0.393\n",
      "tensor([0.0275, 0.1193, 0.1341, 0.0275, 0.2018, 0.0279, 0.0275, 0.2034, 0.2034,\n",
      "        0.0275])\n",
      "tensor(92.2700)\n",
      "tensor(93.5900)\n",
      "Round 1264, reward -0.470\n",
      "tensor([0.0410, 0.0389, 0.0389, 0.2873, 0.0389, 0.0410, 0.0389, 0.2873, 0.1490,\n",
      "        0.0389])\n",
      "tensor(93.4800)\n",
      "tensor(95.9900)\n",
      "Round 1265, reward -0.444\n",
      "tensor([0.0242, 0.1784, 0.0242, 0.1689, 0.0242, 0.0242, 0.1785, 0.1745, 0.1779,\n",
      "        0.0252])\n",
      "tensor(94.0900)\n",
      "tensor(96.8900)\n",
      "Round 1266, reward -0.429\n",
      "tensor([0.0342, 0.2382, 0.0367, 0.0329, 0.2433, 0.2434, 0.0329, 0.0724, 0.0329,\n",
      "        0.0329])\n",
      "tensor(96.5300)\n",
      "tensor(96.6200)\n",
      "Round 1267, reward -0.162\n",
      "tensor([0.0637, 0.0596, 0.0591, 0.0813, 0.0591, 0.0591, 0.4359, 0.0640, 0.0591,\n",
      "        0.0591])\n",
      "tensor(96.1600)\n",
      "tensor(97.2900)\n",
      "Round 1268, reward -0.375\n",
      "tensor([0.0208, 0.0208, 0.1535, 0.0208, 0.1535, 0.1535, 0.1535, 0.1491, 0.1535,\n",
      "        0.0208])\n",
      "tensor(96.8400)\n",
      "tensor(97.0600)\n",
      "Round 1269, reward -0.240\n",
      "tensor([0.2220, 0.1579, 0.0300, 0.0300, 0.0300, 0.0300, 0.0300, 0.2179, 0.2220,\n",
      "        0.0300])\n",
      "tensor(96.2300)\n",
      "tensor(95.9100)\n",
      "Round 1270, reward -0.076\n",
      "tensor([0.0446, 0.3295, 0.0446, 0.0446, 0.0446, 0.0587, 0.0446, 0.0446, 0.0446,\n",
      "        0.2996])\n",
      "tensor(96.2200)\n",
      "tensor(96.7800)\n",
      "Round 1271, reward -0.347\n",
      "tensor([0.1398, 0.0581, 0.0584, 0.0581, 0.0596, 0.0581, 0.0581, 0.3931, 0.0581,\n",
      "        0.0585])\n",
      "tensor(95.0200)\n",
      "tensor(96.8300)\n",
      "Round 1272, reward -0.407\n",
      "tensor([0.1552, 0.1472, 0.0213, 0.0210, 0.0219, 0.0210, 0.1529, 0.1551, 0.1514,\n",
      "        0.1530])\n",
      "tensor(95.7700)\n",
      "tensor(95.8700)\n",
      "Round 1273, reward -0.190\n",
      "tensor([0.0754, 0.3082, 0.0425, 0.0417, 0.0502, 0.0417, 0.0417, 0.0485, 0.3082,\n",
      "        0.0417])\n",
      "tensor(95.0400)\n",
      "tensor(96.4100)\n",
      "Round 1274, reward -0.405\n",
      "tensor([0.1759, 0.0239, 0.1764, 0.0239, 0.1538, 0.1764, 0.0456, 0.1764, 0.0239,\n",
      "        0.0239])\n",
      "tensor(96.8000)\n",
      "tensor(97.2300)\n",
      "Round 1275, reward -0.311\n",
      "tensor([0.2227, 0.1510, 0.0302, 0.0301, 0.2227, 0.2227, 0.0301, 0.0302, 0.0301,\n",
      "        0.0301])\n",
      "tensor(96.6400)\n",
      "tensor(97.3600)\n",
      "Round 1276, reward -0.350\n",
      "tensor([0.0341, 0.0404, 0.0341, 0.2513, 0.0341, 0.0342, 0.0341, 0.0351, 0.2515,\n",
      "        0.2509])\n",
      "tensor(96.4300)\n",
      "tensor(97.3000)\n",
      "Round 1277, reward -0.363\n",
      "tensor([0.0456, 0.3368, 0.0456, 0.2922, 0.0456, 0.0520, 0.0456, 0.0456, 0.0456,\n",
      "        0.0456])\n",
      "tensor(96.7100)\n",
      "tensor(96.8200)\n",
      "Round 1278, reward -0.174\n",
      "tensor([0.0658, 0.0658, 0.0658, 0.0658, 0.0658, 0.0660, 0.0658, 0.4019, 0.0705,\n",
      "        0.0668])\n",
      "tensor(94.8400)\n",
      "tensor(97.0600)\n",
      "Round 1279, reward -0.411\n",
      "tensor([0.2253, 0.0347, 0.0347, 0.0347, 0.2565, 0.0347, 0.0348, 0.0347, 0.0530,\n",
      "        0.2567])\n",
      "tensor(96.0500)\n",
      "tensor(96.7200)\n",
      "Round 1280, reward -0.362\n",
      "tensor([0.0387, 0.0387, 0.0387, 0.0387, 0.2857, 0.0389, 0.0387, 0.2857, 0.0387,\n",
      "        0.1578])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91.9600)\n",
      "tensor(95.6600)\n",
      "Round 1281, reward -0.478\n",
      "tensor([0.0556, 0.0237, 0.1750, 0.1750, 0.0648, 0.1295, 0.0239, 0.1539, 0.0237,\n",
      "        0.1750])\n",
      "tensor(95.2800)\n",
      "tensor(94.3300)\n",
      "Round 1282, reward -0.100\n",
      "tensor([0.0287, 0.0287, 0.0287, 0.0287, 0.2112, 0.2119, 0.0287, 0.0287, 0.2119,\n",
      "        0.1930])\n",
      "tensor(93.1000)\n",
      "tensor(96.4400)\n",
      "Round 1283, reward -0.452\n",
      "tensor([0.1747, 0.0404, 0.0236, 0.1747, 0.1747, 0.1733, 0.0236, 0.0238, 0.1674,\n",
      "        0.0236])\n",
      "tensor(95.9000)\n",
      "tensor(96.8400)\n",
      "Round 1284, reward -0.379\n",
      "tensor([0.2433, 0.0333, 0.0333, 0.0333, 0.0333, 0.0622, 0.2462, 0.2462, 0.0356,\n",
      "        0.0333])\n",
      "tensor(96.0400)\n",
      "tensor(97.1500)\n",
      "Round 1285, reward -0.378\n",
      "tensor([0.0632, 0.4260, 0.0634, 0.0632, 0.0632, 0.0683, 0.0632, 0.0632, 0.0632,\n",
      "        0.0632])\n",
      "tensor(95.7500)\n",
      "tensor(96.5700)\n",
      "Round 1286, reward -0.379\n",
      "tensor([0.0363, 0.1583, 0.0372, 0.2681, 0.0363, 0.2681, 0.0363, 0.0363, 0.0839,\n",
      "        0.0394])\n",
      "tensor(96.8000)\n",
      "tensor(97.1300)\n",
      "Round 1287, reward -0.285\n",
      "tensor([0.0393, 0.0409, 0.2899, 0.2838, 0.0397, 0.0403, 0.0393, 0.1483, 0.0393,\n",
      "        0.0393])\n",
      "tensor(94.3200)\n",
      "tensor(96.9300)\n",
      "Round 1288, reward -0.424\n",
      "tensor([0.1757, 0.0409, 0.0238, 0.1604, 0.0240, 0.0238, 0.1759, 0.0238, 0.1759,\n",
      "        0.1759])\n",
      "tensor(96.3000)\n",
      "tensor(96.0600)\n",
      "Round 1289, reward -0.074\n",
      "tensor([0.1559, 0.0212, 0.0212, 0.1411, 0.1491, 0.0212, 0.1565, 0.1560, 0.0212,\n",
      "        0.1565])\n",
      "tensor(96.9600)\n",
      "tensor(97.4000)\n",
      "Round 1290, reward -0.309\n",
      "tensor([0.2408, 0.0326, 0.2409, 0.0802, 0.0368, 0.2384, 0.0326, 0.0326, 0.0326,\n",
      "        0.0326])\n",
      "tensor(96.5700)\n",
      "tensor(97.2100)\n",
      "Round 1291, reward -0.346\n",
      "tensor([0.1515, 0.0205, 0.0205, 0.1515, 0.1515, 0.1415, 0.1515, 0.0398, 0.0205,\n",
      "        0.1513])\n",
      "tensor(95.7100)\n",
      "tensor(95.4400)\n",
      "Round 1292, reward -0.090\n",
      "tensor([0.2510, 0.0340, 0.0386, 0.0340, 0.0340, 0.0340, 0.2510, 0.2510, 0.0385,\n",
      "        0.0340])\n",
      "tensor(96.7500)\n",
      "tensor(95.5500)\n",
      "Round 1293, reward -0.063\n",
      "tensor([0.1696, 0.1771, 0.0240, 0.0240, 0.1771, 0.1771, 0.0240, 0.0259, 0.1771,\n",
      "        0.0240])\n",
      "tensor(97.2000)\n",
      "tensor(97.1400)\n",
      "Round 1294, reward -0.050\n",
      "tensor([0.0313, 0.0798, 0.1936, 0.0267, 0.0271, 0.1857, 0.1958, 0.0376, 0.0265,\n",
      "        0.1958])\n",
      "tensor(93.8800)\n",
      "tensor(94.0900)\n",
      "Round 1295, reward -0.309\n",
      "tensor([0.2111, 0.2111, 0.0286, 0.0286, 0.1949, 0.0287, 0.0286, 0.0286, 0.0286,\n",
      "        0.2111])\n",
      "tensor(90.7100)\n",
      "tensor(95.8900)\n",
      "Round 1296, reward -0.504\n",
      "tensor([0.2911, 0.0490, 0.3168, 0.0490, 0.0491, 0.0490, 0.0490, 0.0490, 0.0490,\n",
      "        0.0490])\n",
      "tensor(95.4800)\n",
      "tensor(96.8300)\n",
      "Round 1297, reward -0.394\n",
      "tensor([0.0369, 0.0369, 0.0369, 0.0369, 0.0369, 0.2690, 0.0427, 0.2674, 0.0369,\n",
      "        0.1994])\n",
      "tensor(96.2600)\n",
      "tensor(96.4900)\n",
      "Round 1298, reward -0.260\n",
      "tensor([0.0431, 0.0431, 0.3187, 0.0431, 0.0431, 0.0607, 0.0432, 0.3187, 0.0431,\n",
      "        0.0431])\n",
      "tensor(96.2800)\n",
      "tensor(97.1200)\n",
      "Round 1299, reward -0.366\n",
      "tensor([0.3329, 0.0451, 0.0550, 0.0451, 0.0451, 0.2959, 0.0459, 0.0451, 0.0451,\n",
      "        0.0451])\n",
      "tensor(96.9100)\n",
      "tensor(96.7500)\n",
      "Round 1300, reward -0.058\n",
      "tensor([0.0557, 0.0352, 0.2285, 0.0344, 0.0344, 0.2542, 0.2543, 0.0344, 0.0344,\n",
      "        0.0344])\n",
      "tensor(96.5100)\n",
      "tensor(96.3600)\n",
      "Round 1301, reward -0.069\n",
      "tensor([0.1884, 0.2337, 0.0741, 0.2337, 0.0316, 0.0316, 0.0316, 0.1113, 0.0316,\n",
      "        0.0323])\n",
      "tensor(96.)\n",
      "tensor(97.1700)\n",
      "Round 1302, reward -0.380\n",
      "tensor([0.0302, 0.1511, 0.0309, 0.0302, 0.2207, 0.2231, 0.2231, 0.0302, 0.0302,\n",
      "        0.0302])\n",
      "tensor(94.9600)\n",
      "tensor(97.2200)\n",
      "Round 1303, reward -0.408\n",
      "tensor([0.0412, 0.3043, 0.0779, 0.0600, 0.0420, 0.0412, 0.0414, 0.0465, 0.3043,\n",
      "        0.0412])\n",
      "tensor(96.8700)\n",
      "tensor(97.3000)\n",
      "Round 1304, reward -0.309\n",
      "tensor([0.0281, 0.2076, 0.0281, 0.0294, 0.0281, 0.2075, 0.0281, 0.0281, 0.2076,\n",
      "        0.2076])\n",
      "tensor(96.0800)\n",
      "tensor(96.6000)\n",
      "Round 1305, reward -0.346\n",
      "tensor([0.0373, 0.0441, 0.2748, 0.1822, 0.0372, 0.0372, 0.2736, 0.0374, 0.0372,\n",
      "        0.0390])\n",
      "tensor(94.6400)\n",
      "tensor(94.5300)\n",
      "Round 1306, reward -0.116\n",
      "tensor([0.0343, 0.0346, 0.0343, 0.2487, 0.0352, 0.0343, 0.0377, 0.2534, 0.2533,\n",
      "        0.0343])\n",
      "tensor(83.7200)\n",
      "tensor(91.9100)\n",
      "Round 1307, reward -0.629\n",
      "tensor([0.2538, 0.0352, 0.0344, 0.0344, 0.0344, 0.0344, 0.2497, 0.0344, 0.0359,\n",
      "        0.2534])\n",
      "tensor(95.1700)\n",
      "tensor(95.6800)\n",
      "Round 1308, reward -0.367\n",
      "tensor([0.0208, 0.1534, 0.1533, 0.0305, 0.1534, 0.0208, 0.1405, 0.0208, 0.1534,\n",
      "        0.1534])\n",
      "tensor(90.8900)\n",
      "tensor(91.3800)\n",
      "Round 1309, reward -0.461\n",
      "tensor([0.0478, 0.0478, 0.0501, 0.0478, 0.2597, 0.0496, 0.0486, 0.0478, 0.0478,\n",
      "        0.3531])\n",
      "tensor(96.3100)\n",
      "tensor(91.4600)\n",
      "Round 1310, reward -0.074\n",
      "tensor([0.1754, 0.0237, 0.0237, 0.1754, 0.0237, 0.0410, 0.0237, 0.1754, 0.1625,\n",
      "        0.1754])\n",
      "tensor(89.3800)\n",
      "tensor(90.8000)\n",
      "Round 1311, reward -0.530\n",
      "tensor([0.0437, 0.0437, 0.3231, 0.0437, 0.3226, 0.0437, 0.0437, 0.0448, 0.0437,\n",
      "        0.0472])\n",
      "tensor(86.5800)\n",
      "tensor(95.1500)\n",
      "Round 1312, reward -0.582\n",
      "tensor([0.0333, 0.2447, 0.0333, 0.0351, 0.0617, 0.0333, 0.2460, 0.2460, 0.0333,\n",
      "        0.0334])\n",
      "tensor(97.1300)\n",
      "tensor(96.9800)\n",
      "Round 1313, reward -0.052\n",
      "tensor([0.1876, 0.0365, 0.0365, 0.2700, 0.0832, 0.0365, 0.2395, 0.0369, 0.0366,\n",
      "        0.0365])\n",
      "tensor(96.7100)\n",
      "tensor(97.0100)\n",
      "Round 1314, reward -0.277\n",
      "tensor([0.0437, 0.0437, 0.3229, 0.0441, 0.0437, 0.0477, 0.3226, 0.0437, 0.0442,\n",
      "        0.0437])\n",
      "tensor(94.9300)\n",
      "tensor(96.8700)\n",
      "Round 1315, reward -0.409\n",
      "tensor([0.0534, 0.0545, 0.0534, 0.0534, 0.0549, 0.0535, 0.0928, 0.1357, 0.0536,\n",
      "        0.3947])\n",
      "tensor(95.0400)\n",
      "tensor(96.8800)\n",
      "Round 1316, reward -0.406\n",
      "tensor([0.0290, 0.0290, 0.0293, 0.1906, 0.0304, 0.0290, 0.2140, 0.0290, 0.2058,\n",
      "        0.2140])\n",
      "tensor(97.2000)\n",
      "tensor(97.5000)\n",
      "Round 1317, reward -0.264\n",
      "tensor([0.2481, 0.0343, 0.2528, 0.0345, 0.0342, 0.0342, 0.2528, 0.0342, 0.0344,\n",
      "        0.0404])\n",
      "tensor(96.9100)\n",
      "tensor(96.4800)\n",
      "Round 1318, reward -0.058\n",
      "tensor([0.0260, 0.1919, 0.0260, 0.1919, 0.1854, 0.0260, 0.0260, 0.1917, 0.0260,\n",
      "        0.1092])\n",
      "tensor(96.5800)\n",
      "tensor(96.9700)\n",
      "Round 1319, reward -0.308\n",
      "tensor([0.2209, 0.0300, 0.2210, 0.2209, 0.0299, 0.0299, 0.0299, 0.0300, 0.1576,\n",
      "        0.0299])\n",
      "tensor(97.2200)\n",
      "tensor(97.5500)\n",
      "Round 1320, reward -0.274\n",
      "tensor([0.0366, 0.0300, 0.0445, 0.0645, 0.0299, 0.1430, 0.2210, 0.2207, 0.0329,\n",
      "        0.1767])\n",
      "tensor(96.9000)\n",
      "tensor(97.4300)\n",
      "Round 1321, reward -0.325\n",
      "tensor([0.1584, 0.0343, 0.2319, 0.0314, 0.2304, 0.0316, 0.0314, 0.0314, 0.1876,\n",
      "        0.0314])\n",
      "tensor(95.5400)\n",
      "tensor(96.9100)\n",
      "Round 1322, reward -0.393\n",
      "tensor([0.1421, 0.0631, 0.0192, 0.1421, 0.0204, 0.1420, 0.1418, 0.1421, 0.1411,\n",
      "        0.0461])\n",
      "tensor(96.3100)\n",
      "tensor(96.4900)\n",
      "Round 1323, reward -0.232\n",
      "tensor([0.2081, 0.0303, 0.2123, 0.0287, 0.0287, 0.0294, 0.1915, 0.0298, 0.0287,\n",
      "        0.2124])\n",
      "tensor(95.8200)\n",
      "tensor(96.1800)\n",
      "Round 1324, reward -0.320\n",
      "tensor([0.0513, 0.0749, 0.1817, 0.0513, 0.0557, 0.0514, 0.3786, 0.0513, 0.0513,\n",
      "        0.0526])\n",
      "tensor(95.6200)\n",
      "tensor(95.9900)\n",
      "Round 1325, reward -0.327\n",
      "tensor([0.0384, 0.0396, 0.2577, 0.0349, 0.0349, 0.0349, 0.2578, 0.0349, 0.2321,\n",
      "        0.0349])\n",
      "tensor(96.2600)\n",
      "tensor(96.5000)\n",
      "Round 1326, reward -0.265\n",
      "tensor([0.1474, 0.1106, 0.0205, 0.1474, 0.1026, 0.1369, 0.0199, 0.1474, 0.1474,\n",
      "        0.0199])\n",
      "tensor(96.5600)\n",
      "tensor(96.6700)\n",
      "Round 1327, reward -0.178\n",
      "tensor([0.2906, 0.0439, 0.0441, 0.0774, 0.0439, 0.0446, 0.3241, 0.0439, 0.0439,\n",
      "        0.0439])\n",
      "tensor(97.5800)\n",
      "tensor(97.3100)\n",
      "Round 1328, reward -0.040\n",
      "tensor([0.0431, 0.0431, 0.2987, 0.0430, 0.0609, 0.0430, 0.0430, 0.0430, 0.0650,\n",
      "        0.3172])\n",
      "tensor(96.6200)\n",
      "tensor(97.2300)\n",
      "Round 1329, reward -0.342\n",
      "tensor([0.0336, 0.0335, 0.2476, 0.0570, 0.2465, 0.0335, 0.2476, 0.0335, 0.0336,\n",
      "        0.0335])\n",
      "tensor(94.0900)\n",
      "tensor(95.5700)\n",
      "Round 1330, reward -0.429\n",
      "tensor([0.3057, 0.0414, 0.3057, 0.0951, 0.0417, 0.0414, 0.0414, 0.0414, 0.0414,\n",
      "        0.0448])\n",
      "tensor(96.2500)\n",
      "tensor(96.9900)\n",
      "Round 1331, reward -0.362\n",
      "tensor([0.0325, 0.2394, 0.2401, 0.0368, 0.0325, 0.0329, 0.2339, 0.0866, 0.0327,\n",
      "        0.0325])\n",
      "tensor(93.2100)\n",
      "tensor(94.2200)\n",
      "Round 1332, reward -0.445\n",
      "tensor([0.1780, 0.0241, 0.1779, 0.0381, 0.0247, 0.1565, 0.0241, 0.0241, 0.1745,\n",
      "        0.1779])\n",
      "tensor(94.1300)\n",
      "tensor(95.9500)\n",
      "Round 1333, reward -0.428\n",
      "tensor([0.0525, 0.0437, 0.0435, 0.0435, 0.3218, 0.0890, 0.2753, 0.0436, 0.0435,\n",
      "        0.0435])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(96.7100)\n",
      "tensor(97.6700)\n",
      "Round 1334, reward -0.358\n",
      "tensor([0.1770, 0.1773, 0.0240, 0.0240, 0.1708, 0.0240, 0.0243, 0.0240, 0.1773,\n",
      "        0.1773])\n",
      "tensor(97.4100)\n",
      "tensor(97.2200)\n",
      "Round 1335, reward -0.045\n",
      "tensor([0.0584, 0.0669, 0.0584, 0.0584, 0.0845, 0.0584, 0.0584, 0.4274, 0.0606,\n",
      "        0.0686])\n",
      "tensor(95.9800)\n",
      "tensor(97.6600)\n",
      "Round 1336, reward -0.382\n",
      "tensor([0.1492, 0.2055, 0.0283, 0.0282, 0.0282, 0.1616, 0.1131, 0.0606, 0.0282,\n",
      "        0.1971])\n",
      "tensor(97.1600)\n",
      "tensor(96.8800)\n",
      "Round 1337, reward -0.052\n",
      "tensor([0.1336, 0.0383, 0.2828, 0.2704, 0.0772, 0.0383, 0.0383, 0.0383, 0.0428,\n",
      "        0.0401])\n",
      "tensor(95.1500)\n",
      "tensor(96.2100)\n",
      "Round 1338, reward -0.400\n",
      "tensor([0.1615, 0.0219, 0.1615, 0.1549, 0.1615, 0.0219, 0.1387, 0.1289, 0.0219,\n",
      "        0.0274])\n",
      "tensor(97.3000)\n",
      "tensor(97.5200)\n",
      "Round 1339, reward -0.228\n",
      "tensor([0.0502, 0.0475, 0.0461, 0.0462, 0.2773, 0.3380, 0.0461, 0.0477, 0.0525,\n",
      "        0.0484])\n",
      "tensor(96.5300)\n",
      "tensor(95.9600)\n",
      "Round 1340, reward -0.068\n",
      "tensor([0.1875, 0.0254, 0.1804, 0.1871, 0.1322, 0.1860, 0.0254, 0.0254, 0.0254,\n",
      "        0.0254])\n",
      "tensor(95.4500)\n",
      "tensor(95.8800)\n",
      "Round 1341, reward -0.346\n",
      "tensor([0.0412, 0.3011, 0.0413, 0.0523, 0.0412, 0.0412, 0.0955, 0.3039, 0.0412,\n",
      "        0.0412])\n",
      "tensor(94.8800)\n",
      "tensor(95.8500)\n",
      "Round 1342, reward -0.405\n",
      "tensor([0.0343, 0.2533, 0.2533, 0.2531, 0.0343, 0.0343, 0.0343, 0.0344, 0.0343,\n",
      "        0.0343])\n",
      "tensor(90.2300)\n",
      "tensor(96.0300)\n",
      "Round 1343, reward -0.514\n",
      "tensor([0.1311, 0.1311, 0.0177, 0.1292, 0.0490, 0.0177, 0.1311, 0.1311, 0.1311,\n",
      "        0.1307])\n",
      "tensor(96.9700)\n",
      "tensor(96.5800)\n",
      "Round 1344, reward -0.057\n",
      "tensor([0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.2533, 0.2533, 0.2533, 0.0343,\n",
      "        0.0343])\n",
      "tensor(96.9400)\n",
      "tensor(97.5800)\n",
      "Round 1345, reward -0.337\n",
      "tensor([0.2214, 0.0300, 0.2196, 0.2175, 0.0300, 0.1295, 0.0619, 0.0300, 0.0300,\n",
      "        0.0300])\n",
      "tensor(95.8400)\n",
      "tensor(97.0100)\n",
      "Round 1346, reward -0.384\n",
      "tensor([0.0288, 0.2132, 0.2132, 0.0345, 0.2132, 0.0288, 0.0288, 0.0288, 0.0289,\n",
      "        0.1817])\n",
      "tensor(96.6400)\n",
      "tensor(97.3700)\n",
      "Round 1347, reward -0.351\n",
      "tensor([0.1447, 0.0293, 0.2169, 0.0293, 0.2166, 0.0583, 0.0293, 0.2168, 0.0293,\n",
      "        0.0293])\n",
      "tensor(97.2300)\n",
      "tensor(96.6500)\n",
      "Round 1348, reward -0.050\n",
      "tensor([0.0413, 0.3055, 0.0811, 0.0414, 0.0413, 0.2291, 0.0413, 0.0413, 0.0413,\n",
      "        0.1362])\n",
      "tensor(96.4700)\n",
      "tensor(97.4900)\n",
      "Round 1349, reward -0.366\n",
      "tensor([0.0610, 0.0610, 0.0610, 0.0610, 0.4508, 0.0610, 0.0610, 0.0611, 0.0610,\n",
      "        0.0610])\n",
      "tensor(95.7100)\n",
      "tensor(96.2500)\n",
      "Round 1350, reward -0.358\n",
      "tensor([0.1577, 0.1525, 0.1483, 0.0213, 0.1577, 0.1362, 0.1499, 0.0213, 0.0336,\n",
      "        0.0213])\n",
      "tensor(96.1000)\n",
      "tensor(95.7400)\n",
      "Round 1351, reward -0.080\n",
      "tensor([0.0432, 0.1872, 0.2948, 0.0432, 0.0432, 0.1783, 0.0435, 0.0432, 0.0434,\n",
      "        0.0799])\n",
      "tensor(91.9100)\n",
      "tensor(97.4100)\n",
      "Round 1352, reward -0.479\n",
      "tensor([0.0444, 0.3164, 0.0447, 0.0447, 0.0447, 0.0444, 0.0444, 0.0444, 0.3277,\n",
      "        0.0444])\n",
      "tensor(89.9600)\n",
      "tensor(92.8300)\n",
      "Round 1353, reward -0.519\n",
      "tensor([0.0854, 0.0557, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0441, 0.2984,\n",
      "        0.3080])\n",
      "tensor(94.2300)\n",
      "tensor(96.6800)\n",
      "Round 1354, reward -0.426\n",
      "tensor([0.0317, 0.0335, 0.0316, 0.0564, 0.2338, 0.0319, 0.2338, 0.0818, 0.0316,\n",
      "        0.2338])\n",
      "tensor(96.8300)\n",
      "tensor(96.5900)\n",
      "Round 1355, reward -0.060\n",
      "tensor([0.0413, 0.1899, 0.1927, 0.0484, 0.0651, 0.1895, 0.0261, 0.0266, 0.0373,\n",
      "        0.1830])\n",
      "tensor(96.7200)\n",
      "tensor(96.4200)\n",
      "Round 1356, reward -0.063\n",
      "tensor([0.0408, 0.0408, 0.0408, 0.0409, 0.0491, 0.1024, 0.3016, 0.3016, 0.0409,\n",
      "        0.0410])\n",
      "tensor(96.1200)\n",
      "tensor(95.9000)\n",
      "Round 1357, reward -0.079\n",
      "tensor([0.2465, 0.3438, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512, 0.0512,\n",
      "        0.0512])\n",
      "tensor(91.9000)\n",
      "tensor(96.7200)\n",
      "Round 1358, reward -0.479\n",
      "tensor([0.0279, 0.0279, 0.2062, 0.0279, 0.2063, 0.0279, 0.0292, 0.2063, 0.2063,\n",
      "        0.0341])\n",
      "tensor(97.0400)\n",
      "tensor(96.7800)\n",
      "Round 1359, reward -0.055\n",
      "tensor([0.0250, 0.0251, 0.1805, 0.1850, 0.1839, 0.1850, 0.0250, 0.0250, 0.1397,\n",
      "        0.0257])\n",
      "tensor(96.8500)\n",
      "tensor(97.1100)\n",
      "Round 1360, reward -0.258\n",
      "tensor([0.0437, 0.3226, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.3222, 0.0437,\n",
      "        0.0496])\n",
      "tensor(96.0100)\n",
      "tensor(97.3000)\n",
      "Round 1361, reward -0.380\n",
      "tensor([0.0332, 0.0485, 0.0332, 0.0333, 0.2381, 0.0332, 0.1471, 0.1570, 0.0333,\n",
      "        0.2432])\n",
      "tensor(94.4100)\n",
      "tensor(97.5300)\n",
      "Round 1362, reward -0.422\n",
      "tensor([0.0405, 0.1184, 0.0405, 0.2991, 0.0405, 0.0405, 0.2991, 0.0405, 0.0405,\n",
      "        0.0405])\n",
      "tensor(96.6500)\n",
      "tensor(97.5300)\n",
      "Round 1363, reward -0.357\n",
      "tensor([0.0412, 0.0407, 0.0406, 0.2999, 0.0406, 0.0406, 0.0406, 0.0415, 0.2999,\n",
      "        0.1143])\n",
      "tensor(96.7500)\n",
      "tensor(97.2500)\n",
      "Round 1364, reward -0.325\n",
      "tensor([0.0402, 0.0402, 0.0402, 0.2970, 0.0402, 0.2970, 0.0432, 0.0402, 0.0402,\n",
      "        0.1216])\n",
      "tensor(96.6500)\n",
      "tensor(97.1500)\n",
      "Round 1365, reward -0.328\n",
      "tensor([0.3356, 0.0465, 0.0465, 0.0521, 0.0465, 0.0465, 0.0471, 0.0465, 0.0465,\n",
      "        0.2863])\n",
      "tensor(95.7900)\n",
      "tensor(96.6700)\n",
      "Round 1366, reward -0.380\n",
      "tensor([0.0354, 0.2619, 0.0354, 0.0354, 0.0354, 0.2300, 0.0354, 0.2601, 0.0354,\n",
      "        0.0354])\n",
      "tensor(97.0800)\n",
      "tensor(97.3900)\n",
      "Round 1367, reward -0.271\n",
      "tensor([0.0297, 0.1648, 0.0305, 0.2075, 0.0297, 0.0297, 0.2196, 0.2142, 0.0297,\n",
      "        0.0445])\n",
      "tensor(95.7100)\n",
      "tensor(97.3500)\n",
      "Round 1368, reward -0.389\n",
      "tensor([0.0941, 0.0619, 0.0289, 0.0287, 0.0287, 0.2120, 0.2118, 0.0287, 0.2120,\n",
      "        0.0932])\n",
      "tensor(97.1800)\n",
      "tensor(97.5400)\n",
      "Round 1369, reward -0.284\n",
      "tensor([0.0226, 0.1658, 0.0226, 0.0590, 0.0700, 0.1412, 0.0226, 0.1624, 0.1670,\n",
      "        0.1669])\n",
      "tensor(96.8200)\n",
      "tensor(97.0900)\n",
      "Round 1370, reward -0.263\n",
      "tensor([0.0518, 0.0520, 0.1850, 0.3831, 0.0518, 0.0684, 0.0518, 0.0523, 0.0519,\n",
      "        0.0520])\n",
      "tensor(96.2200)\n",
      "tensor(97.1700)\n",
      "Round 1371, reward -0.371\n",
      "tensor([0.0364, 0.0362, 0.1897, 0.2677, 0.0362, 0.0572, 0.0364, 0.2677, 0.0362,\n",
      "        0.0363])\n",
      "tensor(97.1900)\n",
      "tensor(97.4200)\n",
      "Round 1372, reward -0.235\n",
      "tensor([0.0326, 0.0683, 0.1592, 0.2183, 0.0323, 0.0323, 0.1536, 0.0323, 0.0323,\n",
      "        0.2387])\n",
      "tensor(96.1700)\n",
      "tensor(96.7800)\n",
      "Round 1373, reward -0.354\n",
      "tensor([0.1765, 0.1744, 0.0239, 0.0239, 0.0239, 0.1765, 0.0240, 0.0239, 0.1765,\n",
      "        0.1765])\n",
      "tensor(94.1700)\n",
      "tensor(97.0900)\n",
      "Round 1374, reward -0.427\n",
      "tensor([0.1779, 0.1779, 0.0241, 0.0241, 0.1744, 0.1743, 0.0241, 0.1751, 0.0241,\n",
      "        0.0241])\n",
      "tensor(95.3500)\n",
      "tensor(96.8100)\n",
      "Round 1375, reward -0.398\n",
      "tensor([0.2054, 0.0278, 0.2054, 0.0278, 0.2054, 0.2050, 0.0278, 0.0397, 0.0278,\n",
      "        0.0279])\n",
      "tensor(96.4700)\n",
      "tensor(97.4600)\n",
      "Round 1376, reward -0.365\n",
      "tensor([0.1470, 0.1491, 0.1497, 0.0203, 0.1499, 0.0676, 0.0207, 0.0203, 0.1499,\n",
      "        0.1255])\n",
      "tensor(96.9000)\n",
      "tensor(96.7600)\n",
      "Round 1377, reward -0.059\n",
      "tensor([0.0319, 0.1059, 0.2234, 0.0415, 0.2350, 0.0318, 0.0319, 0.0318, 0.2350,\n",
      "        0.0318])\n",
      "tensor(95.2100)\n",
      "tensor(97.2200)\n",
      "Round 1378, reward -0.402\n",
      "tensor([0.0300, 0.1210, 0.2215, 0.1818, 0.0777, 0.0300, 0.0300, 0.0563, 0.2215,\n",
      "        0.0304])\n",
      "tensor(97.3700)\n",
      "tensor(97.2400)\n",
      "Round 1379, reward -0.046\n",
      "tensor([0.0205, 0.0205, 0.1517, 0.1517, 0.1517, 0.1517, 0.0205, 0.0280, 0.1517,\n",
      "        0.1517])\n",
      "tensor(97.3600)\n",
      "tensor(97.2500)\n",
      "Round 1380, reward -0.046\n",
      "tensor([0.0283, 0.0309, 0.0283, 0.0283, 0.2082, 0.2087, 0.2089, 0.0283, 0.0283,\n",
      "        0.2019])\n",
      "tensor(94.9400)\n",
      "tensor(96.8400)\n",
      "Round 1381, reward -0.409\n",
      "tensor([0.0424, 0.0424, 0.3132, 0.0757, 0.0424, 0.3131, 0.0424, 0.0436, 0.0424,\n",
      "        0.0424])\n",
      "tensor(95.3900)\n",
      "tensor(96.8100)\n",
      "Round 1382, reward -0.397\n",
      "tensor([0.0306, 0.1377, 0.0306, 0.2262, 0.0306, 0.0313, 0.2255, 0.0306, 0.0306,\n",
      "        0.2261])\n",
      "tensor(96.5800)\n",
      "tensor(97.4200)\n",
      "Round 1383, reward -0.358\n",
      "tensor([0.2622, 0.0356, 0.2579, 0.0356, 0.0356, 0.0356, 0.0374, 0.0379, 0.2268,\n",
      "        0.0356])\n",
      "tensor(96.1300)\n",
      "tensor(96.5000)\n",
      "Round 1384, reward -0.314\n",
      "tensor([0.0285, 0.0522, 0.2105, 0.0288, 0.2106, 0.0285, 0.2106, 0.0285, 0.0285,\n",
      "        0.1734])\n",
      "tensor(96.6300)\n",
      "tensor(96.6200)\n",
      "Round 1385, reward -0.066\n",
      "tensor([0.1562, 0.1523, 0.1562, 0.0218, 0.1561, 0.0211, 0.0527, 0.1061, 0.0211,\n",
      "        0.1562])\n",
      "tensor(97.7600)\n",
      "tensor(97.6300)\n",
      "Round 1386, reward -0.035\n",
      "tensor([0.0295, 0.1566, 0.0295, 0.2177, 0.2181, 0.0295, 0.0295, 0.2181, 0.0408,\n",
      "        0.0306])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(90.6400)\n",
      "tensor(94.1700)\n",
      "Round 1387, reward -0.506\n",
      "tensor([0.0538, 0.0538, 0.0538, 0.0538, 0.0543, 0.1456, 0.0538, 0.0538, 0.0804,\n",
      "        0.3972])\n",
      "tensor(97.1500)\n",
      "tensor(97.4300)\n",
      "Round 1388, reward -0.258\n",
      "tensor([0.0216, 0.1597, 0.1154, 0.1595, 0.1596, 0.0216, 0.1596, 0.1597, 0.0217,\n",
      "        0.0216])\n",
      "tensor(96.2000)\n",
      "tensor(97.4000)\n",
      "Round 1389, reward -0.375\n",
      "tensor([0.2095, 0.1787, 0.0351, 0.0284, 0.0284, 0.0441, 0.0284, 0.2095, 0.2095,\n",
      "        0.0284])\n",
      "tensor(96.2200)\n",
      "tensor(96.5600)\n",
      "Round 1390, reward -0.303\n",
      "tensor([0.2148, 0.0411, 0.0293, 0.0314, 0.0294, 0.0308, 0.2074, 0.2166, 0.0301,\n",
      "        0.1691])\n",
      "tensor(96.4500)\n",
      "tensor(95.9300)\n",
      "Round 1391, reward -0.070\n",
      "tensor([0.0344, 0.1790, 0.1791, 0.0242, 0.1674, 0.0242, 0.1638, 0.0247, 0.0242,\n",
      "        0.1789])\n",
      "tensor(96.7800)\n",
      "tensor(96.5300)\n",
      "Round 1392, reward -0.062\n",
      "tensor([0.0602, 0.0602, 0.0696, 0.0646, 0.4432, 0.0615, 0.0602, 0.0602, 0.0602,\n",
      "        0.0603])\n",
      "tensor(96.4500)\n",
      "tensor(97.7300)\n",
      "Round 1393, reward -0.369\n",
      "tensor([0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0638, 0.0877, 0.0592, 0.0592,\n",
      "        0.4338])\n",
      "tensor(96.6200)\n",
      "tensor(97.4000)\n",
      "Round 1394, reward -0.354\n",
      "tensor([0.0240, 0.0584, 0.1391, 0.1765, 0.1762, 0.0242, 0.0240, 0.1765, 0.1771,\n",
      "        0.0240])\n",
      "tensor(96.6700)\n",
      "tensor(96.9700)\n",
      "Round 1395, reward -0.278\n",
      "tensor([0.0270, 0.1740, 0.0236, 0.1740, 0.0276, 0.1740, 0.0282, 0.1740, 0.0236,\n",
      "        0.1740])\n",
      "tensor(97.1200)\n",
      "tensor(97.4800)\n",
      "Round 1396, reward -0.286\n",
      "tensor([0.0322, 0.0323, 0.0883, 0.0324, 0.2377, 0.2378, 0.0368, 0.2382, 0.0322,\n",
      "        0.0322])\n",
      "tensor(96.3300)\n",
      "tensor(96.5400)\n",
      "Round 1397, reward -0.248\n",
      "tensor([0.3573, 0.0484, 0.0486, 0.0635, 0.0484, 0.0484, 0.0484, 0.2403, 0.0484,\n",
      "        0.0484])\n",
      "tensor(90.9600)\n",
      "tensor(95.1100)\n",
      "Round 1398, reward -0.499\n",
      "tensor([0.0325, 0.0284, 0.2097, 0.0285, 0.0284, 0.0288, 0.2097, 0.1985, 0.0284,\n",
      "        0.2072])\n",
      "tensor(93.8000)\n",
      "tensor(95.8700)\n",
      "Round 1399, reward -0.436\n",
      "tensor([0.1917, 0.1986, 0.0269, 0.0269, 0.0269, 0.1986, 0.0738, 0.1986, 0.0269,\n",
      "        0.0311])\n",
      "tensor(90.3200)\n",
      "tensor(89.7100)\n",
      "Round 1400, reward -0.212\n",
      "tensor([0.1523, 0.0206, 0.1523, 0.1523, 0.0243, 0.0206, 0.1522, 0.0206, 0.1523,\n",
      "        0.1523])\n",
      "tensor(96.1900)\n",
      "tensor(92.6400)\n",
      "Round 1401, reward -0.077\n",
      "tensor([0.0723, 0.0723, 0.0723, 0.0725, 0.0723, 0.0723, 0.0728, 0.0723, 0.3487,\n",
      "        0.0723])\n",
      "tensor(96.2800)\n",
      "tensor(97.7900)\n",
      "Round 1402, reward -0.374\n",
      "tensor([0.1545, 0.1538, 0.1545, 0.1250, 0.0209, 0.0241, 0.0308, 0.1518, 0.1541,\n",
      "        0.0305])\n",
      "tensor(95.4500)\n",
      "tensor(95.5200)\n",
      "Round 1403, reward -0.172\n",
      "tensor([0.1438, 0.0196, 0.0195, 0.1438, 0.0980, 0.1244, 0.1438, 0.1438, 0.1438,\n",
      "        0.0195])\n",
      "tensor(96.1200)\n",
      "tensor(96.2800)\n",
      "Round 1404, reward -0.225\n",
      "tensor([0.0284, 0.0288, 0.1993, 0.2102, 0.0284, 0.2100, 0.0284, 0.0284, 0.2094,\n",
      "        0.0285])\n",
      "tensor(96.6200)\n",
      "tensor(97.2500)\n",
      "Round 1405, reward -0.344\n",
      "tensor([0.1765, 0.0889, 0.1863, 0.1863, 0.0252, 0.0337, 0.0376, 0.1863, 0.0252,\n",
      "        0.0540])\n",
      "tensor(96.8700)\n",
      "tensor(97.3900)\n",
      "Round 1406, reward -0.325\n",
      "tensor([0.1370, 0.0237, 0.1717, 0.1751, 0.1297, 0.1456, 0.0237, 0.0242, 0.0238,\n",
      "        0.1455])\n",
      "tensor(95.0300)\n",
      "tensor(96.1000)\n",
      "Round 1407, reward -0.403\n",
      "tensor([0.0503, 0.0557, 0.0503, 0.0503, 0.0503, 0.0503, 0.0503, 0.3711, 0.2208,\n",
      "        0.0504])\n",
      "tensor(95.7900)\n",
      "tensor(96.9900)\n",
      "Round 1408, reward -0.385\n",
      "tensor([0.2948, 0.0401, 0.0399, 0.0399, 0.0421, 0.0399, 0.2906, 0.0399, 0.0444,\n",
      "        0.1283])\n",
      "tensor(96.6500)\n",
      "tensor(97.2600)\n",
      "Round 1409, reward -0.341\n",
      "tensor([0.0311, 0.0311, 0.1179, 0.0311, 0.0377, 0.2295, 0.2060, 0.2228, 0.0311,\n",
      "        0.0618])\n",
      "tensor(96.9900)\n",
      "tensor(94.8800)\n",
      "Round 1410, reward -0.056\n",
      "tensor([0.1750, 0.1747, 0.0306, 0.1750, 0.0237, 0.1750, 0.0237, 0.0237, 0.1748,\n",
      "        0.0237])\n",
      "tensor(96.6100)\n",
      "tensor(96.5500)\n",
      "Round 1411, reward -0.066\n",
      "tensor([0.0352, 0.2570, 0.2399, 0.2488, 0.0349, 0.0349, 0.0351, 0.0349, 0.0350,\n",
      "        0.0444])\n",
      "tensor(96.8400)\n",
      "tensor(97.6700)\n",
      "Round 1412, reward -0.351\n",
      "tensor([0.1703, 0.0232, 0.0485, 0.1703, 0.0310, 0.0230, 0.0230, 0.1703, 0.1700,\n",
      "        0.1703])\n",
      "tensor(95.6600)\n",
      "tensor(95.9800)\n",
      "Round 1413, reward -0.312\n",
      "tensor([0.2494, 0.2494, 0.0338, 0.0346, 0.0338, 0.0485, 0.0338, 0.0338, 0.2494,\n",
      "        0.0338])\n",
      "tensor(96.8000)\n",
      "tensor(97.3200)\n",
      "Round 1414, reward -0.327\n",
      "tensor([0.0842, 0.0583, 0.0584, 0.4280, 0.0584, 0.0663, 0.0625, 0.0583, 0.0673,\n",
      "        0.0583])\n",
      "tensor(94.4600)\n",
      "tensor(96.1800)\n",
      "Round 1415, reward -0.420\n",
      "tensor([0.0327, 0.0327, 0.1955, 0.2417, 0.0327, 0.0327, 0.1248, 0.2415, 0.0330,\n",
      "        0.0327])\n",
      "tensor(97.1300)\n",
      "tensor(97.3200)\n",
      "Round 1416, reward -0.216\n",
      "tensor([0.1919, 0.0307, 0.0322, 0.1919, 0.1903, 0.0606, 0.1695, 0.0407, 0.0661,\n",
      "        0.0260])\n",
      "tensor(94.5400)\n",
      "tensor(95.6800)\n",
      "Round 1417, reward -0.416\n",
      "tensor([0.1440, 0.1424, 0.0195, 0.0789, 0.1440, 0.1440, 0.0195, 0.0195, 0.1440,\n",
      "        0.1440])\n",
      "tensor(95.4800)\n",
      "tensor(96.8500)\n",
      "Round 1418, reward -0.394\n",
      "tensor([0.0291, 0.1515, 0.1516, 0.0205, 0.0205, 0.1516, 0.0205, 0.1516, 0.1516,\n",
      "        0.1514])\n",
      "tensor(97.1200)\n",
      "tensor(96.5400)\n",
      "Round 1419, reward -0.053\n",
      "tensor([0.1738, 0.1452, 0.0235, 0.1738, 0.0683, 0.0235, 0.1738, 0.0235, 0.0235,\n",
      "        0.1712])\n",
      "tensor(89.8500)\n",
      "tensor(92.3700)\n",
      "Round 1420, reward -0.522\n",
      "tensor([0.3240, 0.0439, 0.0439, 0.0439, 0.3240, 0.0445, 0.0439, 0.0439, 0.0443,\n",
      "        0.0439])\n",
      "tensor(94.5700)\n",
      "tensor(97.7100)\n",
      "Round 1421, reward -0.418\n",
      "tensor([0.2355, 0.2355, 0.1070, 0.0319, 0.0319, 0.0319, 0.2296, 0.0321, 0.0325,\n",
      "        0.0323])\n",
      "tensor(95.6500)\n",
      "tensor(96.5500)\n",
      "Round 1422, reward -0.384\n",
      "tensor([0.0643, 0.0429, 0.0429, 0.0429, 0.0495, 0.0429, 0.0429, 0.3171, 0.3116,\n",
      "        0.0429])\n",
      "tensor(97.2600)\n",
      "tensor(97.7600)\n",
      "Round 1423, reward -0.311\n",
      "tensor([0.0298, 0.0298, 0.0298, 0.0298, 0.2204, 0.2196, 0.0298, 0.2084, 0.1723,\n",
      "        0.0303])\n",
      "tensor(97.0400)\n",
      "tensor(97.3500)\n",
      "Round 1424, reward -0.272\n",
      "tensor([0.0217, 0.1529, 0.1528, 0.1529, 0.0207, 0.0207, 0.1527, 0.0208, 0.1529,\n",
      "        0.1521])\n",
      "tensor(95.9700)\n",
      "tensor(96.2600)\n",
      "Round 1425, reward -0.293\n",
      "tensor([0.0343, 0.0343, 0.2533, 0.2533, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343,\n",
      "        0.2534])\n",
      "tensor(95.4700)\n",
      "tensor(96.6100)\n",
      "Round 1426, reward -0.393\n",
      "tensor([0.0254, 0.0245, 0.1811, 0.1801, 0.1811, 0.1811, 0.0245, 0.0259, 0.0253,\n",
      "        0.1510])\n",
      "tensor(97.1800)\n",
      "tensor(96.5800)\n",
      "Round 1427, reward -0.051\n",
      "tensor([0.0300, 0.1712, 0.0859, 0.0300, 0.0300, 0.0300, 0.0300, 0.2206, 0.2217,\n",
      "        0.1507])\n",
      "tensor(96.3600)\n",
      "tensor(97.0300)\n",
      "Round 1428, reward -0.354\n",
      "tensor([0.2220, 0.0317, 0.0300, 0.0300, 0.1862, 0.0302, 0.0300, 0.1962, 0.0300,\n",
      "        0.2136])\n",
      "tensor(96.6400)\n",
      "tensor(97.3700)\n",
      "Round 1429, reward -0.351\n",
      "tensor([0.0332, 0.0332, 0.0375, 0.2328, 0.2083, 0.0334, 0.2452, 0.1100, 0.0332,\n",
      "        0.0332])\n",
      "tensor(96.3400)\n",
      "tensor(97.0100)\n",
      "Round 1430, reward -0.355\n",
      "tensor([0.0243, 0.1595, 0.1797, 0.0243, 0.1797, 0.0243, 0.0243, 0.0243, 0.1797,\n",
      "        0.1797])\n",
      "tensor(94.8400)\n",
      "tensor(97.0900)\n",
      "Round 1431, reward -0.411\n",
      "tensor([0.1137, 0.1156, 0.1092, 0.1156, 0.0698, 0.1156, 0.0156, 0.1156, 0.1136,\n",
      "        0.1156])\n",
      "tensor(96.0400)\n",
      "tensor(96.3800)\n",
      "Round 1432, reward -0.308\n",
      "tensor([0.1127, 0.1378, 0.1376, 0.1378, 0.0187, 0.1376, 0.0252, 0.0186, 0.1378,\n",
      "        0.1362])\n",
      "tensor(97.4400)\n",
      "tensor(97.3800)\n",
      "Round 1433, reward -0.044\n",
      "tensor([0.1088, 0.0253, 0.1870, 0.0440, 0.0268, 0.1837, 0.1866, 0.0253, 0.0253,\n",
      "        0.1870])\n",
      "tensor(97.1600)\n",
      "tensor(97.3100)\n",
      "Round 1434, reward -0.191\n",
      "tensor([0.1906, 0.2239, 0.0307, 0.0304, 0.2003, 0.0304, 0.0304, 0.0305, 0.1284,\n",
      "        0.1043])\n",
      "tensor(96.4900)\n",
      "tensor(97.2200)\n",
      "Round 1435, reward -0.355\n",
      "tensor([0.0226, 0.1660, 0.1548, 0.0225, 0.0225, 0.1630, 0.0403, 0.0765, 0.1660,\n",
      "        0.1660])\n",
      "tensor(97.7000)\n",
      "tensor(97.4300)\n",
      "Round 1436, reward -0.037\n",
      "tensor([0.0606, 0.0606, 0.0606, 0.0607, 0.0606, 0.0674, 0.0607, 0.0606, 0.0606,\n",
      "        0.4477])\n",
      "tensor(92.6300)\n",
      "tensor(97.5300)\n",
      "Round 1437, reward -0.463\n",
      "tensor([0.0415, 0.1976, 0.1973, 0.1975, 0.0267, 0.0615, 0.0267, 0.0267, 0.1976,\n",
      "        0.0267])\n",
      "tensor(96.9700)\n",
      "tensor(96.2800)\n",
      "Round 1438, reward -0.057\n",
      "tensor([0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.4206, 0.1234, 0.0570,\n",
      "        0.0570])\n",
      "tensor(96.0800)\n",
      "tensor(96.3900)\n",
      "Round 1439, reward -0.297\n",
      "tensor([0.1528, 0.0207, 0.0210, 0.1529, 0.1525, 0.1529, 0.0207, 0.1529, 0.0207,\n",
      "        0.1529])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95.1300)\n",
      "tensor(95.6500)\n",
      "Round 1440, reward -0.370\n",
      "tensor([0.1512, 0.1463, 0.1516, 0.1526, 0.0208, 0.1526, 0.1526, 0.0310, 0.0207,\n",
      "        0.0207])\n",
      "tensor(97.7500)\n",
      "tensor(96.8700)\n",
      "Round 1441, reward -0.035\n",
      "tensor([0.0236, 0.1606, 0.1733, 0.1722, 0.0865, 0.1734, 0.0235, 0.0235, 0.0235,\n",
      "        0.1400])\n",
      "tensor(97.4400)\n",
      "tensor(97.1700)\n",
      "Round 1442, reward -0.044\n",
      "tensor([0.1748, 0.1764, 0.0239, 0.0240, 0.0239, 0.0239, 0.1764, 0.1764, 0.1764,\n",
      "        0.0239])\n",
      "tensor(96.6100)\n",
      "tensor(97.7000)\n",
      "Round 1443, reward -0.363\n",
      "tensor([0.2402, 0.1855, 0.2391, 0.0325, 0.0325, 0.0329, 0.0325, 0.0325, 0.0325,\n",
      "        0.1397])\n",
      "tensor(97.4000)\n",
      "tensor(97.8000)\n",
      "Round 1444, reward -0.288\n",
      "tensor([0.0436, 0.0503, 0.0436, 0.0436, 0.0438, 0.3217, 0.3224, 0.0436, 0.0436,\n",
      "        0.0436])\n",
      "tensor(97.2100)\n",
      "tensor(97.0100)\n",
      "Round 1445, reward -0.050\n",
      "tensor([0.0880, 0.0400, 0.0392, 0.2799, 0.0841, 0.2858, 0.0424, 0.0625, 0.0392,\n",
      "        0.0390])\n",
      "tensor(96.7900)\n",
      "tensor(97.7500)\n",
      "Round 1446, reward -0.356\n",
      "tensor([0.0394, 0.0394, 0.0394, 0.1383, 0.2905, 0.2908, 0.0394, 0.0394, 0.0407,\n",
      "        0.0429])\n",
      "tensor(96.7100)\n",
      "tensor(97.8100)\n",
      "Round 1447, reward -0.360\n",
      "tensor([0.2032, 0.0275, 0.2032, 0.0275, 0.0441, 0.0275, 0.2032, 0.2032, 0.0329,\n",
      "        0.0275])\n",
      "tensor(96.6400)\n",
      "tensor(97.4100)\n",
      "Round 1448, reward -0.353\n",
      "tensor([0.1680, 0.0228, 0.0233, 0.0930, 0.0228, 0.0228, 0.1683, 0.1668, 0.1519,\n",
      "        0.1604])\n",
      "tensor(96.8200)\n",
      "tensor(97.2000)\n",
      "Round 1449, reward -0.299\n",
      "tensor([0.1508, 0.1507, 0.1508, 0.0440, 0.0239, 0.1401, 0.1508, 0.0204, 0.1472,\n",
      "        0.0214])\n",
      "tensor(96.9500)\n",
      "tensor(97.6600)\n",
      "Round 1450, reward -0.342\n",
      "tensor([0.0430, 0.0597, 0.0430, 0.0430, 0.0430, 0.0460, 0.3180, 0.0430, 0.0430,\n",
      "        0.3180])\n",
      "tensor(97.3700)\n",
      "tensor(97.6500)\n",
      "Round 1451, reward -0.252\n",
      "tensor([0.1846, 0.1945, 0.1140, 0.1980, 0.0268, 0.0268, 0.0268, 0.0268, 0.0268,\n",
      "        0.1749])\n",
      "tensor(93.9600)\n",
      "tensor(95.7300)\n",
      "Round 1452, reward -0.432\n",
      "tensor([0.1404, 0.1420, 0.1421, 0.1418, 0.0192, 0.0796, 0.0323, 0.1418, 0.0192,\n",
      "        0.1415])\n",
      "tensor(90.7200)\n",
      "tensor(92.9800)\n",
      "Round 1453, reward -0.504\n",
      "tensor([0.1528, 0.0994, 0.1441, 0.0230, 0.1701, 0.0230, 0.0230, 0.1700, 0.1701,\n",
      "        0.0245])\n",
      "tensor(97.)\n",
      "tensor(96.9900)\n",
      "Round 1454, reward -0.056\n",
      "tensor([0.0338, 0.2499, 0.2499, 0.0338, 0.0338, 0.0338, 0.2497, 0.0353, 0.0338,\n",
      "        0.0462])\n",
      "tensor(96.3000)\n",
      "tensor(96.8300)\n",
      "Round 1455, reward -0.341\n",
      "tensor([0.2527, 0.2527, 0.0344, 0.0342, 0.0351, 0.2498, 0.0342, 0.0342, 0.0342,\n",
      "        0.0385])\n",
      "tensor(97.4800)\n",
      "tensor(97.5200)\n",
      "Round 1456, reward -0.089\n",
      "tensor([0.0269, 0.0381, 0.1987, 0.0613, 0.0273, 0.0269, 0.1986, 0.1965, 0.0269,\n",
      "        0.1987])\n",
      "tensor(96.2600)\n",
      "tensor(97.4600)\n",
      "Round 1457, reward -0.373\n",
      "tensor([0.0609, 0.0306, 0.0586, 0.0306, 0.0732, 0.0449, 0.2147, 0.2259, 0.2259,\n",
      "        0.0348])\n",
      "tensor(97.2500)\n",
      "tensor(96.2200)\n",
      "Round 1458, reward -0.049\n",
      "tensor([0.0433, 0.0463, 0.0520, 0.0433, 0.0433, 0.0459, 0.0435, 0.0433, 0.3197,\n",
      "        0.3195])\n",
      "tensor(95.5500)\n",
      "tensor(97.3900)\n",
      "Round 1459, reward -0.393\n",
      "tensor([0.3221, 0.0456, 0.0449, 0.0439, 0.0439, 0.0439, 0.0439, 0.3241, 0.0439,\n",
      "        0.0440])\n",
      "tensor(97.7800)\n",
      "tensor(96.8600)\n",
      "Round 1460, reward -0.035\n",
      "tensor([0.1861, 0.0252, 0.0252, 0.0252, 0.1858, 0.1861, 0.0252, 0.1304, 0.0252,\n",
      "        0.1856])\n",
      "tensor(95.8500)\n",
      "tensor(96.9300)\n",
      "Round 1461, reward -0.383\n",
      "tensor([0.0544, 0.1401, 0.1402, 0.0190, 0.1402, 0.0190, 0.1401, 0.1401, 0.0668,\n",
      "        0.1401])\n",
      "tensor(97.1100)\n",
      "tensor(97.3300)\n",
      "Round 1462, reward -0.233\n",
      "tensor([0.1516, 0.1516, 0.1517, 0.0283, 0.1517, 0.1517, 0.0205, 0.1517, 0.0205,\n",
      "        0.0206])\n",
      "tensor(96.5200)\n",
      "tensor(97.5900)\n",
      "Round 1463, reward -0.365\n",
      "tensor([0.1418, 0.1621, 0.1621, 0.1203, 0.0219, 0.0219, 0.1621, 0.0230, 0.1621,\n",
      "        0.0225])\n",
      "tensor(96.9400)\n",
      "tensor(96.3500)\n",
      "Round 1464, reward -0.057\n",
      "tensor([0.0226, 0.0219, 0.1618, 0.0219, 0.1137, 0.1520, 0.1618, 0.1606, 0.1618,\n",
      "        0.0219])\n",
      "tensor(97.0500)\n",
      "tensor(97.2700)\n",
      "Round 1465, reward -0.234\n",
      "tensor([0.2550, 0.0361, 0.2129, 0.0361, 0.0425, 0.0418, 0.0361, 0.2666, 0.0361,\n",
      "        0.0366])\n",
      "tensor(96.)\n",
      "tensor(96.7500)\n",
      "Round 1466, reward -0.369\n",
      "tensor([0.1705, 0.1808, 0.1648, 0.1807, 0.0245, 0.0245, 0.0245, 0.0245, 0.0245,\n",
      "        0.1808])\n",
      "tensor(96.1500)\n",
      "tensor(96.4400)\n",
      "Round 1467, reward -0.288\n",
      "tensor([0.1366, 0.1356, 0.0186, 0.0185, 0.0185, 0.1366, 0.1366, 0.1366, 0.1366,\n",
      "        0.1260])\n",
      "tensor(96.3800)\n",
      "tensor(97.4900)\n",
      "Round 1468, reward -0.369\n",
      "tensor([0.1735, 0.1735, 0.1476, 0.0662, 0.1703, 0.0235, 0.1735, 0.0235, 0.0250,\n",
      "        0.0235])\n",
      "tensor(94.5000)\n",
      "tensor(97.4300)\n",
      "Round 1469, reward -0.419\n",
      "tensor([0.1555, 0.1749, 0.1747, 0.0506, 0.0237, 0.1746, 0.0238, 0.1749, 0.0237,\n",
      "        0.0237])\n",
      "tensor(96.2900)\n",
      "tensor(97.1800)\n",
      "Round 1470, reward -0.367\n",
      "tensor([0.3242, 0.0439, 0.0439, 0.0439, 0.0439, 0.0441, 0.0439, 0.0439, 0.3244,\n",
      "        0.0439])\n",
      "tensor(95.2400)\n",
      "tensor(95.5800)\n",
      "Round 1471, reward -0.328\n",
      "tensor([0.1884, 0.1234, 0.1881, 0.0255, 0.0255, 0.0255, 0.1843, 0.0255, 0.1884,\n",
      "        0.0255])\n",
      "tensor(95.3000)\n",
      "tensor(96.4800)\n",
      "Round 1472, reward -0.398\n",
      "tensor([0.0277, 0.0429, 0.2046, 0.2046, 0.0277, 0.2046, 0.0277, 0.2046, 0.0277,\n",
      "        0.0277])\n",
      "tensor(95.4100)\n",
      "tensor(96.4600)\n",
      "Round 1473, reward -0.393\n",
      "tensor([0.0231, 0.1204, 0.0884, 0.1697, 0.1709, 0.0380, 0.0232, 0.0244, 0.1709,\n",
      "        0.1709])\n",
      "tensor(96.1000)\n",
      "tensor(96.6100)\n",
      "Round 1474, reward -0.344\n",
      "tensor([0.0238, 0.0238, 0.1755, 0.1755, 0.0238, 0.0238, 0.1755, 0.1755, 0.0273,\n",
      "        0.1755])\n",
      "tensor(96.7100)\n",
      "tensor(97.2400)\n",
      "Round 1475, reward -0.330\n",
      "tensor([0.0249, 0.1756, 0.0238, 0.0259, 0.1756, 0.0238, 0.0238, 0.1756, 0.1756,\n",
      "        0.1756])\n",
      "tensor(96.2000)\n",
      "tensor(96.6200)\n",
      "Round 1476, reward -0.325\n",
      "tensor([0.1320, 0.0217, 0.1603, 0.1603, 0.0674, 0.0217, 0.0217, 0.0955, 0.1603,\n",
      "        0.1590])\n",
      "tensor(97.2300)\n",
      "tensor(97.2200)\n",
      "Round 1477, reward -0.050\n",
      "tensor([0.0956, 0.1972, 0.0271, 0.2000, 0.0541, 0.0271, 0.2001, 0.0271, 0.1445,\n",
      "        0.0272])\n",
      "tensor(97.4800)\n",
      "tensor(97.5000)\n",
      "Round 1478, reward -0.067\n",
      "tensor([0.2031, 0.0363, 0.0362, 0.0361, 0.2618, 0.0361, 0.2666, 0.0516, 0.0361,\n",
      "        0.0361])\n",
      "tensor(95.9700)\n",
      "tensor(97.0600)\n",
      "Round 1479, reward -0.380\n",
      "tensor([0.0283, 0.2080, 0.0282, 0.0282, 0.0282, 0.2078, 0.0282, 0.2078, 0.0282,\n",
      "        0.2073])\n",
      "tensor(97.5200)\n",
      "tensor(97.9400)\n",
      "Round 1480, reward -0.289\n",
      "tensor([0.0259, 0.0247, 0.1582, 0.1823, 0.1819, 0.0383, 0.0247, 0.0247, 0.1564,\n",
      "        0.1828])\n",
      "tensor(97.0900)\n",
      "tensor(97.6100)\n",
      "Round 1481, reward -0.319\n",
      "tensor([0.0888, 0.0598, 0.1777, 0.0598, 0.0598, 0.0599, 0.3073, 0.0598, 0.0670,\n",
      "        0.0599])\n",
      "tensor(96.5500)\n",
      "tensor(97.5100)\n",
      "Round 1482, reward -0.362\n",
      "tensor([0.1582, 0.1582, 0.0221, 0.1582, 0.0214, 0.0229, 0.0216, 0.1571, 0.1300,\n",
      "        0.1501])\n",
      "tensor(96.4800)\n",
      "tensor(96.9300)\n",
      "Round 1483, reward -0.323\n",
      "tensor([0.1554, 0.1548, 0.1554, 0.1554, 0.0210, 0.1554, 0.0211, 0.0308, 0.0225,\n",
      "        0.1283])\n",
      "tensor(91.6800)\n",
      "tensor(96.3700)\n",
      "Round 1484, reward -0.484\n",
      "tensor([0.1666, 0.1666, 0.1666, 0.0225, 0.0226, 0.1666, 0.1485, 0.0225, 0.0225,\n",
      "        0.0949])\n",
      "tensor(97.2900)\n",
      "tensor(97.0200)\n",
      "Round 1485, reward -0.048\n",
      "tensor([0.0511, 0.0533, 0.0511, 0.3761, 0.1109, 0.0512, 0.1528, 0.0511, 0.0511,\n",
      "        0.0512])\n",
      "tensor(94.8000)\n",
      "tensor(97.0200)\n",
      "Round 1486, reward -0.412\n",
      "tensor([0.0351, 0.2024, 0.0994, 0.0334, 0.0334, 0.0377, 0.0335, 0.2454, 0.2462,\n",
      "        0.0335])\n",
      "tensor(95.2900)\n",
      "tensor(96.1600)\n",
      "Round 1487, reward -0.392\n",
      "tensor([0.0238, 0.1717, 0.0234, 0.0232, 0.1717, 0.0603, 0.0234, 0.1591, 0.1717,\n",
      "        0.1717])\n",
      "tensor(96.4900)\n",
      "tensor(97.3700)\n",
      "Round 1488, reward -0.362\n",
      "tensor([0.1688, 0.0415, 0.0229, 0.0229, 0.0865, 0.0229, 0.1363, 0.1664, 0.1625,\n",
      "        0.1693])\n",
      "tensor(96.5500)\n",
      "tensor(97.4300)\n",
      "Round 1489, reward -0.360\n",
      "tensor([0.0228, 0.0215, 0.1589, 0.1589, 0.1496, 0.1273, 0.0215, 0.0217, 0.1589,\n",
      "        0.1588])\n",
      "tensor(97.4300)\n",
      "tensor(97.5200)\n",
      "Round 1490, reward -0.138\n",
      "tensor([0.1862, 0.0269, 0.0916, 0.1987, 0.0269, 0.0271, 0.1900, 0.0270, 0.1988,\n",
      "        0.0269])\n",
      "tensor(96.8400)\n",
      "tensor(97.4800)\n",
      "Round 1491, reward -0.339\n",
      "tensor([0.0235, 0.1734, 0.1734, 0.1576, 0.1734, 0.0244, 0.0535, 0.0237, 0.0239,\n",
      "        0.1731])\n",
      "tensor(95.7800)\n",
      "tensor(96.1300)\n",
      "Round 1492, reward -0.318\n",
      "tensor([0.0342, 0.2520, 0.0363, 0.0345, 0.0342, 0.0342, 0.0342, 0.2529, 0.0344,\n",
      "        0.2529])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(96.8700)\n",
      "tensor(97.3300)\n",
      "Round 1493, reward -0.315\n",
      "tensor([0.1676, 0.0235, 0.0246, 0.0507, 0.1731, 0.0234, 0.1731, 0.1669, 0.1731,\n",
      "        0.0241])\n",
      "tensor(95.5500)\n",
      "tensor(93.5200)\n",
      "Round 1494, reward -0.094\n",
      "tensor([0.2070, 0.0285, 0.0286, 0.2015, 0.2096, 0.0284, 0.0284, 0.2097, 0.0289,\n",
      "        0.0295])\n",
      "tensor(95.6900)\n",
      "tensor(97.2700)\n",
      "Round 1495, reward -0.390\n",
      "tensor([0.1552, 0.0211, 0.1552, 0.1390, 0.1552, 0.1552, 0.0221, 0.0210, 0.0210,\n",
      "        0.1552])\n",
      "tensor(97.4600)\n",
      "tensor(97.1600)\n",
      "Round 1496, reward -0.043\n",
      "tensor([0.0258, 0.1615, 0.0258, 0.1903, 0.1853, 0.0258, 0.1903, 0.1268, 0.0258,\n",
      "        0.0427])\n",
      "tensor(96.1500)\n",
      "tensor(96.8800)\n",
      "Round 1497, reward -0.364\n",
      "tensor([0.1562, 0.1562, 0.0211, 0.0211, 0.0216, 0.1552, 0.1562, 0.1498, 0.0211,\n",
      "        0.1414])\n",
      "tensor(96.7700)\n",
      "tensor(96.6100)\n",
      "Round 1498, reward -0.062\n",
      "tensor([0.2026, 0.2017, 0.0274, 0.0525, 0.2026, 0.0274, 0.0276, 0.0274, 0.2020,\n",
      "        0.0288])\n",
      "tensor(97.5300)\n",
      "tensor(97.8700)\n",
      "Round 1499, reward -0.269\n",
      "tensor([0.1367, 0.1367, 0.1367, 0.0228, 0.1367, 0.1255, 0.0185, 0.1367, 0.1313,\n",
      "        0.0185])\n",
      "tensor(97.0700)\n",
      "tensor(97.0100)\n",
      "Round 1500, reward -0.054\n",
      "tensor([0.0343, 0.2533, 0.0343, 0.0343, 0.0343, 0.0343, 0.2533, 0.0343, 0.0343,\n",
      "        0.2534])\n",
      "tensor(97.5000)\n",
      "tensor(97.8700)\n",
      "Round 1501, reward -0.278\n",
      "tensor([0.1816, 0.1816, 0.1129, 0.1637, 0.0787, 0.0252, 0.0246, 0.0246, 0.0255,\n",
      "        0.1816])\n",
      "tensor(96.5200)\n",
      "tensor(96.8600)\n",
      "Round 1502, reward -0.296\n",
      "tensor([0.1064, 0.1931, 0.0261, 0.0261, 0.0261, 0.1931, 0.1836, 0.0263, 0.1931,\n",
      "        0.0261])\n",
      "tensor(95.8800)\n",
      "tensor(95.8000)\n",
      "Round 1503, reward -0.085\n",
      "tensor([0.2457, 0.0350, 0.0350, 0.2502, 0.0350, 0.2586, 0.0355, 0.0350, 0.0350,\n",
      "        0.0350])\n",
      "tensor(96.1900)\n",
      "tensor(97.4100)\n",
      "Round 1504, reward -0.375\n",
      "tensor([0.0241, 0.0240, 0.1776, 0.1776, 0.0240, 0.1761, 0.0249, 0.1700, 0.1776,\n",
      "        0.0240])\n",
      "tensor(95.0300)\n",
      "tensor(96.7400)\n",
      "Round 1505, reward -0.406\n",
      "tensor([0.1772, 0.1773, 0.1757, 0.1764, 0.0248, 0.0240, 0.0240, 0.1725, 0.0241,\n",
      "        0.0240])\n",
      "tensor(95.3300)\n",
      "tensor(96.9300)\n",
      "Round 1506, reward -0.399\n",
      "tensor([0.2616, 0.2614, 0.0356, 0.1723, 0.0412, 0.0811, 0.0397, 0.0354, 0.0362,\n",
      "        0.0354])\n",
      "tensor(97.0700)\n",
      "tensor(96.5700)\n",
      "Round 1507, reward -0.054\n",
      "tensor([0.1516, 0.0205, 0.0209, 0.1514, 0.0205, 0.1321, 0.1516, 0.1515, 0.1516,\n",
      "        0.0482])\n",
      "tensor(95.5600)\n",
      "tensor(96.0900)\n",
      "Round 1508, reward -0.360\n",
      "tensor([0.1269, 0.2110, 0.0949, 0.0286, 0.0286, 0.2111, 0.0286, 0.2111, 0.0307,\n",
      "        0.0286])\n",
      "tensor(96.5800)\n",
      "tensor(97.3000)\n",
      "Round 1509, reward -0.352\n",
      "tensor([0.1892, 0.1754, 0.0256, 0.1892, 0.0263, 0.1892, 0.1261, 0.0256, 0.0277,\n",
      "        0.0256])\n",
      "tensor(96.2400)\n",
      "tensor(96.8900)\n",
      "Round 1510, reward -0.356\n",
      "tensor([0.0238, 0.1741, 0.0238, 0.1292, 0.1741, 0.0237, 0.0236, 0.1740, 0.1741,\n",
      "        0.0797])\n",
      "tensor(96.7400)\n",
      "tensor(97.0100)\n",
      "Round 1511, reward -0.265\n",
      "tensor([0.0272, 0.1997, 0.1997, 0.1997, 0.1997, 0.0646, 0.0271, 0.0272, 0.0280,\n",
      "        0.0271])\n",
      "tensor(97.2900)\n",
      "tensor(97.7900)\n",
      "Round 1512, reward -0.311\n",
      "tensor([0.1110, 0.2057, 0.0278, 0.0278, 0.2051, 0.1312, 0.0278, 0.0278, 0.0301,\n",
      "        0.2057])\n",
      "tensor(97.3600)\n",
      "tensor(97.4100)\n",
      "Round 1513, reward -0.102\n",
      "tensor([0.0354, 0.0353, 0.0353, 0.2603, 0.2604, 0.0353, 0.0353, 0.0353, 0.2324,\n",
      "        0.0353])\n",
      "tensor(96.6200)\n",
      "tensor(97.8200)\n",
      "Round 1514, reward -0.364\n",
      "tensor([0.1342, 0.1348, 0.1348, 0.1348, 0.0333, 0.1347, 0.0819, 0.0606, 0.1328,\n",
      "        0.0182])\n",
      "tensor(97.4800)\n",
      "tensor(97.3800)\n",
      "Round 1515, reward -0.043\n",
      "tensor([0.0298, 0.0287, 0.1985, 0.0304, 0.0279, 0.0466, 0.2058, 0.0279, 0.1986,\n",
      "        0.2058])\n",
      "tensor(96.7200)\n",
      "tensor(97.2900)\n",
      "Round 1516, reward -0.335\n",
      "tensor([0.0251, 0.0251, 0.1849, 0.0251, 0.0251, 0.1831, 0.1367, 0.0251, 0.1851,\n",
      "        0.1848])\n",
      "tensor(97.6100)\n",
      "tensor(97.9300)\n",
      "Round 1517, reward -0.260\n",
      "tensor([0.0183, 0.1351, 0.0183, 0.0183, 0.1350, 0.1346, 0.1351, 0.1351, 0.1351,\n",
      "        0.1351])\n",
      "tensor(97.4800)\n",
      "tensor(97.8800)\n",
      "Round 1518, reward -0.286\n",
      "tensor([0.0491, 0.0491, 0.1675, 0.0491, 0.3622, 0.0491, 0.0491, 0.0491, 0.0491,\n",
      "        0.1268])\n",
      "tensor(96.9900)\n",
      "tensor(97.8700)\n",
      "Round 1519, reward -0.348\n",
      "tensor([0.0439, 0.0439, 0.0443, 0.0440, 0.3238, 0.0439, 0.0439, 0.0439, 0.0439,\n",
      "        0.3244])\n",
      "tensor(96.3600)\n",
      "tensor(97.6000)\n",
      "Round 1520, reward -0.371\n",
      "tensor([0.2074, 0.0281, 0.0282, 0.2078, 0.2078, 0.0281, 0.0281, 0.2078, 0.0286,\n",
      "        0.0281])\n",
      "tensor(97.3600)\n",
      "tensor(97.6700)\n",
      "Round 1521, reward -0.264\n",
      "tensor([0.0285, 0.0285, 0.0584, 0.2107, 0.2107, 0.0285, 0.0301, 0.1654, 0.0286,\n",
      "        0.2107])\n",
      "tensor(90.3700)\n",
      "tensor(96.4600)\n",
      "Round 1522, reward -0.511\n",
      "tensor([0.0207, 0.1501, 0.1527, 0.0207, 0.1527, 0.1473, 0.0207, 0.1527, 0.1527,\n",
      "        0.0298])\n",
      "tensor(96.6000)\n",
      "tensor(94.8600)\n",
      "Round 1523, reward -0.066\n",
      "tensor([0.0275, 0.0275, 0.2027, 0.0495, 0.2034, 0.0275, 0.2034, 0.0275, 0.2034,\n",
      "        0.0275])\n",
      "tensor(94.7200)\n",
      "tensor(97.5100)\n",
      "Round 1524, reward -0.414\n",
      "tensor([0.0278, 0.0278, 0.0281, 0.2053, 0.0316, 0.2052, 0.2053, 0.0278, 0.0359,\n",
      "        0.2053])\n",
      "tensor(96.0800)\n",
      "tensor(96.1700)\n",
      "Round 1525, reward -0.174\n",
      "tensor([0.0319, 0.1920, 0.0262, 0.0260, 0.0260, 0.1920, 0.1920, 0.0960, 0.0260,\n",
      "        0.1920])\n",
      "tensor(97.2900)\n",
      "tensor(97.5000)\n",
      "Round 1526, reward -0.223\n",
      "tensor([0.2572, 0.0356, 0.0357, 0.0356, 0.0356, 0.2626, 0.2307, 0.0356, 0.0356,\n",
      "        0.0356])\n",
      "tensor(95.8400)\n",
      "tensor(95.1200)\n",
      "Round 1527, reward -0.086\n",
      "tensor([0.0244, 0.1766, 0.0244, 0.0244, 0.1803, 0.0288, 0.1803, 0.0244, 0.1606,\n",
      "        0.1759])\n",
      "tensor(96.2000)\n",
      "tensor(96.4200)\n",
      "Round 1528, reward -0.257\n",
      "tensor([0.2530, 0.0343, 0.2529, 0.2530, 0.0342, 0.0358, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342])\n",
      "tensor(95.4400)\n",
      "tensor(96.9700)\n",
      "Round 1529, reward -0.396\n",
      "tensor([0.0608, 0.0608, 0.0609, 0.0608, 0.0608, 0.0608, 0.0608, 0.4489, 0.0642,\n",
      "        0.0613])\n",
      "tensor(96.7900)\n",
      "tensor(95.9200)\n",
      "Round 1530, reward -0.061\n",
      "tensor([0.2412, 0.1621, 0.0359, 0.0326, 0.1283, 0.0326, 0.0617, 0.0326, 0.2402,\n",
      "        0.0326])\n",
      "tensor(96.4400)\n",
      "tensor(97.8100)\n",
      "Round 1531, reward -0.370\n",
      "tensor([0.1321, 0.1328, 0.0182, 0.0340, 0.1329, 0.0195, 0.1329, 0.1321, 0.1328,\n",
      "        0.1329])\n",
      "tensor(97.2200)\n",
      "tensor(97.4300)\n",
      "Round 1532, reward -0.225\n",
      "tensor([0.1752, 0.0286, 0.1752, 0.1752, 0.0237, 0.0246, 0.1752, 0.1748, 0.0237,\n",
      "        0.0237])\n",
      "tensor(95.1400)\n",
      "tensor(96.8600)\n",
      "Round 1533, reward -0.404\n",
      "tensor([0.0196, 0.0196, 0.1451, 0.1451, 0.1451, 0.0258, 0.1451, 0.1451, 0.1451,\n",
      "        0.0641])\n",
      "tensor(98.0400)\n",
      "tensor(97.8600)\n",
      "Round 1534, reward -0.027\n",
      "tensor([0.0355, 0.2620, 0.0355, 0.0355, 0.2588, 0.2290, 0.0355, 0.0374, 0.0355,\n",
      "        0.0355])\n",
      "tensor(97.1700)\n",
      "tensor(97.1200)\n",
      "Round 1535, reward -0.051\n",
      "tensor([0.1605, 0.0226, 0.0760, 0.1654, 0.0224, 0.0224, 0.1590, 0.0459, 0.1603,\n",
      "        0.1655])\n",
      "tensor(97.4600)\n",
      "tensor(97.6300)\n",
      "Round 1536, reward -0.195\n",
      "tensor([0.0276, 0.1964, 0.1963, 0.0266, 0.0522, 0.0297, 0.0266, 0.1938, 0.0546,\n",
      "        0.1964])\n",
      "tensor(96.8200)\n",
      "tensor(97.1400)\n",
      "Round 1537, reward -0.281\n",
      "tensor([0.0572, 0.0312, 0.1530, 0.0312, 0.1537, 0.0497, 0.0312, 0.0312, 0.2307,\n",
      "        0.2308])\n",
      "tensor(96.7400)\n",
      "tensor(97.0300)\n",
      "Round 1538, reward -0.273\n",
      "tensor([0.0234, 0.1727, 0.1624, 0.1718, 0.1720, 0.1424, 0.0264, 0.0234, 0.0822,\n",
      "        0.0234])\n",
      "tensor(97.3600)\n",
      "tensor(97.2600)\n",
      "Round 1539, reward -0.046\n",
      "tensor([0.0307, 0.1319, 0.2270, 0.0307, 0.0307, 0.2269, 0.0307, 0.0338, 0.0307,\n",
      "        0.2268])\n",
      "tensor(96.6600)\n",
      "tensor(97.4800)\n",
      "Round 1540, reward -0.355\n",
      "tensor([0.1235, 0.2236, 0.2245, 0.2245, 0.0304, 0.0468, 0.0304, 0.0304, 0.0357,\n",
      "        0.0304])\n",
      "tensor(96.3800)\n",
      "tensor(97.1300)\n",
      "Round 1541, reward -0.359\n",
      "tensor([0.2059, 0.0291, 0.1986, 0.2059, 0.2059, 0.0279, 0.0279, 0.0282, 0.0429,\n",
      "        0.0279])\n",
      "tensor(96.5100)\n",
      "tensor(97.6900)\n",
      "Round 1542, reward -0.367\n",
      "tensor([0.0448, 0.1593, 0.1593, 0.0216, 0.1592, 0.0216, 0.0946, 0.1589, 0.0216,\n",
      "        0.1593])\n",
      "tensor(97.4100)\n",
      "tensor(96.9800)\n",
      "Round 1543, reward -0.045\n",
      "tensor([0.0169, 0.0170, 0.1046, 0.1244, 0.1244, 0.1238, 0.1229, 0.1244, 0.1170,\n",
      "        0.1244])\n",
      "tensor(97.7900)\n",
      "tensor(97.8100)\n",
      "Round 1544, reward -0.058\n",
      "tensor([0.1531, 0.0207, 0.0207, 0.1531, 0.1530, 0.1507, 0.1531, 0.1531, 0.0207,\n",
      "        0.0216])\n",
      "tensor(95.9700)\n",
      "tensor(96.7900)\n",
      "Round 1545, reward -0.373\n",
      "tensor([0.0219, 0.0219, 0.1617, 0.1614, 0.0231, 0.1617, 0.1614, 0.0219, 0.1610,\n",
      "        0.1039])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.9800)\n",
      "tensor(97.9400)\n",
      "Round 1546, reward -0.029\n",
      "tensor([0.0237, 0.1753, 0.1616, 0.0262, 0.1753, 0.0237, 0.0237, 0.1753, 0.0400,\n",
      "        0.1753])\n",
      "tensor(97.8200)\n",
      "tensor(98.0200)\n",
      "Round 1547, reward -0.203\n",
      "tensor([0.3235, 0.0438, 0.0438, 0.0438, 0.0438, 0.0438, 0.0438, 0.3235, 0.0438,\n",
      "        0.0465])\n",
      "tensor(97.4800)\n",
      "tensor(97.5500)\n",
      "Round 1548, reward -0.119\n",
      "tensor([0.1408, 0.1407, 0.0201, 0.1408, 0.0191, 0.1407, 0.0976, 0.1408, 0.0193,\n",
      "        0.1402])\n",
      "tensor(96.7600)\n",
      "tensor(96.5600)\n",
      "Round 1549, reward -0.062\n",
      "tensor([0.0247, 0.1760, 0.1759, 0.1760, 0.1760, 0.0238, 0.1760, 0.0238, 0.0240,\n",
      "        0.0238])\n",
      "tensor(95.8600)\n",
      "tensor(96.9600)\n",
      "Round 1550, reward -0.383\n",
      "tensor([0.1957, 0.1957, 0.0266, 0.1957, 0.0265, 0.0265, 0.0268, 0.0265, 0.1957,\n",
      "        0.0845])\n",
      "tensor(96.7600)\n",
      "tensor(97.5400)\n",
      "Round 1551, reward -0.351\n",
      "tensor([0.0227, 0.0258, 0.1379, 0.1676, 0.0227, 0.1077, 0.1676, 0.1568, 0.1675,\n",
      "        0.0238])\n",
      "tensor(97.0900)\n",
      "tensor(97.2000)\n",
      "Round 1552, reward -0.164\n",
      "tensor([0.1859, 0.1947, 0.0264, 0.0319, 0.1613, 0.0264, 0.0264, 0.0264, 0.1953,\n",
      "        0.1250])\n",
      "tensor(97.7300)\n",
      "tensor(97.9400)\n",
      "Round 1553, reward -0.211\n",
      "tensor([0.0380, 0.2514, 0.2513, 0.0340, 0.2513, 0.0340, 0.0340, 0.0379, 0.0340,\n",
      "        0.0340])\n",
      "tensor(96.0500)\n",
      "tensor(97.1000)\n",
      "Round 1554, reward -0.377\n",
      "tensor([0.0203, 0.0203, 0.0422, 0.1496, 0.1484, 0.1497, 0.1497, 0.1497, 0.1497,\n",
      "        0.0203])\n",
      "tensor(97.1600)\n",
      "tensor(97.4000)\n",
      "Round 1555, reward -0.241\n",
      "tensor([0.0303, 0.2237, 0.0595, 0.0303, 0.1202, 0.2237, 0.0303, 0.0321, 0.0303,\n",
      "        0.2196])\n",
      "tensor(97.5600)\n",
      "tensor(97.8000)\n",
      "Round 1556, reward -0.230\n",
      "tensor([0.1227, 0.1226, 0.1227, 0.0249, 0.1227, 0.1154, 0.1227, 0.1071, 0.0166,\n",
      "        0.1227])\n",
      "tensor(95.9000)\n",
      "tensor(96.0900)\n",
      "Round 1557, reward -0.249\n",
      "tensor([0.0243, 0.1791, 0.0242, 0.0242, 0.0242, 0.1624, 0.1791, 0.0242, 0.1791,\n",
      "        0.1791])\n",
      "tensor(97.2100)\n",
      "tensor(97.6200)\n",
      "Round 1558, reward -0.296\n",
      "tensor([0.0422, 0.0423, 0.0423, 0.3121, 0.0803, 0.0422, 0.0422, 0.3119, 0.0422,\n",
      "        0.0422])\n",
      "tensor(97.2400)\n",
      "tensor(97.5000)\n",
      "Round 1559, reward -0.248\n",
      "tensor([0.0328, 0.0588, 0.2424, 0.0444, 0.0328, 0.2424, 0.0328, 0.2424, 0.0329,\n",
      "        0.0382])\n",
      "tensor(96.8400)\n",
      "tensor(97.3700)\n",
      "Round 1560, reward -0.327\n",
      "tensor([0.3012, 0.0482, 0.0408, 0.0408, 0.0408, 0.2828, 0.0408, 0.0408, 0.0408,\n",
      "        0.1232])\n",
      "tensor(97.3100)\n",
      "tensor(97.7300)\n",
      "Round 1561, reward -0.295\n",
      "tensor([0.2189, 0.0351, 0.2596, 0.0511, 0.0351, 0.0351, 0.2596, 0.0351, 0.0351,\n",
      "        0.0351])\n",
      "tensor(96.5100)\n",
      "tensor(97.1600)\n",
      "Round 1562, reward -0.349\n",
      "tensor([0.0716, 0.1773, 0.0322, 0.1782, 0.1120, 0.0241, 0.1782, 0.0246, 0.1776,\n",
      "        0.0241])\n",
      "tensor(97.1000)\n",
      "tensor(97.4900)\n",
      "Round 1563, reward -0.294\n",
      "tensor([0.1345, 0.1453, 0.1459, 0.1427, 0.0198, 0.0198, 0.1459, 0.1459, 0.0198,\n",
      "        0.0804])\n",
      "tensor(97.3100)\n",
      "tensor(97.2700)\n",
      "Round 1564, reward -0.048\n",
      "tensor([0.0301, 0.2224, 0.2194, 0.0301, 0.0302, 0.0304, 0.0303, 0.2221, 0.1548,\n",
      "        0.0301])\n",
      "tensor(96.7600)\n",
      "tensor(97.9300)\n",
      "Round 1565, reward -0.360\n",
      "tensor([0.0191, 0.1408, 0.1404, 0.0866, 0.1408, 0.1408, 0.1408, 0.0306, 0.0191,\n",
      "        0.1408])\n",
      "tensor(97.5200)\n",
      "tensor(97.7000)\n",
      "Round 1566, reward -0.200\n",
      "tensor([0.0373, 0.0373, 0.0372, 0.0372, 0.1115, 0.1123, 0.2748, 0.0372, 0.2740,\n",
      "        0.0412])\n",
      "tensor(97.1700)\n",
      "tensor(97.1000)\n",
      "Round 1567, reward -0.051\n",
      "tensor([0.1548, 0.1580, 0.0558, 0.0216, 0.0893, 0.0216, 0.1593, 0.1592, 0.1586,\n",
      "        0.0218])\n",
      "tensor(96.5700)\n",
      "tensor(97.2900)\n",
      "Round 1568, reward -0.352\n",
      "tensor([0.0256, 0.1809, 0.0256, 0.1182, 0.1894, 0.0257, 0.0302, 0.1894, 0.1894,\n",
      "        0.0256])\n",
      "tensor(96.0500)\n",
      "tensor(97.3100)\n",
      "Round 1569, reward -0.379\n",
      "tensor([0.0340, 0.0341, 0.0340, 0.0340, 0.0411, 0.2513, 0.0340, 0.2513, 0.0349,\n",
      "        0.2513])\n",
      "tensor(97.1000)\n",
      "tensor(97.6700)\n",
      "Round 1570, reward -0.325\n",
      "tensor([0.0319, 0.0280, 0.0280, 0.0280, 0.2070, 0.0280, 0.2070, 0.2070, 0.0280,\n",
      "        0.2070])\n",
      "tensor(96.7600)\n",
      "tensor(97.2800)\n",
      "Round 1571, reward -0.328\n",
      "tensor([0.0442, 0.3180, 0.0442, 0.0442, 0.0442, 0.0463, 0.0442, 0.0442, 0.3265,\n",
      "        0.0442])\n",
      "tensor(96.7200)\n",
      "tensor(97.7800)\n",
      "Round 1572, reward -0.360\n",
      "tensor([0.0298, 0.2201, 0.0298, 0.0299, 0.2201, 0.0298, 0.1876, 0.1773, 0.0316,\n",
      "        0.0441])\n",
      "tensor(97.0800)\n",
      "tensor(95.9800)\n",
      "Round 1573, reward -0.054\n",
      "tensor([0.0442, 0.0281, 0.0281, 0.1944, 0.0281, 0.0281, 0.2053, 0.2076, 0.2078,\n",
      "        0.0281])\n",
      "tensor(96.3300)\n",
      "tensor(96.8700)\n",
      "Round 1574, reward -0.342\n",
      "tensor([0.2073, 0.2047, 0.2073, 0.0314, 0.0281, 0.0320, 0.0281, 0.2052, 0.0281,\n",
      "        0.0280])\n",
      "tensor(96.8300)\n",
      "tensor(97.9200)\n",
      "Round 1575, reward -0.357\n",
      "tensor([0.1701, 0.0286, 0.1701, 0.1307, 0.0930, 0.0230, 0.0230, 0.0230, 0.1701,\n",
      "        0.1684])\n",
      "tensor(97.0300)\n",
      "tensor(97.7300)\n",
      "Round 1576, reward -0.339\n",
      "tensor([0.1105, 0.1384, 0.0187, 0.1384, 0.1384, 0.1384, 0.1384, 0.1384, 0.0215,\n",
      "        0.0187])\n",
      "tensor(97.2700)\n",
      "tensor(97.7200)\n",
      "Round 1577, reward -0.302\n",
      "tensor([0.0323, 0.0323, 0.0364, 0.0323, 0.0339, 0.2383, 0.2383, 0.0323, 0.1639,\n",
      "        0.1601])\n",
      "tensor(97.7800)\n",
      "tensor(98.0100)\n",
      "Round 1578, reward -0.219\n",
      "tensor([0.0229, 0.1669, 0.1660, 0.1664, 0.0237, 0.1696, 0.1002, 0.1383, 0.0229,\n",
      "        0.0230])\n",
      "tensor(96.6100)\n",
      "tensor(97.7500)\n",
      "Round 1579, reward -0.364\n",
      "tensor([0.0241, 0.1274, 0.0258, 0.1775, 0.0241, 0.1783, 0.1783, 0.0241, 0.1783,\n",
      "        0.0621])\n",
      "tensor(96.3400)\n",
      "tensor(97.6600)\n",
      "Round 1580, reward -0.372\n",
      "tensor([0.0353, 0.2604, 0.0353, 0.0353, 0.0392, 0.0353, 0.2580, 0.2202, 0.0353,\n",
      "        0.0458])\n",
      "tensor(97.3200)\n",
      "tensor(97.6300)\n",
      "Round 1581, reward -0.265\n",
      "tensor([0.0475, 0.0475, 0.0476, 0.0483, 0.3513, 0.2563, 0.0588, 0.0475, 0.0475,\n",
      "        0.0475])\n",
      "tensor(96.1500)\n",
      "tensor(97.8200)\n",
      "Round 1582, reward -0.378\n",
      "tensor([0.0243, 0.1788, 0.0247, 0.1488, 0.0242, 0.0452, 0.1769, 0.0242, 0.1787,\n",
      "        0.1743])\n",
      "tensor(97.5400)\n",
      "tensor(97.0600)\n",
      "Round 1583, reward -0.041\n",
      "tensor([0.0210, 0.1339, 0.1549, 0.0210, 0.1549, 0.1547, 0.0291, 0.1549, 0.0210,\n",
      "        0.1549])\n",
      "tensor(96.7900)\n",
      "tensor(97.3000)\n",
      "Round 1584, reward -0.325\n",
      "tensor([0.2494, 0.2508, 0.0339, 0.0377, 0.0339, 0.0339, 0.2508, 0.0339, 0.0339,\n",
      "        0.0417])\n",
      "tensor(97.2800)\n",
      "tensor(97.5700)\n",
      "Round 1585, reward -0.259\n",
      "tensor([0.0282, 0.2081, 0.0282, 0.0282, 0.2045, 0.2081, 0.0282, 0.0282, 0.2081,\n",
      "        0.0303])\n",
      "tensor(94.5300)\n",
      "tensor(96.4400)\n",
      "Round 1586, reward -0.419\n",
      "tensor([0.0271, 0.2000, 0.0628, 0.1839, 0.1997, 0.0271, 0.0271, 0.0272, 0.0454,\n",
      "        0.2000])\n",
      "tensor(96.7200)\n",
      "tensor(96.3800)\n",
      "Round 1587, reward -0.063\n",
      "tensor([0.2081, 0.2081, 0.0295, 0.0282, 0.0282, 0.0282, 0.2081, 0.2047, 0.0283,\n",
      "        0.0286])\n",
      "tensor(97.8500)\n",
      "tensor(97.7700)\n",
      "Round 1588, reward -0.033\n",
      "tensor([0.0829, 0.1253, 0.1748, 0.1732, 0.1729, 0.0238, 0.0246, 0.1748, 0.0240,\n",
      "        0.0237])\n",
      "tensor(97.6200)\n",
      "tensor(97.3800)\n",
      "Round 1589, reward -0.039\n",
      "tensor([0.1642, 0.1172, 0.0222, 0.1393, 0.0224, 0.0222, 0.1642, 0.0229, 0.1628,\n",
      "        0.1627])\n",
      "tensor(97.7500)\n",
      "tensor(98.1500)\n",
      "Round 1590, reward -0.279\n",
      "tensor([0.0289, 0.2133, 0.0289, 0.0289, 0.2132, 0.0289, 0.1870, 0.0289, 0.0289,\n",
      "        0.2133])\n",
      "tensor(97.4700)\n",
      "tensor(97.9000)\n",
      "Round 1591, reward -0.293\n",
      "tensor([0.1537, 0.1537, 0.1473, 0.0211, 0.0208, 0.1537, 0.1536, 0.0208, 0.0219,\n",
      "        0.1537])\n",
      "tensor(97.5700)\n",
      "tensor(97.6900)\n",
      "Round 1592, reward -0.158\n",
      "tensor([0.1442, 0.0207, 0.0311, 0.1526, 0.1523, 0.1526, 0.0207, 0.0207, 0.1526,\n",
      "        0.1526])\n",
      "tensor(97.0300)\n",
      "tensor(97.4000)\n",
      "Round 1593, reward -0.291\n",
      "tensor([0.0533, 0.1708, 0.1709, 0.1702, 0.0231, 0.0232, 0.1708, 0.1707, 0.0231,\n",
      "        0.0239])\n",
      "tensor(96.6400)\n",
      "tensor(97.1500)\n",
      "Round 1594, reward -0.329\n",
      "tensor([0.0505, 0.2341, 0.0318, 0.0317, 0.0803, 0.0317, 0.0353, 0.0372, 0.2345,\n",
      "        0.2329])\n",
      "tensor(97.8900)\n",
      "tensor(98.0500)\n",
      "Round 1595, reward -0.177\n",
      "tensor([0.0265, 0.0265, 0.0265, 0.0265, 0.0788, 0.1957, 0.1931, 0.1957, 0.0350,\n",
      "        0.1957])\n",
      "tensor(96.9700)\n",
      "tensor(97.4000)\n",
      "Round 1596, reward -0.306\n",
      "tensor([0.2172, 0.0297, 0.2172, 0.0294, 0.2163, 0.0294, 0.0297, 0.1678, 0.0294,\n",
      "        0.0338])\n",
      "tensor(96.8000)\n",
      "tensor(95.9500)\n",
      "Round 1597, reward -0.061\n",
      "tensor([0.0286, 0.2113, 0.0286, 0.2113, 0.1920, 0.0286, 0.2110, 0.0286, 0.0314,\n",
      "        0.0286])\n",
      "tensor(97.6500)\n",
      "tensor(97.8200)\n",
      "Round 1598, reward -0.190\n",
      "tensor([0.0251, 0.0245, 0.1539, 0.1810, 0.1810, 0.0245, 0.0245, 0.0249, 0.1810,\n",
      "        0.1796])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.6700)\n",
      "tensor(97.7700)\n",
      "Round 1599, reward -0.140\n",
      "tensor([0.2090, 0.2088, 0.0283, 0.2058, 0.0291, 0.0283, 0.0284, 0.0283, 0.2058,\n",
      "        0.0283])\n",
      "tensor(96.4800)\n",
      "tensor(97.4400)\n",
      "Round 1600, reward -0.364\n",
      "tensor([0.3207, 0.0436, 0.0435, 0.0436, 0.0435, 0.3214, 0.0531, 0.0435, 0.0435,\n",
      "        0.0435])\n",
      "tensor(9.7400)\n",
      "tensor(10.2800)\n",
      "Round 1601, reward -0.951\n",
      "tensor([0.0304, 0.0309, 0.0322, 0.0454, 0.1993, 0.2243, 0.2238, 0.1530, 0.0304,\n",
      "        0.0304])\n",
      "tensor(10.1000)\n",
      "tensor(20.2500)\n",
      "Round 1602, reward -0.983\n",
      "tensor([0.1902, 0.1889, 0.1262, 0.1874, 0.0257, 0.0257, 0.0257, 0.0257, 0.0257,\n",
      "        0.1785])\n",
      "tensor(19.6400)\n",
      "tensor(16.7700)\n",
      "Round 1603, reward -0.674\n",
      "tensor([0.0239, 0.1765, 0.0239, 0.0239, 0.0239, 0.1765, 0.1758, 0.0239, 0.1757,\n",
      "        0.1761])\n",
      "tensor(24.3000)\n",
      "tensor(21.7200)\n",
      "Round 1604, reward -0.669\n",
      "tensor([0.0252, 0.0369, 0.1764, 0.1764, 0.1764, 0.0239, 0.0240, 0.1604, 0.1764,\n",
      "        0.0239])\n",
      "tensor(29.1000)\n",
      "tensor(48.8700)\n",
      "Round 1605, reward -0.962\n",
      "tensor([0.0662, 0.0922, 0.2357, 0.0320, 0.0320, 0.2362, 0.0498, 0.0345, 0.1883,\n",
      "        0.0331])\n",
      "tensor(25.3500)\n",
      "tensor(37.4700)\n",
      "Round 1606, reward -0.967\n",
      "tensor([0.0216, 0.0216, 0.0216, 0.1159, 0.1595, 0.1595, 0.1595, 0.1595, 0.1595,\n",
      "        0.0220])\n",
      "tensor(51.8500)\n",
      "tensor(47.0800)\n",
      "Round 1607, reward -0.601\n",
      "tensor([0.0433, 0.0540, 0.0433, 0.0433, 0.0452, 0.3200, 0.3200, 0.0441, 0.0433,\n",
      "        0.0433])\n",
      "tensor(47.0600)\n",
      "tensor(38.1700)\n",
      "Round 1608, reward -0.619\n",
      "tensor([0.0409, 0.0409, 0.0409, 0.0409, 0.3019, 0.0409, 0.0923, 0.0410, 0.3019,\n",
      "        0.0587])\n",
      "tensor(50.3200)\n",
      "tensor(57.5100)\n",
      "Round 1609, reward -0.908\n",
      "tensor([0.0329, 0.0329, 0.2434, 0.0331, 0.0329, 0.2434, 0.0342, 0.2434, 0.0329,\n",
      "        0.0707])\n",
      "tensor(56.1900)\n",
      "tensor(70.6600)\n",
      "Round 1610, reward -0.882\n",
      "tensor([0.0423, 0.0423, 0.0423, 0.0423, 0.0423, 0.0778, 0.0423, 0.3129, 0.0423,\n",
      "        0.3129])\n",
      "tensor(48.8100)\n",
      "tensor(61.3000)\n",
      "Round 1611, reward -0.913\n",
      "tensor([0.0286, 0.2114, 0.1961, 0.2094, 0.0286, 0.2114, 0.0286, 0.0286, 0.0286,\n",
      "        0.0286])\n",
      "tensor(53.1600)\n",
      "tensor(55.3000)\n",
      "Round 1612, reward -0.896\n",
      "tensor([0.0279, 0.2057, 0.0278, 0.0278, 0.0381, 0.0278, 0.0278, 0.2057, 0.2056,\n",
      "        0.2057])\n",
      "tensor(62.2900)\n",
      "tensor(75.9300)\n",
      "Round 1613, reward -0.848\n",
      "tensor([0.0331, 0.2445, 0.0491, 0.0364, 0.0418, 0.2445, 0.2444, 0.0395, 0.0337,\n",
      "        0.0331])\n",
      "tensor(53.6800)\n",
      "tensor(65.2800)\n",
      "Round 1614, reward -0.894\n",
      "tensor([0.2048, 0.0277, 0.2049, 0.0672, 0.0278, 0.2050, 0.0277, 0.0289, 0.1780,\n",
      "        0.0280])\n",
      "tensor(53.9100)\n",
      "tensor(69.6200)\n",
      "Round 1615, reward -0.893\n",
      "tensor([0.1854, 0.0290, 0.0290, 0.2143, 0.2116, 0.0290, 0.0290, 0.0294, 0.0290,\n",
      "        0.2143])\n",
      "tensor(76.6900)\n",
      "tensor(77.6900)\n",
      "Round 1616, reward -0.719\n",
      "tensor([0.1453, 0.1432, 0.1453, 0.1453, 0.0197, 0.1453, 0.1453, 0.0203, 0.0708,\n",
      "        0.0197])\n",
      "tensor(70.8200)\n",
      "tensor(72.3000)\n",
      "Round 1617, reward -0.783\n",
      "tensor([0.0287, 0.0287, 0.1922, 0.0287, 0.0287, 0.2124, 0.2106, 0.0287, 0.2124,\n",
      "        0.0287])\n",
      "tensor(63.3500)\n",
      "tensor(67.0300)\n",
      "Round 1618, reward -0.841\n",
      "tensor([0.2530, 0.0342, 0.0342, 0.2530, 0.2459, 0.0342, 0.0413, 0.0342, 0.0342,\n",
      "        0.0357])\n",
      "tensor(59.2500)\n",
      "tensor(69.2900)\n",
      "Round 1619, reward -0.866\n",
      "tensor([0.1735, 0.1281, 0.1728, 0.0235, 0.0978, 0.0235, 0.1737, 0.1003, 0.0807,\n",
      "        0.0260])\n",
      "tensor(69.7400)\n",
      "tensor(70.3300)\n",
      "Round 1620, reward -0.767\n",
      "tensor([0.1860, 0.0352, 0.2010, 0.0352, 0.0356, 0.2599, 0.0373, 0.0352, 0.1395,\n",
      "        0.0352])\n",
      "tensor(68.2300)\n",
      "tensor(71.4500)\n",
      "Round 1621, reward -0.805\n",
      "tensor([0.0305, 0.0296, 0.2036, 0.2190, 0.0296, 0.1797, 0.0296, 0.2190, 0.0296,\n",
      "        0.0296])\n",
      "tensor(74.2400)\n",
      "tensor(81.7900)\n",
      "Round 1622, reward -0.750\n",
      "tensor([0.0244, 0.0259, 0.0268, 0.1558, 0.0244, 0.1805, 0.0951, 0.1805, 0.1061,\n",
      "        0.1805])\n",
      "tensor(69.9100)\n",
      "tensor(77.2800)\n",
      "Round 1623, reward -0.791\n",
      "tensor([0.0324, 0.0324, 0.0324, 0.0324, 0.2391, 0.0389, 0.2391, 0.0331, 0.0810,\n",
      "        0.2392])\n",
      "tensor(56.5700)\n",
      "tensor(67.3800)\n",
      "Round 1624, reward -0.880\n",
      "tensor([0.0342, 0.2524, 0.2527, 0.0342, 0.0342, 0.0342, 0.0342, 0.2528, 0.0342,\n",
      "        0.0369])\n",
      "tensor(66.9100)\n",
      "tensor(84.5900)\n",
      "Round 1625, reward -0.816\n",
      "tensor([0.3020, 0.0415, 0.0849, 0.0415, 0.0473, 0.3014, 0.0415, 0.0566, 0.0415,\n",
      "        0.0418])\n",
      "tensor(63.7900)\n",
      "tensor(81.2500)\n",
      "Round 1626, reward -0.838\n",
      "tensor([0.2514, 0.0346, 0.0357, 0.0345, 0.0345, 0.0346, 0.0345, 0.2506, 0.0345,\n",
      "        0.2551])\n",
      "tensor(74.2500)\n",
      "tensor(77.3000)\n",
      "Round 1627, reward -0.750\n",
      "tensor([0.0279, 0.2063, 0.2063, 0.2063, 0.0279, 0.0353, 0.0279, 0.2062, 0.0279,\n",
      "        0.0279])\n",
      "tensor(68.3400)\n",
      "tensor(83.2300)\n",
      "Round 1628, reward -0.804\n",
      "tensor([0.0281, 0.0281, 0.2077, 0.0281, 0.2077, 0.2077, 0.0284, 0.0281, 0.0284,\n",
      "        0.2077])\n",
      "tensor(73.7800)\n",
      "tensor(76.)\n",
      "Round 1629, reward -0.755\n",
      "tensor([0.0190, 0.0794, 0.1405, 0.1405, 0.1405, 0.1404, 0.1405, 0.0396, 0.0190,\n",
      "        0.1405])\n",
      "tensor(78.6300)\n",
      "tensor(78.9300)\n",
      "Round 1630, reward -0.614\n",
      "tensor([0.0192, 0.1415, 0.0192, 0.1068, 0.1407, 0.1418, 0.1418, 0.0192, 0.1279,\n",
      "        0.1419])\n",
      "tensor(62.8400)\n",
      "tensor(76.7200)\n",
      "Round 1631, reward -0.844\n",
      "tensor([0.0719, 0.0498, 0.0395, 0.1912, 0.0259, 0.1914, 0.0259, 0.1877, 0.0259,\n",
      "        0.1908])\n",
      "tensor(73.2300)\n",
      "tensor(83.5400)\n",
      "Round 1632, reward -0.760\n",
      "tensor([0.0343, 0.2533, 0.0343, 0.0343, 0.2533, 0.0343, 0.0343, 0.0343, 0.0343,\n",
      "        0.2533])\n",
      "tensor(77.7500)\n",
      "tensor(79.8400)\n",
      "Round 1633, reward -0.711\n",
      "tensor([0.0393, 0.0393, 0.1380, 0.0393, 0.1128, 0.0393, 0.2029, 0.0603, 0.2898,\n",
      "        0.0393])\n",
      "tensor(85.1600)\n",
      "tensor(85.4900)\n",
      "Round 1634, reward -0.530\n",
      "tensor([0.1756, 0.0238, 0.0238, 0.1756, 0.1756, 0.0238, 0.0238, 0.0271, 0.1756,\n",
      "        0.1755])\n",
      "tensor(77.4800)\n",
      "tensor(84.1000)\n",
      "Round 1635, reward -0.714\n",
      "tensor([0.2011, 0.0558, 0.2016, 0.0273, 0.0273, 0.2016, 0.2015, 0.0273, 0.0294,\n",
      "        0.0273])\n",
      "tensor(81.5300)\n",
      "tensor(84.3800)\n",
      "Round 1636, reward -0.661\n",
      "tensor([0.1800, 0.1800, 0.0245, 0.0244, 0.0779, 0.0244, 0.0562, 0.0726, 0.1800,\n",
      "        0.1800])\n",
      "tensor(81.5900)\n",
      "tensor(86.4000)\n",
      "Round 1637, reward -0.661\n",
      "tensor([0.1994, 0.0329, 0.0275, 0.1273, 0.0270, 0.0275, 0.1994, 0.1994, 0.0270,\n",
      "        0.1327])\n",
      "tensor(88.8100)\n",
      "tensor(85.5900)\n",
      "Round 1638, reward -0.242\n",
      "tensor([0.1776, 0.1712, 0.1766, 0.1783, 0.1751, 0.0241, 0.0241, 0.0241, 0.0246,\n",
      "        0.0241])\n",
      "tensor(85.8600)\n",
      "tensor(84.8500)\n",
      "Round 1639, reward -0.295\n",
      "tensor([0.2567, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.2431, 0.2567, 0.0349,\n",
      "        0.0347])\n",
      "tensor(77.4000)\n",
      "tensor(71.7600)\n",
      "Round 1640, reward -0.415\n",
      "tensor([0.0904, 0.0587, 0.0590, 0.4331, 0.0586, 0.0656, 0.0586, 0.0586, 0.0586,\n",
      "        0.0587])\n",
      "tensor(77.8500)\n",
      "tensor(86.6600)\n",
      "Round 1641, reward -0.710\n",
      "tensor([0.1402, 0.0190, 0.1402, 0.0764, 0.1402, 0.0190, 0.1402, 0.1402, 0.0443,\n",
      "        0.1402])\n",
      "tensor(80.2200)\n",
      "tensor(80.9400)\n",
      "Round 1642, reward -0.664\n",
      "tensor([0.0642, 0.0596, 0.0596, 0.0622, 0.0596, 0.0596, 0.0755, 0.0596, 0.4404,\n",
      "        0.0596])\n",
      "tensor(78.1100)\n",
      "tensor(81.8100)\n",
      "Round 1643, reward -0.706\n",
      "tensor([0.1724, 0.1748, 0.0238, 0.0241, 0.0237, 0.0329, 0.1748, 0.1748, 0.0238,\n",
      "        0.1748])\n",
      "tensor(81.7800)\n",
      "tensor(81.0300)\n",
      "Round 1644, reward -0.358\n",
      "tensor([0.0281, 0.0285, 0.2054, 0.2074, 0.2076, 0.0281, 0.2076, 0.0281, 0.0281,\n",
      "        0.0311])\n",
      "tensor(85.8900)\n",
      "tensor(85.4700)\n",
      "Round 1645, reward -0.294\n",
      "tensor([0.0274, 0.1575, 0.1850, 0.1729, 0.0250, 0.1668, 0.0287, 0.0265, 0.0253,\n",
      "        0.1850])\n",
      "tensor(83.1600)\n",
      "tensor(88.4400)\n",
      "Round 1646, reward -0.638\n",
      "tensor([0.0412, 0.0412, 0.1006, 0.0426, 0.0412, 0.3047, 0.0412, 0.3047, 0.0412,\n",
      "        0.0412])\n",
      "tensor(80.9600)\n",
      "tensor(81.)\n",
      "Round 1647, reward -0.415\n",
      "tensor([0.0608, 0.0607, 0.4488, 0.0617, 0.0614, 0.0608, 0.0607, 0.0607, 0.0636,\n",
      "        0.0607])\n",
      "tensor(77.4600)\n",
      "tensor(90.0200)\n",
      "Round 1648, reward -0.714\n",
      "tensor([0.0282, 0.2058, 0.0468, 0.0295, 0.0279, 0.0279, 0.0279, 0.2058, 0.2058,\n",
      "        0.1946])\n",
      "tensor(86.1600)\n",
      "tensor(83.1900)\n",
      "Round 1649, reward -0.290\n",
      "tensor([0.1690, 0.1810, 0.0245, 0.1664, 0.0245, 0.1801, 0.1810, 0.0245, 0.0245,\n",
      "        0.0245])\n",
      "tensor(88.1800)\n",
      "tensor(88.4100)\n",
      "Round 1650, reward -0.438\n",
      "tensor([0.0458, 0.0458, 0.3385, 0.0458, 0.0464, 0.0458, 0.2928, 0.0458, 0.0458,\n",
      "        0.0475])\n",
      "tensor(83.0300)\n",
      "tensor(90.4100)\n",
      "Round 1651, reward -0.640\n",
      "tensor([0.0243, 0.1796, 0.0243, 0.1795, 0.0243, 0.0243, 0.1731, 0.1664, 0.0245,\n",
      "        0.1796])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78.5500)\n",
      "tensor(87.7800)\n",
      "Round 1652, reward -0.701\n",
      "tensor([0.2077, 0.2077, 0.0281, 0.0296, 0.0285, 0.0281, 0.2077, 0.2059, 0.0282,\n",
      "        0.0284])\n",
      "tensor(82.6300)\n",
      "tensor(87.1600)\n",
      "Round 1653, reward -0.646\n",
      "tensor([0.0264, 0.1499, 0.0568, 0.1952, 0.0845, 0.1803, 0.0445, 0.0756, 0.0267,\n",
      "        0.1603])\n",
      "tensor(90.6900)\n",
      "tensor(90.8400)\n",
      "Round 1654, reward -0.344\n",
      "tensor([0.1191, 0.1903, 0.1852, 0.0280, 0.0300, 0.1899, 0.1803, 0.0258, 0.0258,\n",
      "        0.0258])\n",
      "tensor(89.7800)\n",
      "tensor(91.1000)\n",
      "Round 1655, reward -0.522\n",
      "tensor([0.0243, 0.0244, 0.0261, 0.1799, 0.1793, 0.1799, 0.0602, 0.1220, 0.0243,\n",
      "        0.1796])\n",
      "tensor(85.6500)\n",
      "tensor(86.9300)\n",
      "Round 1656, reward -0.597\n",
      "tensor([0.1437, 0.0194, 0.1161, 0.1437, 0.0195, 0.1432, 0.0916, 0.1437, 0.0355,\n",
      "        0.1437])\n",
      "tensor(84.1600)\n",
      "tensor(84.8000)\n",
      "Round 1657, reward -0.601\n",
      "tensor([0.2072, 0.1799, 0.0283, 0.0282, 0.0281, 0.0281, 0.2074, 0.0281, 0.0635,\n",
      "        0.2011])\n",
      "tensor(89.2100)\n",
      "tensor(86.9800)\n",
      "Round 1658, reward -0.234\n",
      "tensor([0.0220, 0.1627, 0.1627, 0.1627, 0.0220, 0.0862, 0.0448, 0.1544, 0.0235,\n",
      "        0.1591])\n",
      "tensor(86.6100)\n",
      "tensor(87.6600)\n",
      "Round 1659, reward -0.578\n",
      "tensor([0.1732, 0.1806, 0.0254, 0.0685, 0.1167, 0.0244, 0.0277, 0.1783, 0.1807,\n",
      "        0.0244])\n",
      "tensor(88.1500)\n",
      "tensor(86.8100)\n",
      "Round 1660, reward -0.254\n",
      "tensor([0.0345, 0.0345, 0.2492, 0.0345, 0.0345, 0.0348, 0.0345, 0.0345, 0.2550,\n",
      "        0.2537])\n",
      "tensor(81.2700)\n",
      "tensor(89.0200)\n",
      "Round 1661, reward -0.665\n",
      "tensor([0.0453, 0.0284, 0.1547, 0.1530, 0.1547, 0.1449, 0.1547, 0.1223, 0.0209,\n",
      "        0.0209])\n",
      "tensor(88.9200)\n",
      "tensor(86.9200)\n",
      "Round 1662, reward -0.240\n",
      "tensor([0.0440, 0.0440, 0.0440, 0.0440, 0.0440, 0.0442, 0.3249, 0.0440, 0.3224,\n",
      "        0.0447])\n",
      "tensor(89.2200)\n",
      "tensor(88.7700)\n",
      "Round 1663, reward -0.234\n",
      "tensor([0.0579, 0.1316, 0.0179, 0.1316, 0.1316, 0.1271, 0.1213, 0.0178, 0.1316,\n",
      "        0.1316])\n",
      "tensor(90.3000)\n",
      "tensor(91.4100)\n",
      "Round 1664, reward -0.510\n",
      "tensor([0.1369, 0.0209, 0.0267, 0.0209, 0.0209, 0.1547, 0.1547, 0.1547, 0.1547,\n",
      "        0.1547])\n",
      "tensor(91.6000)\n",
      "tensor(92.4800)\n",
      "Round 1665, reward -0.478\n",
      "tensor([0.0656, 0.0449, 0.1588, 0.0449, 0.0449, 0.1750, 0.0449, 0.0449, 0.3315,\n",
      "        0.0449])\n",
      "tensor(91.5100)\n",
      "tensor(90.4800)\n",
      "Round 1666, reward -0.187\n",
      "tensor([0.2001, 0.0271, 0.0271, 0.0696, 0.1960, 0.0367, 0.2001, 0.1891, 0.0271,\n",
      "        0.0271])\n",
      "tensor(85.4800)\n",
      "tensor(86.4600)\n",
      "Round 1667, reward -0.596\n",
      "tensor([0.0254, 0.0242, 0.0242, 0.1789, 0.1638, 0.1771, 0.0242, 0.0245, 0.1789,\n",
      "        0.1787])\n",
      "tensor(90.5300)\n",
      "tensor(91.8700)\n",
      "Round 1668, reward -0.507\n",
      "tensor([0.0263, 0.1754, 0.0844, 0.1108, 0.1754, 0.0251, 0.1754, 0.0280, 0.1754,\n",
      "        0.0237])\n",
      "tensor(88.2100)\n",
      "tensor(88.7500)\n",
      "Round 1669, reward -0.521\n",
      "tensor([0.0237, 0.1753, 0.0238, 0.1753, 0.1746, 0.1754, 0.0237, 0.0237, 0.0291,\n",
      "        0.1754])\n",
      "tensor(85.1200)\n",
      "tensor(90.5400)\n",
      "Round 1670, reward -0.607\n",
      "tensor([0.0283, 0.0283, 0.0319, 0.2049, 0.0283, 0.2065, 0.0283, 0.2067, 0.0283,\n",
      "        0.2086])\n",
      "tensor(81.3200)\n",
      "tensor(81.3800)\n",
      "Round 1671, reward -0.431\n",
      "tensor([0.0242, 0.1620, 0.1781, 0.0241, 0.0277, 0.1781, 0.1781, 0.0243, 0.0271,\n",
      "        0.1762])\n",
      "tensor(84.7800)\n",
      "tensor(83.3700)\n",
      "Round 1672, reward -0.313\n",
      "tensor([0.0532, 0.0754, 0.0419, 0.0419, 0.0419, 0.0419, 0.0420, 0.3099, 0.0419,\n",
      "        0.3099])\n",
      "tensor(81.9400)\n",
      "tensor(83.9200)\n",
      "Round 1673, reward -0.656\n",
      "tensor([0.0318, 0.2347, 0.0318, 0.2347, 0.0634, 0.0736, 0.2324, 0.0318, 0.0341,\n",
      "        0.0318])\n",
      "tensor(90.4900)\n",
      "tensor(91.8900)\n",
      "Round 1674, reward -0.508\n",
      "tensor([0.1686, 0.0232, 0.1713, 0.0232, 0.0232, 0.0232, 0.1195, 0.1701, 0.1713,\n",
      "        0.1064])\n",
      "tensor(83.9400)\n",
      "tensor(86.1800)\n",
      "Round 1675, reward -0.626\n",
      "tensor([0.0281, 0.0281, 0.0282, 0.2078, 0.2078, 0.0281, 0.0281, 0.2078, 0.2078,\n",
      "        0.0281])\n",
      "tensor(88.9600)\n",
      "tensor(88.6900)\n",
      "Round 1676, reward -0.239\n",
      "tensor([0.0435, 0.2644, 0.0360, 0.2064, 0.0360, 0.0397, 0.0360, 0.0360, 0.2660,\n",
      "        0.0360])\n",
      "tensor(88.0300)\n",
      "tensor(89.9200)\n",
      "Round 1677, reward -0.556\n",
      "tensor([0.0226, 0.1029, 0.1644, 0.0223, 0.1641, 0.0247, 0.1604, 0.1516, 0.1646,\n",
      "        0.0223])\n",
      "tensor(84.3800)\n",
      "tensor(91.5200)\n",
      "Round 1678, reward -0.619\n",
      "tensor([0.0888, 0.2207, 0.2201, 0.0299, 0.0676, 0.0299, 0.2208, 0.0587, 0.0299,\n",
      "        0.0337])\n",
      "tensor(88.5700)\n",
      "tensor(91.1500)\n",
      "Round 1679, reward -0.546\n",
      "tensor([0.1758, 0.1759, 0.0252, 0.0239, 0.1759, 0.0238, 0.1759, 0.0238, 0.0238,\n",
      "        0.1759])\n",
      "tensor(84.2400)\n",
      "tensor(85.7400)\n",
      "Round 1680, reward -0.621\n",
      "tensor([0.0327, 0.0457, 0.2413, 0.0669, 0.0327, 0.0327, 0.2414, 0.2414, 0.0327,\n",
      "        0.0327])\n",
      "tensor(90.6800)\n",
      "tensor(92.5600)\n",
      "Round 1681, reward -0.505\n",
      "tensor([0.0307, 0.0257, 0.0257, 0.1897, 0.1897, 0.1897, 0.0257, 0.0911, 0.1897,\n",
      "        0.0423])\n",
      "tensor(89.9900)\n",
      "tensor(92.6100)\n",
      "Round 1682, reward -0.519\n",
      "tensor([0.2034, 0.0489, 0.2034, 0.0275, 0.2034, 0.0276, 0.2034, 0.0275, 0.0275,\n",
      "        0.0275])\n",
      "tensor(82.0100)\n",
      "tensor(90.8900)\n",
      "Round 1683, reward -0.655\n",
      "tensor([0.2112, 0.2112, 0.1921, 0.0292, 0.2112, 0.0286, 0.0307, 0.0286, 0.0286,\n",
      "        0.0286])\n",
      "tensor(87.3100)\n",
      "tensor(87.8600)\n",
      "Round 1684, reward -0.539\n",
      "tensor([0.0305, 0.2126, 0.0305, 0.0305, 0.0305, 0.0872, 0.0308, 0.1022, 0.2199,\n",
      "        0.2253])\n",
      "tensor(77.9800)\n",
      "tensor(82.1500)\n",
      "Round 1685, reward -0.708\n",
      "tensor([0.1789, 0.0245, 0.1298, 0.1811, 0.0263, 0.0400, 0.0328, 0.1811, 0.1811,\n",
      "        0.0245])\n",
      "tensor(91.2600)\n",
      "tensor(92.7100)\n",
      "Round 1686, reward -0.492\n",
      "tensor([0.1529, 0.1529, 0.0207, 0.1529, 0.0207, 0.0207, 0.1529, 0.1529, 0.1529,\n",
      "        0.0207])\n",
      "tensor(90.1700)\n",
      "tensor(87.)\n",
      "Round 1687, reward -0.215\n",
      "tensor([0.2528, 0.2528, 0.0342, 0.0342, 0.0342, 0.0342, 0.0410, 0.2480, 0.0342,\n",
      "        0.0342])\n",
      "tensor(88.8900)\n",
      "tensor(92.9600)\n",
      "Round 1688, reward -0.540\n",
      "tensor([0.1800, 0.0244, 0.0377, 0.1804, 0.0376, 0.1804, 0.0244, 0.1303, 0.1804,\n",
      "        0.0244])\n",
      "tensor(91.2200)\n",
      "tensor(86.8800)\n",
      "Round 1689, reward -0.194\n",
      "tensor([0.3266, 0.0575, 0.0575, 0.0575, 0.2047, 0.0575, 0.0575, 0.0575, 0.0664,\n",
      "        0.0575])\n",
      "tensor(89.8700)\n",
      "tensor(91.5800)\n",
      "Round 1690, reward -0.521\n",
      "tensor([0.2119, 0.2151, 0.0293, 0.2162, 0.0293, 0.0293, 0.1811, 0.0293, 0.0293,\n",
      "        0.0293])\n",
      "tensor(91.2300)\n",
      "tensor(87.0700)\n",
      "Round 1691, reward -0.193\n",
      "tensor([0.0363, 0.2671, 0.0363, 0.1372, 0.0363, 0.0363, 0.0363, 0.2658, 0.0363,\n",
      "        0.1124])\n",
      "tensor(83.8800)\n",
      "tensor(88.9600)\n",
      "Round 1692, reward -0.627\n",
      "tensor([0.1809, 0.0245, 0.1542, 0.0245, 0.0245, 0.0245, 0.1809, 0.1808, 0.1809,\n",
      "        0.0245])\n",
      "tensor(89.1400)\n",
      "tensor(89.6000)\n",
      "Round 1693, reward -0.491\n",
      "tensor([0.1304, 0.1316, 0.0178, 0.0710, 0.1311, 0.1054, 0.1316, 0.1316, 0.0179,\n",
      "        0.1316])\n",
      "tensor(86.4600)\n",
      "tensor(86.4400)\n",
      "Round 1694, reward -0.284\n",
      "tensor([0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.2379, 0.2379, 0.0322, 0.2379,\n",
      "        0.0932])\n",
      "tensor(91.5800)\n",
      "tensor(94.5300)\n",
      "Round 1695, reward -0.486\n",
      "tensor([0.1436, 0.1561, 0.1561, 0.1554, 0.1560, 0.0259, 0.0211, 0.1435, 0.0211,\n",
      "        0.0211])\n",
      "tensor(93.9600)\n",
      "tensor(93.0300)\n",
      "Round 1696, reward -0.132\n",
      "tensor([0.0334, 0.0335, 0.2433, 0.0365, 0.0341, 0.2464, 0.2467, 0.0538, 0.0390,\n",
      "        0.0334])\n",
      "tensor(86.7400)\n",
      "tensor(89.2300)\n",
      "Round 1697, reward -0.580\n",
      "tensor([0.0342, 0.0342, 0.0342, 0.2524, 0.0342, 0.0377, 0.2524, 0.0342, 0.2524,\n",
      "        0.0342])\n",
      "tensor(89.6800)\n",
      "tensor(91.5800)\n",
      "Round 1698, reward -0.525\n",
      "tensor([0.1746, 0.0239, 0.0239, 0.0239, 0.1766, 0.1649, 0.0239, 0.1766, 0.0373,\n",
      "        0.1745])\n",
      "tensor(92.2600)\n",
      "tensor(92.4400)\n",
      "Round 1699, reward -0.329\n",
      "tensor([0.1545, 0.1544, 0.0389, 0.0209, 0.0209, 0.1190, 0.0278, 0.1545, 0.1545,\n",
      "        0.1545])\n",
      "tensor(92.2500)\n",
      "tensor(93.3400)\n",
      "Round 1700, reward -0.468\n",
      "tensor([0.2938, 0.0398, 0.1283, 0.0399, 0.2012, 0.0430, 0.0398, 0.1347, 0.0398,\n",
      "        0.0398])\n",
      "tensor(88.7500)\n",
      "tensor(93.)\n",
      "Round 1701, reward -0.543\n",
      "tensor([0.1301, 0.1337, 0.1337, 0.1333, 0.0539, 0.1121, 0.1334, 0.0181, 0.0181,\n",
      "        0.1337])\n",
      "tensor(83.2700)\n",
      "tensor(89.5400)\n",
      "Round 1702, reward -0.636\n",
      "tensor([0.0299, 0.1680, 0.0299, 0.0299, 0.2112, 0.2206, 0.0299, 0.0299, 0.2208,\n",
      "        0.0299])\n",
      "tensor(84.8100)\n",
      "tensor(93.3200)\n",
      "Round 1703, reward -0.612\n",
      "tensor([0.0299, 0.0299, 0.0299, 0.2211, 0.0299, 0.2212, 0.1554, 0.0299, 0.0314,\n",
      "        0.2212])\n",
      "tensor(89.6300)\n",
      "tensor(86.2600)\n",
      "Round 1704, reward -0.226\n",
      "tensor([0.0286, 0.0286, 0.2111, 0.0286, 0.2111, 0.0286, 0.1951, 0.0286, 0.0286,\n",
      "        0.2111])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.0700)\n",
      "tensor(94.1500)\n",
      "Round 1705, reward -0.450\n",
      "tensor([0.0244, 0.1795, 0.1801, 0.0250, 0.0248, 0.1801, 0.0244, 0.1571, 0.1801,\n",
      "        0.0244])\n",
      "tensor(92.9700)\n",
      "tensor(92.9000)\n",
      "Round 1706, reward -0.155\n",
      "tensor([0.1738, 0.0248, 0.1732, 0.0243, 0.1773, 0.1773, 0.0241, 0.0240, 0.0240,\n",
      "        0.1773])\n",
      "tensor(92.4500)\n",
      "tensor(93.7100)\n",
      "Round 1707, reward -0.465\n",
      "tensor([0.2223, 0.0301, 0.0301, 0.1617, 0.2130, 0.0310, 0.2137, 0.0363, 0.0301,\n",
      "        0.0317])\n",
      "tensor(92.2200)\n",
      "tensor(93.7000)\n",
      "Round 1708, reward -0.471\n",
      "tensor([0.0363, 0.0363, 0.2052, 0.2684, 0.2683, 0.0363, 0.0366, 0.0363, 0.0399,\n",
      "        0.0363])\n",
      "tensor(88.8000)\n",
      "tensor(90.7400)\n",
      "Round 1709, reward -0.542\n",
      "tensor([0.1742, 0.0236, 0.1743, 0.0236, 0.0780, 0.1744, 0.1582, 0.0236, 0.1463,\n",
      "        0.0236])\n",
      "tensor(87.1300)\n",
      "tensor(88.0200)\n",
      "Round 1710, reward -0.565\n",
      "tensor([0.0343, 0.0343, 0.0343, 0.2531, 0.2532, 0.0343, 0.0348, 0.2532, 0.0343,\n",
      "        0.0343])\n",
      "tensor(89.2600)\n",
      "tensor(94.1300)\n",
      "Round 1711, reward -0.533\n",
      "tensor([0.2501, 0.0338, 0.2419, 0.0346, 0.0531, 0.0339, 0.0338, 0.2501, 0.0348,\n",
      "        0.0338])\n",
      "tensor(80.1200)\n",
      "tensor(91.2300)\n",
      "Round 1712, reward -0.681\n",
      "tensor([0.0281, 0.0281, 0.2077, 0.2077, 0.2077, 0.0281, 0.0281, 0.2077, 0.0286,\n",
      "        0.0281])\n",
      "tensor(86.0700)\n",
      "tensor(91.1600)\n",
      "Round 1713, reward -0.591\n",
      "tensor([0.1688, 0.0241, 0.1782, 0.0260, 0.0241, 0.1779, 0.1745, 0.0241, 0.0241,\n",
      "        0.1782])\n",
      "tensor(81.0800)\n",
      "tensor(80.3000)\n",
      "Round 1714, reward -0.368\n",
      "tensor([0.0434, 0.0434, 0.3199, 0.0499, 0.0434, 0.0434, 0.0434, 0.0434, 0.3159,\n",
      "        0.0540])\n",
      "tensor(81.9400)\n",
      "tensor(92.9900)\n",
      "Round 1715, reward -0.656\n",
      "tensor([0.2035, 0.0283, 0.0283, 0.2088, 0.0283, 0.0285, 0.2089, 0.0283, 0.0283,\n",
      "        0.2089])\n",
      "tensor(88.5900)\n",
      "tensor(90.1300)\n",
      "Round 1716, reward -0.545\n",
      "tensor([0.0240, 0.1775, 0.1746, 0.0240, 0.0240, 0.1731, 0.1771, 0.0240, 0.0240,\n",
      "        0.1775])\n",
      "tensor(82.8100)\n",
      "tensor(87.2400)\n",
      "Round 1717, reward -0.643\n",
      "tensor([0.0245, 0.1806, 0.0246, 0.1808, 0.1808, 0.0491, 0.0245, 0.0245, 0.1779,\n",
      "        0.1327])\n",
      "tensor(87.4000)\n",
      "tensor(87.3300)\n",
      "Round 1718, reward -0.268\n",
      "tensor([0.1888, 0.0265, 0.1961, 0.0268, 0.0265, 0.1961, 0.1961, 0.0265, 0.0282,\n",
      "        0.0884])\n",
      "tensor(91.9300)\n",
      "tensor(94.7400)\n",
      "Round 1719, reward -0.478\n",
      "tensor([0.2077, 0.0282, 0.0287, 0.0281, 0.0281, 0.2077, 0.2077, 0.2075, 0.0281,\n",
      "        0.0281])\n",
      "tensor(90.4900)\n",
      "tensor(92.9500)\n",
      "Round 1720, reward -0.509\n",
      "tensor([0.4283, 0.0584, 0.0651, 0.0660, 0.0584, 0.0584, 0.0665, 0.0585, 0.0584,\n",
      "        0.0818])\n",
      "tensor(92.5700)\n",
      "tensor(94.1400)\n",
      "Round 1721, reward -0.464\n",
      "tensor([0.1416, 0.0414, 0.0414, 0.3047, 0.0414, 0.0414, 0.0415, 0.2639, 0.0414,\n",
      "        0.0414])\n",
      "tensor(87.6900)\n",
      "tensor(93.5100)\n",
      "Round 1722, reward -0.563\n",
      "tensor([0.0256, 0.0239, 0.1762, 0.1758, 0.0238, 0.1761, 0.0238, 0.1762, 0.0238,\n",
      "        0.1748])\n",
      "tensor(92.0400)\n",
      "tensor(93.6100)\n",
      "Round 1723, reward -0.475\n",
      "tensor([0.0331, 0.0331, 0.0331, 0.0331, 0.2444, 0.0331, 0.0331, 0.2441, 0.0707,\n",
      "        0.2424])\n",
      "tensor(84.0300)\n",
      "tensor(86.8000)\n",
      "Round 1724, reward -0.624\n",
      "tensor([0.0443, 0.0546, 0.0443, 0.0443, 0.0443, 0.0486, 0.0448, 0.3274, 0.3030,\n",
      "        0.0443])\n",
      "tensor(84.3700)\n",
      "tensor(85.4400)\n",
      "Round 1725, reward -0.616\n",
      "tensor([0.1915, 0.0259, 0.1913, 0.0956, 0.0259, 0.1914, 0.0259, 0.1651, 0.0328,\n",
      "        0.0545])\n",
      "tensor(91.4900)\n",
      "tensor(89.4400)\n",
      "Round 1726, reward -0.188\n",
      "tensor([0.2697, 0.0365, 0.2697, 0.2048, 0.0365, 0.0365, 0.0365, 0.0365, 0.0366,\n",
      "        0.0365])\n",
      "tensor(88.5800)\n",
      "tensor(94.0500)\n",
      "Round 1727, reward -0.546\n",
      "tensor([0.0335, 0.2043, 0.0335, 0.0344, 0.0334, 0.2463, 0.2351, 0.1100, 0.0361,\n",
      "        0.0334])\n",
      "tensor(82.0900)\n",
      "tensor(88.7900)\n",
      "Round 1728, reward -0.654\n",
      "tensor([0.0357, 0.0344, 0.0344, 0.0375, 0.0344, 0.2471, 0.0344, 0.2539, 0.0344,\n",
      "        0.2540])\n",
      "tensor(88.9000)\n",
      "tensor(93.2800)\n",
      "Round 1729, reward -0.540\n",
      "tensor([0.1522, 0.1681, 0.1680, 0.0228, 0.1681, 0.0228, 0.0228, 0.1681, 0.0228,\n",
      "        0.0844])\n",
      "tensor(91.5000)\n",
      "tensor(90.7300)\n",
      "Round 1730, reward -0.188\n",
      "tensor([0.0341, 0.0341, 0.2518, 0.0341, 0.2518, 0.2518, 0.0341, 0.0341, 0.0341,\n",
      "        0.0399])\n",
      "tensor(90.7300)\n",
      "tensor(93.4800)\n",
      "Round 1731, reward -0.504\n",
      "tensor([0.3184, 0.0431, 0.0431, 0.0431, 0.0431, 0.0614, 0.3184, 0.0431, 0.0432,\n",
      "        0.0431])\n",
      "tensor(93.1700)\n",
      "tensor(92.8100)\n",
      "Round 1732, reward -0.151\n",
      "tensor([0.2481, 0.0344, 0.0343, 0.0384, 0.0348, 0.0343, 0.2535, 0.0343, 0.0343,\n",
      "        0.2535])\n",
      "tensor(89.3300)\n",
      "tensor(91.2700)\n",
      "Round 1733, reward -0.532\n",
      "tensor([0.2083, 0.2049, 0.0282, 0.0282, 0.2083, 0.0282, 0.0283, 0.0282, 0.2080,\n",
      "        0.0295])\n",
      "tensor(87.2600)\n",
      "tensor(87.9100)\n",
      "Round 1734, reward -0.550\n",
      "tensor([0.2591, 0.2537, 0.0351, 0.0351, 0.0351, 0.2411, 0.0351, 0.0351, 0.0354,\n",
      "        0.0353])\n",
      "tensor(94.7100)\n",
      "tensor(93.8700)\n",
      "Round 1735, reward -0.114\n",
      "tensor([0.1388, 0.1662, 0.1661, 0.1659, 0.1068, 0.0225, 0.0225, 0.0225, 0.1662,\n",
      "        0.0225])\n",
      "tensor(91.1400)\n",
      "tensor(90.6700)\n",
      "Round 1736, reward -0.195\n",
      "tensor([0.1542, 0.0232, 0.1542, 0.1542, 0.0209, 0.1432, 0.0209, 0.1542, 0.1542,\n",
      "        0.0209])\n",
      "tensor(91.5700)\n",
      "tensor(91.5300)\n",
      "Round 1737, reward -0.186\n",
      "tensor([0.1443, 0.1791, 0.1778, 0.1791, 0.0244, 0.0242, 0.0243, 0.0242, 0.0434,\n",
      "        0.1791])\n",
      "tensor(91.3200)\n",
      "tensor(91.4600)\n",
      "Round 1738, reward -0.324\n",
      "tensor([0.0418, 0.2217, 0.0300, 0.2215, 0.0552, 0.0300, 0.0300, 0.1183, 0.2215,\n",
      "        0.0300])\n",
      "tensor(93.1400)\n",
      "tensor(94.2600)\n",
      "Round 1739, reward -0.449\n",
      "tensor([0.1540, 0.1539, 0.0209, 0.1541, 0.1456, 0.0209, 0.1540, 0.0218, 0.0209,\n",
      "        0.1541])\n",
      "tensor(90.1900)\n",
      "tensor(90.2800)\n",
      "Round 1740, reward -0.308\n",
      "tensor([0.1511, 0.0251, 0.1802, 0.1836, 0.0249, 0.1836, 0.0249, 0.0249, 0.0488,\n",
      "        0.1530])\n",
      "tensor(89.9100)\n",
      "tensor(91.8500)\n",
      "Round 1741, reward -0.520\n",
      "tensor([0.1561, 0.1561, 0.1561, 0.1498, 0.1418, 0.1550, 0.0211, 0.0211, 0.0217,\n",
      "        0.0213])\n",
      "tensor(84.9400)\n",
      "tensor(92.9100)\n",
      "Round 1742, reward -0.610\n",
      "tensor([0.0330, 0.0330, 0.0744, 0.2440, 0.0330, 0.0331, 0.2441, 0.2391, 0.0330,\n",
      "        0.0331])\n",
      "tensor(88.6900)\n",
      "tensor(94.)\n",
      "Round 1743, reward -0.544\n",
      "tensor([0.0343, 0.2532, 0.0343, 0.0343, 0.2527, 0.0343, 0.0353, 0.0343, 0.2532,\n",
      "        0.0343])\n",
      "tensor(92.9700)\n",
      "tensor(95.2600)\n",
      "Round 1744, reward -0.455\n",
      "tensor([0.0278, 0.0278, 0.2052, 0.0279, 0.0453, 0.2051, 0.0278, 0.0278, 0.2005,\n",
      "        0.2049])\n",
      "tensor(90.2400)\n",
      "tensor(91.4300)\n",
      "Round 1745, reward -0.512\n",
      "tensor([0.2989, 0.0413, 0.0847, 0.0405, 0.0405, 0.0405, 0.0405, 0.2990, 0.0737,\n",
      "        0.0405])\n",
      "tensor(92.5900)\n",
      "tensor(93.7900)\n",
      "Round 1746, reward -0.462\n",
      "tensor([0.0284, 0.0284, 0.0284, 0.2084, 0.2096, 0.0284, 0.0286, 0.0284, 0.2017,\n",
      "        0.2097])\n",
      "tensor(93.0600)\n",
      "tensor(93.5100)\n",
      "Round 1747, reward -0.407\n",
      "tensor([0.0237, 0.0237, 0.1750, 0.1750, 0.0237, 0.1748, 0.0257, 0.1751, 0.0283,\n",
      "        0.1749])\n",
      "tensor(93.7600)\n",
      "tensor(95.5900)\n",
      "Round 1748, reward -0.437\n",
      "tensor([0.1762, 0.0238, 0.1762, 0.0238, 0.1761, 0.1762, 0.0239, 0.0239, 0.1762,\n",
      "        0.0239])\n",
      "tensor(92.7700)\n",
      "tensor(93.7800)\n",
      "Round 1749, reward -0.455\n",
      "tensor([0.2418, 0.0342, 0.0342, 0.0342, 0.0344, 0.0444, 0.0342, 0.2526, 0.2526,\n",
      "        0.0374])\n",
      "tensor(92.3000)\n",
      "tensor(93.6100)\n",
      "Round 1750, reward -0.469\n",
      "tensor([0.0238, 0.0238, 0.1760, 0.1760, 0.0247, 0.1760, 0.1760, 0.1760, 0.0238,\n",
      "        0.0238])\n",
      "tensor(92.7800)\n",
      "tensor(94.4000)\n",
      "Round 1751, reward -0.459\n",
      "tensor([0.1711, 0.0256, 0.0259, 0.1890, 0.1341, 0.0256, 0.0256, 0.1882, 0.0256,\n",
      "        0.1892])\n",
      "tensor(86.9200)\n",
      "tensor(87.4900)\n",
      "Round 1752, reward -0.548\n",
      "tensor([0.0301, 0.0699, 0.0896, 0.0308, 0.0301, 0.0301, 0.2015, 0.2222, 0.0791,\n",
      "        0.2167])\n",
      "tensor(94.4900)\n",
      "tensor(94.7700)\n",
      "Round 1753, reward -0.326\n",
      "tensor([0.0448, 0.0448, 0.0448, 0.0448, 0.0449, 0.0448, 0.0448, 0.3102, 0.0448,\n",
      "        0.3312])\n",
      "tensor(88.2500)\n",
      "tensor(93.5900)\n",
      "Round 1754, reward -0.552\n",
      "tensor([0.1633, 0.0221, 0.1581, 0.1207, 0.1634, 0.0221, 0.0221, 0.0296, 0.1380,\n",
      "        0.1606])\n",
      "tensor(94.9400)\n",
      "tensor(94.7100)\n",
      "Round 1755, reward -0.109\n",
      "tensor([0.0326, 0.0325, 0.0898, 0.0325, 0.0325, 0.0325, 0.2401, 0.0443, 0.2401,\n",
      "        0.2232])\n",
      "tensor(94.3300)\n",
      "tensor(94.0100)\n",
      "Round 1756, reward -0.124\n",
      "tensor([0.0365, 0.0371, 0.0365, 0.0365, 0.2011, 0.0365, 0.0365, 0.2700, 0.2700,\n",
      "        0.0391])\n",
      "tensor(89.1800)\n",
      "tensor(92.7500)\n",
      "Round 1757, reward -0.535\n",
      "tensor([0.0281, 0.2079, 0.0281, 0.2076, 0.0281, 0.0281, 0.0281, 0.2079, 0.0281,\n",
      "        0.2078])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88.7100)\n",
      "tensor(93.4500)\n",
      "Round 1758, reward -0.544\n",
      "tensor([0.0850, 0.0867, 0.0850, 0.0850, 0.0956, 0.0850, 0.0897, 0.2177, 0.0850,\n",
      "        0.0850])\n",
      "tensor(90.9100)\n",
      "tensor(86.2300)\n",
      "Round 1759, reward -0.200\n",
      "tensor([0.0291, 0.2149, 0.0291, 0.0311, 0.0291, 0.2142, 0.0291, 0.1849, 0.2094,\n",
      "        0.0291])\n",
      "tensor(94.3900)\n",
      "tensor(94.2600)\n",
      "Round 1760, reward -0.122\n",
      "tensor([0.0425, 0.0425, 0.0718, 0.0425, 0.3142, 0.0474, 0.0425, 0.0425, 0.0425,\n",
      "        0.3114])\n",
      "tensor(89.0800)\n",
      "tensor(93.3900)\n",
      "Round 1761, reward -0.537\n",
      "tensor([0.2535, 0.0343, 0.0343, 0.0343, 0.0343, 0.2532, 0.2532, 0.0343, 0.0343,\n",
      "        0.0343])\n",
      "tensor(90.9000)\n",
      "tensor(93.2200)\n",
      "Round 1762, reward -0.500\n",
      "tensor([0.1064, 0.3024, 0.0415, 0.0410, 0.0412, 0.0410, 0.0413, 0.0410, 0.3027,\n",
      "        0.0414])\n",
      "tensor(94.5100)\n",
      "tensor(94.4500)\n",
      "Round 1763, reward -0.119\n",
      "tensor([0.1643, 0.1412, 0.0225, 0.1643, 0.0222, 0.0292, 0.1534, 0.1643, 0.0235,\n",
      "        0.1152])\n",
      "tensor(93.2800)\n",
      "tensor(94.1200)\n",
      "Round 1764, reward -0.439\n",
      "tensor([0.1906, 0.0275, 0.2033, 0.0275, 0.2012, 0.0640, 0.0276, 0.0275, 0.2033,\n",
      "        0.0275])\n",
      "tensor(92.1200)\n",
      "tensor(93.3300)\n",
      "Round 1765, reward -0.472\n",
      "tensor([0.1898, 0.0259, 0.1912, 0.0267, 0.0259, 0.0259, 0.0260, 0.1302, 0.1674,\n",
      "        0.1912])\n",
      "tensor(94.5100)\n",
      "tensor(95.3300)\n",
      "Round 1766, reward -0.409\n",
      "tensor([0.0239, 0.1753, 0.0239, 0.0239, 0.1764, 0.1764, 0.0239, 0.1764, 0.1762,\n",
      "        0.0239])\n",
      "tensor(94.3100)\n",
      "tensor(95.3300)\n",
      "Round 1767, reward -0.420\n",
      "tensor([0.1300, 0.0309, 0.0286, 0.1973, 0.2116, 0.0286, 0.0289, 0.0286, 0.2029,\n",
      "        0.1125])\n",
      "tensor(92.3900)\n",
      "tensor(92.7000)\n",
      "Round 1768, reward -0.386\n",
      "tensor([0.0438, 0.0438, 0.0456, 0.3234, 0.0438, 0.0445, 0.0443, 0.0438, 0.0438,\n",
      "        0.3234])\n",
      "tensor(87.1900)\n",
      "tensor(94.1000)\n",
      "Round 1769, reward -0.572\n",
      "tensor([0.0558, 0.0572, 0.4062, 0.0558, 0.0558, 0.1211, 0.0780, 0.0558, 0.0566,\n",
      "        0.0578])\n",
      "tensor(90.5900)\n",
      "tensor(95.2300)\n",
      "Round 1770, reward -0.507\n",
      "tensor([0.0315, 0.1675, 0.1675, 0.1672, 0.0227, 0.0227, 0.0668, 0.1654, 0.0227,\n",
      "        0.1660])\n",
      "tensor(90.7000)\n",
      "tensor(91.8800)\n",
      "Round 1771, reward -0.502\n",
      "tensor([0.1784, 0.0241, 0.0243, 0.1784, 0.0241, 0.0241, 0.1775, 0.1784, 0.0241,\n",
      "        0.1666])\n",
      "tensor(86.1000)\n",
      "tensor(92.4900)\n",
      "Round 1772, reward -0.591\n",
      "tensor([0.1978, 0.1933, 0.1905, 0.0268, 0.1978, 0.0268, 0.0279, 0.0269, 0.0855,\n",
      "        0.0268])\n",
      "tensor(87.8400)\n",
      "tensor(89.0400)\n",
      "Round 1773, reward -0.558\n",
      "tensor([0.0442, 0.3242, 0.0439, 0.0440, 0.3241, 0.0439, 0.0439, 0.0439, 0.0439,\n",
      "        0.0440])\n",
      "tensor(87.6300)\n",
      "tensor(90.0300)\n",
      "Round 1774, reward -0.564\n",
      "tensor([0.0368, 0.0368, 0.2722, 0.0368, 0.0369, 0.0368, 0.0506, 0.1842, 0.2720,\n",
      "        0.0368])\n",
      "tensor(85.5300)\n",
      "tensor(90.8600)\n",
      "Round 1775, reward -0.600\n",
      "tensor([0.0279, 0.2059, 0.2063, 0.0333, 0.0279, 0.0279, 0.0296, 0.0284, 0.2063,\n",
      "        0.2063])\n",
      "tensor(86.6600)\n",
      "tensor(92.4600)\n",
      "Round 1776, reward -0.581\n",
      "tensor([0.0399, 0.2681, 0.2946, 0.0399, 0.1499, 0.0399, 0.0399, 0.0417, 0.0464,\n",
      "        0.0399])\n",
      "tensor(92.5800)\n",
      "tensor(94.4000)\n",
      "Round 1777, reward -0.464\n",
      "tensor([0.0345, 0.2539, 0.1449, 0.1282, 0.0459, 0.0344, 0.0350, 0.0344, 0.2538,\n",
      "        0.0351])\n",
      "tensor(87.0600)\n",
      "tensor(95.1700)\n",
      "Round 1778, reward -0.574\n",
      "tensor([0.0443, 0.0443, 0.0443, 0.0445, 0.0445, 0.0443, 0.3276, 0.0443, 0.0443,\n",
      "        0.3174])\n",
      "tensor(92.2400)\n",
      "tensor(93.9400)\n",
      "Round 1779, reward -0.471\n",
      "tensor([0.0349, 0.2552, 0.0360, 0.0349, 0.0349, 0.0349, 0.0349, 0.2421, 0.2576,\n",
      "        0.0349])\n",
      "tensor(93.2900)\n",
      "tensor(94.9300)\n",
      "Round 1780, reward -0.448\n",
      "tensor([0.0443, 0.2880, 0.0443, 0.0443, 0.3277, 0.0446, 0.0444, 0.0443, 0.0443,\n",
      "        0.0737])\n",
      "tensor(94.7500)\n",
      "tensor(95.8400)\n",
      "Round 1781, reward -0.410\n",
      "tensor([0.2233, 0.0304, 0.0304, 0.2168, 0.2246, 0.0304, 0.1517, 0.0304, 0.0316,\n",
      "        0.0304])\n",
      "tensor(86.7100)\n",
      "tensor(94.1000)\n",
      "Round 1782, reward -0.580\n",
      "tensor([0.2616, 0.0355, 0.0365, 0.0354, 0.0354, 0.2356, 0.0365, 0.2527, 0.0354,\n",
      "        0.0354])\n",
      "tensor(84.6900)\n",
      "tensor(86.7300)\n",
      "Round 1783, reward -0.614\n",
      "tensor([0.1483, 0.1444, 0.0539, 0.1483, 0.0205, 0.0201, 0.1478, 0.0201, 0.1483,\n",
      "        0.1483])\n",
      "tensor(92.1900)\n",
      "tensor(93.9800)\n",
      "Round 1784, reward -0.472\n",
      "tensor([0.3204, 0.0434, 0.0449, 0.0434, 0.0434, 0.0434, 0.3203, 0.0434, 0.0542,\n",
      "        0.0434])\n",
      "tensor(81.9800)\n",
      "tensor(93.1500)\n",
      "Round 1785, reward -0.655\n",
      "tensor([0.0371, 0.0371, 0.0371, 0.0371, 0.0392, 0.2738, 0.0371, 0.1944, 0.0371,\n",
      "        0.2702])\n",
      "tensor(91.9300)\n",
      "tensor(94.6500)\n",
      "Round 1786, reward -0.478\n",
      "tensor([0.0281, 0.0281, 0.0286, 0.1997, 0.0282, 0.1888, 0.0281, 0.2075, 0.2017,\n",
      "        0.0614])\n",
      "tensor(92.1500)\n",
      "tensor(93.8800)\n",
      "Round 1787, reward -0.473\n",
      "tensor([0.2508, 0.0339, 0.2507, 0.0339, 0.0340, 0.0351, 0.2507, 0.0339, 0.0430,\n",
      "        0.0339])\n",
      "tensor(94.0500)\n",
      "tensor(92.2200)\n",
      "Round 1788, reward -0.130\n",
      "tensor([0.0708, 0.1693, 0.0547, 0.2896, 0.0394, 0.0393, 0.0393, 0.0393, 0.0393,\n",
      "        0.2191])\n",
      "tensor(92.2600)\n",
      "tensor(95.4400)\n",
      "Round 1789, reward -0.471\n",
      "tensor([0.0988, 0.0989, 0.0988, 0.0988, 0.1104, 0.0991, 0.0989, 0.0988, 0.0988,\n",
      "        0.0988])\n",
      "tensor(95.0900)\n",
      "tensor(95.1600)\n",
      "Round 1790, reward -0.181\n",
      "tensor([0.1789, 0.0242, 0.0320, 0.0242, 0.1757, 0.1729, 0.0564, 0.0282, 0.1285,\n",
      "        0.1789])\n",
      "tensor(94.7400)\n",
      "tensor(94.9500)\n",
      "Round 1791, reward -0.288\n",
      "tensor([0.0295, 0.2180, 0.0295, 0.2153, 0.0295, 0.2180, 0.1704, 0.0308, 0.0295,\n",
      "        0.0295])\n",
      "tensor(95.3300)\n",
      "tensor(96.)\n",
      "Round 1792, reward -0.381\n",
      "tensor([0.2195, 0.0384, 0.2195, 0.0297, 0.2195, 0.1484, 0.0297, 0.0297, 0.0349,\n",
      "        0.0308])\n",
      "tensor(93.9700)\n",
      "tensor(95.0700)\n",
      "Round 1793, reward -0.429\n",
      "tensor([0.0253, 0.0513, 0.1873, 0.1872, 0.0253, 0.1092, 0.0253, 0.0253, 0.1766,\n",
      "        0.1871])\n",
      "tensor(90.2400)\n",
      "tensor(93.5100)\n",
      "Round 1794, reward -0.514\n",
      "tensor([0.0337, 0.2493, 0.0337, 0.2386, 0.0340, 0.0767, 0.0338, 0.0337, 0.0343,\n",
      "        0.2321])\n",
      "tensor(95.2600)\n",
      "tensor(96.1600)\n",
      "Round 1795, reward -0.394\n",
      "tensor([0.0286, 0.0286, 0.2075, 0.0286, 0.2112, 0.2112, 0.0286, 0.0286, 0.1987,\n",
      "        0.0286])\n",
      "tensor(92.9700)\n",
      "tensor(95.3400)\n",
      "Round 1796, reward -0.455\n",
      "tensor([0.0320, 0.0320, 0.2361, 0.0320, 0.2299, 0.0908, 0.2361, 0.0474, 0.0320,\n",
      "        0.0320])\n",
      "tensor(92.1700)\n",
      "tensor(94.9400)\n",
      "Round 1797, reward -0.473\n",
      "tensor([0.2833, 0.0385, 0.0384, 0.0384, 0.0384, 0.1544, 0.0384, 0.2841, 0.0384,\n",
      "        0.0475])\n",
      "tensor(90.7900)\n",
      "tensor(95.4300)\n",
      "Round 1798, reward -0.502\n",
      "tensor([0.0591, 0.4368, 0.0591, 0.0606, 0.0591, 0.0591, 0.0591, 0.0591, 0.0638,\n",
      "        0.0841])\n",
      "tensor(91.1900)\n",
      "tensor(95.3600)\n",
      "Round 1799, reward -0.494\n",
      "tensor([0.2513, 0.0347, 0.0346, 0.0346, 0.2505, 0.0346, 0.0346, 0.2557, 0.0349,\n",
      "        0.0346])\n",
      "tensor(85.2800)\n",
      "tensor(92.8100)\n",
      "Round 1800, reward -0.604\n",
      "tensor([0.0411, 0.0411, 0.0412, 0.0411, 0.0411, 0.2316, 0.1573, 0.0411, 0.3038,\n",
      "        0.0606])\n",
      "tensor(85.5800)\n",
      "tensor(87.3900)\n",
      "Round 1801, reward -0.599\n",
      "tensor([0.2003, 0.1990, 0.0271, 0.0271, 0.2000, 0.2003, 0.0397, 0.0273, 0.0271,\n",
      "        0.0523])\n",
      "tensor(93.7100)\n",
      "tensor(95.5000)\n",
      "Round 1802, reward -0.438\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "tensor(93.6600)\n",
      "tensor(93.6600)\n",
      "Round 1803, reward -0.139\n",
      "tensor([0.0437, 0.3229, 0.0438, 0.0437, 0.0437, 0.3229, 0.0437, 0.0437, 0.0483,\n",
      "        0.0437])\n",
      "tensor(94.7800)\n",
      "tensor(95.7300)\n",
      "Round 1804, reward -0.407\n",
      "tensor([0.0431, 0.0429, 0.0429, 0.0429, 0.0656, 0.0430, 0.0429, 0.3169, 0.0430,\n",
      "        0.3169])\n",
      "tensor(95.5400)\n",
      "tensor(95.6000)\n",
      "Round 1805, reward -0.160\n",
      "tensor([0.0343, 0.2532, 0.2525, 0.0343, 0.0355, 0.0343, 0.0343, 0.0343, 0.0343,\n",
      "        0.2532])\n",
      "tensor(92.7800)\n",
      "tensor(95.1500)\n",
      "Round 1806, reward -0.460\n",
      "tensor([0.1332, 0.0649, 0.0649, 0.0649, 0.3452, 0.0649, 0.0649, 0.0649, 0.0666,\n",
      "        0.0657])\n",
      "tensor(85.4400)\n",
      "tensor(90.3800)\n",
      "Round 1807, reward -0.602\n",
      "tensor([0.2301, 0.0335, 0.2301, 0.2231, 0.0311, 0.0311, 0.1272, 0.0313, 0.0312,\n",
      "        0.0312])\n",
      "tensor(90.3200)\n",
      "tensor(92.9500)\n",
      "Round 1808, reward -0.512\n",
      "tensor([0.0538, 0.0537, 0.0537, 0.0537, 0.0537, 0.1739, 0.0537, 0.3966, 0.0537,\n",
      "        0.0537])\n",
      "tensor(91.7800)\n",
      "tensor(93.3000)\n",
      "Round 1809, reward -0.481\n",
      "tensor([0.0439, 0.0439, 0.0439, 0.0439, 0.3246, 0.0439, 0.3240, 0.0439, 0.0439,\n",
      "        0.0439])\n",
      "tensor(90.2500)\n",
      "tensor(94.6500)\n",
      "Round 1810, reward -0.514\n",
      "tensor([0.1937, 0.0290, 0.0283, 0.2089, 0.0379, 0.0283, 0.0283, 0.0283, 0.2086,\n",
      "        0.2088])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(92.2800)\n",
      "tensor(95.2800)\n",
      "Round 1811, reward -0.471\n",
      "tensor([0.0554, 0.4092, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554,\n",
      "        0.1474])\n",
      "tensor(92.8100)\n",
      "tensor(94.1500)\n",
      "Round 1812, reward -0.458\n",
      "tensor([0.0362, 0.2673, 0.2122, 0.0362, 0.0362, 0.2673, 0.0362, 0.0362, 0.0362,\n",
      "        0.0362])\n",
      "tensor(91.9600)\n",
      "tensor(94.0300)\n",
      "Round 1813, reward -0.478\n",
      "tensor([0.1578, 0.1578, 0.1578, 0.0214, 0.0214, 0.1557, 0.1575, 0.0215, 0.0214,\n",
      "        0.1277])\n",
      "tensor(90.1800)\n",
      "tensor(91.6600)\n",
      "Round 1814, reward -0.514\n",
      "tensor([0.0431, 0.0431, 0.0432, 0.0431, 0.0431, 0.3186, 0.0606, 0.3188, 0.0431,\n",
      "        0.0432])\n",
      "tensor(92.8300)\n",
      "tensor(95.1200)\n",
      "Round 1815, reward -0.458\n",
      "tensor([0.0250, 0.1191, 0.1846, 0.1843, 0.1846, 0.0255, 0.0340, 0.0250, 0.1846,\n",
      "        0.0333])\n",
      "tensor(93.9900)\n",
      "tensor(91.6200)\n",
      "Round 1816, reward -0.132\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "tensor(93.3500)\n",
      "tensor(93.3500)\n",
      "Round 1817, reward -0.147\n",
      "tensor([0.0431, 0.3186, 0.0437, 0.0498, 0.0431, 0.3186, 0.0431, 0.0538, 0.0431,\n",
      "        0.0431])\n",
      "tensor(94.8100)\n",
      "tensor(94.9700)\n",
      "Round 1818, reward -0.258\n",
      "tensor([0.0575, 0.0577, 0.0578, 0.0575, 0.0575, 0.4252, 0.0575, 0.0575, 0.0823,\n",
      "        0.0893])\n",
      "tensor(94.4300)\n",
      "tensor(95.7800)\n",
      "Round 1819, reward -0.420\n",
      "tensor([0.1005, 0.0997, 0.1019, 0.0997, 0.0997, 0.0997, 0.0997, 0.0997, 0.0997,\n",
      "        0.0997])\n",
      "tensor(93.2100)\n",
      "tensor(93.2400)\n",
      "Round 1820, reward -0.185\n",
      "tensor([0.0460, 0.0446, 0.0445, 0.3288, 0.0475, 0.2589, 0.0445, 0.0445, 0.0445,\n",
      "        0.0962])\n",
      "tensor(90.3600)\n",
      "tensor(95.0600)\n",
      "Round 1821, reward -0.511\n",
      "tensor([0.1112, 0.1901, 0.1901, 0.1901, 0.0257, 0.0258, 0.1899, 0.0257, 0.0258,\n",
      "        0.0257])\n",
      "tensor(95.9000)\n",
      "tensor(95.4600)\n",
      "Round 1822, reward -0.085\n",
      "tensor([0.0616, 0.0616, 0.0616, 0.0616, 0.0616, 0.0616, 0.0616, 0.0616, 0.4459,\n",
      "        0.0616])\n",
      "tensor(88.6300)\n",
      "tensor(92.8700)\n",
      "Round 1823, reward -0.545\n",
      "tensor([0.0654, 0.0676, 0.0654, 0.0654, 0.0654, 0.0654, 0.1706, 0.0654, 0.3043,\n",
      "        0.0654])\n",
      "tensor(95.5800)\n",
      "tensor(96.0600)\n",
      "Round 1824, reward -0.352\n",
      "tensor([0.0655, 0.1068, 0.0655, 0.0732, 0.0655, 0.0655, 0.0655, 0.3604, 0.0655,\n",
      "        0.0669])\n",
      "tensor(94.1700)\n",
      "tensor(95.8100)\n",
      "Round 1825, reward -0.427\n",
      "tensor([0.3206, 0.0441, 0.0441, 0.0441, 0.0442, 0.0441, 0.0442, 0.0441, 0.3262,\n",
      "        0.0441])\n",
      "tensor(94.2400)\n",
      "tensor(94.7800)\n",
      "Round 1826, reward -0.394\n",
      "tensor([0.2446, 0.2446, 0.0426, 0.0331, 0.2424, 0.0331, 0.0331, 0.0331, 0.0392,\n",
      "        0.0542])\n",
      "tensor(92.9900)\n",
      "tensor(95.6200)\n",
      "Round 1827, reward -0.455\n",
      "tensor([0.0483, 0.0482, 0.0482, 0.0482, 0.0482, 0.2580, 0.0482, 0.0482, 0.0482,\n",
      "        0.3562])\n",
      "tensor(94.3000)\n",
      "tensor(95.6400)\n",
      "Round 1828, reward -0.423\n",
      "tensor([0.0431, 0.3160, 0.0431, 0.0431, 0.0431, 0.0431, 0.3184, 0.0641, 0.0431,\n",
      "        0.0431])\n",
      "tensor(95.0200)\n",
      "tensor(96.1600)\n",
      "Round 1829, reward -0.404\n",
      "tensor([0.0445, 0.3290, 0.0458, 0.0445, 0.0445, 0.3110, 0.0445, 0.0445, 0.0470,\n",
      "        0.0447])\n",
      "tensor(90.9600)\n",
      "tensor(91.4300)\n",
      "Round 1830, reward -0.456\n",
      "tensor([0.0535, 0.0721, 0.0421, 0.3109, 0.0421, 0.0421, 0.3109, 0.0421, 0.0421,\n",
      "        0.0421])\n",
      "tensor(93.4100)\n",
      "tensor(93.4900)\n",
      "Round 1831, reward -0.230\n",
      "tensor([0.0356, 0.0666, 0.2629, 0.1970, 0.0356, 0.0371, 0.0356, 0.0356, 0.2584,\n",
      "        0.0356])\n",
      "tensor(92.9300)\n",
      "tensor(95.2800)\n",
      "Round 1832, reward -0.456\n",
      "tensor([0.0308, 0.2271, 0.0308, 0.2272, 0.0308, 0.1778, 0.0464, 0.0308, 0.0308,\n",
      "        0.1676])\n",
      "tensor(94.0500)\n",
      "tensor(95.4900)\n",
      "Round 1833, reward -0.429\n",
      "tensor([0.3579, 0.0584, 0.0485, 0.0486, 0.0487, 0.0485, 0.0485, 0.0485, 0.0485,\n",
      "        0.2436])\n",
      "tensor(95.3900)\n",
      "tensor(95.7300)\n",
      "Round 1834, reward -0.325\n",
      "tensor([0.3236, 0.0439, 0.0439, 0.0439, 0.0439, 0.3247, 0.0439, 0.0439, 0.0439,\n",
      "        0.0441])\n",
      "tensor(92.3100)\n",
      "tensor(96.0400)\n",
      "Round 1835, reward -0.470\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1004, 0.1000,\n",
      "        0.1000])\n",
      "tensor(96.0800)\n",
      "tensor(96.0800)\n",
      "Round 1836, reward -0.080\n",
      "tensor([0.0997, 0.1030, 0.0997, 0.0997, 0.0997, 0.0997, 0.0997, 0.0997, 0.0997,\n",
      "        0.0997])\n",
      "tensor(95.8600)\n",
      "tensor(95.8700)\n",
      "Round 1837, reward -0.098\n",
      "tensor([0.0290, 0.1956, 0.0290, 0.2141, 0.2019, 0.2143, 0.0290, 0.0290, 0.0290,\n",
      "        0.0290])\n",
      "tensor(95.1600)\n",
      "tensor(96.1100)\n",
      "Round 1838, reward -0.398\n",
      "tensor([0.0368, 0.0696, 0.2328, 0.2448, 0.0332, 0.0332, 0.0332, 0.0332, 0.0384,\n",
      "        0.2450])\n",
      "tensor(95.1900)\n",
      "tensor(95.1500)\n",
      "Round 1839, reward -0.103\n",
      "tensor([0.0381, 0.0381, 0.0381, 0.0381, 0.2807, 0.0381, 0.0381, 0.1706, 0.0381,\n",
      "        0.2817])\n",
      "tensor(93.8300)\n",
      "tensor(95.6700)\n",
      "Round 1840, reward -0.435\n",
      "tensor([0.0267, 0.1976, 0.0269, 0.0452, 0.0267, 0.1972, 0.0608, 0.0267, 0.1945,\n",
      "        0.1976])\n",
      "tensor(92.9200)\n",
      "tensor(93.9300)\n",
      "Round 1841, reward -0.452\n",
      "tensor([0.2226, 0.0302, 0.0303, 0.0302, 0.2228, 0.2228, 0.1507, 0.0302, 0.0302,\n",
      "        0.0302])\n",
      "tensor(93.8200)\n",
      "tensor(94.2600)\n",
      "Round 1842, reward -0.388\n",
      "tensor([0.0586, 0.0586, 0.0586, 0.0586, 0.0586, 0.4330, 0.0586, 0.0586, 0.0982,\n",
      "        0.0586])\n",
      "tensor(92.8100)\n",
      "tensor(95.9300)\n",
      "Round 1843, reward -0.459\n",
      "tensor([0.0427, 0.3079, 0.0427, 0.0427, 0.0468, 0.0427, 0.0427, 0.3155, 0.0735,\n",
      "        0.0427])\n",
      "tensor(94.0800)\n",
      "tensor(96.0400)\n",
      "Round 1844, reward -0.429\n",
      "tensor([0.0303, 0.0303, 0.0304, 0.0491, 0.2206, 0.0303, 0.2230, 0.1319, 0.2239,\n",
      "        0.0303])\n",
      "tensor(96.0500)\n",
      "tensor(96.)\n",
      "Round 1845, reward -0.081\n",
      "tensor([0.0281, 0.2073, 0.1698, 0.1902, 0.0852, 0.0281, 0.0281, 0.0281, 0.2072,\n",
      "        0.0281])\n",
      "tensor(94.9200)\n",
      "tensor(94.7000)\n",
      "Round 1846, reward -0.109\n",
      "tensor([0.0590, 0.0865, 0.4358, 0.0590, 0.0634, 0.0590, 0.0604, 0.0590, 0.0590,\n",
      "        0.0590])\n",
      "tensor(91.6700)\n",
      "tensor(95.3700)\n",
      "Round 1847, reward -0.484\n",
      "tensor([0.0452, 0.0438, 0.0438, 0.0476, 0.3203, 0.0438, 0.3239, 0.0438, 0.0439,\n",
      "        0.0438])\n",
      "tensor(95.6100)\n",
      "tensor(96.5200)\n",
      "Round 1848, reward -0.385\n",
      "tensor([0.0587, 0.0587, 0.0587, 0.0589, 0.0587, 0.0587, 0.0587, 0.0587, 0.4334,\n",
      "        0.0972])\n",
      "tensor(89.0100)\n",
      "tensor(95.8900)\n",
      "Round 1849, reward -0.538\n",
      "tensor([0.0474, 0.3232, 0.0437, 0.0437, 0.0437, 0.0437, 0.3232, 0.0437, 0.0439,\n",
      "        0.0437])\n",
      "tensor(95.5600)\n",
      "tensor(96.2600)\n",
      "Round 1850, reward -0.377\n",
      "tensor([0.0610, 0.0611, 0.0610, 0.0619, 0.4491, 0.0610, 0.0610, 0.0617, 0.0610,\n",
      "        0.0610])\n",
      "tensor(92.8500)\n",
      "tensor(95.7000)\n",
      "Round 1851, reward -0.458\n",
      "tensor([0.1796, 0.0296, 0.0301, 0.0296, 0.0298, 0.2189, 0.0412, 0.2189, 0.1927,\n",
      "        0.0296])\n",
      "tensor(95.6800)\n",
      "tensor(95.9000)\n",
      "Round 1852, reward -0.270\n",
      "tensor([0.0355, 0.2621, 0.2292, 0.0355, 0.0355, 0.0355, 0.0355, 0.2601, 0.0355,\n",
      "        0.0355])\n",
      "tensor(92.6100)\n",
      "tensor(95.5700)\n",
      "Round 1853, reward -0.463\n",
      "tensor([0.2512, 0.2512, 0.0340, 0.0340, 0.0403, 0.0340, 0.0361, 0.0340, 0.0340,\n",
      "        0.2512])\n",
      "tensor(93.9800)\n",
      "tensor(95.8900)\n",
      "Round 1854, reward -0.432\n",
      "tensor([0.0605, 0.0605, 0.0605, 0.0605, 0.0613, 0.4246, 0.0867, 0.0617, 0.0605,\n",
      "        0.0633])\n",
      "tensor(91.1000)\n",
      "tensor(95.4000)\n",
      "Round 1855, reward -0.496\n",
      "tensor([0.0244, 0.1806, 0.0244, 0.0244, 0.0245, 0.1757, 0.0244, 0.1804, 0.1675,\n",
      "        0.1736])\n",
      "tensor(93.8700)\n",
      "tensor(94.3300)\n",
      "Round 1856, reward -0.390\n",
      "tensor([0.0295, 0.0295, 0.2015, 0.0300, 0.1847, 0.0295, 0.0295, 0.0295, 0.2182,\n",
      "        0.2179])\n",
      "tensor(90.9900)\n",
      "tensor(95.9600)\n",
      "Round 1857, reward -0.498\n",
      "tensor([0.0291, 0.0291, 0.0291, 0.2148, 0.1074, 0.0291, 0.0291, 0.1444, 0.1732,\n",
      "        0.2148])\n",
      "tensor(93.3900)\n",
      "tensor(94.6200)\n",
      "Round 1858, reward -0.444\n",
      "tensor([0.0394, 0.0394, 0.2911, 0.2872, 0.0394, 0.0394, 0.0394, 0.0394, 0.1460,\n",
      "        0.0394])\n",
      "tensor(93.0800)\n",
      "tensor(93.2900)\n",
      "Round 1859, reward -0.328\n",
      "tensor([0.0743, 0.1448, 0.0743, 0.0743, 0.0876, 0.1119, 0.0743, 0.1949, 0.0743,\n",
      "        0.0893])\n",
      "tensor(93.4100)\n",
      "tensor(91.7100)\n",
      "Round 1860, reward -0.145\n",
      "tensor([0.0708, 0.0708, 0.3627, 0.0708, 0.0708, 0.0708, 0.0708, 0.0708, 0.0709,\n",
      "        0.0708])\n",
      "tensor(93.4700)\n",
      "tensor(93.8000)\n",
      "Round 1861, reward -0.368\n",
      "tensor([0.0293, 0.0293, 0.0354, 0.0297, 0.2165, 0.0293, 0.0316, 0.1659, 0.2165,\n",
      "        0.2165])\n",
      "tensor(85.9800)\n",
      "tensor(88.7000)\n",
      "Round 1862, reward -0.593\n",
      "tensor([0.2120, 0.0419, 0.0419, 0.0419, 0.2336, 0.0419, 0.0419, 0.0419, 0.2613,\n",
      "        0.0419])\n",
      "tensor(90.2700)\n",
      "tensor(95.2100)\n",
      "Round 1863, reward -0.513\n",
      "tensor([0.0291, 0.0291, 0.1731, 0.2148, 0.0346, 0.2148, 0.0291, 0.2149, 0.0313,\n",
      "        0.0291])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.8900)\n",
      "tensor(95.2700)\n",
      "Round 1864, reward -0.348\n",
      "tensor([0.0342, 0.0342, 0.0342, 0.0365, 0.0446, 0.0342, 0.2530, 0.0358, 0.2508,\n",
      "        0.2424])\n",
      "tensor(95.2700)\n",
      "tensor(96.6300)\n",
      "Round 1865, reward -0.400\n",
      "tensor([0.2420, 0.0695, 0.0334, 0.0328, 0.0401, 0.2420, 0.2420, 0.0328, 0.0328,\n",
      "        0.0328])\n",
      "tensor(94.7300)\n",
      "tensor(96.3800)\n",
      "Round 1866, reward -0.414\n",
      "tensor([0.3246, 0.0441, 0.0439, 0.0439, 0.0439, 0.0439, 0.3234, 0.0443, 0.0439,\n",
      "        0.0439])\n",
      "tensor(96.1800)\n",
      "tensor(96.6700)\n",
      "Round 1867, reward -0.338\n",
      "tensor([0.0606, 0.0606, 0.0673, 0.0606, 0.0606, 0.0606, 0.4475, 0.0613, 0.0606,\n",
      "        0.0606])\n",
      "tensor(94.0300)\n",
      "tensor(95.9300)\n",
      "Round 1868, reward -0.431\n",
      "tensor([0.0428, 0.3154, 0.0428, 0.0559, 0.3161, 0.0559, 0.0428, 0.0428, 0.0428,\n",
      "        0.0428])\n",
      "tensor(92.4400)\n",
      "tensor(94.8600)\n",
      "Round 1869, reward -0.467\n",
      "tensor([0.0320, 0.2363, 0.0320, 0.0320, 0.0320, 0.2363, 0.0926, 0.0320, 0.2296,\n",
      "        0.0453])\n",
      "tensor(93.6800)\n",
      "tensor(95.7300)\n",
      "Round 1870, reward -0.439\n",
      "tensor([0.3827, 0.0518, 0.0518, 0.0518, 0.1514, 0.0518, 0.0518, 0.0518, 0.0519,\n",
      "        0.1032])\n",
      "tensor(93.6700)\n",
      "tensor(95.5700)\n",
      "Round 1871, reward -0.439\n",
      "tensor([0.2719, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.2723, 0.1968,\n",
      "        0.0370])\n",
      "tensor(94.7500)\n",
      "tensor(95.8800)\n",
      "Round 1872, reward -0.411\n",
      "tensor([0.0438, 0.0364, 0.1997, 0.0365, 0.0364, 0.0364, 0.0364, 0.2689, 0.0364,\n",
      "        0.2691])\n",
      "tensor(92.0700)\n",
      "tensor(95.9400)\n",
      "Round 1873, reward -0.475\n",
      "tensor([0.0277, 0.0277, 0.2045, 0.0277, 0.0981, 0.0277, 0.2045, 0.2045, 0.0283,\n",
      "        0.1494])\n",
      "tensor(95.5400)\n",
      "tensor(95.5000)\n",
      "Round 1874, reward -0.094\n",
      "tensor([0.0351, 0.0351, 0.0351, 0.0351, 0.2591, 0.0351, 0.2352, 0.2591, 0.0363,\n",
      "        0.0351])\n",
      "tensor(93.1900)\n",
      "tensor(95.3000)\n",
      "Round 1875, reward -0.450\n",
      "tensor([0.0389, 0.0391, 0.1686, 0.0486, 0.0389, 0.0389, 0.0389, 0.2877, 0.0389,\n",
      "        0.2612])\n",
      "tensor(95.0200)\n",
      "tensor(95.6300)\n",
      "Round 1876, reward -0.383\n",
      "tensor([0.2356, 0.0461, 0.0319, 0.2356, 0.0319, 0.0876, 0.0319, 0.2356, 0.0319,\n",
      "        0.0319])\n",
      "tensor(95.5300)\n",
      "tensor(95.7400)\n",
      "Round 1877, reward -0.269\n",
      "tensor([0.0578, 0.0573, 0.0573, 0.4231, 0.0580, 0.1175, 0.0573, 0.0573, 0.0573,\n",
      "        0.0573])\n",
      "tensor(94.8900)\n",
      "tensor(95.)\n",
      "Round 1878, reward -0.220\n",
      "tensor([0.1659, 0.1947, 0.0264, 0.0264, 0.0264, 0.1947, 0.1252, 0.0264, 0.1876,\n",
      "        0.0264])\n",
      "tensor(93.6000)\n",
      "tensor(95.3900)\n",
      "Round 1879, reward -0.441\n",
      "tensor([0.3228, 0.0440, 0.0442, 0.3250, 0.0440, 0.0440, 0.0440, 0.0440, 0.0440,\n",
      "        0.0440])\n",
      "tensor(94.7400)\n",
      "tensor(93.9700)\n",
      "Round 1880, reward -0.114\n",
      "tensor([0.0436, 0.0515, 0.0436, 0.0436, 0.0436, 0.3219, 0.0436, 0.0436, 0.3215,\n",
      "        0.0436])\n",
      "tensor(94.6100)\n",
      "tensor(96.1600)\n",
      "Round 1881, reward -0.416\n",
      "tensor([0.0325, 0.0324, 0.2391, 0.0324, 0.0324, 0.0324, 0.2374, 0.2346, 0.0906,\n",
      "        0.0365])\n",
      "tensor(92.1900)\n",
      "tensor(95.4900)\n",
      "Round 1882, reward -0.473\n",
      "tensor([0.2126, 0.0288, 0.0288, 0.0288, 0.0288, 0.2129, 0.1885, 0.0289, 0.2129,\n",
      "        0.0290])\n",
      "tensor(89.4900)\n",
      "tensor(92.7000)\n",
      "Round 1883, reward -0.529\n",
      "tensor([0.0238, 0.0238, 0.1755, 0.0244, 0.1757, 0.1757, 0.1757, 0.0350, 0.0390,\n",
      "        0.1516])\n",
      "tensor(94.2700)\n",
      "tensor(93.9300)\n",
      "Round 1884, reward -0.125\n",
      "tensor([0.0361, 0.0359, 0.2654, 0.0359, 0.0359, 0.0359, 0.2563, 0.0359, 0.0359,\n",
      "        0.2268])\n",
      "tensor(87.7600)\n",
      "tensor(89.9500)\n",
      "Round 1885, reward -0.561\n",
      "tensor([0.0607, 0.0607, 0.0607, 0.0628, 0.0607, 0.0609, 0.0619, 0.4449, 0.0607,\n",
      "        0.0660])\n",
      "tensor(87.5500)\n",
      "tensor(95.0700)\n",
      "Round 1886, reward -0.565\n",
      "tensor([0.2480, 0.2601, 0.0441, 0.0352, 0.0556, 0.0354, 0.0385, 0.0352, 0.2127,\n",
      "        0.0352])\n",
      "tensor(94.9000)\n",
      "tensor(95.9800)\n",
      "Round 1887, reward -0.406\n",
      "tensor([0.2077, 0.2077, 0.0281, 0.0281, 0.2077, 0.0284, 0.0281, 0.0281, 0.0281,\n",
      "        0.2077])\n",
      "tensor(90.9400)\n",
      "tensor(95.9100)\n",
      "Round 1888, reward -0.499\n",
      "tensor([0.0573, 0.3591, 0.0572, 0.0658, 0.0572, 0.1741, 0.0572, 0.0572, 0.0575,\n",
      "        0.0572])\n",
      "tensor(94.2000)\n",
      "tensor(96.2300)\n",
      "Round 1889, reward -0.427\n",
      "tensor([0.0398, 0.0397, 0.0397, 0.0397, 0.2732, 0.0397, 0.1487, 0.0397, 0.0463,\n",
      "        0.2934])\n",
      "tensor(94.4200)\n",
      "tensor(95.3300)\n",
      "Round 1890, reward -0.415\n",
      "tensor([0.0340, 0.0326, 0.0326, 0.0535, 0.0810, 0.0326, 0.2410, 0.0326, 0.2190,\n",
      "        0.2410])\n",
      "tensor(95.4300)\n",
      "tensor(96.3000)\n",
      "Round 1891, reward -0.389\n",
      "tensor([0.1352, 0.1352, 0.1341, 0.0183, 0.1351, 0.0183, 0.1352, 0.0183, 0.1352,\n",
      "        0.1352])\n",
      "tensor(94.4700)\n",
      "tensor(94.6500)\n",
      "Round 1892, reward -0.278\n",
      "tensor([0.0241, 0.1771, 0.1772, 0.0240, 0.0240, 0.0240, 0.0240, 0.1741, 0.1743,\n",
      "        0.1772])\n",
      "tensor(93.5400)\n",
      "tensor(93.5700)\n",
      "Round 1893, reward -0.177\n",
      "tensor([0.3749, 0.0555, 0.0575, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554, 0.0554,\n",
      "        0.1796])\n",
      "tensor(94.0700)\n",
      "tensor(94.7700)\n",
      "Round 1894, reward -0.413\n",
      "tensor([0.0493, 0.3476, 0.0496, 0.0493, 0.0493, 0.2562, 0.0510, 0.0493, 0.0493,\n",
      "        0.0493])\n",
      "tensor(89.7300)\n",
      "tensor(93.5900)\n",
      "Round 1895, reward -0.524\n",
      "tensor([0.0336, 0.0585, 0.2423, 0.0336, 0.0356, 0.0338, 0.2468, 0.0336, 0.2485,\n",
      "        0.0336])\n",
      "tensor(91.6300)\n",
      "tensor(95.5200)\n",
      "Round 1896, reward -0.485\n",
      "tensor([0.0438, 0.3183, 0.0438, 0.0438, 0.3232, 0.0438, 0.0468, 0.0438, 0.0439,\n",
      "        0.0487])\n",
      "tensor(91.2000)\n",
      "tensor(92.2800)\n",
      "Round 1897, reward -0.491\n",
      "tensor([0.0325, 0.0325, 0.2404, 0.0325, 0.0325, 0.0326, 0.2402, 0.0325, 0.0836,\n",
      "        0.2404])\n",
      "tensor(92.7700)\n",
      "tensor(95.5900)\n",
      "Round 1898, reward -0.460\n",
      "tensor([0.0353, 0.2603, 0.2597, 0.0352, 0.0353, 0.2301, 0.0352, 0.0383, 0.0352,\n",
      "        0.0352])\n",
      "tensor(92.8800)\n",
      "tensor(93.7300)\n",
      "Round 1899, reward -0.449\n",
      "tensor([0.0309, 0.2259, 0.0309, 0.2284, 0.2285, 0.0309, 0.0309, 0.0311, 0.1315,\n",
      "        0.0309])\n",
      "tensor(90.4200)\n",
      "tensor(92.0500)\n",
      "Round 1900, reward -0.510\n",
      "tensor([0.0318, 0.0936, 0.0529, 0.0318, 0.0318, 0.2350, 0.0318, 0.2251, 0.2343,\n",
      "        0.0318])\n",
      "tensor(96.1400)\n",
      "tensor(96.4900)\n",
      "Round 1901, reward -0.309\n",
      "tensor([0.0800, 0.0337, 0.0415, 0.2493, 0.0338, 0.0337, 0.0466, 0.0337, 0.1983,\n",
      "        0.2493])\n",
      "tensor(96.0400)\n",
      "tensor(96.1700)\n",
      "Round 1902, reward -0.206\n",
      "tensor([0.0324, 0.2391, 0.0341, 0.2284, 0.0333, 0.0967, 0.2389, 0.0324, 0.0324,\n",
      "        0.0324])\n",
      "tensor(96.0300)\n",
      "tensor(96.1100)\n",
      "Round 1903, reward -0.166\n",
      "tensor([0.1821, 0.0412, 0.1819, 0.0249, 0.1819, 0.1153, 0.0302, 0.0246, 0.1821,\n",
      "        0.0358])\n",
      "tensor(95.7100)\n",
      "tensor(95.8000)\n",
      "Round 1904, reward -0.183\n",
      "tensor([0.0242, 0.0244, 0.1673, 0.0242, 0.1791, 0.0242, 0.1791, 0.1790, 0.0242,\n",
      "        0.1742])\n",
      "tensor(95.2500)\n",
      "tensor(95.0200)\n",
      "Round 1905, reward -0.101\n",
      "tensor([0.0368, 0.0334, 0.0334, 0.0334, 0.2343, 0.1767, 0.0334, 0.1388, 0.2465,\n",
      "        0.0334])\n",
      "tensor(94.3400)\n",
      "tensor(92.0500)\n",
      "Round 1906, reward -0.123\n",
      "tensor([0.0636, 0.4390, 0.0594, 0.0598, 0.0688, 0.0594, 0.0594, 0.0716, 0.0594,\n",
      "        0.0594])\n",
      "tensor(92.5900)\n",
      "tensor(96.6200)\n",
      "Round 1907, reward -0.464\n",
      "tensor([0.2078, 0.0288, 0.0281, 0.0281, 0.2070, 0.2078, 0.0281, 0.0281, 0.2077,\n",
      "        0.0284])\n",
      "tensor(89.0800)\n",
      "tensor(91.1300)\n",
      "Round 1908, reward -0.537\n",
      "tensor([0.0343, 0.2528, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.2534, 0.2534,\n",
      "        0.0347])\n",
      "tensor(95.6500)\n",
      "tensor(96.5500)\n",
      "Round 1909, reward -0.384\n",
      "tensor([0.2506, 0.0454, 0.0339, 0.0763, 0.2071, 0.0344, 0.0339, 0.0339, 0.2506,\n",
      "        0.0339])\n",
      "tensor(96.1300)\n",
      "tensor(96.5700)\n",
      "Round 1910, reward -0.331\n",
      "tensor([0.1252, 0.0306, 0.0306, 0.2261, 0.0345, 0.2264, 0.2263, 0.0306, 0.0388,\n",
      "        0.0306])\n",
      "tensor(95.0700)\n",
      "tensor(95.7700)\n",
      "Round 1911, reward -0.389\n",
      "tensor([0.0404, 0.0404, 0.0416, 0.0404, 0.0945, 0.0639, 0.0414, 0.0404, 0.2985,\n",
      "        0.2985])\n",
      "tensor(95.1200)\n",
      "tensor(96.6400)\n",
      "Round 1912, reward -0.404\n",
      "tensor([0.0295, 0.0295, 0.2178, 0.0295, 0.0311, 0.0295, 0.1931, 0.1911, 0.2178,\n",
      "        0.0312])\n",
      "tensor(91.5800)\n",
      "tensor(94.6500)\n",
      "Round 1913, reward -0.486\n",
      "tensor([0.0437, 0.3196, 0.0434, 0.3208, 0.0548, 0.0434, 0.0437, 0.0434, 0.0438,\n",
      "        0.0436])\n",
      "tensor(86.5200)\n",
      "tensor(96.1300)\n",
      "Round 1914, reward -0.583\n",
      "tensor([0.2881, 0.0392, 0.0399, 0.0502, 0.0390, 0.1382, 0.0390, 0.2883, 0.0390,\n",
      "        0.0390])\n",
      "tensor(95.2200)\n",
      "tensor(95.8100)\n",
      "Round 1915, reward -0.376\n",
      "tensor([0.0608, 0.0608, 0.0609, 0.0608, 0.0619, 0.0608, 0.0608, 0.0630, 0.4494,\n",
      "        0.0608])\n",
      "tensor(95.8700)\n",
      "tensor(95.6900)\n",
      "Round 1916, reward -0.085\n",
      "tensor([0.0998, 0.0998, 0.1002, 0.0998, 0.0998, 0.0998, 0.0998, 0.0998, 0.0998,\n",
      "        0.1011])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95.9100)\n",
      "tensor(95.9000)\n",
      "Round 1917, reward -0.084\n",
      "tensor([0.0321, 0.1173, 0.0321, 0.0323, 0.2165, 0.2368, 0.2368, 0.0321, 0.0321,\n",
      "        0.0321])\n",
      "tensor(95.7700)\n",
      "tensor(94.6300)\n",
      "Round 1918, reward -0.088\n",
      "tensor([0.0294, 0.0294, 0.0294, 0.2169, 0.1731, 0.0294, 0.2169, 0.0294, 0.0294,\n",
      "        0.2169])\n",
      "tensor(95.1200)\n",
      "tensor(96.9900)\n",
      "Round 1919, reward -0.404\n",
      "tensor([0.3081, 0.0417, 0.0422, 0.0417, 0.0417, 0.0421, 0.3001, 0.0417, 0.0990,\n",
      "        0.0417])\n",
      "tensor(96.2200)\n",
      "tensor(96.8300)\n",
      "Round 1920, reward -0.353\n",
      "tensor([0.0413, 0.0412, 0.0412, 0.2182, 0.0412, 0.0412, 0.1899, 0.0412, 0.0412,\n",
      "        0.3033])\n",
      "tensor(95.8700)\n",
      "tensor(96.1300)\n",
      "Round 1921, reward -0.284\n",
      "tensor([0.0575, 0.1098, 0.0575, 0.0575, 0.0575, 0.0626, 0.0575, 0.4250, 0.0575,\n",
      "        0.0575])\n",
      "tensor(95.7600)\n",
      "tensor(94.9500)\n",
      "Round 1922, reward -0.088\n",
      "tensor([0.0272, 0.0272, 0.0766, 0.1950, 0.0272, 0.0272, 0.1910, 0.2008, 0.0272,\n",
      "        0.2008])\n",
      "tensor(96.1600)\n",
      "tensor(96.7100)\n",
      "Round 1923, reward -0.348\n",
      "tensor([0.0826, 0.0826, 0.2567, 0.0826, 0.0826, 0.0826, 0.0826, 0.0826, 0.0826,\n",
      "        0.0826])\n",
      "tensor(96.4500)\n",
      "tensor(96.9000)\n",
      "Round 1924, reward -0.324\n",
      "tensor([0.0473, 0.1607, 0.1663, 0.0356, 0.0240, 0.0234, 0.1728, 0.1725, 0.1728,\n",
      "        0.0245])\n",
      "tensor(95.7100)\n",
      "tensor(96.0400)\n",
      "Round 1925, reward -0.313\n",
      "tensor([0.0735, 0.0734, 0.3375, 0.0734, 0.0734, 0.0734, 0.0734, 0.0734, 0.0752,\n",
      "        0.0734])\n",
      "tensor(95.7600)\n",
      "tensor(96.2900)\n",
      "Round 1926, reward -0.355\n",
      "tensor([0.0235, 0.1717, 0.1737, 0.0239, 0.0235, 0.0677, 0.0235, 0.1737, 0.1664,\n",
      "        0.1524])\n",
      "tensor(94.3200)\n",
      "tensor(94.2500)\n",
      "Round 1927, reward -0.124\n",
      "tensor([0.2084, 0.2088, 0.0283, 0.0303, 0.1930, 0.2088, 0.0376, 0.0283, 0.0283,\n",
      "        0.0283])\n",
      "tensor(94.8700)\n",
      "tensor(94.0400)\n",
      "Round 1928, reward -0.110\n",
      "tensor([0.0346, 0.0346, 0.2493, 0.1149, 0.0427, 0.0346, 0.1642, 0.0346, 0.2558,\n",
      "        0.0346])\n",
      "tensor(92.6700)\n",
      "tensor(95.3400)\n",
      "Round 1929, reward -0.462\n",
      "tensor([0.0306, 0.0302, 0.2231, 0.2230, 0.2202, 0.0302, 0.0302, 0.0302, 0.1521,\n",
      "        0.0302])\n",
      "tensor(95.8500)\n",
      "tensor(96.5000)\n",
      "Round 1930, reward -0.366\n",
      "tensor([0.1628, 0.0223, 0.0223, 0.0224, 0.1647, 0.1647, 0.1647, 0.1647, 0.0891,\n",
      "        0.0223])\n",
      "tensor(95.1500)\n",
      "tensor(94.1200)\n",
      "Round 1931, reward -0.104\n",
      "tensor([0.1354, 0.1352, 0.1354, 0.1354, 0.0183, 0.1330, 0.0184, 0.1354, 0.1353,\n",
      "        0.0183])\n",
      "tensor(91.6500)\n",
      "tensor(91.9700)\n",
      "Round 1932, reward -0.405\n",
      "tensor([0.0598, 0.0597, 0.4409, 0.0597, 0.0597, 0.0598, 0.0813, 0.0597, 0.0597,\n",
      "        0.0597])\n",
      "tensor(94.1500)\n",
      "tensor(95.8800)\n",
      "Round 1933, reward -0.428\n",
      "tensor([0.0321, 0.0321, 0.2373, 0.0321, 0.0322, 0.2373, 0.0321, 0.2373, 0.0321,\n",
      "        0.0955])\n",
      "tensor(93.3900)\n",
      "tensor(95.3800)\n",
      "Round 1934, reward -0.446\n",
      "tensor([0.0681, 0.0469, 0.0426, 0.0426, 0.0431, 0.0426, 0.0426, 0.0428, 0.3144,\n",
      "        0.3144])\n",
      "tensor(91.2200)\n",
      "tensor(94.5400)\n",
      "Round 1935, reward -0.494\n",
      "tensor([0.2166, 0.0293, 0.1919, 0.0293, 0.0293, 0.0293, 0.0293, 0.1999, 0.0293,\n",
      "        0.2157])\n",
      "tensor(94.2200)\n",
      "tensor(95.4400)\n",
      "Round 1936, reward -0.424\n",
      "tensor([0.1003, 0.0794, 0.0793, 0.0793, 0.0793, 0.1757, 0.1226, 0.0871, 0.0793,\n",
      "        0.1175])\n",
      "tensor(96.3900)\n",
      "tensor(96.7500)\n",
      "Round 1937, reward -0.305\n",
      "tensor([0.0218, 0.1531, 0.1533, 0.0208, 0.1482, 0.1533, 0.1533, 0.1533, 0.0208,\n",
      "        0.0220])\n",
      "tensor(95.6100)\n",
      "tensor(96.4100)\n",
      "Round 1938, reward -0.381\n",
      "tensor([0.0430, 0.3146, 0.0650, 0.0426, 0.0450, 0.0426, 0.0436, 0.0426, 0.0464,\n",
      "        0.3147])\n",
      "tensor(95.3900)\n",
      "tensor(96.7300)\n",
      "Round 1939, reward -0.396\n",
      "tensor([0.2096, 0.0284, 0.0284, 0.2010, 0.2096, 0.0284, 0.2095, 0.0284, 0.0284,\n",
      "        0.0284])\n",
      "tensor(95.5400)\n",
      "tensor(96.7700)\n",
      "Round 1940, reward -0.392\n",
      "tensor([0.2533, 0.0343, 0.0344, 0.0343, 0.2533, 0.0343, 0.2533, 0.0343, 0.0343,\n",
      "        0.0343])\n",
      "tensor(95.0200)\n",
      "tensor(96.4100)\n",
      "Round 1941, reward -0.406\n",
      "tensor([0.1142, 0.0202, 0.1489, 0.1489, 0.1489, 0.1489, 0.1456, 0.0841, 0.0202,\n",
      "        0.0202])\n",
      "tensor(96.7400)\n",
      "tensor(96.9500)\n",
      "Round 1942, reward -0.238\n",
      "tensor([0.0479, 0.0479, 0.0480, 0.0483, 0.1506, 0.1700, 0.0479, 0.0480, 0.0479,\n",
      "        0.3435])\n",
      "tensor(94.1700)\n",
      "tensor(96.3400)\n",
      "Round 1943, reward -0.427\n",
      "tensor([0.0218, 0.1281, 0.1425, 0.1610, 0.0227, 0.1607, 0.0218, 0.1583, 0.1612,\n",
      "        0.0218])\n",
      "tensor(95.5300)\n",
      "tensor(96.1400)\n",
      "Round 1944, reward -0.370\n",
      "tensor([0.0394, 0.0394, 0.0395, 0.1297, 0.2564, 0.0394, 0.2766, 0.0397, 0.1006,\n",
      "        0.0394])\n",
      "tensor(94.4300)\n",
      "tensor(95.8300)\n",
      "Round 1945, reward -0.420\n",
      "tensor([0.0259, 0.1880, 0.0259, 0.1900, 0.1886, 0.0259, 0.0259, 0.1135, 0.1905,\n",
      "        0.0259])\n",
      "tensor(95.1100)\n",
      "tensor(95.5800)\n",
      "Round 1946, reward -0.362\n",
      "tensor([0.0851, 0.0851, 0.0851, 0.0851, 0.0853, 0.0851, 0.0851, 0.0886, 0.2308,\n",
      "        0.0851])\n",
      "tensor(96.)\n",
      "tensor(96.0100)\n",
      "Round 1947, reward -0.094\n",
      "tensor([0.0423, 0.0993, 0.0420, 0.0653, 0.2730, 0.0420, 0.0420, 0.0420, 0.0420,\n",
      "        0.3102])\n",
      "tensor(95.4200)\n",
      "tensor(95.9400)\n",
      "Round 1948, reward -0.362\n",
      "tensor([0.1552, 0.0210, 0.1552, 0.0210, 0.1548, 0.1552, 0.0210, 0.1552, 0.0210,\n",
      "        0.1401])\n",
      "tensor(96.7600)\n",
      "tensor(96.5600)\n",
      "Round 1949, reward -0.062\n",
      "tensor([0.0429, 0.0459, 0.0480, 0.0429, 0.3163, 0.0429, 0.0429, 0.0579, 0.0429,\n",
      "        0.3173])\n",
      "tensor(89.9600)\n",
      "tensor(96.3300)\n",
      "Round 1950, reward -0.519\n",
      "tensor([0.0344, 0.2517, 0.2534, 0.0344, 0.2539, 0.0344, 0.0344, 0.0344, 0.0344,\n",
      "        0.0344])\n",
      "tensor(93.4900)\n",
      "tensor(95.0700)\n",
      "Round 1951, reward -0.443\n",
      "tensor([0.1881, 0.0303, 0.0255, 0.0255, 0.1874, 0.1881, 0.0255, 0.1881, 0.1161,\n",
      "        0.0255])\n",
      "tensor(95.2200)\n",
      "tensor(96.3400)\n",
      "Round 1952, reward -0.399\n",
      "tensor([0.2037, 0.0279, 0.0279, 0.2058, 0.0433, 0.2058, 0.0279, 0.2021, 0.0279,\n",
      "        0.0279])\n",
      "tensor(96.0500)\n",
      "tensor(96.2400)\n",
      "Round 1953, reward -0.245\n",
      "tensor([0.2660, 0.1471, 0.0360, 0.0521, 0.1440, 0.0360, 0.0364, 0.0360, 0.2104,\n",
      "        0.0360])\n",
      "tensor(96.5000)\n",
      "tensor(96.1200)\n",
      "Round 1954, reward -0.069\n",
      "tensor([0.2296, 0.0312, 0.0312, 0.0312, 0.0312, 0.2305, 0.0312, 0.0312, 0.2304,\n",
      "        0.1223])\n",
      "tensor(96.8500)\n",
      "tensor(96.6400)\n",
      "Round 1955, reward -0.060\n",
      "tensor([0.0327, 0.0327, 0.0331, 0.2413, 0.1977, 0.0327, 0.1232, 0.2413, 0.0327,\n",
      "        0.0327])\n",
      "tensor(95.5700)\n",
      "tensor(96.4300)\n",
      "Round 1956, reward -0.385\n",
      "tensor([0.0364, 0.0363, 0.0363, 0.0370, 0.2186, 0.0363, 0.2670, 0.0363, 0.2597,\n",
      "        0.0363])\n",
      "tensor(96.8300)\n",
      "tensor(96.6200)\n",
      "Round 1957, reward -0.060\n",
      "tensor([0.0267, 0.0902, 0.0267, 0.1970, 0.1947, 0.0267, 0.1879, 0.1970, 0.0267,\n",
      "        0.0267])\n",
      "tensor(96.4100)\n",
      "tensor(95.6000)\n",
      "Round 1958, reward -0.071\n",
      "tensor([0.2331, 0.0324, 0.0324, 0.0352, 0.0324, 0.2391, 0.0324, 0.0324, 0.2368,\n",
      "        0.0941])\n",
      "tensor(94.4200)\n",
      "tensor(94.5800)\n",
      "Round 1959, reward -0.267\n",
      "tensor([0.0447, 0.0449, 0.0447, 0.0447, 0.0462, 0.0469, 0.3264, 0.0447, 0.0447,\n",
      "        0.3121])\n",
      "tensor(89.5300)\n",
      "tensor(92.9700)\n",
      "Round 1960, reward -0.528\n",
      "tensor([0.0282, 0.2081, 0.0283, 0.0282, 0.2061, 0.2081, 0.2081, 0.0286, 0.0282,\n",
      "        0.0282])\n",
      "tensor(90.9500)\n",
      "tensor(95.4600)\n",
      "Round 1961, reward -0.499\n",
      "tensor([0.0935, 0.0935, 0.0935, 0.1580, 0.0935, 0.0935, 0.0935, 0.0939, 0.0935,\n",
      "        0.0935])\n",
      "tensor(95.5900)\n",
      "tensor(95.6300)\n",
      "Round 1962, reward -0.139\n",
      "tensor([0.0953, 0.0953, 0.0953, 0.0953, 0.0953, 0.0953, 0.0953, 0.0953, 0.1421,\n",
      "        0.0953])\n",
      "tensor(96.8500)\n",
      "tensor(96.9200)\n",
      "Round 1963, reward -0.136\n",
      "tensor([0.0288, 0.0377, 0.0289, 0.1887, 0.2054, 0.2112, 0.0288, 0.2129, 0.0288,\n",
      "        0.0288])\n",
      "tensor(96.6300)\n",
      "tensor(96.1600)\n",
      "Round 1964, reward -0.066\n",
      "tensor([0.3026, 0.0410, 0.0410, 0.0410, 0.0410, 0.0410, 0.3022, 0.0443, 0.1051,\n",
      "        0.0410])\n",
      "tensor(91.8700)\n",
      "tensor(94.5900)\n",
      "Round 1965, reward -0.480\n",
      "tensor([0.0333, 0.2413, 0.2459, 0.0333, 0.0333, 0.0333, 0.0667, 0.0333, 0.2462,\n",
      "        0.0333])\n",
      "tensor(93.5700)\n",
      "tensor(94.9600)\n",
      "Round 1966, reward -0.441\n",
      "tensor([0.0440, 0.0439, 0.0439, 0.0440, 0.0439, 0.0439, 0.0439, 0.3247, 0.3237,\n",
      "        0.0440])\n",
      "tensor(92.5100)\n",
      "tensor(94.8500)\n",
      "Round 1967, reward -0.466\n",
      "tensor([0.0996, 0.0996, 0.0997, 0.1002, 0.1028, 0.1001, 0.0996, 0.0996, 0.0996,\n",
      "        0.0996])\n",
      "tensor(93.4100)\n",
      "tensor(93.4400)\n",
      "Round 1968, reward -0.180\n",
      "tensor([0.0203, 0.0518, 0.0203, 0.1501, 0.0205, 0.1501, 0.1501, 0.1501, 0.1363,\n",
      "        0.1501])\n",
      "tensor(90.0700)\n",
      "tensor(91.8000)\n",
      "Round 1969, reward -0.517\n",
      "tensor([0.2041, 0.2048, 0.0337, 0.0277, 0.0277, 0.2048, 0.0277, 0.2047, 0.0370,\n",
      "        0.0277])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91.8100)\n",
      "tensor(91.2600)\n",
      "Round 1970, reward -0.181\n",
      "tensor([0.0343, 0.2532, 0.0345, 0.0343, 0.0343, 0.0343, 0.0343, 0.2533, 0.2533,\n",
      "        0.0343])\n",
      "tensor(94.4700)\n",
      "tensor(95.8100)\n",
      "Round 1971, reward -0.419\n",
      "tensor([0.0336, 0.0340, 0.2483, 0.0528, 0.0336, 0.0336, 0.2467, 0.2483, 0.0353,\n",
      "        0.0337])\n",
      "tensor(94.9000)\n",
      "tensor(96.5900)\n",
      "Round 1972, reward -0.409\n",
      "tensor([0.0735, 0.0630, 0.0630, 0.0630, 0.0630, 0.4226, 0.0630, 0.0630, 0.0630,\n",
      "        0.0630])\n",
      "tensor(88.9600)\n",
      "tensor(94.4400)\n",
      "Round 1973, reward -0.539\n",
      "tensor([0.0346, 0.0346, 0.0346, 0.0429, 0.2365, 0.0346, 0.2515, 0.2553, 0.0346,\n",
      "        0.0410])\n",
      "tensor(96.7800)\n",
      "tensor(95.8800)\n",
      "Round 1974, reward -0.062\n",
      "tensor([0.0341, 0.2323, 0.0597, 0.0341, 0.2517, 0.0341, 0.0341, 0.0341, 0.0341,\n",
      "        0.2517])\n",
      "tensor(96.2300)\n",
      "tensor(97.1000)\n",
      "Round 1975, reward -0.368\n",
      "tensor([0.0535, 0.0535, 0.0536, 0.0535, 0.1886, 0.3830, 0.0535, 0.0535, 0.0535,\n",
      "        0.0535])\n",
      "tensor(96.1400)\n",
      "tensor(96.8200)\n",
      "Round 1976, reward -0.361\n",
      "tensor([0.0273, 0.0273, 0.2014, 0.2014, 0.2014, 0.0273, 0.0273, 0.2014, 0.0579,\n",
      "        0.0273])\n",
      "tensor(96.3200)\n",
      "tensor(96.6600)\n",
      "Round 1977, reward -0.301\n",
      "tensor([0.2046, 0.0277, 0.2047, 0.0277, 0.1850, 0.0333, 0.2030, 0.0277, 0.0564,\n",
      "        0.0299])\n",
      "tensor(94.2400)\n",
      "tensor(96.3100)\n",
      "Round 1978, reward -0.426\n",
      "tensor([0.0274, 0.2024, 0.0274, 0.0274, 0.1162, 0.0308, 0.0274, 0.2024, 0.1516,\n",
      "        0.1872])\n",
      "tensor(96.2800)\n",
      "tensor(96.2100)\n",
      "Round 1979, reward -0.075\n",
      "tensor([0.1572, 0.0215, 0.0846, 0.1587, 0.1361, 0.1353, 0.0909, 0.1587, 0.0215,\n",
      "        0.0354])\n",
      "tensor(96.3800)\n",
      "tensor(96.)\n",
      "Round 1980, reward -0.072\n",
      "tensor([0.0439, 0.0439, 0.0439, 0.3234, 0.0439, 0.0439, 0.3244, 0.0439, 0.0439,\n",
      "        0.0447])\n",
      "tensor(96.0800)\n",
      "tensor(95.6400)\n",
      "Round 1981, reward -0.080\n",
      "tensor([0.0563, 0.4159, 0.0563, 0.0563, 0.0563, 0.0572, 0.0563, 0.0563, 0.0583,\n",
      "        0.1310])\n",
      "tensor(87.9200)\n",
      "tensor(92.8200)\n",
      "Round 1982, reward -0.558\n",
      "tensor([0.0299, 0.0299, 0.0299, 0.2208, 0.1181, 0.0588, 0.0366, 0.0526, 0.2206,\n",
      "        0.2030])\n",
      "tensor(89.8200)\n",
      "tensor(91.4800)\n",
      "Round 1983, reward -0.522\n",
      "tensor([0.1798, 0.1801, 0.0244, 0.1741, 0.0244, 0.0244, 0.1647, 0.1794, 0.0244,\n",
      "        0.0244])\n",
      "tensor(95.9600)\n",
      "tensor(95.4200)\n",
      "Round 1984, reward -0.083\n",
      "tensor([0.0341, 0.0345, 0.0340, 0.0340, 0.0408, 0.2516, 0.0340, 0.0340, 0.2512,\n",
      "        0.2516])\n",
      "tensor(94.6100)\n",
      "tensor(96.8200)\n",
      "Round 1985, reward -0.417\n",
      "tensor([0.0341, 0.0341, 0.0386, 0.2522, 0.0341, 0.0341, 0.2522, 0.0341, 0.2522,\n",
      "        0.0341])\n",
      "tensor(95.0300)\n",
      "tensor(96.2500)\n",
      "Round 1986, reward -0.405\n",
      "tensor([0.1762, 0.1762, 0.0238, 0.1761, 0.1762, 0.0238, 0.1758, 0.0242, 0.0238,\n",
      "        0.0238])\n",
      "tensor(95.1200)\n",
      "tensor(95.8900)\n",
      "Round 1987, reward -0.392\n",
      "tensor([0.0362, 0.0363, 0.0362, 0.0362, 0.0817, 0.1657, 0.0362, 0.0362, 0.2676,\n",
      "        0.2676])\n",
      "tensor(93.5900)\n",
      "tensor(94.8400)\n",
      "Round 1988, reward -0.439\n",
      "tensor([0.2558, 0.2559, 0.0346, 0.0346, 0.0347, 0.0346, 0.0346, 0.0346, 0.0347,\n",
      "        0.2457])\n",
      "tensor(95.4900)\n",
      "tensor(96.7400)\n",
      "Round 1989, reward -0.393\n",
      "tensor([0.2082, 0.2044, 0.0282, 0.0303, 0.0282, 0.2081, 0.0282, 0.2082, 0.0282,\n",
      "        0.0282])\n",
      "tensor(96.2800)\n",
      "tensor(96.0300)\n",
      "Round 1990, reward -0.075\n",
      "tensor([0.1712, 0.0240, 0.1773, 0.1772, 0.0241, 0.0240, 0.0240, 0.0240, 0.1770,\n",
      "        0.1773])\n",
      "tensor(93.2900)\n",
      "tensor(96.4300)\n",
      "Round 1991, reward -0.448\n",
      "tensor([0.1951, 0.0286, 0.0286, 0.0286, 0.0286, 0.2112, 0.0286, 0.0286, 0.2111,\n",
      "        0.2112])\n",
      "tensor(95.9100)\n",
      "tensor(94.6100)\n",
      "Round 1992, reward -0.084\n",
      "tensor([0.1511, 0.0552, 0.0552, 0.0552, 0.0552, 0.0552, 0.0552, 0.0552, 0.0553,\n",
      "        0.4075])\n",
      "tensor(96.7300)\n",
      "tensor(96.4900)\n",
      "Round 1993, reward -0.063\n",
      "tensor([0.0484, 0.0484, 0.0484, 0.0491, 0.0484, 0.0578, 0.3411, 0.0484, 0.2616,\n",
      "        0.0484])\n",
      "tensor(95.5400)\n",
      "tensor(96.6000)\n",
      "Round 1994, reward -0.390\n",
      "tensor([0.0227, 0.1680, 0.1680, 0.1671, 0.1678, 0.0263, 0.0623, 0.0273, 0.1677,\n",
      "        0.0227])\n",
      "tensor(94.4900)\n",
      "tensor(96.1600)\n",
      "Round 1995, reward -0.419\n",
      "tensor([0.0564, 0.0564, 0.0564, 0.1252, 0.0564, 0.4166, 0.0564, 0.0564, 0.0635,\n",
      "        0.0564])\n",
      "tensor(94.6700)\n",
      "tensor(95.8800)\n",
      "Round 1996, reward -0.413\n",
      "tensor([0.2487, 0.0505, 0.2484, 0.0337, 0.0337, 0.0337, 0.2487, 0.0337, 0.0341,\n",
      "        0.0350])\n",
      "tensor(95.5000)\n",
      "tensor(95.0700)\n",
      "Round 1997, reward -0.095\n",
      "tensor([0.1025, 0.0893, 0.0893, 0.1734, 0.0987, 0.0893, 0.0894, 0.0894, 0.0893,\n",
      "        0.0895])\n",
      "tensor(94.8900)\n",
      "tensor(95.3500)\n",
      "Round 1998, reward -0.366\n",
      "tensor([0.0600, 0.1293, 0.0600, 0.0600, 0.0600, 0.3736, 0.0600, 0.0651, 0.0600,\n",
      "        0.0721])\n",
      "tensor(92.8300)\n",
      "tensor(96.4200)\n",
      "Round 1999, reward -0.458\n",
      "tensor([0.0607, 0.4475, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0667, 0.0608,\n",
      "        0.0607])\n",
      "tensor(94.9700)\n",
      "tensor(96.1400)\n",
      "Round 2000, reward -0.406\n",
      "tensor([0.1752, 0.0238, 0.1704, 0.0238, 0.1760, 0.0238, 0.0324, 0.1761, 0.1746,\n",
      "        0.0238])\n",
      "tensor(94.9800)\n",
      "tensor(96.5100)\n",
      "Round 2001, reward -0.407\n",
      "tensor([0.0340, 0.0340, 0.0340, 0.0340, 0.2510, 0.0407, 0.2510, 0.0400, 0.0340,\n",
      "        0.2476])\n",
      "tensor(93.2000)\n",
      "tensor(96.7600)\n",
      "Round 2002, reward -0.450\n",
      "tensor([0.0432, 0.2898, 0.0446, 0.0517, 0.0875, 0.0404, 0.0510, 0.0530, 0.0404,\n",
      "        0.2984])\n",
      "tensor(94.9400)\n",
      "tensor(95.8500)\n",
      "Round 2003, reward -0.402\n",
      "tensor([0.2444, 0.2284, 0.0332, 0.0331, 0.0332, 0.0331, 0.0331, 0.2444, 0.0842,\n",
      "        0.0331])\n",
      "tensor(96.4700)\n",
      "tensor(97.1300)\n",
      "Round 2004, reward -0.351\n",
      "tensor([0.2033, 0.0633, 0.1586, 0.0275, 0.1837, 0.0304, 0.1512, 0.0275, 0.0275,\n",
      "        0.1269])\n",
      "tensor(95.0400)\n",
      "tensor(95.8700)\n",
      "Round 2005, reward -0.397\n",
      "tensor([0.0343, 0.0343, 0.2474, 0.2506, 0.0343, 0.0343, 0.2452, 0.0512, 0.0343,\n",
      "        0.0343])\n",
      "tensor(89.1800)\n",
      "tensor(94.1900)\n",
      "Round 2006, reward -0.535\n",
      "tensor([0.0308, 0.0308, 0.0308, 0.0310, 0.2276, 0.0308, 0.0315, 0.1960, 0.1627,\n",
      "        0.2278])\n",
      "tensor(95.9500)\n",
      "tensor(95.2400)\n",
      "Round 2007, reward -0.083\n",
      "tensor([0.0433, 0.0582, 0.3172, 0.0443, 0.3201, 0.0433, 0.0433, 0.0433, 0.0436,\n",
      "        0.0433])\n",
      "tensor(95.9900)\n",
      "tensor(96.8900)\n",
      "Round 2008, reward -0.375\n",
      "tensor([0.0368, 0.0332, 0.2425, 0.0332, 0.0332, 0.0332, 0.0332, 0.2438, 0.0654,\n",
      "        0.2454])\n",
      "tensor(94.5600)\n",
      "tensor(95.3200)\n",
      "Round 2009, reward -0.405\n",
      "tensor([0.0610, 0.0610, 0.0610, 0.0613, 0.0610, 0.4507, 0.0610, 0.0610, 0.0610,\n",
      "        0.0610])\n",
      "tensor(87.4600)\n",
      "tensor(92.7000)\n",
      "Round 2010, reward -0.567\n",
      "tensor([0.0345, 0.0352, 0.0346, 0.2552, 0.0345, 0.2552, 0.0345, 0.0345, 0.0345,\n",
      "        0.2471])\n",
      "tensor(94.0900)\n",
      "tensor(92.3900)\n",
      "Round 2011, reward -0.129\n",
      "tensor([0.0589, 0.0546, 0.4034, 0.0546, 0.0547, 0.0546, 0.0546, 0.0598, 0.1502,\n",
      "        0.0546])\n",
      "tensor(94.1900)\n",
      "tensor(95.8800)\n",
      "Round 2012, reward -0.427\n",
      "tensor([0.2468, 0.0334, 0.0334, 0.0576, 0.0334, 0.0334, 0.0347, 0.2465, 0.2469,\n",
      "        0.0337])\n",
      "tensor(83.1600)\n",
      "tensor(93.9500)\n",
      "Round 2013, reward -0.638\n",
      "tensor([0.0315, 0.0315, 0.0315, 0.0315, 0.2328, 0.2328, 0.0315, 0.1132, 0.2318,\n",
      "        0.0317])\n",
      "tensor(96.4800)\n",
      "tensor(97.1600)\n",
      "Round 2014, reward -0.352\n",
      "tensor([0.0923, 0.0282, 0.0293, 0.0282, 0.2083, 0.0282, 0.0282, 0.1483, 0.2038,\n",
      "        0.2053])\n",
      "tensor(95.7800)\n",
      "tensor(96.4600)\n",
      "Round 2015, reward -0.370\n",
      "tensor([0.0420, 0.0442, 0.0417, 0.0417, 0.3079, 0.0417, 0.0417, 0.0856, 0.3079,\n",
      "        0.0458])\n",
      "tensor(96.2900)\n",
      "tensor(96.4800)\n",
      "Round 2016, reward -0.238\n",
      "tensor([0.0400, 0.0400, 0.0402, 0.0400, 0.2959, 0.0401, 0.0400, 0.2520, 0.0400,\n",
      "        0.1716])\n",
      "tensor(96.0100)\n",
      "tensor(96.6800)\n",
      "Round 2017, reward -0.363\n",
      "tensor([0.0563, 0.0563, 0.0617, 0.0742, 0.0591, 0.0563, 0.0563, 0.4141, 0.0869,\n",
      "        0.0788])\n",
      "tensor(95.9000)\n",
      "tensor(96.3300)\n",
      "Round 2018, reward -0.335\n",
      "tensor([0.0310, 0.0309, 0.0309, 0.2282, 0.1224, 0.0321, 0.0371, 0.2283, 0.2283,\n",
      "        0.0309])\n",
      "tensor(93.2900)\n",
      "tensor(95.3600)\n",
      "Round 2019, reward -0.448\n",
      "tensor([0.0350, 0.0350, 0.0350, 0.0350, 0.2583, 0.0350, 0.2582, 0.2383, 0.0351,\n",
      "        0.0353])\n",
      "tensor(95.6900)\n",
      "tensor(96.7900)\n",
      "Round 2020, reward -0.387\n",
      "tensor([0.0349, 0.0349, 0.0349, 0.0349, 0.2552, 0.2464, 0.0349, 0.2543, 0.0349,\n",
      "        0.0350])\n",
      "tensor(94.7500)\n",
      "tensor(95.9400)\n",
      "Round 2021, reward -0.411\n",
      "tensor([0.1879, 0.0257, 0.1216, 0.0254, 0.0255, 0.1879, 0.1874, 0.0254, 0.0254,\n",
      "        0.1878])\n",
      "tensor(96.7100)\n",
      "tensor(97.1200)\n",
      "Round 2022, reward -0.309\n",
      "tensor([0.0359, 0.0359, 0.0388, 0.2655, 0.2654, 0.0359, 0.0359, 0.0359, 0.2147,\n",
      "        0.0359])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.1800)\n",
      "tensor(92.9600)\n",
      "Round 2023, reward -0.150\n",
      "tensor([0.2192, 0.0317, 0.0305, 0.0305, 0.1481, 0.0305, 0.2251, 0.2235, 0.0305,\n",
      "        0.0306])\n",
      "tensor(96.4000)\n",
      "tensor(96.0900)\n",
      "Round 2024, reward -0.072\n",
      "tensor([0.0352, 0.0344, 0.0344, 0.2541, 0.0344, 0.0344, 0.0344, 0.2500, 0.0345,\n",
      "        0.2541])\n",
      "tensor(93.5300)\n",
      "tensor(93.8800)\n",
      "Round 2025, reward -0.372\n",
      "tensor([0.2074, 0.2079, 0.0281, 0.0281, 0.0281, 0.2079, 0.0282, 0.0281, 0.0282,\n",
      "        0.2079])\n",
      "tensor(95.8900)\n",
      "tensor(96.7100)\n",
      "Round 2026, reward -0.375\n",
      "tensor([0.0281, 0.2078, 0.2078, 0.0281, 0.2078, 0.0281, 0.0281, 0.2078, 0.0281,\n",
      "        0.0281])\n",
      "tensor(94.5500)\n",
      "tensor(94.8300)\n",
      "Round 2027, reward -0.325\n",
      "tensor([0.1349, 0.0306, 0.2262, 0.0306, 0.2262, 0.0355, 0.0306, 0.0306, 0.0306,\n",
      "        0.2241])\n",
      "tensor(95.4000)\n",
      "tensor(96.4100)\n",
      "Round 2028, reward -0.393\n",
      "tensor([0.0962, 0.0962, 0.0962, 0.0962, 0.0962, 0.1009, 0.0962, 0.0962, 0.1291,\n",
      "        0.0967])\n",
      "tensor(95.2200)\n",
      "tensor(95.4200)\n",
      "Round 2029, reward -0.271\n",
      "tensor([0.1414, 0.1265, 0.0193, 0.1424, 0.1425, 0.1425, 0.0193, 0.1424, 0.1036,\n",
      "        0.0202])\n",
      "tensor(97.2000)\n",
      "tensor(97.1000)\n",
      "Round 2030, reward -0.050\n",
      "tensor([0.0613, 0.0265, 0.1960, 0.1376, 0.0265, 0.0265, 0.0265, 0.1444, 0.1959,\n",
      "        0.1587])\n",
      "tensor(97.1200)\n",
      "tensor(97.2100)\n",
      "Round 2031, reward -0.146\n",
      "tensor([0.0591, 0.0588, 0.4335, 0.0588, 0.0588, 0.0588, 0.0949, 0.0588, 0.0598,\n",
      "        0.0588])\n",
      "tensor(95.6400)\n",
      "tensor(95.6800)\n",
      "Round 2032, reward -0.137\n",
      "tensor([0.2385, 0.0329, 0.0602, 0.0329, 0.0329, 0.2433, 0.2433, 0.0329, 0.0501,\n",
      "        0.0329])\n",
      "tensor(95.3100)\n",
      "tensor(95.9800)\n",
      "Round 2033, reward -0.381\n",
      "tensor([0.0431, 0.3049, 0.0431, 0.0443, 0.1691, 0.0431, 0.0431, 0.0431, 0.0538,\n",
      "        0.2126])\n",
      "tensor(93.1300)\n",
      "tensor(96.3900)\n",
      "Round 2034, reward -0.452\n",
      "tensor([0.0339, 0.0339, 0.0339, 0.2503, 0.0339, 0.2503, 0.0421, 0.2503, 0.0376,\n",
      "        0.0339])\n",
      "tensor(91.0500)\n",
      "tensor(94.8600)\n",
      "Round 2035, reward -0.497\n",
      "tensor([0.0304, 0.2247, 0.1500, 0.0304, 0.0304, 0.0304, 0.0304, 0.0534, 0.2247,\n",
      "        0.1951])\n",
      "tensor(93.4700)\n",
      "tensor(93.4000)\n",
      "Round 2036, reward -0.144\n",
      "tensor([0.0299, 0.1800, 0.0244, 0.0330, 0.0244, 0.1469, 0.1790, 0.1800, 0.0896,\n",
      "        0.1128])\n",
      "tensor(96.0600)\n",
      "tensor(95.7700)\n",
      "Round 2037, reward -0.081\n",
      "tensor([0.0312, 0.0312, 0.1896, 0.0312, 0.1625, 0.0312, 0.2304, 0.0312, 0.0312,\n",
      "        0.2304])\n",
      "tensor(95.0400)\n",
      "tensor(96.0800)\n",
      "Round 2038, reward -0.402\n",
      "tensor([0.0285, 0.2108, 0.2108, 0.0304, 0.0312, 0.2079, 0.0285, 0.0286, 0.1650,\n",
      "        0.0581])\n",
      "tensor(94.5300)\n",
      "tensor(96.6500)\n",
      "Round 2039, reward -0.419\n",
      "tensor([0.1514, 0.0208, 0.0207, 0.1531, 0.1531, 0.0207, 0.1531, 0.1531, 0.0207,\n",
      "        0.1531])\n",
      "tensor(96.9600)\n",
      "tensor(97.0400)\n",
      "Round 2040, reward -0.142\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1ed07c9114e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m40\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m40\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m800\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cnn'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cifar'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c247676012f1>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# mini batch gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mV_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "cv_loss, cv_acc = [], []\n",
    "val_loss_pre, counter = 0, 0\n",
    "net_best = None\n",
    "best_loss = None\n",
    "val_acc_list, net_list = [], []\n",
    "\n",
    "reward_save = []\n",
    "\n",
    "constant = 64\n",
    "target_acc = 0.99\n",
    "args.emb = False\n",
    "m = max(int(args.frac * args.num_users), 1)\n",
    "\n",
    "last_replay_data = []\n",
    "\n",
    "if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "    net_avg = CNNCifar(args=args).to(args.device)\n",
    "elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "    net_avg = CNNMnist(args=args).to(args.device)\n",
    "elif args.model == 'mlp':\n",
    "    len_in = 1\n",
    "    for x in img_size:\n",
    "        len_in *= x\n",
    "    net_avg = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "\n",
    "\n",
    "for iter in range(args.epochs):\n",
    "    if iter==0:\n",
    "        random_n = 0\n",
    "        n_weight = []\n",
    "        while random_n < args.num_users*args.frac:\n",
    "            n_weight.append(random.random()) # 随机初始化参数\n",
    "            random_n += 1\n",
    "        action = F.softmax(torch.tensor(n_weight))\n",
    "        \n",
    "    loss_locals = []\n",
    "    w_locals = []\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    p_emb_collect = []\n",
    "    \n",
    "    for i in layer_name:\n",
    "        if i == 'conv1':\n",
    "            emb_global = layer_dict[i].forward(torch.cat([net_glob.state_dict()[i+'.weight'].reshape(1,-1), net_glob.state_dict()[i+'.bias'].reshape(1,-1)], 1))\n",
    "        else:\n",
    "            emb_global += layer_dict[i].forward(torch.cat([net_glob.state_dict()[i+'.weight'].reshape(1,-1), net_glob.state_dict()[i+'.bias'].reshape(1,-1)], 1))\n",
    "    emb_global = emb_global/4\n",
    "    p_emb_collect.append(emb_global)\n",
    "    \n",
    "    for idx in idxs_users:\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx], flag=True)\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        start = time.time()\n",
    "        ############ 储存参数 ##############\n",
    "        for i in layer_name:\n",
    "            if i == 'conv1':\n",
    "                emb_feature = layer_dict[i].forward(torch.cat([w[i+'.weight'].reshape(1,-1), w[i+'.bias'].reshape(1,-1)], 1))\n",
    "            else:\n",
    "                emb_feature += layer_dict[i].forward(torch.cat([w[i+'.weight'].reshape(1,-1), w[i+'.bias'].reshape(1,-1)], 1))\n",
    "        end = time.time()\n",
    "        print('emb time: ', end-start)\n",
    "        avg_emb_feature = emb_feature/4\n",
    "        p_emb_collect.append(avg_emb_feature)\n",
    "        ############ 储存loss ##############\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    p_emb_collect = torch.cat(p_emb_collect).unsqueeze(0).to(args.device) # para * 11\n",
    "    start = time.time()\n",
    "    action_next = trainer.select_action(p_emb_collect,\n",
    "                                          torch.tensor(loss_locals).reshape(1,-1).to(args.device), \n",
    "                                          action.reshape(1,-1).to(args.device)) #s = [p, loss, last_action]\n",
    "    end = time.time()\n",
    "    print('drl time: ', end-start)\n",
    "    print(action_next)\n",
    "    ###########计算当前轮的reward，然后将当前轮的reward添加到上一个replay_data中\n",
    "    # update global weights\n",
    "    w_avg_glob = FedAvg(w_locals)\n",
    "    w_glob = FedPareto(w_locals, action_next)\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "    net_avg.load_state_dict(w_avg_glob)\n",
    "    \n",
    "#     reward = -sum(loss_locals) / len(loss_locals)\n",
    "    net_glob.eval()\n",
    "    global_acc, loss_train = test_img(net_glob, dataset_test, args)\n",
    "    avg_acc, _ = test_img(net_avg, dataset_test, args)\n",
    "    print(global_acc)\n",
    "    print(avg_acc)\n",
    "    # 当acc达到一个高度后，就采用avg和rl的reward之差试试\n",
    "    \n",
    "    diff = global_acc.numpy() - avg_acc.numpy()\n",
    "    \n",
    "#     reward = constant ** (global_acc.numpy()/100 - target_acc) - 1\n",
    "    \n",
    "    reward1 = constant ** (global_acc.numpy()/100 - target_acc) - 1\n",
    "    reward2 = constant ** diff - 1\n",
    "    reward =  0.7 * reward1 + 0.3 * np.clip(reward2, -1, 0)\n",
    "        \n",
    "    reward_save.append(reward)\n",
    "    \n",
    "    if len(last_replay_data)==3:\n",
    "#         last_replay_data.append(reward)#r\n",
    "        last_replay_data.append([p_emb_collect, \n",
    "                                 torch.tensor(loss_locals).reshape(1,-1).to(args.device), \n",
    "                                 action.reshape(1,-1).to(args.device)])#s_next\n",
    "        trainer.replay_buffer.add(last_replay_data[0],\n",
    "                                  last_replay_data[1],\n",
    "                                  last_replay_data[2],\n",
    "                                  last_replay_data[3])\n",
    "    last_replay_data = [[p_emb_collect, \n",
    "                         torch.tensor(loss_locals).reshape(1,-1).to(args.device), \n",
    "                         action.reshape(1,-1).to(args.device)], \n",
    "                        action_next.reshape(1,-1).to(args.device), reward]#s, a, r\n",
    "    action = action_next\n",
    "\n",
    "    # print loss\n",
    "    print('Round {:3d}, reward {:.3f}'.format(iter, reward))\n",
    "    \n",
    "    if iter > 40 and iter % 40 == 0:\n",
    "        trainer.optimize()\n",
    "    if iter % 800 == 0:\n",
    "        if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "            net_glob = CNNCifar(args=args).to(args.device)\n",
    "        elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "            net_glob = CNNMnist(args=args).to(args.device)\n",
    "        elif args.model == 'mlp':\n",
    "            len_in = 1\n",
    "            for x in img_size:\n",
    "                len_in *= x\n",
    "            net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "        else:\n",
    "            exit('Error: unrecognized model')\n",
    "            \n",
    "#     args.lr = max(args.lr*args.lr_decay, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 0.980\n",
      "Round   1, Average loss 0.976\n",
      "Round   2, Average loss 0.955\n",
      "Round   3, Average loss 0.954\n",
      "Round   4, Average loss 0.925\n",
      "Round   5, Average loss 0.929\n",
      "Round   6, Average loss 0.912\n",
      "Round   7, Average loss 0.803\n",
      "Round   8, Average loss 0.713\n",
      "Round   9, Average loss 0.841\n"
     ]
    }
   ],
   "source": [
    "reward_validation_save = []\n",
    "\n",
    "if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "    net_glob = CNNCifar(args=args).to(args.device)\n",
    "elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "    net_glob = CNNMnist(args=args).to(args.device)\n",
    "elif args.model == 'mlp':\n",
    "    len_in = 1\n",
    "    for x in img_size:\n",
    "        len_in *= x\n",
    "    net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "\n",
    "last_replay_data = []\n",
    "\n",
    "#args.validation_epochs\n",
    "for iter in range(10):\n",
    "    if iter==0:\n",
    "        random_n = 0\n",
    "        n_weight = []\n",
    "        while random_n < args.num_users*args.frac:\n",
    "            n_weight.append(random.random()) # 随机初始化参数\n",
    "            random_n+=1\n",
    "        action = F.softmax(torch.tensor(n_weight))\n",
    "    loss_locals = []\n",
    "    w_locals = []\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    p_emb_collect = []\n",
    "    \n",
    "    for i in layer_name:\n",
    "        if i == 'conv1':\n",
    "            emb_global = layer_dict[i].forward(torch.cat([net_glob.state_dict()[i+'.weight'].reshape(1,-1), net_glob.state_dict()[i+'.bias'].reshape(1,-1)], 1))\n",
    "        else:\n",
    "            emb_global += layer_dict[i].forward(torch.cat([net_glob.state_dict()[i+'.weight'].reshape(1,-1), net_glob.state_dict()[i+'.bias'].reshape(1,-1)], 1))\n",
    "    emb_global = emb_global/4\n",
    "    p_emb_collect.append(emb_global)\n",
    "    \n",
    "    for idx in idxs_users:\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        ############ 储存参数 ##############\n",
    "        for i in layer_name:\n",
    "            if i == 'conv1':\n",
    "                emb_feature = layer_dict[i].forward(torch.cat([w[i+'.weight'].reshape(1,-1), w[i+'.bias'].reshape(1,-1)], 1))\n",
    "            else:\n",
    "                emb_feature += layer_dict[i].forward(torch.cat([w[i+'.weight'].reshape(1,-1), w[i+'.bias'].reshape(1,-1)], 1))\n",
    "\n",
    "        avg_emb_feature = emb_feature/4\n",
    "        p_emb_collect.append(avg_emb_feature)\n",
    "        ############ 储存loss ##############\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    p_emb_collect = torch.cat(p_emb_collect).unsqueeze(0).to(args.device)\n",
    "    action_next = trainer.select_action(p_emb_collect,\n",
    "                                          torch.tensor(loss_locals).reshape(1,-1).to(args.device), \n",
    "                                          action.reshape(1,-1).to(args.device))\n",
    "    ###########计算当前轮的reward，然后将当前轮的reward添加到上一个replay_data中\n",
    "    net_glob.eval()\n",
    "    global_acc, loss_train = test_img(net_glob, dataset_test, args)\n",
    "#     print(global_acc)\n",
    "    reward = constant ** (global_acc.numpy()/100 - target_acc) - 1\n",
    "    if reward >= 0:\n",
    "        print('well done')\n",
    "        break\n",
    "\n",
    "    reward_validation_save.append(reward)\n",
    "    action = action_next\n",
    "    # update global weights\n",
    "#     w_glob = FedAvg(w_locals)\n",
    "    w_glob = FedPareto(w_locals, action_next)\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    print('Round {:3d}, Average loss {:.3f}'.format(iter, -reward))\n",
    "#     loss_train.append(-reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 68.52\n",
      "Testing accuracy: 69.39\n"
     ]
    }
   ],
   "source": [
    "# plot loss curve\n",
    "# plt.figure()\n",
    "# plt.plot(range(len(loss_train)), loss_train)\n",
    "# plt.ylabel('train_loss')\n",
    "# plt.show()\n",
    "# plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))\n",
    "\n",
    "# testing\n",
    "net_glob.eval()\n",
    "acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
    "print(\"Testing accuracy: {:.2f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.6834769156158794,\n",
       " -0.681719784983571,\n",
       " -0.9760755957743401,\n",
       " -0.6722808493226585,\n",
       " -0.967535049539062,\n",
       " -0.9551799840774271,\n",
       " -0.633999219277886,\n",
       " -0.9250730979201847,\n",
       " -0.9476683778237509,\n",
       " -0.9542464715049741,\n",
       " -0.8902805457022114,\n",
       " -0.9252840227724937,\n",
       " -0.8892770017824101,\n",
       " -0.9277056446508225,\n",
       " -0.545312677155666,\n",
       " -0.5511813899459174,\n",
       " -0.8387437601544677,\n",
       " -0.7734900166323073,\n",
       " -0.510505623920146,\n",
       " -0.43015049667893873,\n",
       " -0.4538470402209337,\n",
       " -0.8251212476289496,\n",
       " -0.7600108542735058,\n",
       " -0.4049099812075322,\n",
       " -0.7208439524051975,\n",
       " -0.7258362948851038,\n",
       " -0.7096574119505297,\n",
       " -0.7372357662593461,\n",
       " -0.6603717325375382,\n",
       " -0.7799003632167819,\n",
       " -0.4023214911940043,\n",
       " -0.7273301790326187,\n",
       " -0.8166303369589549,\n",
       " -0.3666690816709653,\n",
       " -0.5740801644753328,\n",
       " -0.7329416145538236,\n",
       " -0.677844937131376,\n",
       " -0.693224795960234,\n",
       " -0.3881278394226757,\n",
       " -0.7555811809195097,\n",
       " -0.42891316192173573,\n",
       " -0.7096577131588127,\n",
       " -0.687894236192671,\n",
       " -0.781186436847958,\n",
       " -0.7397397389397347,\n",
       " -0.8104268423434033,\n",
       " -0.30666600369713204,\n",
       " -0.7395229105938931,\n",
       " -0.6964445778956962,\n",
       " -0.7095368335613481,\n",
       " -0.6349663823417067,\n",
       " -0.33941107046737623,\n",
       " -0.42815482908611646,\n",
       " -0.6100857331927312,\n",
       " -0.615817464794379,\n",
       " -0.2608374668704001,\n",
       " -0.6741768776841153,\n",
       " -0.3484438656348333,\n",
       " -0.6594100431655849,\n",
       " -0.5996337388919473,\n",
       " -0.6588206170267721,\n",
       " -0.6655079148776526,\n",
       " -0.3104104064149974,\n",
       " -0.4970488269550495,\n",
       " -0.2538419680596958,\n",
       " -0.5638042927532673,\n",
       " -0.6089495016683757,\n",
       " -0.21453922241823464,\n",
       " -0.39304940474775685,\n",
       " -0.2416165667052542,\n",
       " -0.5911299030682773,\n",
       " -0.6680523635549206,\n",
       " -0.694037501751227,\n",
       " -0.20803532754375423,\n",
       " -0.4093863467849459,\n",
       " -0.5895019783963512,\n",
       " -0.2261090575272438,\n",
       " -0.5214704565359646,\n",
       " -0.6469787626464975,\n",
       " -0.6793153886647888,\n",
       " -0.20803532754375423,\n",
       " -0.5537437586845018,\n",
       " -0.3525139306122531,\n",
       " -0.4977102234308382,\n",
       " -0.17984018116143005,\n",
       " -0.5560626637887569,\n",
       " -0.23470201469867316,\n",
       " -0.20371972204052516,\n",
       " -0.2657413095537211,\n",
       " -0.7028159796236881,\n",
       " -0.5659781169789808,\n",
       " -0.5565596086016648,\n",
       " -0.21474096704272339,\n",
       " -0.5241333062226253,\n",
       " -0.3272121524692423,\n",
       " -0.3147607002899899,\n",
       " -0.6460967941605302,\n",
       " -0.6504145622969164,\n",
       " -0.572576861266354,\n",
       " -0.5735611829292413,\n",
       " -0.631528023005768,\n",
       " -0.3333624020483655,\n",
       " -0.6175269259110225,\n",
       " -0.3028854869721614,\n",
       " -0.5292492912917257,\n",
       " -0.24008890131198365,\n",
       " -0.5396360051586979,\n",
       " -0.2179593378986924,\n",
       " -0.21129801697412448,\n",
       " -0.16647532520067498,\n",
       " -0.20185874263421183,\n",
       " -0.6104104057730999,\n",
       " -0.4066735294516275,\n",
       " -0.5230228478125429,\n",
       " -0.49627803302239,\n",
       " -0.32983847687513457,\n",
       " -0.4777859029108164,\n",
       " -0.25615716811560796,\n",
       " -0.29369733929719855,\n",
       " -0.5972303803071605,\n",
       " -0.5837046298093309,\n",
       " -0.4752271342193466,\n",
       " -0.6322933683844962,\n",
       " -0.31604033182741875,\n",
       " -0.6028854863030206,\n",
       " -0.30927457854852397,\n",
       " -0.6084613170578373,\n",
       " -0.2593738594292217,\n",
       " -0.6182536865804402,\n",
       " -0.6712125954187711,\n",
       " -0.5673636306102285,\n",
       " -0.20289358509619937,\n",
       " -0.4567615293115103,\n",
       " -0.5774951998737174,\n",
       " -0.6478552962850801,\n",
       " -0.3106231391185061,\n",
       " -0.2962668754610099,\n",
       " -0.2815211364468819,\n",
       " -0.574147120266528,\n",
       " -0.6627648143748042,\n",
       " -0.13566379692931146,\n",
       " -0.4839343933620951,\n",
       " -0.23817223122948694,\n",
       " -0.5872143279676771,\n",
       " -0.5183591987425673,\n",
       " -0.6455004203342639,\n",
       " -0.6146862304616427,\n",
       " -0.21048433997711088,\n",
       " -0.6092745784411726,\n",
       " -0.6035328046580852,\n",
       " -0.29756519918551605,\n",
       " -0.13963959698038714,\n",
       " -0.44941794407972213,\n",
       " -0.5729055688498357,\n",
       " -0.25254121790139333,\n",
       " -0.49708915210419435,\n",
       " -0.5801750226469753,\n",
       " -0.4651985603720221,\n",
       " -0.6075729961711411,\n",
       " -0.5120946208473778,\n",
       " -0.27553096524515286,\n",
       " -0.5508631660155903,\n",
       " -0.598539521484939,\n",
       " -0.17940741708082125,\n",
       " -0.14126854899137614,\n",
       " -0.4865516411719214,\n",
       " -0.4974887718261014,\n",
       " -0.6333624020483655,\n",
       " -0.5106567411559435,\n",
       " -0.43512786713519425,\n",
       " -0.12284654442038226,\n",
       " -0.5858495859977106,\n",
       " -0.4249088238770944,\n",
       " -0.36503163003519873,\n",
       " -0.4626606496857295,\n",
       " -0.48195281192417827,\n",
       " -0.44108314818562944,\n",
       " -0.49911381692155204,\n",
       " -0.4962327003569786,\n",
       " -0.4989407442353445,\n",
       " -0.5957136272687733,\n",
       " -0.5325631626980319,\n",
       " -0.20516239492112123,\n",
       " -0.23295721441766007,\n",
       " -0.11778383182117484,\n",
       " -0.12667438426406147,\n",
       " -0.5327628351461959,\n",
       " -0.4773715577622828,\n",
       " -0.12356616024776136,\n",
       " -0.13331193736344973,\n",
       " -0.12810317924786147,\n",
       " -0.4642299456412433,\n",
       " -0.3053551301129153,\n",
       " -0.5718385378299101,\n",
       " -0.3709864493403993,\n",
       " -0.5225480210756492,\n",
       " -0.536054565624799,\n",
       " -0.41104516972939886,\n",
       " -0.44577146121788463,\n",
       " -0.4940230557882007,\n",
       " -0.4858413566104412,\n",
       " -0.6144281694660159,\n",
       " -0.5227467648161479,\n",
       " -0.15435786677883617,\n",
       " -0.4176377763220804,\n",
       " -0.48345224027820516,\n",
       " -0.5075879570859494,\n",
       " -0.4574985937471141,\n",
       " -0.6253470021991495,\n",
       " -0.6506301825971752,\n",
       " -0.14428131887912893,\n",
       " -0.5822167354906219,\n",
       " -0.5344832610979792,\n",
       " -0.458333291187548,\n",
       " -0.4843574830830203,\n",
       " -0.4509066975994331,\n",
       " -0.5423341287098715,\n",
       " -0.5253170619782719,\n",
       " -0.5744683995872477,\n",
       " -0.627320838174431,\n",
       " -0.5366330865136484,\n",
       " -0.2746305203424384,\n",
       " -0.5723710357332438,\n",
       " -0.11826782305156211,\n",
       " -0.1285785920945987,\n",
       " -0.4999900618408234,\n",
       " -0.5885962337095285,\n",
       " -0.5698752933297513,\n",
       " -0.10183023282380527,\n",
       " -0.563568605298923,\n",
       " -0.6304537624341956,\n",
       " -0.3624567410586875,\n",
       " -0.3790356220166919,\n",
       " -0.5508631695415183,\n",
       " -0.54104431603586,\n",
       " -0.45164832820197387,\n",
       " -0.46201759107123364,\n",
       " -0.10158135610791909,\n",
       " -0.530746899146662,\n",
       " -0.4481912104044049,\n",
       " -0.09733552991797051,\n",
       " -0.4787560511674289,\n",
       " -0.5525412165444403,\n",
       " -0.4582550231439643,\n",
       " -0.4526934644005357,\n",
       " -0.3966222053102134,\n",
       " -0.3987911791073516,\n",
       " -0.18221437176290692,\n",
       " -0.46624207335315404,\n",
       " -0.499614998746543,\n",
       " -0.5377869453652542,\n",
       " -0.5115012618156067,\n",
       " -0.16405420727763742,\n",
       " -0.45409198628966335,\n",
       " -0.44618289285370694,\n",
       " -0.10008630048673077,\n",
       " -0.4383561478603319,\n",
       " -0.4934766586228475,\n",
       " -0.41428027444800813,\n",
       " -0.4611032508934497,\n",
       " -0.113164946523441,\n",
       " -0.42752069536845794,\n",
       " -0.46026007511531386,\n",
       " -0.48095310564007876,\n",
       " -0.5174575680934471,\n",
       " -0.5221509603184107,\n",
       " -0.18981441295788248,\n",
       " -0.10826350831134264,\n",
       " -0.40428870793273913,\n",
       " -0.4633360357420897,\n",
       " -0.4493215202913152,\n",
       " -0.29433671484567697,\n",
       " -0.09331200010861387,\n",
       " -0.35176346626471977,\n",
       " -0.4236108292467188,\n",
       " -0.5982341296542366,\n",
       " -0.11681445596474094,\n",
       " -0.13425389096924073,\n",
       " -0.13636743174214475,\n",
       " -0.4604471803975043,\n",
       " -0.4668664961523118,\n",
       " -0.1622427232718808,\n",
       " -0.4675830341264948,\n",
       " -0.2321795994612063,\n",
       " -0.190121057515751,\n",
       " -0.11487085960246711,\n",
       " -0.08543948121048373,\n",
       " -0.4338720523458196,\n",
       " -0.6141192861613844,\n",
       " -0.515749025858237,\n",
       " -0.1153574578669963,\n",
       " -0.44166854329106053,\n",
       " -0.11047414517129703,\n",
       " -0.48516999827358825,\n",
       " -0.41613294799603123,\n",
       " -0.6185867365210332,\n",
       " -0.09983669818393501,\n",
       " -0.5167536256024845,\n",
       " -0.5080006819219525,\n",
       " -0.08799021445326603,\n",
       " -0.3887131105328227,\n",
       " -0.4311126080325227,\n",
       " -0.14054951980613625,\n",
       " -0.45057005879967515,\n",
       " -0.4269633724092561,\n",
       " -0.38969611506121693,\n",
       " -0.4956072242311853,\n",
       " -0.43041200469022023,\n",
       " -0.40083902218662826,\n",
       " -0.44445679411462446,\n",
       " -0.18206374211935333,\n",
       " -0.15299466503578252,\n",
       " -0.42754111542152856,\n",
       " -0.4398516126017993,\n",
       " -0.4019447928207427,\n",
       " -0.5199598951709818,\n",
       " -0.451625200420123,\n",
       " -0.6236283272718177,\n",
       " -0.6797153318054501,\n",
       " -0.13940645136777197,\n",
       " -0.49518470668491077,\n",
       " -0.3893803237122322,\n",
       " -0.4102671047050078,\n",
       " -0.5063957451455006,\n",
       " -0.4312751585825161,\n",
       " -0.5251226730227916,\n",
       " -0.47634766614532464,\n",
       " -0.1180259700789834,\n",
       " -0.40467167089604816,\n",
       " -0.5926821262466193,\n",
       " -0.10555023250664101,\n",
       " -0.41457351693533473,\n",
       " -0.4047837439867411,\n",
       " -0.5695174447138145,\n",
       " -0.4750299605161149,\n",
       " -0.27539097101849225,\n",
       " -0.43446707364180437,\n",
       " -0.5310085388103678,\n",
       " -0.5950469360251749,\n",
       " -0.4660287009874814,\n",
       " -0.39779109204384544,\n",
       " -0.3638256651999526,\n",
       " -0.36557878182893766,\n",
       " -0.4697586533882282,\n",
       " -0.47461630894399043,\n",
       " -0.4087322258865144,\n",
       " -0.09958718254026123,\n",
       " -0.11699943000311386,\n",
       " -0.08595055485430869,\n",
       " -0.3638634718949064,\n",
       " -0.3696195902158267,\n",
       " -0.46335942464447594,\n",
       " -0.4798519652357933,\n",
       " -0.3462338647325601,\n",
       " -0.42368012870450245,\n",
       " -0.403489776070211,\n",
       " -0.47992085420215913,\n",
       " -0.390282919595786,\n",
       " -0.3844214163962138,\n",
       " -0.4372437156562683,\n",
       " -0.08030647084820781,\n",
       " -0.4599920866931996,\n",
       " -0.4823887975810006,\n",
       " -0.10924709762400785,\n",
       " -0.5106879249286388,\n",
       " -0.47309058114396696,\n",
       " -0.5350888128564396,\n",
       " -0.4055314384658043,\n",
       " -0.4043832530487271,\n",
       " -0.42710652021884393,\n",
       " -0.5106879211227326,\n",
       " -0.24408809927504677,\n",
       " -0.5165539738280767,\n",
       " -0.4177027415304089,\n",
       " -0.3769666690091219,\n",
       " -0.3977476160003763,\n",
       " -0.4398023876516312,\n",
       " -0.3762966899897097,\n",
       " -0.5298389777047849,\n",
       " -0.3994758297390789,\n",
       " -0.10629141400202073,\n",
       " -0.1035690955983764,\n",
       " -0.40091126082076123,\n",
       " -0.4230125159000123,\n",
       " -0.5512363730590906,\n",
       " -0.4141896496834184,\n",
       " -0.43750509234818,\n",
       " -0.09179609180997221,\n",
       " -0.4666827469966934,\n",
       " -0.4410001424350183,\n",
       " -0.4976151295299055,\n",
       " -0.11632925555777313,\n",
       " -0.11096439978015125,\n",
       " -0.5219520629768495,\n",
       " -0.09027658923255558,\n",
       " -0.46957268926836104,\n",
       " -0.534508421073471,\n",
       " -0.0892614144816565,\n",
       " -0.40214222130583727,\n",
       " -0.30529097135353667,\n",
       " -0.330896568863011,\n",
       " -0.08671617393749766,\n",
       " -0.4009646963010176,\n",
       " -0.4114473617061992,\n",
       " -0.44541367075366584,\n",
       " -0.5171530848518425,\n",
       " -0.07720599007630023,\n",
       " -0.3993640582048042,\n",
       " -0.4232838570873171,\n",
       " -0.4400711323601131,\n",
       " -0.42907186712479495,\n",
       " -0.32516300399469844,\n",
       " -0.14819640770164622,\n",
       " -0.08133653058081253,\n",
       " -0.4198444074964386,\n",
       " -0.39701730952933845,\n",
       " -0.5171522371906911,\n",
       " -0.4726050313940943,\n",
       " -0.27920164447151213,\n",
       " -0.5112980169728176,\n",
       " -0.4655766476954747,\n",
       " -0.5943726989552189,\n",
       " -0.5940273430054112,\n",
       " -0.40996732373303446,\n",
       " -0.42027931815375474,\n",
       " -0.0888524532914173,\n",
       " -0.11971775229855976,\n",
       " -0.16022621110722074,\n",
       " -0.4230269802687333,\n",
       " -0.41171194213531037,\n",
       " -0.1948796107491647,\n",
       " -0.07824120345380328,\n",
       " -0.17785133415152604,\n",
       " -0.3792115714679407,\n",
       " -0.468025988217622,\n",
       " -0.39839080250435227,\n",
       " -0.13602205133799858,\n",
       " -0.38607269577741027,\n",
       " -0.39241115915689273,\n",
       " -0.3773041500269843,\n",
       " -0.433293371352249,\n",
       " -0.4702325240886344,\n",
       " -0.20082174590728388,\n",
       " -0.4264296020202686,\n",
       " -0.5471184271831541,\n",
       " -0.4482030783956966,\n",
       " -0.2192836397064166,\n",
       " -0.20016411227540226,\n",
       " -0.4142112606228204,\n",
       " -0.40986326037604426,\n",
       " -0.4187968458638571,\n",
       " -0.40744609716504876,\n",
       " -0.2516556566518227,\n",
       " -0.08082161668240086,\n",
       " -0.40947230487801833,\n",
       " -0.41291286779005765,\n",
       " -0.4330214159575195,\n",
       " -0.4283403178145113,\n",
       " -0.4178030770094341,\n",
       " -0.39227281538275605,\n",
       " -0.2028417652739267,\n",
       " -0.39282163371997614,\n",
       " -0.08900730833693053,\n",
       " -0.41030790810051354,\n",
       " -0.11798158440673145,\n",
       " -0.14289276568445225,\n",
       " -0.30820438476013745,\n",
       " -0.40757936357609836,\n",
       " -0.4158088204991201,\n",
       " -0.13542899713068757,\n",
       " -0.21726191119174298,\n",
       " -0.12260641182848434,\n",
       " -0.4222776551964193,\n",
       " -0.40077050197290637,\n",
       " -0.1653286805785208,\n",
       " -0.2604314063174672,\n",
       " -0.2697352972046388,\n",
       " -0.39876996963027334,\n",
       " -0.5364404427022524,\n",
       " -0.43635864949485825,\n",
       " -0.3902441343411367,\n",
       " -0.4094664583214528,\n",
       " -0.3884255534889063,\n",
       " -0.2203589483605077,\n",
       " -0.18969668503059517,\n",
       " -0.23432836070720736,\n",
       " -0.5930208551814753,\n",
       " -0.06675898477234596,\n",
       " -0.2556607643320893,\n",
       " -0.3346531152194993,\n",
       " -0.05640410534895539,\n",
       " -0.5543982540494834,\n",
       " -0.43444571006339666,\n",
       " -0.3992668850186078,\n",
       " -0.46402761516489616,\n",
       " -0.3619181732229839,\n",
       " -0.3768066172301285,\n",
       " -0.4132407415074476,\n",
       " -0.5298591020240605,\n",
       " -0.06067260965219953,\n",
       " -0.4907567906151574,\n",
       " -0.3647744846147648,\n",
       " -0.38393193814126386,\n",
       " -0.08390409763319268,\n",
       " -0.3575415194679472,\n",
       " -0.386332289394537,\n",
       " -0.3549422848404182,\n",
       " -0.49876612634280565,\n",
       " -0.4109180465069212,\n",
       " -0.28012500581945776,\n",
       " -0.4306690509109412,\n",
       " -0.5896215021040782,\n",
       " -0.5429462173024946,\n",
       " -0.4041973005171614,\n",
       " -0.389643599617594,\n",
       " -0.2915616841583278,\n",
       " -0.4845760618173181,\n",
       " -0.1254808738326511,\n",
       " -0.3692221322025203,\n",
       " -0.32825287359275646,\n",
       " -0.2593404201126341,\n",
       " -0.31359625085496606,\n",
       " -0.2324418400435341,\n",
       " -0.06859979868360246,\n",
       " -0.41765780894344845,\n",
       " -0.36833411824325896,\n",
       " -0.22892024272797895,\n",
       " -0.36805521006308034,\n",
       " -0.4532219138027128,\n",
       " -0.4249981774773287,\n",
       " -0.06833709599092828,\n",
       " -0.2964774634852616,\n",
       " -0.32693283208252394,\n",
       " -0.09658316796181529,\n",
       " -0.5282720606423594,\n",
       " -0.5059849103159948,\n",
       " -0.40920913371765283,\n",
       " -0.39774167831899787,\n",
       " -0.35507285462837396,\n",
       " -0.1989020200574538,\n",
       " -0.37939053990043053,\n",
       " -0.43577785831135807,\n",
       " -0.06040660874406771,\n",
       " -0.40402418479399294,\n",
       " -0.0643842206916724,\n",
       " -0.2763798332915869,\n",
       " -0.08518397997780551,\n",
       " -0.22192191881961015,\n",
       " -0.2501767171473904,\n",
       " -0.34736819546705744,\n",
       " -0.46089898497867,\n",
       " -0.48757000303116194,\n",
       " -0.2642688205647612,\n",
       " -0.5469234015908158,\n",
       " -0.4611229497406294,\n",
       " -0.455491261651691,\n",
       " -0.39261490154032597,\n",
       " -0.39093793384619063,\n",
       " -0.06040660874406771,\n",
       " -0.395143845713275,\n",
       " -0.4213861178073474,\n",
       " -0.3808378933897099,\n",
       " -0.062000753267812424,\n",
       " -0.38293418323652645,\n",
       " -0.4970708395929191,\n",
       " -0.41534537245512365,\n",
       " -0.44573572944979917,\n",
       " -0.07200421090441594,\n",
       " -0.34613631307937787,\n",
       " -0.40463459089003573,\n",
       " -0.3863719964344533,\n",
       " -0.26899812355468633,\n",
       " -0.11273635827466147,\n",
       " -0.06781136265695478,\n",
       " -0.32424011663434565,\n",
       " -0.07616905309352974,\n",
       " -0.22555643426191593,\n",
       " -0.07875826324533854,\n",
       " -0.34049651937260605,\n",
       " -0.4651423373066476,\n",
       " -0.16854928834623256,\n",
       " -0.058275020604934606,\n",
       " -0.39204959897937086,\n",
       " -0.40691739451143594,\n",
       " -0.3537588567895858,\n",
       " -0.25833991550695934,\n",
       " -0.13724207431012403,\n",
       " -0.10777100574924067,\n",
       " -0.35557025580234625,\n",
       " -0.3772726527476058,\n",
       " -0.4502272794190488,\n",
       " -0.08133653058081253,\n",
       " -0.4121176975635072,\n",
       " -0.49357072479505315,\n",
       " -0.3898182902461541,\n",
       " -0.3519305147702962,\n",
       " -0.3623627506993872,\n",
       " -0.30813254296928627,\n",
       " -0.43636613526600876,\n",
       " -0.5555511294544121,\n",
       " -0.5446473914681893,\n",
       " -0.2039261203655077,\n",
       " -0.08697123294358715,\n",
       " -0.4581993965122099,\n",
       " -0.4452026367882861,\n",
       " -0.0896532636990264,\n",
       " -0.07953284993814141,\n",
       " -0.06014070018847033,\n",
       " -0.22260414182818777,\n",
       " -0.3339251424144625,\n",
       " -0.3608319432808243,\n",
       " -0.4113415362781866,\n",
       " -0.14345025877802575,\n",
       " -0.14690910402520535,\n",
       " -0.3306418278737261,\n",
       " -0.3898271817628065,\n",
       " -0.30334509725725695,\n",
       " -0.3862779754428777,\n",
       " -0.08697123294358715,\n",
       " -0.33458329003746556,\n",
       " -0.44242880361200243,\n",
       " -0.27642137708999315,\n",
       " -0.35366582315578254,\n",
       " -0.08773557940837548,\n",
       " -0.22194693232504076,\n",
       " -0.4219711934062674,\n",
       " -0.05102858203537018,\n",
       " -0.33458329003746556,\n",
       " -0.11997018535218981,\n",
       " -0.3391001886628595,\n",
       " -0.37560095200063087,\n",
       " -0.32687543675857766,\n",
       " -0.28700886979173923,\n",
       " -0.17496556365252544,\n",
       " -0.4660314406393004,\n",
       " -0.05934170119717261,\n",
       " -0.1676108886417549,\n",
       " -0.40535960359691564,\n",
       " -0.3459125465902333,\n",
       " -0.3841003393497986,\n",
       " -0.4381905217303341,\n",
       " -0.4354287976094863,\n",
       " -0.5261090575267817,\n",
       " -0.06279623383085149,\n",
       " -0.07875826324533854,\n",
       " -0.14389054242978008,\n",
       " -0.4283366950828855,\n",
       " -0.4090955659002118,\n",
       " -0.1897532670776027,\n",
       " -0.04642408003489616,\n",
       " -0.13791147676014964,\n",
       " -0.3361737295474361,\n",
       " -0.21181346574220664,\n",
       " -0.3377477987224337,\n",
       " -0.428523849010643,\n",
       " -0.4504862679479813,\n",
       " -0.38703952086518173,\n",
       " -0.35585374724953206,\n",
       " -0.3960439879827873,\n",
       " -0.2450294712554826,\n",
       " -0.06675898477234596,\n",
       " -0.18720268528854175,\n",
       " -0.35279090211717556,\n",
       " -0.4746223491114029,\n",
       " -0.43470133305181347,\n",
       " -0.4089185063673441,\n",
       " -0.4011900893979822,\n",
       " -0.3606256223378402,\n",
       " -0.46491984195585967,\n",
       " -0.4209188969604302,\n",
       " -0.2922050760529674,\n",
       " -0.2638486293125057,\n",
       " -0.4130677712917243,\n",
       " -0.08210790259654167,\n",
       " -0.35141943949428356,\n",
       " -0.35750594645415334,\n",
       " -0.3311217696942304,\n",
       " -0.2651378938962946,\n",
       " -0.23248221095269997,\n",
       " -0.060938499933042005,\n",
       " -0.3414910076444091,\n",
       " -0.3900620641588028,\n",
       " -0.41826962636114307,\n",
       " -0.39245246359325964,\n",
       " -0.2887978303382513,\n",
       " -0.30499091281711127,\n",
       " -0.3903642445390987,\n",
       " -0.09403024173426391,\n",
       " -0.2929873203687507,\n",
       " -0.12184889760917272,\n",
       " -0.4538963308574472,\n",
       " -0.46758367238764575,\n",
       " -0.3988102936936997,\n",
       " -0.3385924187880569,\n",
       " -0.06943008888961318,\n",
       " -0.04615215083106647,\n",
       " -0.45481157674323824,\n",
       " -0.15579448999207526,\n",
       " -0.18457089274520794,\n",
       " -0.04533589191545155,\n",
       " -0.07017332237703269,\n",
       " -0.3094381048890795,\n",
       " -0.3012423070728523,\n",
       " -0.36051405576568984,\n",
       " -0.3224329012931915,\n",
       " -0.3503701878342477,\n",
       " -0.3748290984169953,\n",
       " -0.333951825465884,\n",
       " -0.37315753949024155,\n",
       " -0.4502554420431104,\n",
       " -0.05102858203537018,\n",
       " -0.3422824820935889,\n",
       " -0.41996570301960096,\n",
       " -0.3650311202801253,\n",
       " -0.42015352263786565,\n",
       " -0.4154579388804094,\n",
       " -0.26432366919406924,\n",
       " -0.35583069203900036,\n",
       " -0.31936065339668956,\n",
       " -0.35293802660954066,\n",
       " -0.13646959216630802,\n",
       " -0.38456162786161296,\n",
       " -0.3829651956554416,\n",
       " -0.4396390988410368,\n",
       " -0.38076178879663497,\n",
       " -0.06332593577258976,\n",
       " -0.05264589527093356,\n",
       " -0.1484966373849027,\n",
       " -0.39748817981679235,\n",
       " -0.24222540751978439,\n",
       " -0.38245446592518795,\n",
       " -0.2561199308626814,\n",
       " -0.3524166057401502,\n",
       " -0.11111582340069012,\n",
       " -0.3818264412632921,\n",
       " -0.16899382561549364,\n",
       " -0.3167302398561186,\n",
       " -0.04723898215815971,\n",
       " -0.35348166715073054,\n",
       " -0.39575351361138544,\n",
       " -0.35973956062778023,\n",
       " -0.3471897676174557,\n",
       " -0.06675898477234596,\n",
       " -0.05318424033384228,\n",
       " -0.21584398152924167,\n",
       " -0.41046460102741433,\n",
       " -0.043700315776953824,\n",
       " -0.3828055788704759,\n",
       " -0.356059072403028,\n",
       " -0.38873147401435243,\n",
       " -0.4772376906820453,\n",
       " -0.38513827101806153,\n",
       " -0.46045036933546124,\n",
       " -0.03821847627814309,\n",
       " -0.29071260289432305,\n",
       " -0.4056145967553682,\n",
       " -0.47462224664649383,\n",
       " -0.5879112579990904,\n",
       " -0.5384207237674405,\n",
       " -0.35139031520095726,\n",
       " -0.089715492266038,\n",
       " -0.09858750970231975,\n",
       " -0.1202001358776956,\n",
       " -0.04342725331373772,\n",
       " -0.29275770366602544,\n",
       " -0.36451018983235595,\n",
       " -0.06912467617241885,\n",
       " -0.161347541308955,\n",
       " -0.39177595578073876,\n",
       " -0.4811331063509223,\n",
       " -0.07382977709008387,\n",
       " -0.28443922644916,\n",
       " -0.07148152971192055,\n",
       " -0.23387251079740637,\n",
       " -0.4306695470319858,\n",
       " -0.4034323210482483,\n",
       " -0.06991127437042033,\n",
       " -0.3957141377608907,\n",
       " -0.4075077043114602,\n",
       " -0.4165525152584507,\n",
       " -0.38536849767693065,\n",
       " -0.10168327291145218,\n",
       " -0.07720599007630023,\n",
       " -0.3836151817605631,\n",
       " -0.37300361148146505,\n",
       " -0.4184334068708839,\n",
       " -0.04669589614591377,\n",
       " -0.30674118860468086,\n",
       " -0.03821847627814309,\n",
       " -0.35149663673506426,\n",
       " -0.43070900089830283,\n",
       " -0.4215144385612082,\n",
       " -0.43189555359560455,\n",
       " -0.43802184184140164,\n",
       " -0.47199374675679295,\n",
       " -0.04615215083106647,\n",
       " -0.20738826268492822,\n",
       " -0.4728166675075697,\n",
       " -0.07148152971192055,\n",
       " -0.4273882583826974,\n",
       " -0.40542663241812066,\n",
       " -0.6815747650673126,\n",
       " -0.6793594266760526,\n",
       " -0.6702501378213871,\n",
       " -0.9708744968845995,\n",
       " -0.6654452747577478,\n",
       " -0.938196738249147,\n",
       " -0.9580903355325405,\n",
       " -0.9577578576785879,\n",
       " -0.8643626043587456,\n",
       " -0.9114729868867933,\n",
       " -0.5506854423058186,\n",
       " -0.8576586358103984,\n",
       " -0.9402191659186343,\n",
       " -0.6102144702162198,\n",
       " -0.8416677851485956,\n",
       " -0.9104754742388288,\n",
       " -0.36262461011013797,\n",
       " -0.8229257122943874,\n",
       " -0.42755693352867064,\n",
       " -0.8455697997088487,\n",
       " -0.7445652060898437,\n",
       " -0.6980823117736943,\n",
       " -0.8176948883545667,\n",
       " -0.7746207148357804,\n",
       " -0.724251152455825,\n",
       " -0.402445292901083,\n",
       " -0.7281228225241313,\n",
       " -0.5622782375822595,\n",
       " -0.31747474631278505,\n",
       " -0.7206729788532162,\n",
       " -0.34580224035484874,\n",
       " -0.37971533180545003,\n",
       " -0.7354840292435221,\n",
       " -0.7829910262295103,\n",
       " -0.6695676402733937,\n",
       " -0.7394148639647411,\n",
       " -0.38144225719487396,\n",
       " -0.7538470402209336,\n",
       " -0.6437339180276771,\n",
       " -0.6661141996636198,\n",
       " -0.6563940810896547,\n",
       " -0.731828491183242,\n",
       " -0.7012052397546609,\n",
       " -0.654962110661705,\n",
       " -0.6713492551969367,\n",
       " -0.2933591734003921,\n",
       " -0.6092198354645683,\n",
       " -0.6149209012569435,\n",
       " -0.3149209177108886,\n",
       " -0.6092738235152497,\n",
       " -0.27820122543114356,\n",
       " -0.6819717665215603,\n",
       " -0.533518192112068,\n",
       " -0.24579146039514255,\n",
       " -0.6873404948534652,\n",
       " -0.6752893173012748,\n",
       " -0.3078094146177025,\n",
       " -0.29047402553760204,\n",
       " -0.5896487821404476,\n",
       " -0.5273558280729409,\n",
       " -0.3516457908799347,\n",
       " -0.6582467517492563,\n",
       " -0.22709352219940415,\n",
       " -0.23932316044194102,\n",
       " -0.7681559117172692,\n",
       " -0.21068792496077543,\n",
       " -0.6932730053821732,\n",
       " -0.5291105238251615,\n",
       " -0.665836306375172,\n",
       " -0.5599211614980428,\n",
       " -0.20371972204052516,\n",
       " -0.6446219097999483,\n",
       " -0.6592402187758111,\n",
       " -0.648151376296673,\n",
       " -0.3388108132143041,\n",
       " -0.6988348165328976,\n",
       " -0.15775119869547027,\n",
       " -0.5668234349900001,\n",
       " -0.19350255364657262,\n",
       " -0.16891051766016316,\n",
       " -0.5145544113478684,\n",
       " -0.5387480327997054,\n",
       " -0.7292511628076168,\n",
       " -0.5736046764291842,\n",
       " -0.5497410162851012,\n",
       " -0.6692926762719151,\n",
       " -0.5082187413189588,\n",
       " -0.5820429110137489,\n",
       " -0.6368526643467436,\n",
       " -0.6997102952937183,\n",
       " -0.601562140384654,\n",
       " -0.3053551301129153,\n",
       " -0.49844058608148273,\n",
       " -0.5074170210036597,\n",
       " -0.1666972131218879,\n",
       " -0.5832579006091099,\n",
       " -0.5491632506411358,\n",
       " -0.6766369262868768,\n",
       " -0.5353340657305993,\n",
       " -0.5213508437040548,\n",
       " -0.4877071949611145,\n",
       " -0.4477346277229326,\n",
       " -0.15887767050693855,\n",
       " -0.6292221668804803,\n",
       " -0.6562511198436748,\n",
       " -0.45278036999282856,\n",
       " -0.6409076775548275,\n",
       " -0.18264480244653283,\n",
       " -0.5387302446993035,\n",
       " -0.4278354608499112,\n",
       " -0.4905255608374218,\n",
       " -0.5300749816447893,\n",
       " -0.6045337106353736,\n",
       " -0.49052108682665024,\n",
       " -0.5063473930313078,\n",
       " -0.13636743174214475,\n",
       " -0.4962262330779898,\n",
       " -0.49531193613181657,\n",
       " -0.4532739689895766,\n",
       " -0.5389398851615257,\n",
       " -0.12691264318506557,\n",
       " -0.5577215750042429,\n",
       " -0.5846421341306858,\n",
       " -0.5560629515617733,\n",
       " -0.1495715672673086,\n",
       " -0.4389691969702445,\n",
       " -0.48966344996944855,\n",
       " -0.6133159858294666,\n",
       " -0.6490224310029695,\n",
       " -0.6477060914016317,\n",
       " -0.4968262187828636,\n",
       " -0.1358984990768957,\n",
       " -0.5783766475954648,\n",
       " -0.15458479423764998,\n",
       " -0.49449908761223704,\n",
       " -0.49205428694801856,\n",
       " -0.1821022379979181,\n",
       " -0.4924218930273815,\n",
       " -0.4315304607496607,\n",
       " -0.5713026174958005,\n",
       " -0.3136254799728858,\n",
       " -0.4372328905305634,\n",
       " -0.1347241907828876,\n",
       " -0.13847325482169903,\n",
       " -0.42908310670311356,\n",
       " -0.6002342570374997,\n",
       " -0.34203853044974164,\n",
       " -0.5858496070168038,\n",
       " -0.48690898617170075,\n",
       " -0.5448364945766968,\n",
       " -0.6217457849835686,\n",
       " -0.6161998952822179,\n",
       " -0.5290561586611491,\n",
       " -0.4962302951190333,\n",
       " -0.17636747181713822,\n",
       " -0.4781065452879275,\n",
       " -0.5207577807720729,\n",
       " -0.5143886598193642,\n",
       " -0.5684418142775783,\n",
       " -0.51896058019604,\n",
       " -0.576971493400057,\n",
       " -0.44438674231753467,\n",
       " -0.4230134655279395,\n",
       " -0.4100723302320348,\n",
       " -0.41514655374362847,\n",
       " -0.5414254928541099,\n",
       " -0.5370184264231308,\n",
       " -0.42368525197069407,\n",
       " -0.16691900876199017,\n",
       " -0.44153815140638336,\n",
       " -0.4226170168841003,\n",
       " -0.39616015965516727,\n",
       " -0.4118720890445036,\n",
       " -0.11560041980248019,\n",
       " -0.4462288132068325,\n",
       " -0.5379424301934372,\n",
       " -0.4318738953884394,\n",
       " -0.46329577318863935,\n",
       " -0.46683251269123893,\n",
       " -0.3014587715862223,\n",
       " -0.42299667258528567,\n",
       " -0.1070316713654737,\n",
       " -0.4989498967570122,\n",
       " -0.1593275007870913,\n",
       " -0.4788534830341597,\n",
       " -0.547676509178096,\n",
       " -0.19033294968199052,\n",
       " -0.43393989683023637,\n",
       " -0.5729055688690656,\n",
       " -0.6286048301779641,\n",
       " -0.4413132458337942,\n",
       " -0.45441715707192637,\n",
       " -0.44016413799121007,\n",
       " -0.17810663213567685,\n",
       " -0.14842589765365075,\n",
       " -0.5033068095458264,\n",
       " -0.49307034407449246,\n",
       " -0.1307135155477237,\n",
       " -0.12691264318506557,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(reward_save)), reward_save)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37ec049ed0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(reward_validation_save)), reward_validation_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(3.2702, grad_fn=<MeanBackward0>),\n",
       " tensor(2.9770, grad_fn=<MeanBackward0>),\n",
       " tensor(2.7793, grad_fn=<MeanBackward0>),\n",
       " tensor(2.4843, grad_fn=<MeanBackward0>),\n",
       " tensor(2.1071, grad_fn=<MeanBackward0>),\n",
       " tensor(1.5442, grad_fn=<MeanBackward0>),\n",
       " tensor(-4.5923, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.8652, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.4988, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.1608, grad_fn=<MeanBackward0>),\n",
       " tensor(1.2864, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.0721, grad_fn=<MeanBackward0>),\n",
       " tensor(1.6967, grad_fn=<MeanBackward0>),\n",
       " tensor(2.4605, grad_fn=<MeanBackward0>),\n",
       " tensor(2.7364, grad_fn=<MeanBackward0>),\n",
       " tensor(3.7283, grad_fn=<MeanBackward0>),\n",
       " tensor(3.8890, grad_fn=<MeanBackward0>),\n",
       " tensor(3.7621, grad_fn=<MeanBackward0>),\n",
       " tensor(2.9361, grad_fn=<MeanBackward0>),\n",
       " tensor(1.7782, grad_fn=<MeanBackward0>),\n",
       " tensor(-7.9244, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6418, grad_fn=<MeanBackward0>),\n",
       " tensor(-11.1273, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.5466, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.7683, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.5853, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.0952, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5925, grad_fn=<MeanBackward0>),\n",
       " tensor(-7.3181, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8046, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9033, grad_fn=<MeanBackward0>),\n",
       " tensor(1.3996, grad_fn=<MeanBackward0>),\n",
       " tensor(1.7005, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.0165, grad_fn=<MeanBackward0>),\n",
       " tensor(1.1385, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8886, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8980, grad_fn=<MeanBackward0>),\n",
       " tensor(-6.4610, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2261, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2613, grad_fn=<MeanBackward0>),\n",
       " tensor(-7.1340, grad_fn=<MeanBackward0>),\n",
       " tensor(-6.2582, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3305, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5371, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2225, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0464, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1049, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.0272, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5778, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3717, grad_fn=<MeanBackward0>),\n",
       " tensor(-4.8602, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0570, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1749, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4446, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5661, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2082, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0286, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0237, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6064, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4614, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1888, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2630, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1458, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1301, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4477, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2360, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3538, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0594, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3788, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4433, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3661, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0474, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1580, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2233, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2705, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4913, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4197, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8920, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1745, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2259, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8839, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4874, grad_fn=<MeanBackward0>),\n",
       " tensor(-5.8424, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2664, grad_fn=<MeanBackward0>),\n",
       " tensor(-4.0400, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3647, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2442, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2409, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6149, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6317, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2615, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2746, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2315, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0016, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0785, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3730, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1191, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0744, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6984, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2977, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2912, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1589, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2407, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1728, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0176, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0922, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7770, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9754, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5491, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1608, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2760, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1516, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1138, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2632, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2649, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4475, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3831, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0383, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4589, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1070, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3622, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2730, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1578, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2449, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1185, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0371, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1275, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2261, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0237, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1226, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4607, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0071, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2410, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5326, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1067, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0872, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1675, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1432, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1268, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0086, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3588, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0372, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0219, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3971, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6977, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6044, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0615, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0824, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0836, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3841, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1076, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3197, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5823, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6539, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2067, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1008, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0019, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9420, grad_fn=<MeanBackward0>),\n",
       " tensor(2.0336, grad_fn=<MeanBackward0>),\n",
       " tensor(2.2483, grad_fn=<MeanBackward0>),\n",
       " tensor(1.5244, grad_fn=<MeanBackward0>),\n",
       " tensor(1.5727, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0872, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0183, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1113, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6060, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5665, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1666, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5482, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6718, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4971, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4940, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0934, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1439, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0719, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4027, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3283, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0189, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0394, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1964, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2353, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0159, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0326, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3578, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4450, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0624, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0301, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2189, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2508, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5100, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6530, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4922, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0258, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4813, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9431, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8965, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8421, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3678, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3574, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6134, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.9150, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5877, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5635, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4128, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5987, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9212, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5501, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0896, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2529, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2099, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3718, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2558, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2261, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2854, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4246, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3673, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0849, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4282, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3343, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0412, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5460, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5823, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5299, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0113, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2394, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0921, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7328, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6763, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4575, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1622, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2071, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7722, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7821, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1048, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2063, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2723, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1382, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2183, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2355, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4621, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2654, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1854, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0287, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9624, grad_fn=<MeanBackward0>),\n",
       " tensor(1.2110, grad_fn=<MeanBackward0>),\n",
       " tensor(1.2359, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2858, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5252, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.1188, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.0512, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.3533, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8867, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4203, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6194, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8384, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7373, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3750, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0831, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.9794, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.7519, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.0354, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.7235, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.5723, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6233, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1481, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0233, grad_fn=<MeanBackward0>),\n",
       " tensor(1.4410, grad_fn=<MeanBackward0>),\n",
       " tensor(1.3674, grad_fn=<MeanBackward0>),\n",
       " tensor(1.2268, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6818, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1991, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.0083, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.3599, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.0343, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.8534, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.2565, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.6799, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8958, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1740, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9370, grad_fn=<MeanBackward0>),\n",
       " tensor(1.6179, grad_fn=<MeanBackward0>),\n",
       " tensor(1.7985, grad_fn=<MeanBackward0>),\n",
       " tensor(1.1498, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5185, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5939, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5822, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.4720, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.4105, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7546, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2742, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5329, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0741, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7618, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1354, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6848, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.9497, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.9863, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7787, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1354, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6576, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1774, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3029, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6362, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7161, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7810, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0204, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3134, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3203, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4455, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2471, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0636, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2964, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1110, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2072, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4238, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3074, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5153, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7055, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1458, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1247, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1333, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2900, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1082, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2104, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5639, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4094, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2703, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5974, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2053, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4445, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1856, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3502, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1012, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5097, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7727, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2584, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2047, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1819, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1504, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0466, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2318, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2603, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5284, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2841, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3694, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5001, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1855, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3066, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5695, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0265, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4118, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2818, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0370, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3221, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0452, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0077, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5248, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2664, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4075, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0006, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1668, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4640, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0161, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0094, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2279, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3394, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2141, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2404, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2400, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2082, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5769, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3902, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3398, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8891, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.3006, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.2845, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8092, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2874, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3049, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6728, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6398, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3779, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6994, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6313, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3835, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4493, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5381, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5805, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2494, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3840, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0525, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4393, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0936, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4720, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8444, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8866, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4147, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0228, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1588, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0351, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6739, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0042, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2568, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1029, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3271, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4928, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3503, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4056, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1185, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0524, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2673, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2313, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4940, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5089, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1377, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8337, grad_fn=<MeanBackward0>),\n",
       " tensor(1.3738, grad_fn=<MeanBackward0>),\n",
       " tensor(1.7037, grad_fn=<MeanBackward0>),\n",
       " tensor(1.5714, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8765, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3459, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8553, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.2497, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.9588, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.6612, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.5995, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4065, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0091, grad_fn=<MeanBackward0>),\n",
       " tensor(1.4481, grad_fn=<MeanBackward0>),\n",
       " tensor(1.7918, grad_fn=<MeanBackward0>),\n",
       " tensor(2.3822, grad_fn=<MeanBackward0>),\n",
       " tensor(2.3531, grad_fn=<MeanBackward0>),\n",
       " tensor(2.4837, grad_fn=<MeanBackward0>),\n",
       " tensor(1.7688, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0005, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2135, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.1377, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.0290, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.2353, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.2721, grad_fn=<MeanBackward0>),\n",
       " tensor(-2.3085, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.7339, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.1456, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3280, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4045, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9768, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9489, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8243, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3681, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.9598, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.2444, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.4080, grad_fn=<MeanBackward0>),\n",
       " tensor(-1.1405, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7640, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1373, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4145, grad_fn=<MeanBackward0>),\n",
       " tensor(1.2848, grad_fn=<MeanBackward0>),\n",
       " tensor(1.1606, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0576, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2848, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3531, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7951, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7920, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6977, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3269, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5716, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9176, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0015, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8852, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4664, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1482, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6812, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7210, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7807, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2100, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1367, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4700, grad_fn=<MeanBackward0>),\n",
       " tensor(0.7490, grad_fn=<MeanBackward0>),\n",
       " tensor(0.5157, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1199, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.5503, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.4486, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.6846, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.3613, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1416, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3274, grad_fn=<MeanBackward0>),\n",
       " tensor(0.4460, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2358, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2382, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2665, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0658, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1958, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.1272, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1129, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2307, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2700, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.2404, grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0852, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2933, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0720, grad_fn=<MeanBackward0>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.loss_actor_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37e0149d50>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5gc1Znu369zmp48mtEoDJIQQiQJBhFNso1JBpzBay+22dXay+7Fa9/rBbxe26xtnK7tdVgvMsuyThdsg7ENmJzBBAESyjnHyaFzOPePqlN9qrp6ZqSZmtFUf7/n0aOeququ0NVvfec93/kOCSHAMAzDuBPPVB8AwzAM4xws8gzDMC6GRZ5hGMbFsMgzDMO4GBZ5hmEYF+Ob6gNQaWpqEh0dHVN9GAzDMNOKN954o1sI0Wy37pgS+Y6ODqxcuXKqD4NhGGZaQUS7Kq1ju4ZhGMbFsMgzDMO4GBZ5hmEYF8MizzAM42IcF3ki8hLRW0T0kNP7YhiGYcxMRiR/M4ANk7AfhmEYxoKjIk9EswBcCeAuJ/fDMAzD2ON0JP8DAF8AUKy0AREtJ6KVRLSyq6vL0YPZ0Z3AE+sPOboPhmGYYwnHRJ6IrgJwWAjxxkjbCSFWCCE6hRCdzc22A7YmjA/f+Rf87c9Xomso4+h+GIZhjhWcjOTPA3A1Ee0EcC+AS4jolw7ub0Sy+aIh7g+/vX+qDoNhGGZScUzkhRC3CiFmCSE6AFwH4GkhxMec2t9obDk8ZLze2ZOcqsNgGIaZVKomT344nTdeDymvGYZh3MykFCgTQjwL4NnJ2FclkrmC8Xo4k5vCI2EYhpk8qiaST2Y0kY+HfBzJMwxTNVSNyCeymrDPiIcwnGGRZximOnCFyO/rT+G+13cjlS1U3CaZUUSeI3mGYaoEV4j86j39+Of712Bb13DFbRL6A6AlHsQgizzDMFWCK0R+QUsMAEYU+WQ2D6+H0BQLcscrwzBVgytEfm5jBB4Cth4eIZLPFBAJeFET9CGdKyJXqFhpgWEYxjW4QuSDPi/mNkZHjeSjAR9iIS1rlH15hmGqAVeIPAAsnBHDuv2DFdcnsgVEgl7UhPwAeEAUwzDVgWtEvnNuA3b1JHF4KG27PpnRIvlIwAsASOUqZ+IwDMO4BfeIfEc9AOCNnX226xNZzZMP6yKfzHIkzzCM+3GNyJ/YFgcRsPHgkO36gWQONSE/wn6O5BmGqR5cI/Ihvxez6yO2na/5QhE7uhOY3xI1RD7NIs8wTBXgGpEHgPnNUWzrSpQt39mTRLZQxMKWGsWuYZFnGMb9uEzkY9jeNYxiUZiWbzmkWTgLZ9SU7BoWeYapCi79/nO4488bpvowpgxXifycxggy+SK6h83T+x0Y0DJuZtWHjUie7RqGcTdCCHz23rew+dAw7nxu+1QfzpThKpGfVR8GAOztT5mWD6a1MgY1IR93vDJMldA9nMWDq7SpPqU2VCOuEvn2uggAYG+fWeSH0nlEA174vB6E/OzJO8Gbu/tw6fefw1Ca6wIxxwZ9yazxWv7uqxFHRZ6IZhPRM0S0nojWEdHNTu6vXX9a77OI/GAqZ4x09XoIQZ+HI/kJ5rYH1mDzoeGKKawMM9n0JjSRn9MQqergw+lIPg/g80KIxQDOBnATES12amexoA91ET/29pkn6h5K5xEPl2Y6DAe8SHMkP6Fs17Oacnku/MYcG0iRn9sYwWCqegc/OiryQogDQog39ddDADYAaHdyn82xIHqGs6Zlg+lSJA8AYb+X7ZoJJqtX9Rys4oiJObaQIt/RGEUqV6jayrOT5skTUQeApQBetSxfTkQriWhlV1fXuPfTEA0YX65kKJ1HPKRE8n4v2zUTiJqyWs0RE3Ns0afYNUD1FiWcFJEnohiA+wF8VghhKhUphFghhOgUQnQ2NzePe1+NsQC6E+YUyrJIPuDlFMoJRH1gDqQ4kmeODXqTWdQEfWiMBQBofXPViOMiT0R+aAL/KyHEA07vr2IkH+ZI3ikSSrE3tmtGRgiBc+94Cne/uGOqD8X19CayqIv6EdcDvGq9N53OriEA/wVggxDie07uS9IQDaI/mUNe99+EEBhM5YwvGgD8Xg+yI3QQ/ub1PXhqwyHHj9UtJDOlB2a1RktjZXt3AvsH0rj9ofVTfSiu4BuPbMBrO3pt1+3vT6GtNowa3aplu8YZzgPwcQCXENEq/d8VTu6wMao1zfqSmtgUigL5ojDlyRIBQti+HQDwhfvfxo3/s9LJw3QVaic22zUj8/K2HgDA8fq8xMzRM5DMYcXz2/HhO/9iu35XTxJzGyKIh/VIvkrvTaeza14UQpAQ4lQhxBL93yNO7rNBF3lp2cg+Qa+HjG2IgEoaP5ypzqf9eFBr8z+4aj/+ogsZU85WvY5Sbdg/ypbMaOzqLRUj7E+aLdpUtoDDQxnMUUWe7Rp3IJtmUqyLeshOJY0HgSAqhPLbR5gnlrEnoUfyUb0u0Ko9/VN5OFPKlkNDhlVoh2zp9FdpVDmR7OwpjYeR9akke/SxMnMaI4YmVGvml+tE3mOouSbiUssJY4vk5aCeaq51caSk9Ej+3uXnwEPlUVW10JvI4t3ffx6fvOf1itsM6r5wf5JFfrzs6i5F8labUIp+e10YsYAPRKjaUa+uFXlp08jRrx41kidCsYLK79OLm7XXsciPlYTe8RoP+zCzLozDQ5lR3uFO9vRq99oLW7pxeNB+rmEjkk9mK7YmmbGh1qiyirxMkQ4HvPB4CDVBn/GAPRL2W4odTkdcKPLa/8WiwHObu/Du7z+vL1cieaBiz2uXLlABn+sujWMk9R9UJOBDc03QuIbTmXSugHte2oH1+wdH31jnwEBJEB5bd9B2G9n5ly8Kw+Zijo7u4YxhxVhFPqNnzwV9moVYE/Ifccfr5kNDOPebT+PO57ZNwNFOHa5TMlIiefUHavLkR7BruvRa9IOpXFkNHMaepN7/EQl40eISkf/Z89vxlT+tx53Pj/0HLi2CsN+LVyuk9Q2mc8a92JeoTltrouhOZDGvWctSsgp4Rg88gnqwFg/7jziS79bv4zv+vHG8hzqluE7kZSRvbQqTJZKv1FKWArV67wDO/9Yz06JJPZDK4St/XDdls13JiDTs96K5JojDQ/ZWxXTizd19AIBMbuz1Tg4MpBHwebB4Zrxs4hrJQCqHufowe2v0uXpPP3Z0l09fydjTM5xBR2MERCNE8n5d5EO+I86uUVtam6ZxdVX3ibzH7Mkby0l9TRAVYvnuIftZpY5l7nlpJ+55eSd++ty2KXkopbJ5hP2a91kfCaA/lZsWD8dK/Oz57Xhmk1ZH6UhSag8MpNFWG0JLTRDdw+VReiZfQDpXxJzGKABzvXMAuOYnL+Hi7z579AfuIt7Y1Yc3dtm3hiS9iSyaY0HEQ/6KnrwcHzOSXZPM5m2Llw1nSts/vOaAad3+/hT+uHr/6CdyDOA+kZeevEVkTJ48AcUKAZrVanh958g32rFATPclf/jUFtz1wuQPl09kC4gGtR9TOOCFEKVIajwIIXD7n9bjuc3lhevyhSIeXXvAkYfJ1x8pzQd6JCLfl8iiIRpAUyxoG8nLFD4ZyXOGTWU+8NOX8YGf2g9yAjRhTmYLaIwFURsuF/mSJy/tGl/FEa/X/uQlnPilR8u+s2FlJHePsk4IgQ/89GX8r//31rSI8F0n8iVP3irypq1s4/h9/SkMWX7UN9+7CgMO/hgfens/Om55eFwWRyRQGs37yNoDI2zpDMlMHpGA9qCJTODMW0OZPO5+aQduuPu1softihe249O/fBOPrZv48hMnt8cBAOfMaywT+XSuYFg5ZcerF8JrimmlNaylM6RdMLdRinwpklcL5lVjSdwfPrUFF3z7GdPAupGQ5cQbY4ERRT7glXaN39auEUJg86Fh5IsCv3tjr2ndsP5QaKsNmT5//0DaaOHf/6b5PccirhN5GbGXBXiWSN4uAvzFX3bB5yEc1xQ1LXdypNx/v7QTALCj6+i9WFVQZ9SExntIR7V/+aCRYj/WH+tIqK2qHz61xbRu62Ft0Fol73s85PICl5/ciln1YSQsIv+jp7fg/f/xMlbatPCGMnnUhHxoqtFGXfdYq6HqQjHbJpLvUTphrdNXTjQ7uxN4eVu3o/s4EhKZPL73xGbs7k1iV09yTOMs5Ij2hkgA9dFAWSd2Jl9A0Ocxgr54yIfhTN5UFhswD5D681pzRlQik4fXQ2iJm0Vezc+X96FECHHMjRNxnchLKR8pkjdH9SX29acwqz5cliNv/ayJJJPXBLpwBPvY05vEMxsPG38nFSGy+rwTwYGBFB5ZU7mFoIp8WP9fjUyPtiV0eFATyXjIh4OWvpFcQbteR5Kh8ujaA7joO8+UfZaVVK6AkN+LaNBnRHOStfu0jK1fvbq77H3D6Txqgj40xYIAgO4h87FJoWiKBRAL+oz6SoDZDtjde3RZXb9+dXeZ6Nhx0XefxUd/9uqo200UQ+mR+2j2KbnoBwfSppGslZAP31jIh6ZYoKwPJJMrGlYNoGXXCAEMW4IP+SAO+73YZ8mmG85oc0PXhs1+vvx+FrXWlOXR/8/LO7Hk9idM5zTVuE7krYOhrMsBbfSrnXALIeAhMqVbasuP7Bh2difGHMmm9eyNIxlyfe1PXsIn73ndiEqSuQL8XsLVp83EwQqDcMbDlx5ch7//1ZsVyxUksnlEg1oEH7bYNc9sOozTbn+8YqXAkZAW1kkza8sGWB3Uc9KPJOp9dlMXdvYk8X8f3zTidlLka0I+JLJ5k0BJD9bOix1K65G8FPlh67wG2nccD/lRG/ajP1USJnU2M/XBdf63nsZdL2wf9dwOD6Vx2+/XYPkvygvrJTJ526qrk2EL7etP4ZSvPI6//Xnlgn9qqvLBwbTpIVepWqzMfInpD9Xu4Yzpe8rkiwgqRQmNcsMWW0e2CBa11aB7OGu6Jtr36S+zg3b1JuHzEE6fW1/2e/vT21owtGbvQMXznWxcJ/JUsePVvI2dcAuhrfNYVF79rFe29yCdKyBfKOKKf38Bf9Yj3E0Hh/C5+1YhVyjiou8+i/f/x8tjOl4ZyR/JQA3ZtJf/p7IFhP1etNWGcGAgfdSdkW/v7bd9r7Sr7nt9j+375P6BUv+AFPlf/mUXAODJoyjdLO2ak9vjGEjljNaBEMKIWPf2V476hBC47fdrcNkPnsehwTR8Xu17faOCpy5J6+cTDfpQFKVJUfb3p4wf9R5L1JcvFJHKFRAL+tGsi3yXReSlUNSG/aiP+k12jfpAkK2xdK6AvX0pfO3hDRiN13fo52Tz1Z/05ceMSo1qC8v6YJGtiVyhiJvvfQtr95mFSh3sZcc9L+3ATb9+07Rss16Q7ckNpZbnH1btw4XfecaIgvcpD+oDA2n0KteiUikCGURFAl40xQLI5IumlEdp10gq1a+RIn9im9YPo1qEiUwesaAPtWHzaNndvUm06y3+/mTOlLosCyGu388i7xiVPPmx1K4RECCiMjtHtgo2HBjEdStewbce3YhEpoD1BwbxmV9pN/UH//NlPPDWPqzRfxgbDw6hYFM7QY3wn1x/CHt6tRv8aHx/+SNJZvPGaNNsvmi6IUezJgAtJ/zlrd24+scvGaVwVQ7pwlZpqL4pktdFXt74Gw5o9saK57fj1e2Vq1PaDfPvGsog4PPg+JYa429A80Gl1THS+W3rGsavX92NjQeHsOL57Yb1sr0rMWJJ5FSugHDAg5h+TvJ9b+3WWjLvPW0mhtJ5kw0lSzuonnxZJK/vMx72oy4cMHm3h5RrK8+tp4IVVSyW+76yM7itzr5PZtWefqSyBWxTCvCpgnbWN57CGV97EgCwbv8g/rBqP277/Rpj/dp9AzjnjqfxG/1B/8ymw0aAIvnKn9bj4bcPmDqr1ZZWrlDEwYE0br53FXb1JLFabxnu7Ush4POgKRbAoYG0qXjbpkND+LtfrCyz5eQ+okEfGqPSHiudTyZXNJUXl5UorQ8Nq8ir38NwJo9o0GtE8vL+7B3WUjdn6tdaffjJ0hbrLCOlB9PlHfGThftEXj+j8sFQyusKVSiLRS3iJ6tfoz8SZBNsy6FhU559oSiM9Kx1SvSzo9vsj/5h1T6c9tXH8bg+5P27im1gFR27G6JYFDg4kEaNLj4lkdc88VpL3ewNBwZx9h1P4Xv6fuweOv3JLN7/Hy/jo3dpHq11XEAmXzBu3O5EFslsvsy2Sdl48jL6HUjljNrpL2zpxuo9/fjlK7tM71+zdwBLbn8CD7y5z7T88FAGzbEgmuNB429Aa00BwDuObyq7brf/aT2+8cgGCCFMPu2BgZRJfNZViLRyhaI2/4DPWxL5jBT5PgR9Hrx78QwA5mhePqRjIR8iAR8iAW+ZJz+YyiHg8yDk9yISME8mv/HgEGbVhzUbRxfwngqdyv98/9tYcvsTpntEbmu9Hup9fuK/PmqyvbqG08Y2ciL2fKFo3Ldv7x3Ak+u1Fpi8Bx5ecwCv7+zFJ//7dXzvic22x6dmQu1VrJdktmDKRtmlrzswkEZrPIS22jAODqZNLZxfvbobj607hKX/9gR29ZQ6POVENZGA15jeT+3otkbypdmhrJ68dq0Xt2mBxKHB0mcMZ/KIhbSZpQpKGQoZ1MyIayIvW3fJbN74/agPt2y+iFO/8ji+8LvVttfLadwn8mPx5EeK5FE5kpfREpH581Vf7m3Fi5MRWSpbwIlfehQ337sKuYIwxF1mWQBmu+auF7Zj4b/8uewHe9eL23H2HU8ZaZ5SbFPZAsIBrxGtyPc9r+eX//DprehNZDH/tkfwi7/sNH2mtZPPGiHu7UsZ59oznMFtD6zBtT95CT98aoshMomMkl3jl9k1mqWVyBZw1akz0RQLoDeZxS0PrMG/PLgWL20tZXes0D3nt/aYbZTDQ2m0xINoqdHtD12gZOR3Snst+pOlCKtnOIO7X9qBFc9vx0tbe4zoLx7yoXs4i8F03khf3Fahg1ItbGUV+UNDGcysC2Oenn2lXju5jXwA2+XKD6ZLM5RFAuYpKDceHMKi1jjqI37jvlHfL1tRmw4O4bd6qt/BgbTxfcn991o6INOWEbvq9yuvp/ow3NGdwMYDpf6Gv/n5Svzujb3YomQz7dI7Rvf2pfDrV3fjZ89r35/MSrvjkQ1GQLFWeZgms3n0DGcRC/rQGA0Yot2byKIxFkBrbQgHB9Lm5AHld6YGAQnDrin1gXQpD9VMvljBrin9pvKFIn67cg/mN0eN36Jqse3tS2FGTdAInuTvShP/UguiL6Etl/dDUyxo6pB9eqP2oKyU7psrFB2tkOlCkdf+L/PklTMlohE9eWskL7fdrz+ld/UkTZ+vNvHWKJH8DXe/hi2HhrB/IGX6Qe/qSUIIgaF0Dmd21GN2Q9i4ge5+cYfhwX7+N6uQzRfxz797G5+7b1XZoKA7n9+Off2pipH8K4o98sYuTUC/9Id1poh+V49V5M03m4xITptdh57hLNbqzdDvPbEZD7y5F8WiQCpXMFInS3ZN3oiaasM+1Ee0NDcpgo+tO4iDA2ms3tNv+OuJTAEPvb0fj+qpbIcHM2ipCaIuYp6IOZHVvNL6SAD5ojAE7tlNpeuzdv+AEaUdP6MGvYkshtN5LGiOIRrwYpuesjqcyeO6FX/Bb1buQSpbML4nmV0jtwG0B0DQ5zHETJ17QLbk5ITxzTU2Ip/KozZcuk4yks/kC9jRncCi1hrURko2jtoSeMe3nwGgTXcnee+PX8SS25/QPlvff0+iZHsVigJDGfP3qfrwUuSlbw4A6w8MGtdG8r9/u9qI2ruHM4aH7iHCbb9fg68/sgFPbzxkdFpuPjSMvmQWT204hJe2lu7BZLagjyXwYW5jBDu7k8YxN0YDaI2HjEg+pJcj2KuI5a6eBG64+zV0D2eQ1PtNvB4yHpxququWXVNu16i26N6+FHb2JPE375iHqEz91T+jL5FF93AGC2fUlERe/20kMnnEAj7UR7XlvXoLQv6WzpnfiKFM3tjXE+u1/ojasN/UIbt23wCGM3ncfO9bOOUrjzs2SnwyJvK+jIg2EdFWIrplEvYHQBN5q0VTem2fJ18UqODJy9r02v97+5KmiECNnjYqWRfJbAHv/+nLpm3nNESQyRfx6NqDpt57+SNV5/58csNhrNrTj/tW7sEDb+0zPGGgNMhjV3cCyVwB4YDPuNl39yaxpzeJnT1JI5qRIg8Az20udYJZI/ndvUn8z8s7yzrFlsyqRSpXgN9bumX8Xo8hiqU8+VLH64DiQdfrE6zLjJK1+wZw9h1P4ZqfvGREdA+u2od/+PVb+PQv3wCgRVUtNSHELZUGkxlthG1dRDtfmb0hH0iN0QC2HBo2IvkFzTH0DGcwrOexz2+JGd70fzyzFa9s78UXfvc2PnnPa0hnNaEK69k1QMmTTyuplTNrQ6Z0RTkEXo4+1tL6yjtepdiE/T6j32IwlUehKDAjHtQj+axx/hI5uGdHd6Ks8uKe3qRxjJl8EclsAQ+8uRfzb3ukLKVyb18KHtJaHIeHMth4cNB0D3QPZ9E1wsC8gVQO23U750/KsP5P3bMShwbTxsQxqWzB+D6+dNViANr3Nqx3ZrbXRwwvuzeRQUNUi+QHUjkcGEhhgW7x7egaBhEwszaEB1ftx3Obu/DQ6v1I6H45AIQC2j2pBlKZfMGoWwPAdp5XeU1rw37Dv5fL5INvwYxYKXhKS5EvIKoHGdrx65G8FPl5jQBKdqoMtg4OpvHeH7+IW+5/G994ZAOu+tGL+PrD6/HImoPGd+MEPkc+VYeIvAB+AuDdAPYCeJ2I/iiEcGwWY7XjVdXxsVWhFJonD/vsmtL/mr8s6TV8vTjWHzB3uAyl86YOrqVz6rC7N4nP/OpNvVMxhlyhXBAkqmWjeriXnjQDD719AAcH00hl82iLh1Cri94tD2gdZjVBH06fU4+/bO8xDd751D1aOtv85igWz6w17e+Pq/fjj6v3498eWo97l5+NvX1aupjsmFI7wPLFYqnZrEe98seSyhWMh1tt2I+GSADbu4cNT/hN5YElz0v9vjL5AvqTOTTXBBEL+uAh5UeWzSMa8BkRPgA8sf6QIZIntsWx9fAQ4mEfYkEf2upC6EvmkC8KxEI+zGuK4vWd2kNPtdde2d5rG8nLc9Q68zTh0B4UpYi3FMlr74kF/UZnrLFNJm88sKRdI4QwxD4S0IRjyyFNRNWouybkQ65QxL7+FM6d32i6/17Z3mPqbzjpy48Zr62lknd0J1Ab9qMxFsQr23vw87/swgkzaoz1A8nsiFVE07kiVu60z07KFQTa64JI9CSRyReM71WWcUhm84bVIW0pIYRu1wTRqnvcmw8N4+rTZmLb4QQG9bEHzTVBoyUd8HmRUEZZy8yutEnkzXaN3+uBz0NlDwJAK33g9RD8XjI+Y7s+4GlBc8z4DQ6kcigWhd6S9MLv9aA27C9F8r3atT1R9/f396dQHwmU5czfq2SpqX0Aq/b0myzcicLpSH4ZgK1CiO1CiCyAewFc4+QOx1K7xlPBrinKFErLVZHbFovAktl1iAV9eFoZjCRtgStPbbM9JlVIls6uM15n80XEw36014Wxv98+eqqUtiYzTg4NZsrsGslQJo+lc7T9rdzVB5+HcNLMuLF+W1fCFI3J9K/GaADRoA+/fnU3dvcmMbMuXNbJBGi1PWQHmIzgvB5C0OdByhLJN8QCuods7z3OU0YZ+zxkCE1LTRBEhLiSqyz7AOoj5vPtHsqiKRbEvOYodnQnjFoycnJ32XKa3RDBwcG03smYwBWntGJBixaxpQxPvjy7Jp0vGA+xuY0RUwRsiLzxsPOYRAfQLKyoYmsVilqHZ0JJB4yHfIY/O5TOoTUewkfPmoOA14N9fSkUigKnzjI/mDceHMJQOodT2s3LgZKVeOP5xwHQRL4+GkBLTRCb9YfJpkNDqIv4UacLrzX108pIA31a9BHXqWzRmDGsXr/+ml2jRfJ1kQAG0zkMpvLIFYRm19SWMoPqI37MbtAGJapjDwDNMkoonf1GYJG1inzJrpHbWR8EQKnmfNDnNfow5H0qyyYAmsgncwUIUWqxNUQDxu9/V08ScxsjxrH2DGeN7K85FcTbp/9eAC2F2QmcFvl2AGpy9V59mQERLSeilUS0squrvBDVkTK2wVD2o1hLg6HsPfmiEAj4PDhvQaPJH//Wo1q96WuWzLQ9pteUKHrJnHrTupqQD221YXQPZ8pS0gAYvqVanwbQopCaoA97+pI4PJRBU00Q0YDXNGE5oHXuSjFsrgnaTmt4/TJNRKRInNRei0sXz8ADb+3Do2sPonNuPU6fWw+f/tmfPK8DgOZNytK49UpUHQv6cHAwbcoLb4gEDEtKPnhkVAsAn75ovvE6XxSGv9miZ9bElSqCMruhzirywxk0xYJojgUxmNYyHeqjATTXlAQiFvRhVn0YhaLAzp4E9vWnsKg1jmuXzMRAKmccc8ivdrxq30s6V0BIF4RY0G9Khx1WRmACWnRpFXnTyGBFmGTEGwn6ENOH3wshkNQLv8WC2jL5UDmlvc70uTu6ExjO5HH6HPNyoJQtJb/33b1J1EfM1wQAmmNB1EcC2NWbRK4gcOUp5oClNuw3HpYA8M5FLQBQ9qCVmVCpXMHwzWXrJpHNY0jvfK7TR6De9qDW6myIBkzlROY2RjG7PmJcU3VEeNdQBkklbdcuSk/qlVFVQn6PqXCeLCMtbZ2Q34O0/htMZPLwkPY9xZW+roSSuimPW9pru3uTmNMQMVrUA6mcEax0WEqlSLZ1DSOTL+Kdi1rwtxfMs91mvEx5x6sQYoUQolMI0dnc3Dzuz6s0GMqk2xUGQxWF9gCwDoaS6ZICWkvhwoUttvturwvjyc9diBUfP8O0XFoldRE/FrfFcfnJrca6eMhv5NuqOd9Sq3fqfvWtV5wIALhE/3Gd3F6LlngQj687hGy+iM659VrEGzI7cE2xoPGDbqkJoi6s/VCvO3O2sc2XrjoRj/3TBcaP7NT2WizWI/58UeB/v+cE1Ib9OHdBEwAtiyLo82BYLyDWUhPEuQsajc97z8mteGTNAcP3jof8aIqVBOKz71qIv7tgHm6/5mTct/xs/OMlC/C+pRZk6CoAACAASURBVO34wUeWGMcl3ysjw7gyICWpR/INUbNQdQ9rD7sm/XxX7elHWzyEE1pLrZd42I9Zuni8qFseHU1RtOgtld369Q77vQj5tWa89NvTil0TCXiRKwijs3EonYPXQ4awhPxepPNFU99PUs+Cku8HpBiWIvmakN8YgCX962jAh0y+aFh685tLgtFeF8amg0PIFQRm1JbnyEuRl4IJaA/k5phF5PUski26F33Zya346tUnAdBaLau/fCm+/5ElxvZfe9/J+OH1S3HH+081f47+uelcQe+Q95pGQctzkp2WD+sjRBuiAcxUyoksO67BsC5iQZ/JzuwaypgyugD5UC2lgXYNZTAjbj5HLVK3t2us67UceR+ItKkDZc1642GuiHzPcBb5QhH7+lKY2xhBTdAHr4fQn8wZx91geRhKpOX3oc7Zxr0+0Tgt8vsAzFb+nqUvc4ySJz/CiFeL5y4RAGDT8frajl6kdf/UQ2Q0I60QERa0xHDpSSURb64Joig0gV31r5ci4PPgpx8rPQRqQn7j5labwdGA5kNLkT9jTj1eu+2d+M+PnYHVX74Ul5/civb6iHETndnRYDp/SWOsFLXNrAsbD79FrSUfNhLw4bimKG48/zjccvkifOai+SZRaNPF4wcfWYJf3ngWPtw5GzUhH97Y1YcXtnTjE+d1mJrGV53ahlxBGJ29tWE/rlnSjhNm1ODdi2fgguObcOsVJ+Lape04a14jPn/pCfB7Pbh2aTvO0x8kMsVRpk+qQ8tlJN+gRJYAsLMniaZYScAy+SIWtMQMTxgAlnU0GFHtW3oKams8ZNhRm3SRC/m9ICJEA17DW5cdr9o1M4/sHdZtCNkKDPk9KBSFUWNH2zZfNp4gmS0Ynx9R0jaH0nm9c9FndDBKwa5VBOPKU9uM+6Ym6MOtly8yXZMD+jrV653XHC2P5GuCqIv4jX00xYKI65lA8nqpLae22jCuPm1m2W+hRYnkZWqvjHqTmbx2nULm/hR1H51ztZbuiW1xnKDfo33JHO5436n4xLkdOHteA7qHM+hPZk32ZEhJST00lEFRwPTQAPRIXkkptdo16no52hXQ5qiQLUkjktdtt4aIllBwYCCNfFFgbkMURGSUrZCRvMy6kpw9r8FoLXlIe6g5hdMi/zqA44noOCIKALgOwB+d3GElu8Y0M1SFKpSaiKPsEfC1hzfg/G89g6LQPt8qpADwDxcvMP1958fPwE8+eroRdTVaIicpXrGQz/Ai1VRMj4cQC/qMHvvGWAAt8RACPq2zh4jwiXPnAgCuPKXN8D2tfm1jNGDk885piOA4/Xjm6Pni6s11cnstPn3hfESDPmO9dr20822IBnD+8U1Gp6QU8Q+doT7HS9H3mn0DiId8CAe8qI8G8Oeb34E7P3aGzWCzErJpvK0rAQ+Vrptq1ySzBeNH1tFo9joXtMSMSB4A5rdE4fGQIa4LZ8TQVqv9+GU+eG3YbzzIfvnKbsysDRmtmpqQ3/DbzSJvrrYpK1BK5Hay+V8sCqRzRYQtnYVa2mYp51vNAhk2RF5bJlt6cUUw1Id1TciPv7uwZHsBpbRfVYxPbKvBeQuasHROHf77E2eiPuJHR2MUdYpozqoPGyUAZtVp11i2AlWsXvOSWXXGtZL2lLz2w5k8EtmCkf6qIltX93xqGV7854vh9ZBxL+/oTuCUWbX4ytUnoTUewv7+FPb3p9GuWI+qPSazWtosIj9aJK969vLaS+JhnzmSl558TLNr5INWHpMWlOTRNZxBPOTDaUpf3PzmKO5dfg5O1u3RxTPjZQHLROJodo0QIk9E/wDgMQBeAHcLIdY5uU+141XVEnPHa4XBUBXsGkCzAmY3hG1r2wDA+cc3mf5+jx7Nv7StG69s78Xitrhp/f2fORffeWwTzuyoN3xetVNSa/prFoXPQ6aOJ8kli2bgDzedh0VtpR/6He8/Fbc88Db+1zuPx7MbD2N2fcQ411kNEVx/5myc2BrHRSc0Y/3t74HP2suso0bydkiRDfk9JisGgBEl9idzJhHyWJtINkiR23p4GA3RoNHHoM7+k8jkEdGj2998+hzcev8aPLXxMFpqgvhI52xT5/B8fQ7Qpz9/EXKFIogIAZ/WBJf9CXURv+lH9onzOgyRjga9RvSWzhcN/9YaycsORUlIyfiIh/w2qabatqlcKZKPBryKyOeM8QBSbA4MpBHwaiNmH7zpPDREAsgps9/ISPv/vOcE/Odz2xDwetCTyKKtNqR5yyHtfjqxLY5FrXH8/u/PAwA89k8XIB7y45v6XKYBnwcz68K47ORW/PKVXfiM3l9Sa2M51IT82PnNK7GzO4GQ32u0FNO5gpba6/ci6PPAQ6URyzUhn+mBol6vWNBnXMeFetaP2upY0BLDg6u0ZIFZyj0a9nuNjlcp8u2WEg+je/Je46FsFXnZkpQPfHmMjdEAcgVhBGPyPpIjlwvFIpprgvjA6e04uT2OB9/ajw93zgIAvOekGdjWNYybLAHiROOoyAOAEOIRAI84vR8DQ+QtKZSmTeyrUBYrdLyW1tvn0QMo6/CUyHx2a8Q5uyGCH16/FECp3IAq8h4i40aaWReu+PlqhAAArbUh3PPJZQCA0/VOXpnl0BAJwOf14GLd15dCY0c44MUFC5tx5Smttuvlsc2Ih8quVzzkQ8DnQTZfLCvbPBoySj04mDY9GFviQfQkskhlC8jki8ZDpqUmhFsuX4SnNh7Gtz94Knxej+mBKFM/Wy1+dUMsYHTu1ob9pvz/s44r9S/ITs9iUSCbLxoPZGuNnuF0hUhez7uXD4OoYdd4jOUppeNVNuuHM3k9H9uLmP5AOziYMiyUJfr3rtZHP1vPz77p4gW46eIFOOsbWi2aSxfPABHh5zeehXte2oEF+oPPuLZ6y0u2ZgJerS9iRjyEJz53obGdzByqCZXfN7JjsU8pmpfW7RoiQk3IbzxUZbbVaPi9HvzixmWm1oLav6ImEah2jcxUky02Y5tRsmu0jCjVrilZkA1R7f6TrW1p78kWyZbDWqtQdk7XRfx4dlMXZtWHMachAiLCotY4brm8dPzzmmP47odOG/U6jJcp73idaCp68qYRr6NVoazw4bqdYxeRVnqPjOjfpdc7sUMbtefDvysTY3io1CS0y4g5EqTPvXBGbJQtzfz8U8vwkTPn2K6TPrG82VWIyPDFKxXMqoTacdwSN0dwhaIwhsmrnW7Hz6jBtm9cgYtO0B5eIb8XHzxjFn72150m8VaREZesJQNotXAAGJ3O2nlqIi8FwdpxanjymbzJd5UdtDIylEJesmt8xnKZQhlWM3oUu0Y+jA/0p01WDaDdi7ddsQjf/sCppoJcQCkHW96DS2bX4QfXLYWvwjW5TE8IqDTlocdD+NH1S/HwP77Ddr123rJDuYhkrpTLPqchYuT2L5xRg3jIj5dvuQRnHddgpHfa8Y7jmzG3sdTRrLYMZ5vsmtLAvKF0Dn4vmSJxeWzp/Ah2jWLnJDIFU8tsRk0QBwfS2NuXQtBXar3Kh5UcdGaki+qts719qYqZNZOF45H8ZFOxCuUotWte3tqNLYeHMK85VlZPXjKSJ2+3DNCGOO+444oRfWhAExO1eJLXU4rkjzQatvKJczvwnpNayzqixkNMFxs7kQdKow+t0dRo1Cu2ySIlapPjAlbodVJilh+wtaUzWoQk+ylU2+DOj5+BvmTO9GCIh/zY318qSxHyWe0a3ZNP50wpgDLil6KRzOVN75P//+DJzbhwYbORySPPqzeZRTZfRCxQsi96ElnbB/7yC+aXLVMZa6fe3MYo/v6i+VhqSfNVee9p9mnCEimY0pOXD8WOpijW7BuAh2AMvppZF8Z9f3fOmI5NMqs+jOvOnI2dPQnMaVCut99rDEpMKX0n1mNTa/kYds0YPPnW2hC6hzPY2Z3ArPqw8XuWkfvWrmHUhHzGvaOOtj2ucWpF3oWRvPb/yBN5a4Nt/uquV4xlH73rVXQPZ02evFU4ijKSt9HrSiIv9zca1omvPURGDvJ4R8ER0YQKPADDSilUmBH9woVaOqw133o0/F6P0Sl98QmllNp5zVF4SBvZWhv2G9Hp0dKoeKeSSMBX9kCti2h13+WP39rxmlIi+ZjSCinNkGW2a+Ry6TNvPDiEvmTW+DwZqR/SO0yjikcNlDqmx8Kv/uYs/OfHzqgYudvxhcsWGVU2jwaPh4yBYKlswZjzV9qVsxsixjU4GogI3/zAqbh3+TkIKCNaVU8+nSuU5cgD9naN10PG9Qmqdk3W3McyIx5CUWhpubMs6agAsKc3ZRpH8N0PnWYEi+3jbImPF9eJfKl2jWW5zWtZPEn1NVVPvlzktXfb+eOVPPOxYp1L1OMB/uWqxfi3a0/G9cvsLZOp5FPnd+DaJTNxwzkdtuu/+YFTsO6r7zmqpuqKv+7E+5a244y5pYgy5Pcazfb3ntZmiviPBtnMto4SLttOH+wiRdqaQplQRd7U8Wqup2L47kaHrg9ffq9W06VrKGN8XjSoDWiTA59iQR9mN0SMvoUj4bwFTYYFM5mE/Jo/rtXl185LduR/8PRZjuwzrFgxKaUFYT4uS8erpRxxyO9FJq+lSg+nLZG83mI9PJQxZSo164MQAbMGzIiH8PVrTwEAo9T2VOFCu0b7vzxP3mzXqKiTFKievM9DUAu3CiOSLxf0MQTrI2KN5L2kZdR8/Oy54/tghwj6vPjBdUtHXB88yrtryew6LFEG3kiaY0Hs6E6gYwKavzP0SNquE1GlPhJAUZSmIpTirVbbLOjpkVGlIztotWuU+jQS+VA4NJgx3uvzetDRGMFKPT01FtIG1nzz/afgmp+8ZDsnwLGGTGdU7Zprls5ESzyIC44f/4BHO0IBL1J6J3eqQiRfnkJprm8T0ssapHIF5IvCdG+oHffvW1oatB/ye7HirzvxV3e9WhboXb9sNt61uMWxQU5jxYUib1+FcqTBUGpBJnWOV69FuQtF+zlggfFH8lbGkm5Ybfh92jUZbx8FoI0wDPq9RgZSJWQH7QE9YyNosWuSSsdpVMnGsE5oLr17NcKUIr+3L4lFSqS+qDWOh/VpJWVn+Wmz6/DzTy2bkAec04T9XvQmtJmQpP0U9HmNjnGn9imvccoyK5Qk5PeaBkNppaO9ynrNZpIpmDOV/qQTWmvwiXM70NEYwRlzzX0c5y1owr3LzzbZNYDmKky1wAMutGvUwVDmKpSVI3lV5NU8eK/XRuQ99oI+kic/Fv7nU8tMf1sfMAzw7hM1r3he8/ibv9GgD9cvm2OMqqyEtIVkOeS4UpsG0ETeKNJWIU8eKE0PqD4I5PaD6bypA1g9pnlNpXO9YGGzaZDasUpN2G+kFLbUlI/vcIKWmqBRr17O0Wsl6PMgWygaraGMMu4B0L4ztW6S2snt93rwlatPwifOs88EOnteI46fMfK9NFW4TuTHUrvGKshyGjRtu1L2TFkkL4Rpvcp4Rf7Chc2mm2q8n+dGbji3Ay/+88WjCvNE0qB3rP3w6a0ASjnlXr2DUZbPBcxpnSEjy6RU2wYwj1ZVO2rVkgFX6dVMrzy1bVq26NriIaXA3OREsjKxYH9/2tQXoCIfvHJGM21ikZIEylabnLdhqjtMJwrX2jUy59263A5TJI/S+6w/sHxBVBwROxG/RdOo3Gn443YaIjJlNkwGspCWRB19KUseSJug0ohXQBsR61XKK1i3V2u5zGuOYdPXLrMdyzEdUP3ryYrkSyKfqujJG2MX9IeA1vFa2k5OVPLs5sPwe48Nq2UicF0kb6RQFoVpsm2TJ6+8FkKU2TXSs/fZplAe2YjXI0H9jCPIemMcxPpDV71erUxATonky0VeHaCjFjADUDZsXiXo89r6ytOBmXWTL/LtSpG/VNY+Tz5s+U5SOXN2jRT5tfsGRxxlPt1wnZSMyZNXOl6LorzjVX631ohd63itFMmP/4aoNF0hM3UEfB688IWLbdcZkbzut6uRuddDCHg9il2TL8vkiQXs7ZrpjjoAzlqIzClaaoLwewn7+lN6IblyaZOzl8l05f5kztSCaowGjLEpcvCdG3CdyKuevJpGWSnTRghhmgmHULJKfHYdr2SfJz8R9spIaZ7M1FEpm6dGL/hVmgLRHD0GldmhBtP5snKzaiesXYXH6Yoc+dsQDUya7ejxkDFZfKXBULIWjWx59eoTiEuICKfoVTRPaJ3a3PaJxHWePOkpjkIICKF43BUEVMCaXVM5hTJfFKb1KhPjyY//M5iJx+MhLG6LmwZnAdro0319KSNzxlpqQQ6uATS7xhrJqyNR3RTJn9xeiwdvOs+wPyYLWSmyUsdrLKhd40RGG/DUl8yWDapb2BLD85u7yiakmc64TuQBOb2fedSr2ZMv/SGENkN9aV3JKrFG7IWilntvO+J1AkJvzqg5dnnk5vKiXLJ0b8ImuwYwD7UfTOfLSt+qHM2I1mOZJbPLpyJ0mnjYjy59whA7Tz5qRPI5DGVKc8uq/MMlCzCUzjs2MncqcKXIe0grJaymUVrneJUs/Jc/W95beiDYiXzlEa8s8tWG5snnlIm4rZG8x5RCWRMq93l/dP1SzG6IODppRLVQG/Zjsz6zl71dU5qzV5ZEtkbydZEAvvXBU8veO51xscjbz/4EoHzqJ9MqJU/eKvLC2RGvajnk6Zo+V03EQ9rcq2v2DqCtNlR2D6ilbe06XoHRqzoyY6c27MfePm20qjX1FSiJfCKTR48u8tZI3o24ruMVkKWEhcWusffnJTL/2eMx165RKeievJ01M9F58syxj+xIfWrjYWOCdZWQT7NrikWh15t3ZUx1zCBHI89riuIKm+qnUSOSz1eM5N2IK0XeQwQhzKNeTZOG2LxHlkIllKpQWjMDRkyhnACVH6n0AnPsoXaWnr+gqWx9KOBFOl/EUForYjZZ6YTVihxrcMbcetMgJ0nQ54HPQxjO5I3a8w1V8J04JvJE9B0i2khEbxPR74lo0npiPCQHQ6nLKgvotz5wiiGwRMqI1wrVJu1nhpoIT770mu2aYx91kpD5NpkkIZ8HmVwBvUndGhjDlHfM0SN/MuqMYipE2mxRCVXkq+A7cTKSfwLAyUKIUwFsBnCrg/syIT15NZJXJdg60GjJ7HpDYEeqXSM/23bE6wSIPBclm17MVwqlzbGZ2EVOUiEFhSN5Z+nWx7vYTXovkXP29iazCHg9Ri14N+OYyAshHhdCyJkwXgEwaTlJRHIwlLpM9eTLt5fCbpr5yTYf3n4w1EToM3vy0wu7qpMqYb8XO3uSeGFLFwBwBo3DfLhzNjyEEWcNiwV9GE7n0TucRUM0MCFZccc6k9UT9CkA99mtIKLlAJYDwJw5EzMDksdDEEJYZnwy7dR8DMoi7TUZr8uP116MJyK7xlTWwP33nit472kzK2ZxyaH1P3hSm6CdI3lnWTqnHtvvuHLEbVriQezuTWJWfbgqOl2BcYo8ET0JwO6x+UUhxB/0bb4IIA/gV3afIYRYAWAFAHR2dk6IE12ya8zLjOO2bK9aNOqI1ko1auxHvE5snjx78tODH11feXYsa98NR/JTz9I59fjx01sghLmiqJsZl8gLId410noi+gSAqwC8U1RMWp94PLpdU6xQu8aqx1pna6nj1bBubMwsQiWvftyHbbs/ZvqijqQO+jxlI2KZyeeMufUoCmDToSEsnMR5CaYSJ7NrLgPwBQBXCyGSTu2nwr7LBkOZI/lyu8boeEXlKpSAFp3xiFdmLBwaKE1GUy3+77HO2fMacM68RgBA2KZSpRtx0pP/MYAggCf0m/sVIcSnHdyfgUcWKFPEvFIVSm1dSfYr5cGrn+NUZT0WeXdxRkc9XtvZC4D9+GOFoM+LX9y4DPet3INz55ePbXAjjom8EGKBU589GqPWriHr9lA8edi+Z6RlEwVXoXQXn3v3QhzoT+HBVftth9kzU4PP68FfnTV3qg9j0nBle8Wu49XsyVvtGmWUK1WuXaOtn/jjLX02q7yb8Hs9OKFVqy4Z9nNJA2ZqcKXIA+WThoxqwZDNa7ttHZyxied1dR9ysu6Aj79bZmpwpch7PFoKYrFYWjaaDWPkyRMZYmvXUeakDrMMuA9Z8tbPk/YyU4Qr7zytQNkRePJKxgyhJLZ2wb+TGRLs1riPgh5p+Dg/lpkiXHnn2XrysH8t//YonnzJn7f/7MnAXF6Nma4U9Nak3cTSDDMZuLI3yKhdg7FF8mrlSXUw1GR3vDLu49qlM/HGrj7807sXTvWhMFWKK0Ve1pMXFcsajJxdU6pj40whskqo+3Oyg5eZPCIBH/7vh0+b6sNgqhhXtiFtyxqok4bYVqG0+aBJ9uQZhmEmGpeKvBwMVVpmLkJpieSPkcFQKuzJMwwzEbhS5InKJw0ZsQol7CtP2ne8TuSRMgzDOIsrRd6oXTPGFEpTJG/6nKmL5NmTZxhmInCpyMsqlKVlI9kwam68OurU1qZ3suNV+Wy2axiGmQhcKvJHVk9erVdDKD0c7DpZueOVYZjphCtFvuTJl5aNPDNUacIOVcTtRqKzJ88wzHTClSI/midfPsdrKU/etJmNYcOVIhmGmU64VOTLUyg9JvG2QIonP4KtY10/0fDzg2GYicaVIk+kVaA0e/JqaqRZTU2ThoCMTk9b0WUlZhhmGuG4yBPR54lIENGkzbVFNpG8eX359qV5XU1ryt7rbKlhfoAwDDOxOCryRDQbwKUAdju5HyseAgTME3mbjsvmbyPSHyVSZ0+eYZjphNOR/PcBfAGY3KRvWU++gsbbDoYqvXe0zx7fsTEMw0wmjok8EV0DYJ8QYvUo2y0nopVEtLKrq2tC9l2qJ18pkrd68pWqP5a/39E8eeWjT2qrdW4/DMNUDeMqNUxETwJotVn1RQC3QbNqRkQIsQLACgDo7OyckIhf1pOvKPK21SUrrzNtN85jGws3nDMXt15x4iTsiWEYtzMukRdCvMtuORGdAuA4AKv1yHcWgDeJaJkQ4uB49jkW7GaGshyf5W/1vaY1tp/tNKfPrUdInxuUYRhmPDgyaYgQYg2AFvk3Ee0E0CmE6HZif1bsBkOp2FahhBwMNUrH6yQknXLpBIZhJgpX5snbDYZSKa9dU3md3WczDMNMFyZl+j8hRMdk7EdCRCgWK6dQllWhtHS8VsrKsW470fDjg2GYicalkTyObDCUsmy0qJ6FmGGY6YRLRV6zaypF8lZGKkNs99kMwzDTBVeKvN/nQa4wUiQ/sl0zEpMxGGqsDyeGYZjRcKXIh3wepHOFEQZDjcxIEuuoJ8+tBIZhJhh3irzfq4u8/Xo7y8W24KTte8d1aAzDMJOKK0U+HPAilStUzpMfQahHm1vVLtqe3xw9ouNjGIaZLCYlhXKy0eya4lHbNSNhjeQ3/ttl3BnLMMwxiysj+aBeEiCdK9quH02TT2ytAQCc2dFQts4q6CG/FwHfxFxG+cnc78owzEThykg+rIt8MpsHAJw0M25ab2e5yEVCAJ0dDXjl1neitTaEz963yna71257JxLZwoQeNzcIGIaZaFwp8rK412Aqj/ctbcf3P7LEtH4sWtpaG7JdLiP5lrj9eoZhmGMJV9o1Ib92WtlCEe114bL19pH82MJojrYZhplOuFTkS2V65zREytaPr+OVVZ5hmOmDK0U+rIj8bDuRHzGFcmQmQ+NHS+NkGIYZK64U+aC/dFqzG8rtmrEOhrLDyUie2wgMw0w0rhR5adf4PIS22nKRH4+asl3DMMx0wpUiL+2aWfVheG3qEIxHplnjGYaZTrhS5GUkb+fHAyNn0ow2EGlyqlA6vw+GYaoDR0WeiP6RiDYS0Toi+raT+1KRKZSVRN5WqMco3lyFkmGY6YRjIk9EFwO4BsBpQoiTAHzXqX1ZiQV98BAwr8m+cNhoNeNHwklP/vKTWwEAp86qc2wfDMNUF06OeP0MgG8KITIAIIQ47OC+TNSE/Lh3+Tk4uT1uu348Ou2kXXPpSa3Y+c0rndsBwzBVh5N2zUIA7yCiV4noOSI6024jIlpORCuJaGVXV9eE7XzZcQ2IBOyfYSPp9KilhjnRkWGYacS4InkiehJAq82qL+qf3QDgbABnAvgNEc0TliLvQogVAFYAQGdn5+R0OdpO0E368YzyVtZ4hmGmEeMSeSHEuyqtI6LPAHhAF/XXiKgIoAnAxIXrR8l4fHXOk2cYZjrhpF3zIICLAYCIFgIIAOh2cH9jhvPkGYapFpzseL0bwN1EtBZAFsANVqtmqhipnvxoqHVxGIZhjnUcE3khRBbAx5z6/KkiFnJlCX6GYVyKK0e8Hg1jdWFiQRZ5hmGmD1Up8kfiGq3+8qV4+yuXGn8HJ2g+V4ZhmMmAw9JRqA37TX9z6QGGYaYTVRmWjhTHHyN9wwzDMBNCVYq8HRygMwzjRljkGYZhXExVijw7MgzDVAtVKfIjwQ8AhmHcRFWKvF2lSaNA2WQfDMMwjINUpcgfLdcumTnVh8AwDHNEcJ78GNlxxxVTfQgMwzBHTHWKvI0nUx8NACgf/CThQVAMw0xHqlLk7Xz3G86Zi0jAiw93zp7042EYhnGKqhR5O3xeD65fNmeqD4NhGGZC4Y5XhmEYF8MizzAM42KqUuR5wBPDMNVCdYo8D3liGKZKcEzkiWgJEb1CRKuIaCURLXNqXwzDMIw9Tkby3wbwVSHEEgD/qv99TBDlKfwYhqkSnBR5ASCuv64FsN/BfR0Rp8+px62XL5rqw2AYhnEcJ0X+swC+Q0R7AHwXwK12GxHRct3OWdnV1eXg4Zh539L2SdsXwzDMVDEu34KIngTQarPqiwDeCeCfhBD3E9GHAfwXgHdZNxRCrACwAgA6OzsnrUeUyxQwDFMNjEvkhRBloi0hop8DuFn/87cA7hrPviYa1niGYaoBJ+2a/QAu1F9fAmCLg/s6YljjGYapBpxMM/lbAP9ORD4AaQDLHdzXEcN2DcMwR7/p9AAABpdJREFU1YBjIi+EeBHAGU59/nhhiWcYphqoyhGvAHvyDMNUB9Ur8hzLMwxTBVStyLPGMwxTDVStyHtY5BmGqQKqVuQ5u4ZhmGqgekV+qg+AYRhmEqhekWeVZximCqhekedYnmGYKqB6RZ41nmGYKqBqRZ5hGKYaqFqR50ieYZhqoGpF3sMqzzBMFVC1Is8SzzBMNVC9Is+RPMMwVUD1ivxUHwDDMMwkUL0izyrPMEwVUMUizyrPMIz7GZfIE9GHiGgdERWJqNOy7lYi2kpEm4joPeM7TIZhGOZoGO/0f2sBvB/AnepCIloM4DoAJwGYCeBJIloohCiMc38MwzDMETCuSF4IsUEIsclm1TUA7hVCZIQQOwBsBbBsPPtiGIZhjhynPPl2AHuUv/fqy8ogouVEtJKIVnZ1dTl0OAzDMNXJqHYNET0JoNVm1ReFEH8Y7wEIIVYAWAEAnZ2dYryfxzAMw5QYVeSFEO86is/dB2C28vcsfRnDMAwziThl1/wRwHVEFCSi4wAcD+A1h/bFMAzDVGC8KZTvI6K9AM4B8DARPQYAQoh1AH4DYD2ARwHcxJk1DMMwk8+4UiiFEL8H8PsK674O4Ovj+XyGYRhmfFTtiFeGYZhqgEWeYRjGxbDIMwzDuBgWeYZhGBfDIs8wDONiWOQZhmFcDIs8wzCMi2GRZxiGcTEs8gzDMC5mvJOGTGu+8b5TcGJbzVQfBsMwjGNUtch/9Kw5U30IDMMwjsJ2DcMwjIthkWcYhnExLPIMwzAuhkWeYRjGxbDIMwzDuBgWeYZhGBfDIs8wDONiWOQZhmFcDAkhpvoYDIioC8Cuo3x7E4DuCTyc6QCfc3XA51wdjOec5wohmu1WHFMiPx6IaKUQonOqj2My4XOuDvicqwOnzpntGoZhGBfDIs8wDONi3CTyK6b6AKYAPufqgM+5OnDknF3jyTMMwzDluCmSZxiGYSywyDMMw7gYV4g8EV1GRJuIaCsR3TLVxzNRENHdRHSYiNYqyxqI6Aki2qL/X68vJyL6oX4N3iai06fuyI8eIppNRM8Q0XoiWkdEN+vLXXveRBQioteIaLV+zl/Vlx9HRK/q53YfEQX05UH97636+o6pPP6jhYi8RPQWET2k/+3q8wUAItpJRGuIaBURrdSXOXpvT3uRJyIvgJ8AuBzAYgDXE9HiqT2qCeMeAJdZlt0C4CkhxPEAntL/BrTzP17/txzATyfpGCeaPIDPCyEWAzgbwE369+nm884AuEQIcRqAJQAuI6KzAXwLwPeFEAsA9AG4Ud/+RgB9+vLv69tNR24GsEH52+3nK7lYCLFEyYl39t4WQkzrfwDOAfCY8vetAG6d6uOawPPrALBW+XsTgDb9dRuATfrrOwFcb7fddP4H4A8A3l0t5w0gAuBNAGdBG/3o05cb9zmAxwCco7/26dvRVB/7EZ7nLF3QLgHwEABy8/kq570TQJNlmaP39rSP5AG0A9ij/L1XX+ZWZgghDuivDwKYob923XXQm+VLAbwKl5+3bl2sAnAYwBMAtgHoF0Lk9U3U8zLOWV8/AKBxco943PwAwBcAFPW/G+Hu85UIAI8T0RtEtFxf5ui9XdUTeU93hBCCiFyZA0tEMQD3A/isEGKQiIx1bjxvIUQBwBIiqgPwewCLpviQHIOIrgJwWAjxBhFdNNXHM8mcL4TYR0QtAJ4goo3qSifubTdE8vsAzFb+nqUvcyuHiKgNAPT/D+vLXXMdiMgPTeB/JYR4QF/s+vMGACFEP4BnoNkVdUQkAzH1vIxz1tfXAuiZ5EMdD+cBuJqIdgK4F5pl8+9w7/kaCCH26f8fhvYwXwaH7203iPzrAI7Xe+YDAK4D8McpPiYn+SOAG/TXN0DzrOXyv9Z75M8GMKA0AacNpIXs/wVggxDie8oq1543ETXrETyIKAytD2IDNLH/oL6Z9ZzltfgggKeFbtpOB4QQtwohZgkhOqD9Xp8WQvwVXHq+EiKKElGNfA3gUgBr4fS9PdUdERPUmXEFgM3QfMwvTvXxTOB5/T8ABwDkoPlxN0LzIp8CsAXAkwAa9G0JWpbRNgBrAHRO9fEf5TmfD823fBvAKv3fFW4+bwCnAnhLP+e1AP5VXz4PwGsAtgL4LYCgvjyk/71VXz9vqs9hHOd+EYCHquF89fNbrf9bJ7XK6XubyxowDMO4GDfYNQzDMEwFWOQZhmFcDIs8wzCMi2GRZxiGcTEs8gzDMC6GRZ5hGMbFsMgzDMO4mP8P3p1Wf9gWfSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(trainer.loss_actor_save)), trainer.loss_actor_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37e013aa90>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcBklEQVR4nO3df5Ac5X3n8fd3Zne1+gkSWmQFsOUQ3TmkKpGdLULKrjscXxKMk2BXuVxwKVtJkZL/wFV2xVUpyP1wUjmuSCW273wXU8EHMYkdO6RsFypMbINMLnY5BlYYywKBWYxkJCR2EZLQj/05880f3TPTM9Mzs7vTs8M8/XlVraanu2f26d3Zzzz6ztNPm7sjIiJhKfS7ASIikj2Fu4hIgBTuIiIBUriLiARI4S4iEqChfjcAYOvWrb5jx45+N0NEZKDs37//FXcfS9v2ugj3HTt2MDEx0e9miIgMFDM70mqbyjIiIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISoFyG+3eem+bIyfP9boaISM+8Lk5iWm0fvPsxAA7f8Z4+t0REpDdy2XMXEQmdwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQlQx3A3syvM7BEze9rMnjKzj8br/8TMjpnZk/HX9YnH3GZmk2b2rJn9Zi8PQEREmi1l+oFF4OPu/oSZbQT2m9lD8bZPu/tfJnc2s6uAG4FfAH4GeNjM/p27l7JsuIiItNax5+7ux939iXj5LHAIuKzNQ24Avuzuc+7+AjAJXJ1FY0VEZGmWVXM3sx3AW4FH41UfMbMDZnaPmW2O110GvJh42FHavxmIiEjGlhzuZrYB+ArwMXd/DbgTuBLYBRwHPrmcb2xme8xswswmpqenl/NQERHpYEnhbmbDRMH+RXf/KoC7v+zuJXcvA5+jVno5BlyRePjl8bo67n6Xu4+7+/jY2Fg3xyAiIg2WMlrGgLuBQ+7+qcT67Ynd3gccjJf3Ajea2RozezOwE3gsuyaLiEgnSxkt83bgg8CPzOzJeN0fAzeZ2S7AgcPAhwHc/Skzuw94mmikzS0aKSMisro6hru7fxewlE0PtnnM7cDtXbRLRES6oDNURUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQClLtwd/d+N0FEpOdyGO79boGISO/lL9z73QARkVWQv3BX111EciB34S4ikge5C3f120UkD3IX7qWy4l1EwpercH/p9Axv+W/f6HczRER6Llfh/vz0uX43QURkVeQq3EVE8kLhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISoI7hbmZXmNkjZva0mT1lZh+N128xs4fM7Ln4dnO83szsM2Y2aWYHzOxtvT4IERGpt5Se+yLwcXe/CrgGuMXMrgJuBfa5+05gX3wf4N3AzvhrD3Bn5q0WEZG2Ooa7ux939yfi5bPAIeAy4Abg3ni3e4H3xss3AH/rke8DF5vZ9sxbLiIiLS2r5m5mO4C3Ao8C29z9eLzpBLAtXr4MeDHxsKPxOhERWSVLDncz2wB8BfiYu7+W3ObRhUmXdRUMM9tjZhNmNjE9Pb2ch4qISAdLCnczGyYK9i+6+1fj1S9Xyi3x7VS8/hhwReLhl8fr6rj7Xe4+7u7jY2NjK22/iIikWMpoGQPuBg65+6cSm/YCu+Pl3cD9ifUfikfNXAOcSZRvRERkFQwtYZ+3Ax8EfmRmT8br/hi4A7jPzG4GjgAfiLc9CFwPTAIXgN/PtMUiItJRx3B39+8C1mLzu1L2d+CWLtslIiJd0BmqIiIBUriLiARI4S4iEiCFu4hIgBTuIiIByn24nzw3x+57HuPV8/P9boqISGZyH+6f/95h/v+Pp/nC94/0uykiIpnJfbiLiIRI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiAQoV+Huy7qEt4jI4MpXuPe7ASIiqyRf4a6uu4jkRL7Cvd8NEBFZJbkKd6W7iORFrsLdle4ikhP5Cndlu4jkhMJdRCRA+Qr3fjdARGSV5Cvc1XUXkZzIV7j3uwEiIqskX+GudBeRnOgY7mZ2j5lNmdnBxLo/MbNjZvZk/HV9YtttZjZpZs+a2W/2quEro3QXkXxYSs/988B1Kes/7e674q8HAczsKuBG4Bfix3zWzIpZNbZb6rmLSF50DHd3/xfg1SU+3w3Al919zt1fACaBq7toX6aU7SKSF93U3D9iZgfiss3meN1lwIuJfY7G65qY2R4zmzCzienp6S6asXTquYtIXqw03O8ErgR2AceBTy73Cdz9Lncfd/fxsbGxFTZjmd9TfXcRyYkVhbu7v+zuJXcvA5+jVno5BlyR2PXyeN3rgnruIpIXKwp3M9ueuPs+oDKSZi9wo5mtMbM3AzuBx7prYnaU7SKSF0OddjCzLwHXAlvN7CjwCeBaM9tFlJeHgQ8DuPtTZnYf8DSwCNzi7qXeNH35dIaqiORFx3B395tSVt/dZv/bgdu7aZSIiHRHZ6iKiAQoX+GuqruI5ES+wl3ZLiI5oXAXEQlQvsK93w0QEVkluQp3EZG8yFW4a5y7iORFvsK93w0QEVkluQp3pbuI5EWuwl3j3EUkL/IV7sp2EcmJfIX7Mvb9xP0Huf3rT/esLSIivRRcuL90eoYvfP9I6siY5fTc7/3XI3zuOy9k2DIRkdXTcVbIQfM/HzzEAweO8/PbN/LLb9pSt001dxHJi+B67utHoverBw4cb9rWqefu7vzzs1OUynoTEJHBFly4L8bBPHV2rmlbp8h++NAUv/c3j/P/vvOTHrRMRGT1BBfupy/MAy3ORu3QdT/x2iwAP331QubtEhFZTcGF+6lquDdvU7FFRPIiuHA/fWEBgHKXo2VERAZZcOFe6bmnfSa6konDPvmtZ/nOc9PdNktEZFUFNRSyXHbOzEQ999Rx7it4zv/z7UkADt/xnm6aJiKyqoLquZ+dW6z22FfweaqISDCCCvfZhVJ1ObXmvpqNERHpo6DCfWY+Ge7N29vV3NWrF5GQBBXus4vte+7taGoCEQlJUOGe7LkfPTXDD356qm57u7xXz11EQhJUuM8ulKvLL7xynvd99nt129N655VQ75TtZc03IyIDJLBwj3ruI8X0w0o/a7XN8JqEs7OLXbVNRGQ1dQx3M7vHzKbM7GBi3RYze8jMnotvN8frzcw+Y2aTZnbAzN7Wy8Y3qoT72pFi6va0+F5qz70yfl5EZBAspef+eeC6hnW3AvvcfSewL74P8G5gZ/y1B7gzm2YuzUwc7utbhXub+WY61dzPz6vnLiKDo2O4u/u/AK82rL4BuDdevhd4b2L933rk+8DFZrY9q8Z2Uqm5t+65Nyd4ZVRNp9E1+sBVRAbJSmvu29y9cjWME8C2ePky4MXEfkfjdU3MbI+ZTZjZxPR0NnO3zHQqy6TWZepuWlru0EoRkX7q+gNVj84MWnbyuftd7j7u7uNjY2PdNgOo1dzXjSx9ypyllmWU7SIySFYa7i9Xyi3x7VS8/hhwRWK/y+N1q2JuoYQZjA6n99zTVM5a7XQSU0npLiIDZKXhvhfYHS/vBu5PrP9QPGrmGuBMonzTczMLJUaHihQsfXvqTJHVrnv751ZZRkQGScf6hZl9CbgW2GpmR4FPAHcA95nZzcAR4APx7g8C1wOTwAXg93vQ5pZmF8qMDhcoWHq6tx0t0+G5VzIXvIhIv3QMd3e/qcWmd6Xs68At3TZqpWYWSqwdbtNzT1tXPYepfXjrBFURGSTBnaE6OlzEltFzrw2FbP/cmn5ARAZJUOG+UCozXCzQouPe9kPTTlUXZbuIDJKgwr3sUCjY8mruydEybed7V7qLyOAIK9zLTsGg0OKo2pzDpJ67iAQlrHB3p1gwrFVhpt1QSIAWPf7Kc4uIDIrAwh3MrC6jk+WUxnh292odvvNoGYW7iAyOwMI9Lssk0j1ZTmnMZ0+U2T2xQ7shkyIigyC4cC+a1Y1zL9f13OsT2qmFf6eeuXruIjJIwgr3ctRrt7qeeyLcm3rutTnPktvSKu/6QFVEBklQ4V5yx4yGmntiOeUxybJMu/xWz11EBklQ4e7xaJnCUnvuiXXutbNQ098EFO4iMjiCCveyR2WZ+pp7bbmp5u7JdV7dNy3IS+WMGysi0kNBhXupHJdlSO+5N3bJHa/rubc7oUllGREZJEGFe7UskzgqT/S4O52hWp2KQOEuIgMuqHCvlGVaj5ZpLsskL5BdWU676pKyXUQGSVDhXqrMLdNqnHuHC2SXvfV+led55dwcL756IZsGi4j0yNKvJD0AojNUraHmXtvePP1AY1mmsl9zuleeZ/x/PAzA4Tvek1GrRUSyF1TP3VNGy3ibnnv0gWptyt+yau4iEoigwr3kTqFAQ829tj2tR+6JBU/U35v2U7iLyAAJKtwrZZkln8TUMHFYbZ6ZtOfOuLEiIj0UVLhXyjLW4gPVpv2pHy3T7mLZvSzL7D9yih23fp3jZ2Z69j1EJF+CCve00TLtMjmaz722X/uae3btbPR3/3oYgO9NnuzdNxGRXAkq3MvuTddQbTvOvfpPZZ6ZeJx7SpKr5i4igySocK+UZWg5t0zKYxJXYqrsu5gS7uWGdX9w7+P8+Tee6bbJQO0D4DZX+RMRWZagwr1WllnZB6qVoE+rrzfm/cOHprjzn5/PpN2V/xX84X0/5IuPHsnkOUUk34IK98oFsluOc2+eOawW+F4L8LSyzGqNc//SYz9dle8jImELLNyjEseSr6FK4gLZiZOYVjvcTfUYEclYYOEelWWsYV1F2vQD1bHt5Vr4p4d7tm2tb0eH+W9ERJapq7llzOwwcBYoAYvuPm5mW4B/AHYAh4EPuPup7pq5NJULZNedoZqc8jclOJPzyVRHy6zyOHcRkaxl0XN/p7vvcvfx+P6twD533wnsi++viuhiHa2HQjb23T35b4eaey+zPflmpAqNiGShF2WZG4B74+V7gff24HukSp84LH05uu91o2Xa1tw1/4CIDJBuw92Bb5nZfjPbE6/b5u7H4+UTwLa0B5rZHjObMLOJ6enpLpsRiUbL0HL6gdQLZCe2VbYvZSikiMjrWbfzub/D3Y+Z2aXAQ2ZWd1aPu7uZpcaiu98F3AUwPj6eSXRG49zbXIkp7QLZibGQleXFkmruIjLYuuq5u/ux+HYK+BpwNfCymW0HiG+num3k0tuzvKGQUN9zb19zV7iLyOBYcbib2Xoz21hZBn4DOAjsBXbHu+0G7u+2kUtVKcu0PompXjS2vfbYdtdQVVlGRAZJN2WZbcDX4hLIEPD37v4NM3scuM/MbgaOAB/ovplLU6pcZi8Z7ontTZmdKMvUzefexzNURUSysOJwd/efAL+Usv4k8K5uGrXC9iRGyyTHubepudc9vrYmdeIwZbuIDJBgzlCtdKybP1BN7tT8mLqhkPEJT6q5i8igCybcK3XyxukH2tXco3XJKX/7M7eMiEjWggn3SvgWClYX4vWjZRrLMl5Xh68s6gNVERl0wYR7siyT1GnisNp1UxPXU01J8rTefFY0cZiIZC2YcK+Eb6FhbpZOZ6imXSA77QNV1dxFZJAEE+6VkC4WrGVPOL3mXtuvXc+9l2UZTRwmIlkLKNyj28YLX7S9QLZ74gLZtZ77ak/5q/8ViEjWwgn3lmWZ2nJqzb1uyt/249wVwiIyKMIJ90RZJm09kFqXqbtAdoe5ZTRiRkQGRUDhHt02lmXaXSA7UZWJL5Ddfpx7r0bMpExCKSLSlYDCfQllmZQQrTyuccx70lDBKHvv6u6l5LUARUQyEFy4F9t8oNooGejtwrtYsJY99yyu0NTLMfQikk8BhXt023wSU225+TJ7yaGQrWvqQwXDPX0UTdq65Sqp4y4iGQsn3ONkNmu8bmqHWSETU/62Gg1T7bmnFMez6HWrLCMiWQsn3JcwWib1AtmJba1iuhjX3FN77lmEu6oyIpKxgMI9um0qyyQ6xalnqCaGQrauuReiKzWlBHnamPjlyqJuLyKSFEy4lxJlmaROc8tU++4da+6efuZqBsG8mHgHUoVGRLIQTLh7oiyTrK3X53HzOPdKmLY7A7VYMMrl9BJMNj33xLLOghWRDAQT7q1Hy7SbTjdRc283zr1olNxTe9VZhHHyfwRZvFmIiAQT7q2n/K0tp84tUxkt02Gce6uyTBZhnHwOjXkXkSwEE+61M1SXPitkUttwt3i0TNpFPDIY6lJWuItIxoIJ9+SVmFqPc294DI2jZdKfuzLOPS38szmJSeEuItkKJtyrF8huOKLOZ6hWyjKtB7oPFdv03DMY3qJwF5GsBRPuSyrLNDym8UPUduPcvcXcMllMHaAPVEUka8GEu7cM9+Z9avfrr6HauubeevtiBj33+pq7BrqLSPeCCfdKD7pgVtdD73T1pOT0A21r7i3GuWeRxRotIyJZCybcyy1r7u3mliFxDdXWc8sUrPUHqln03FVzF5GsDXS4uzsnzswCyWuotinLNM0KmZw4zFv28isjcNLq61mEcVk1dxHJWM/C3cyuM7NnzWzSzG7txff4p4Mn+A9/8Qh/9cgkc3HyNg6F7NRzr57EROsPVAuF1pfZyyLck4Gu6QdEJAtDvXhSMysCfwX8OnAUeNzM9rr701l+n/E3beY//fyl/MU3n2XjaHQoxYa3q71PvsTk1DnWjRT53vMn67Y1XUO1RYWlXVkmk557eXB77rMLJS7Ml9iyfqTfTVlVswsl5ktlNowMUWg4LbpUdl46PcORkxfYuW0Dl25c0/Lavo3rZfnKZefVC/NsGh1mZCga2TZ9bo7ps3NsWT/CGzaNAvDa7CLTZ2e5aO0IWzeMBP+z70m4A1cDk+7+EwAz+zJwA5BpuF+6aZTP/u4v88gzU/zZ15/m7Owim0aH2bJ+uLrPMyfOcvTUTNNskQC//X+/W11+4eT5lt+nYMaBo2e45e+faNr24S/sZ3S4SMFql/irnBzVbr6aZHtevTBfXXaHf/9f/4mRYoE1w8XqfpbyOIvXNu4Tras/4LrHVfdv/qHUxv03X/Qk+eFz5d6p8wtRyK0ZYjRurzV8j2T7ku2qrrfmY1mOZHsg+n0VLHrGurJbyv6VYzSLzjY+O7dIsWDVtka5HT1TZXK5ssOZmYXq4zaMDDE8VGChVGbNUJGFUrm6Haj+bE5fmGftSJH1I0OcujDPYtnZsGaI9SNFIBoSWypHzzlUsHjai+g5yl57LRXjbcn1leMrmFEopP9uk5pfV1Z336n/X23jzyztteEedU7cnXVrihQtmpOpVIp+ZpVpPBr/PmonE0b3o+MvVI9zsVSm5I4RPd9iqcxi2VksRf+bXiiXq+3ZvG6YC/Ml5hZrPbWNo0MslMrMLtTWbRodYmSoQKnsLJaj5ym7Mzoc/X5KZWdmoVR9PRes8jqOXhOF+LXR6Q3CrHYBoWSlwOLfU8GM/3z1G/nwf7yy7fOsRK/C/TLgxcT9o8CvJHcwsz3AHoA3vvGNXX2zd77lUt6xcyuTU+fYuW0jV45tYKhQYPtFo4yOFLlq+yaGCsa+Z6aYXShx8tw8MwvRC+D0hXnecNEoL52eYdPoMDsuWc/Bl86waXSY8/OLvGnLOn7u0o38zMVrKZedtSNF1sZ/jEb0R172qPdQGa9eCbdKsDX+/uv/MGBkqMCVY+tZLDvPnDjLptFhHE+8GD31cdGWlG0t9kluTIZe0xtBYqE5nCvL0fqL1g1zyfoRjp+ZjdtbC6GmQKB5PV7flpUyq8VZqWH65uQbo6XsT/zHVzBj4+hQLTDjYyk78R9ydNwFgy3r17BupMjZuUXOzi6wUCozVCgwu1DCzHjLGzZyyYYRps/OcfiV88yXyly8boTzc4vMzJe4eF3Uyzw3u8j5+RIQBXr0u6gFF3GQJH/2pXI0ZNas8U2o/bWAK5KhHd2n4b4nnrv2M2z8maW9NoaKBQy4MF+i7E7RooA2o/rGlf73YdVtDtUAL5edoWKBokWzvRYLBYYKxlDRGC5GbwDDBWPz+hFem1lk+twsa4eLXL55Hds2rWH67Bw/fvkca4YKvOGiUcY2ruHV8/P8ZPo8Jffqm2jlZz+7UOL8XImhgjE6XKh7IyonAtq989np5fhF7w3HW/mZe1wN2H7x2rbPs1LWzR9Uyyc1ez9wnbv/QXz/g8CvuPtH0vYfHx/3iYmJzNshIhIyM9vv7uNp23r1geox4IrE/cvjdSIisgp6Fe6PAzvN7M1mNgLcCOzt0fcSEZEGPam5u/uimX0E+CZQBO5x96d68b1ERKRZrz5Qxd0fBB7s1fOLiEhrA32GqoiIpFO4i4gESOEuIhIghbuISIB6chLTshthNg0cWeHDtwKvZNicQaBjzgcdcz50c8xvcvextA2vi3DvhplNtDpDK1Q65nzQMedDr45ZZRkRkQAp3EVEAhRCuN/V7wb0gY45H3TM+dCTYx74mruIiDQLoecuIiINFO4iIgEa6HBfjYtw94OZ3WNmU2Z2MLFui5k9ZGbPxbeb4/VmZp+JfwYHzOxt/Wv5ypnZFWb2iJk9bWZPmdlH4/XBHreZjZrZY2b2w/iY/zRe/2YzezQ+tn+Ip83GzNbE9yfj7Tv62f6VMrOimf3AzB6I7wd9vABmdtjMfmRmT5rZRLyup6/tgQ33xEW43w1cBdxkZlf1t1WZ+TxwXcO6W4F97r4T2Bffh+j4d8Zfe4A7V6mNWVsEPu7uVwHXALfEv8+Qj3sO+DV3/yVgF3CdmV0D/DnwaXf/OeAUcHO8/83AqXj9p+P9BtFHgUOJ+6Efb8U73X1XYkx7b1/b0fUAB+8L+FXgm4n7twG39btdGR7fDuBg4v6zwPZ4eTvwbLz818BNafsN8hdwP/DreTluYB3wBNG1hl8BhuL11dc50fURfjVeHor3s363fZnHeXkcZL8GPEB02dRgjzdx3IeBrQ3revraHtieO+kX4b6sT21ZDdvc/Xi8fALYFi8H93OI//v9VuBRAj/uuETxJDAFPAQ8D5x298V4l+RxVY853n4GuGR1W9y1/wX8EVC5+vslhH28FQ58y8z2m9meeF1PX9s9u1iH9I67u5kFOYbVzDYAXwE+5u6vWeVy8YR53O5eAnaZ2cXA14C39LlJPWNmvwVMuft+M7u23+1ZZe9w92NmdinwkJk9k9zYi9f2IPfc83YR7pfNbDtAfDsVrw/m52Bmw0TB/kV3/2q8OvjjBnD308AjRGWJi82s0vFKHlf1mOPtFwEnV7mp3Xg78Dtmdhj4MlFp5n8T7vFWufux+HaK6E38anr82h7kcM/bRbj3Arvj5d1ENenK+g/Fn7BfA5xJ/FdvYFjURb8bOOTun0psCva4zWws7rFjZmuJPmM4RBTy7493azzmys/i/cC3PS7KDgJ3v83dL3f3HUR/r992998l0OOtMLP1Zraxsgz8BnCQXr+2+/1BQ5cfUlwP/JioTvlf+t2eDI/rS8BxYIGo3nYzUa1xH/Ac8DCwJd7XiEYNPQ/8CBjvd/tXeMzvIKpLHgCejL+uD/m4gV8EfhAf80Hgv8frfxZ4DJgE/hFYE68fje9Pxtt/tt/H0MWxXws8kIfjjY/vh/HXU5Ws6vVrW9MPiIgEaJDLMiIi0oLCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQAp3EZEA/RshXovf10QEFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(trainer.loss_critic_save)), trainer.loss_critic_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
